{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SEL-NNML Tuning - Kaggle Heart Failure Prediction Dataset**\n",
    "\n",
    "This notebook implements several tuning methods on the `Stacking Ensemble Learning with a Neural Network Meta-Learner (SEL-NNML)` model using the `Kaggle Heart Failure Prediction Dataset (KHFPD)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Global Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global configuration loaded successfully!\n",
      "Random State: 42\n",
      "Test Size: 0.2\n",
      "CV Folds: 5\n",
      "Optimization Iterations: 100\n",
      "Optimization Metric: accuracy\n",
      "Optimization Direction: maximize\n",
      "Skip Training: False\n"
     ]
    }
   ],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Data splitting configuration\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Cross-validation configuration\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "OPTIMIZATION_ITERATIONS = 100\n",
    "OPTIMIZATION_METRIC = 'accuracy'\n",
    "OPTIMIZATION_DIRECTION='maximize'\n",
    "\n",
    "# Parallel processing configuration\n",
    "N_JOBS = -1 \n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_PATH = '../datasets/processed/ds1_kaggle_heart_clean.csv'\n",
    "TARGET_COLUMN = 'HeartDisease'\n",
    "\n",
    "# Training configuration\n",
    "SKIP_TRAINING = False  # Set to True to load pre-existing models instead of training\n",
    "\n",
    "print('Global configuration loaded successfully!')\n",
    "print(f'Random State: {RANDOM_STATE}')\n",
    "print(f'Test Size: {TEST_SIZE}')\n",
    "print(f'CV Folds: {CV_FOLDS}')\n",
    "print(f'Optimization Iterations: {OPTIMIZATION_ITERATIONS}')\n",
    "print(f'Optimization Metric: {OPTIMIZATION_METRIC}')\n",
    "print(f'Optimization Direction: {OPTIMIZATION_DIRECTION}')\n",
    "print(f'Skip Training: {SKIP_TRAINING}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src import base_model_tuning, meta_model_tuning\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 746 entries, 0 to 745\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                746 non-null    int64  \n",
      " 1   Sex                746 non-null    bool   \n",
      " 2   RestingBP          746 non-null    int64  \n",
      " 3   Cholesterol        746 non-null    int64  \n",
      " 4   FastingBS          746 non-null    bool   \n",
      " 5   MaxHR              746 non-null    int64  \n",
      " 6   ExerciseAngina     746 non-null    bool   \n",
      " 7   Oldpeak            746 non-null    float64\n",
      " 8   HeartDisease       746 non-null    bool   \n",
      " 9   ChestPainType_ASY  746 non-null    bool   \n",
      " 10  ChestPainType_ATA  746 non-null    bool   \n",
      " 11  ChestPainType_NAP  746 non-null    bool   \n",
      " 12  ChestPainType_TA   746 non-null    bool   \n",
      " 13  RestingECG_LVH     746 non-null    bool   \n",
      " 14  RestingECG_Normal  746 non-null    bool   \n",
      " 15  RestingECG_ST      746 non-null    bool   \n",
      " 16  ST_Slope_Down      746 non-null    bool   \n",
      " 17  ST_Slope_Flat      746 non-null    bool   \n",
      " 18  ST_Slope_Up        746 non-null    bool   \n",
      "dtypes: bool(14), float64(1), int64(4)\n",
      "memory usage: 39.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ST_Slope_Down</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>False</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>156</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>False</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>False</td>\n",
       "      <td>122</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>False</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>True</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>3.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>False</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>False</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age    Sex  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  \\\n",
       "0     40   True        140          289      False    172           False   \n",
       "1     49  False        160          180      False    156           False   \n",
       "2     37   True        130          283      False     98           False   \n",
       "3     48  False        138          214      False    108            True   \n",
       "4     54   True        150          195      False    122           False   \n",
       "..   ...    ...        ...          ...        ...    ...             ...   \n",
       "741   45   True        110          264      False    132           False   \n",
       "742   68   True        144          193       True    141           False   \n",
       "743   57   True        130          131      False    115            True   \n",
       "744   57  False        130          236      False    174           False   \n",
       "745   38   True        138          175      False    173           False   \n",
       "\n",
       "     Oldpeak  HeartDisease  ChestPainType_ASY  ChestPainType_ATA  \\\n",
       "0        0.0         False              False               True   \n",
       "1        1.0          True              False              False   \n",
       "2        0.0         False              False               True   \n",
       "3        1.5          True               True              False   \n",
       "4        0.0         False              False              False   \n",
       "..       ...           ...                ...                ...   \n",
       "741      1.2          True              False              False   \n",
       "742      3.4          True               True              False   \n",
       "743      1.2          True               True              False   \n",
       "744      0.0          True              False               True   \n",
       "745      0.0         False              False              False   \n",
       "\n",
       "     ChestPainType_NAP  ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  \\\n",
       "0                False             False           False               True   \n",
       "1                 True             False           False               True   \n",
       "2                False             False           False              False   \n",
       "3                False             False           False               True   \n",
       "4                 True             False           False               True   \n",
       "..                 ...               ...             ...                ...   \n",
       "741              False              True           False               True   \n",
       "742              False             False           False               True   \n",
       "743              False             False           False               True   \n",
       "744              False             False            True              False   \n",
       "745               True             False           False               True   \n",
       "\n",
       "     RestingECG_ST  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
       "0            False          False          False         True  \n",
       "1            False          False           True        False  \n",
       "2             True          False          False         True  \n",
       "3            False          False           True        False  \n",
       "4            False          False          False         True  \n",
       "..             ...            ...            ...          ...  \n",
       "741          False          False           True        False  \n",
       "742          False          False           True        False  \n",
       "743          False          False           True        False  \n",
       "744          False          False           True        False  \n",
       "745          False          False          False         True  \n",
       "\n",
       "[746 rows x 19 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into desired training and testing\n",
    "- After that, Scaling the data using Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Min-Max Scaler function for this dataset to ../artifacts/ds1/models/min_max_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "# Separate numeric and boolean columns\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "bool_cols = X_train.select_dtypes(include=['bool', 'uint8']).columns  # includes one-hot from get_dummies\n",
    "\n",
    "# Initialize scaler and fit_transform only on numeric data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "# Concatenate back with boolean features (without modification)\n",
    "X_train = pd.concat([X_train_scaled, X_train[bool_cols]], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test[bool_cols]], axis=1)\n",
    "\n",
    "# Save Min-Max Scaler\n",
    "scaler_filename = '../artifacts/ds1/models/min_max_scaler.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f'Saved Min-Max Scaler function for this dataset to {scaler_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Default Base Models (Baseline)**\n",
    "\n",
    "Create base models with default parameters as a baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training default base models...\n",
      "Default Base Models Training Time: 0.52 seconds\n",
      "Default Base Models Training Time: 0.52 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    default_models_training_start = time.time()\n",
    "    \n",
    "    # Initialize base models with default parameters\n",
    "    default_logistic_regression = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    default_decision_tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    default_random_forest = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    default_knn = KNeighborsClassifier(n_jobs=N_JOBS)\n",
    "    default_svc = SVC(random_state=RANDOM_STATE, probability=True)  # probability=True for predict_proba\n",
    "    default_adaboost = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "    default_gradient_boosting = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Fit all default models\n",
    "    print(\"Training default base models...\")\n",
    "    default_logistic_regression.fit(X_train, y_train)\n",
    "    default_decision_tree.fit(X_train, y_train)\n",
    "    default_random_forest.fit(X_train, y_train)\n",
    "    default_knn.fit(X_train, y_train)\n",
    "    default_svc.fit(X_train, y_train)\n",
    "    default_adaboost.fit(X_train, y_train)\n",
    "    default_gradient_boosting.fit(X_train, y_train)\n",
    "    \n",
    "    default_models_training_end = time.time()\n",
    "    default_models_training_time = default_models_training_end - default_models_training_start\n",
    "    \n",
    "    print(f'Default Base Models Training Time: {default_models_training_time:.2f} seconds')\n",
    "    \n",
    "    # Store in dictionary\n",
    "    default_base_models = {\n",
    "        'Logistic Regression': default_logistic_regression,\n",
    "        'Decision Tree': default_decision_tree,\n",
    "        'Random Forest': default_random_forest,\n",
    "        'K-Nearest Neighbors': default_knn,\n",
    "        'Support Vector Machine': default_svc,\n",
    "        'AdaBoost': default_adaboost,\n",
    "        'Gradient Boosting': default_gradient_boosting\n",
    "    }\n",
    "else:\n",
    "    print(\"Skipping default base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Stacking with Default Base Models + Linear Regression**\n",
    "\n",
    "Create a stacking ensemble using default base learners with Linear Regression as the meta-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking model with Linear Regression meta-learner...\n",
      "Stacking + Linear Regression Training Time: 2.84 seconds\n",
      "Stacking + Linear Regression Training Time: 2.84 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    stack_lr_training_start = time.time()\n",
    "    \n",
    "    # Create stacking ensemble with Linear Regression as meta-learner\n",
    "    base_estimators = [\n",
    "        ('Logistic Regression', default_logistic_regression),\n",
    "        ('Decision Tree', default_decision_tree),\n",
    "        ('Random Forest', default_random_forest),\n",
    "        ('K-Nearest Neighbors', default_knn),\n",
    "        ('Support Vector Machine', default_svc),\n",
    "        ('AdaBoost', default_adaboost),\n",
    "        ('Gradient Boosting', default_gradient_boosting)\n",
    "    ]\n",
    "    \n",
    "    # Linear Regression meta-learner (using LogisticRegression for classification)\n",
    "    meta_lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    \n",
    "    stacking_lr = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_lr,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    print(\"Training Stacking model with Linear Regression meta-learner...\")\n",
    "    stacking_lr.fit(X_train, y_train)\n",
    "    \n",
    "    stack_lr_training_end = time.time()\n",
    "    stack_lr_training_time = stack_lr_training_end - stack_lr_training_start\n",
    "    \n",
    "    print(f'Stacking + Linear Regression Training Time: {stack_lr_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping Stacking + LR training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Stacking with Default Base Models + Default MLP**\n",
    "\n",
    "Create a stacking ensemble using default base learners with a default MLP (Multi-Layer Perceptron) as the meta-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking model with default MLP meta-learner...\n",
      "Stacking + Default MLP Training Time: 1.15 seconds\n",
      "Stacking + Default MLP Training Time: 1.15 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    stack_mlp_training_start = time.time()\n",
    "    \n",
    "    # Create stacking ensemble with default MLP as meta-learner\n",
    "    # Using default MLP with just random_state for reproducibility\n",
    "    meta_mlp = MLPClassifier(random_state=RANDOM_STATE, max_iter=300)\n",
    "    \n",
    "    stacking_mlp = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_mlp,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    print(\"Training Stacking model with default MLP meta-learner...\")\n",
    "    stacking_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    stack_mlp_training_end = time.time()\n",
    "    stack_mlp_training_time = stack_mlp_training_end - stack_mlp_training_start\n",
    "    \n",
    "    print(f'Stacking + Default MLP Training Time: {stack_mlp_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping Stacking + MLP training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Base Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Set `SKIP_TRAINING = True` in the global configuration to skip steps 4 and 5 and load pre-existing models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,100] A new study created in memory with name: Logistic Regression Model Fine Tuning with TPESampler\n",
      "Best trial: 4. Best value: 0.843908:   6%|▌         | 6/100 [00:00<00:02, 40.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,126] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:25:55,150] Trial 1 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-11-06 03:25:55,174] Trial 2 finished with value: 0.5704481792717087 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-11-06 03:25:55,199] Trial 3 finished with value: 0.8288375350140056 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-11-06 03:25:55,223] Trial 4 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:25:55,247] Trial 5 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:25:55,282] Trial 6 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.843908:   7%|▋         | 7/100 [00:00<00:02, 40.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,306] Trial 7 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.84563:  14%|█▍        | 14/100 [00:00<00:02, 35.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,330] Trial 8 finished with value: 0.8087254901960785 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:25:55,355] Trial 9 finished with value: 0.5888795518207283 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:25:55,392] Trial 10 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.23114272501983432}. Best is trial 10 with value: 0.8439495798319328.\n",
      "[I 2025-11-06 03:25:55,430] Trial 11 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.15812151458626894}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:25:55,456] Trial 12 finished with value: 0.8422689075630252 and parameters: {'solver': 'lbfgs', 'C': 0.2826411346239431}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:25:55,482] Trial 13 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.22334872496479957}. Best is trial 11 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.84563:  14%|█▍        | 14/100 [00:00<00:02, 35.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,508] Trial 14 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 2.79098579692265}. Best is trial 11 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847269:  22%|██▏       | 22/100 [00:00<00:02, 37.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,534] Trial 15 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.08051559097588631}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:25:55,559] Trial 16 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.0697350521837258}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:25:55,585] Trial 17 finished with value: 0.83890756302521 and parameters: {'solver': 'sag', 'C': 1.3579090291127154}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:25:55,611] Trial 18 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.051197944989624766}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,637] Trial 19 finished with value: 0.8405602240896359 and parameters: {'solver': 'newton-cholesky', 'C': 0.008669040269005453}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,663] Trial 20 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.8998683788955593}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,688] Trial 21 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.048720630498620646}. Best is trial 18 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847269:  22%|██▏       | 22/100 [00:00<00:02, 37.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,714] Trial 22 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.08004964515949366}. Best is trial 18 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847269:  30%|███       | 30/100 [00:00<00:01, 37.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,740] Trial 23 finished with value: 0.8304901960784313 and parameters: {'solver': 'lbfgs', 'C': 0.007375728907568315}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,766] Trial 24 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.1121745944965221}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,792] Trial 25 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.032428127512365235}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,818] Trial 26 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.6910214262026088}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,844] Trial 27 finished with value: 0.8439495798319328 and parameters: {'solver': 'sag', 'C': 0.11333540081021493}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,870] Trial 28 finished with value: 0.8304901960784313 and parameters: {'solver': 'lbfgs', 'C': 0.006548996783712982}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,896] Trial 29 finished with value: 0.84390756302521 and parameters: {'solver': 'newton-cg', 'C': 0.02156627449426617}. Best is trial 18 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847269:  30%|███       | 30/100 [00:00<00:01, 37.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,922] Trial 30 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 0.5728845685542986}. Best is trial 18 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847269:  38%|███▊      | 38/100 [00:01<00:01, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:55,948] Trial 31 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.061712088176031694}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:55,975] Trial 32 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1262642748705284}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:56,002] Trial 33 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.035109862732477626}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:56,027] Trial 34 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.3835045307309365}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:56,053] Trial 35 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 1.7618478700595461}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:56,078] Trial 36 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.16285844385179687}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:25:56,104] Trial 37 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.01372963989786973}. Best is trial 18 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847269:  38%|███▊      | 38/100 [00:01<00:01, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,130] Trial 38 finished with value: 0.8305182072829131 and parameters: {'solver': 'lbfgs', 'C': 0.0030410067875272263}. Best is trial 18 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  46%|████▌     | 46/100 [00:01<00:01, 38.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,155] Trial 39 finished with value: 0.8489495798319329 and parameters: {'solver': 'newton-cg', 'C': 0.05856966305534113}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,181] Trial 40 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.02845165810479552}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,207] Trial 41 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.04768319394347644}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,232] Trial 42 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.10096174908404337}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,258] Trial 43 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06921802568515421}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,283] Trial 44 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 0.3970896440591376}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,309] Trial 45 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.1703981162451707}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  46%|████▌     | 46/100 [00:01<00:01, 38.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,334] Trial 46 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00021618818013690103}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  54%|█████▍    | 54/100 [00:01<00:01, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,360] Trial 47 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 0.014579010740313215}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,385] Trial 48 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.21828528522579935}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,411] Trial 49 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.04657721498227121}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,436] Trial 50 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.022902951698565554}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,462] Trial 51 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cholesky', 'C': 0.09731474393794935}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,488] Trial 52 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.07214026929869125}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,524] Trial 53 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cholesky', 'C': 0.31808075912658296}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  54%|█████▍    | 54/100 [00:01<00:01, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,550] Trial 54 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 0.011622799886819657}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  62%|██████▏   | 62/100 [00:01<00:00, 38.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,576] Trial 55 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.07312656232811188}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,601] Trial 56 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.0381551221442807}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,627] Trial 57 finished with value: 0.8321848739495797 and parameters: {'solver': 'lbfgs', 'C': 0.003923855267960684}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,653] Trial 58 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 8.064276941408533}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,679] Trial 59 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03791621774817249}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,704] Trial 60 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.03383766483232433}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,730] Trial 61 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.04837022121925017}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  62%|██████▏   | 62/100 [00:01<00:00, 38.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,756] Trial 62 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.14990407553147933}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  70%|███████   | 70/100 [00:01<00:00, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,782] Trial 63 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.020280185040408252}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,808] Trial 64 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.15729553484021594}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,833] Trial 65 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.1649766208187189}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,859] Trial 66 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 0.5774556008496657}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,885] Trial 67 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.2490275872874681}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,911] Trial 68 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.1646985429222083}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:56,936] Trial 69 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 1.0908336922463593}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  70%|███████   | 70/100 [00:01<00:00, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,962] Trial 70 finished with value: 0.8405602240896359 and parameters: {'solver': 'lbfgs', 'C': 0.009756665159036369}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  78%|███████▊  | 78/100 [00:02<00:00, 38.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:56,988] Trial 71 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.2735543395700848}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,014] Trial 72 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.1415139420071471}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,040] Trial 73 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 0.41742037788882863}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,065] Trial 74 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03733329128405272}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,091] Trial 75 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03869645307868557}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,117] Trial 76 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.02670737351395773}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,143] Trial 77 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.025293525506976892}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  78%|███████▊  | 78/100 [00:02<00:00, 38.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,169] Trial 78 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026728604297654224}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  86%|████████▌ | 86/100 [00:02<00:00, 38.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,196] Trial 79 finished with value: 0.8321708683473389 and parameters: {'solver': 'sag', 'C': 0.005678286963186669}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,222] Trial 80 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.01628463082294873}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,248] Trial 81 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.027002765082027362}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,273] Trial 82 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.03920263854915853}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,299] Trial 83 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.025816750619589275}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,325] Trial 84 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.058005808362322546}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,353] Trial 85 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.037204868252900765}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  86%|████████▌ | 86/100 [00:02<00:00, 38.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,379] Trial 86 finished with value: 0.84390756302521 and parameters: {'solver': 'sag', 'C': 0.020681162708917507}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  94%|█████████▍| 94/100 [00:02<00:00, 38.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,407] Trial 87 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.011952087204337748}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,434] Trial 88 finished with value: 0.7835994397759103 and parameters: {'solver': 'sag', 'C': 0.0016487953630811834}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,460] Trial 89 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.0174598179732157}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,486] Trial 90 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.09225357958481319}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,511] Trial 91 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026449542063198377}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,537] Trial 92 finished with value: 0.8472689075630253 and parameters: {'solver': 'sag', 'C': 0.028716978099140422}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,563] Trial 93 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05269692097958248}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895:  94%|█████████▍| 94/100 [00:02<00:00, 38.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,589] Trial 94 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.04100851208918775}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 39. Best value: 0.84895: 100%|██████████| 100/100 [00:02<00:00, 38.21it/s]\n",
      "[I 2025-11-06 03:25:57,720] A new study created in memory with name: Decision Tree Model Fine Tuning with TPESampler\n",
      "Best trial: 39. Best value: 0.84895: 100%|██████████| 100/100 [00:02<00:00, 38.21it/s]\n",
      "[I 2025-11-06 03:25:57,720] A new study created in memory with name: Decision Tree Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,615] Trial 95 finished with value: 0.8472549019607843 and parameters: {'solver': 'sag', 'C': 0.03088753596943577}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,641] Trial 96 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.01192382113477604}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,666] Trial 97 finished with value: 0.8405602240896359 and parameters: {'solver': 'newton-cg', 'C': 0.008521018011915764}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,692] Trial 98 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05941864093493929}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-11-06 03:25:57,718] Trial 99 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05954942719938483}. Best is trial 39 with value: 0.8489495798319329.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using TPESampler: {'solver': 'newton-cg', 'C': 0.05856966305534113}\n",
      "Best accuracy: 0.8489, at trial: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:   3%|▎         | 3/100 [00:00<00:02, 43.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,735] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[I 2025-11-06 03:25:57,749] Trial 1 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,773] Trial 2 finished with value: 0.807044817927171 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,788] Trial 3 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:   4%|▍         | 4/100 [00:00<00:02, 47.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,803] Trial 4 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:  11%|█         | 11/100 [00:00<00:01, 60.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,818] Trial 5 finished with value: 0.8070448179271708 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,835] Trial 6 finished with value: 0.8272128851540617 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,851] Trial 7 finished with value: 0.8036974789915966 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,867] Trial 8 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,883] Trial 9 finished with value: 0.8002941176470589 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,901] Trial 10 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,919] Trial 11 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.843978:  15%|█▌        | 15/100 [00:00<00:01, 59.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:57,937] Trial 12 finished with value: 0.8204901960784314 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:25:57,955] Trial 13 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-11-06 03:25:57,973] Trial 14 finished with value: 0.8221708683473388 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-11-06 03:25:57,991] Trial 15 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8439775910364145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.843978:  16%|█▌        | 16/100 [00:00<00:01, 59.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,009] Trial 16 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8439775910364145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  23%|██▎       | 23/100 [00:00<00:01, 57.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,026] Trial 17 finished with value: 0.8288515406162464 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.8439775910364145.\n",
      "[I 2025-11-06 03:25:58,044] Trial 18 finished with value: 0.8036974789915966 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8439775910364145.\n",
      "[I 2025-11-06 03:25:58,063] Trial 19 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,081] Trial 20 finished with value: 0.8321848739495799 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,099] Trial 21 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,117] Trial 22 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,134] Trial 23 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  27%|██▋       | 27/100 [00:00<00:01, 56.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,152] Trial 24 finished with value: 0.8120308123249298 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,171] Trial 25 finished with value: 0.8137254901960784 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,189] Trial 26 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,208] Trial 27 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  34%|███▍      | 34/100 [00:00<00:01, 54.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,227] Trial 28 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,247] Trial 29 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,269] Trial 30 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,290] Trial 31 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,310] Trial 32 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,330] Trial 33 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,349] Trial 34 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  38%|███▊      | 38/100 [00:00<00:01, 53.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,368] Trial 35 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,387] Trial 36 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,407] Trial 37 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,425] Trial 38 finished with value: 0.8137675070028012 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  45%|████▌     | 45/100 [00:00<00:01, 53.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,444] Trial 39 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,462] Trial 40 finished with value: 0.8322268907563025 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,481] Trial 41 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,499] Trial 42 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,517] Trial 43 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,536] Trial 44 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,554] Trial 45 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  50%|█████     | 50/100 [00:00<00:00, 52.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,573] Trial 46 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,591] Trial 47 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,614] Trial 48 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,634] Trial 49 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  56%|█████▌    | 56/100 [00:01<00:00, 52.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,656] Trial 50 finished with value: 0.8137675070028012 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,675] Trial 51 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,694] Trial 52 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,712] Trial 53 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,732] Trial 54 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,751] Trial 55 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,770] Trial 56 finished with value: 0.8373109243697477 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.847339:  60%|██████    | 60/100 [00:01<00:00, 52.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,789] Trial 57 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,808] Trial 58 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,827] Trial 59 finished with value: 0.8288515406162464 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,846] Trial 60 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.8507:  68%|██████▊   | 68/100 [00:01<00:00, 52.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,864] Trial 61 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,883] Trial 62 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,903] Trial 63 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8473389355742297.\n",
      "[I 2025-11-06 03:25:58,921] Trial 64 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:58,940] Trial 65 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:58,959] Trial 66 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:58,977] Trial 67 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.8507:  71%|███████   | 71/100 [00:01<00:00, 52.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:58,995] Trial 68 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,014] Trial 69 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,032] Trial 70 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,051] Trial 71 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.8507:  78%|███████▊  | 78/100 [00:01<00:00, 53.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,069] Trial 72 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,088] Trial 73 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,106] Trial 74 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,125] Trial 75 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,144] Trial 76 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,162] Trial 77 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,181] Trial 78 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.8507:  82%|████████▏ | 82/100 [00:01<00:00, 53.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,199] Trial 79 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,218] Trial 80 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,243] Trial 81 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,263] Trial 82 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.8507:  88%|████████▊ | 88/100 [00:01<00:00, 51.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,283] Trial 83 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,305] Trial 84 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,324] Trial 85 finished with value: 0.8154621848739495 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,347] Trial 86 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,366] Trial 87 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,385] Trial 88 finished with value: 0.815420168067227 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.8507:  93%|█████████▎| 93/100 [00:01<00:00, 51.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,404] Trial 89 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,423] Trial 90 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,442] Trial 91 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,461] Trial 92 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,480] Trial 93 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.8507: 100%|██████████| 100/100 [00:01<00:00, 53.27it/s]\n",
      "[I 2025-11-06 03:25:59,599] A new study created in memory with name: Random Forest Model Fine Tuning with TPESampler\n",
      "Best trial: 64. Best value: 0.8507: 100%|██████████| 100/100 [00:01<00:00, 53.27it/s]\n",
      "[I 2025-11-06 03:25:59,599] A new study created in memory with name: Random Forest Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,500] Trial 94 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,519] Trial 95 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,539] Trial 96 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,558] Trial 97 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,578] Trial 98 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:25:59,597] Trial 99 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 64 with value: 0.850700280112045.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using TPESampler: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}\n",
      "Best accuracy: 0.8507, at trial: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.845658:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,663] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.848992:   2%|▏         | 2/100 [00:00<00:07, 13.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,741] Trial 1 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8489915966386554.\n",
      "[I 2025-11-06 03:25:59,817] Trial 2 finished with value: 0.8288655462184874 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8489915966386554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   4%|▍         | 4/100 [00:00<00:07, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,903] Trial 3 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   6%|▌         | 6/100 [00:00<00:07, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:25:59,989] Trial 4 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:00,056] Trial 5 finished with value: 0.842282913165266 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   6%|▌         | 6/100 [00:00<00:07, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:00,111] Trial 6 finished with value: 0.8355882352941176 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   8%|▊         | 8/100 [00:00<00:07, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:00,236] Trial 7 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   8%|▊         | 8/100 [00:00<00:07, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:00,362] Trial 8 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  10%|█         | 10/100 [00:00<00:08, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:00,467] Trial 9 finished with value: 0.8489775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  10%|█         | 10/100 [00:01<00:08, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:00,618] Trial 10 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 98, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  12%|█▏        | 12/100 [00:01<00:10,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:00,788] Trial 11 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 96, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  13%|█▎        | 13/100 [00:01<00:10,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:00,949] Trial 12 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  14%|█▍        | 14/100 [00:01<00:11,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:01,111] Trial 13 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  15%|█▌        | 15/100 [00:01<00:11,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:01,255] Trial 14 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  16%|█▌        | 16/100 [00:01<00:10,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:01,366] Trial 15 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  17%|█▋        | 17/100 [00:01<00:11,  7.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:01,521] Trial 16 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  18%|█▊        | 18/100 [00:02<00:10,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:01,631] Trial 17 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  19%|█▉        | 19/100 [00:02<00:10,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:01,745] Trial 18 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  20%|██        | 20/100 [00:02<00:10,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:01,899] Trial 19 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  21%|██        | 21/100 [00:02<00:09,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,010] Trial 20 finished with value: 0.8557563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  22%|██▏       | 22/100 [00:02<00:09,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,110] Trial 21 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  23%|██▎       | 23/100 [00:02<00:09,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,223] Trial 22 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  24%|██▍       | 24/100 [00:02<00:08,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,344] Trial 23 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  25%|██▌       | 25/100 [00:02<00:08,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,457] Trial 24 finished with value: 0.8456582633053221 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  26%|██▌       | 26/100 [00:02<00:08,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,588] Trial 25 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  27%|██▋       | 27/100 [00:03<00:09,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,719] Trial 26 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  28%|██▊       | 28/100 [00:03<00:09,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,869] Trial 27 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  28%|██▊       | 28/100 [00:03<00:09,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:02,961] Trial 28 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  30%|███       | 30/100 [00:03<00:08,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:03,112] Trial 29 finished with value: 0.8439915966386554 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  31%|███       | 31/100 [00:03<00:08,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:03,233] Trial 30 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  32%|███▏      | 32/100 [00:03<00:08,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:03,365] Trial 31 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  33%|███▎      | 33/100 [00:03<00:08,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:03,492] Trial 32 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 64, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  34%|███▍      | 34/100 [00:04<00:08,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:03,636] Trial 33 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  36%|███▌      | 36/100 [00:04<00:07,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:03,727] Trial 34 finished with value: 0.8523809523809526 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-11-06 03:26:03,807] Trial 35 finished with value: 0.8557002801120447 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 30, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  37%|███▋      | 37/100 [00:04<00:07,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:03,918] Trial 36 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  38%|███▊      | 38/100 [00:04<00:07,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,050] Trial 37 finished with value: 0.8423109243697479 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 73, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  39%|███▉      | 39/100 [00:04<00:07,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,202] Trial 38 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  40%|████      | 40/100 [00:04<00:07,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,345] Trial 39 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 80, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  40%|████      | 40/100 [00:04<00:07,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,426] Trial 40 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 35, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  42%|████▏     | 42/100 [00:04<00:06,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,559] Trial 41 finished with value: 0.8573949579831932 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  43%|████▎     | 43/100 [00:05<00:06,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,660] Trial 42 finished with value: 0.8523809523809524 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-11-06 03:26:04,722] Trial 43 finished with value: 0.8506862745098038 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 12, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  45%|████▌     | 45/100 [00:05<00:05,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,832] Trial 44 finished with value: 0.8574089635854343 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  46%|████▌     | 46/100 [00:05<00:05,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:04,946] Trial 45 finished with value: 0.8490196078431375 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  47%|████▋     | 47/100 [00:05<00:05,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,047] Trial 46 finished with value: 0.8557282913165265 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  48%|████▊     | 48/100 [00:05<00:05,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,179] Trial 47 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  49%|████▉     | 49/100 [00:05<00:06,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,333] Trial 48 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  50%|█████     | 50/100 [00:05<00:06,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,445] Trial 49 finished with value: 0.8456442577030812 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  51%|█████     | 51/100 [00:06<00:06,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,612] Trial 50 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 95, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  52%|█████▏    | 52/100 [00:06<00:06,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,737] Trial 51 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  53%|█████▎    | 53/100 [00:06<00:06,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,870] Trial 52 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  54%|█████▍    | 54/100 [00:06<00:05,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:05,990] Trial 53 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  55%|█████▌    | 55/100 [00:06<00:05,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:06,131] Trial 54 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  56%|█████▌    | 56/100 [00:06<00:06,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:06,298] Trial 55 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  57%|█████▋    | 57/100 [00:06<00:06,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:06,434] Trial 56 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  58%|█████▊    | 58/100 [00:06<00:05,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:06,575] Trial 57 finished with value: 0.8574089635854343 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  59%|█████▉    | 59/100 [00:07<00:06,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:06,739] Trial 58 finished with value: 0.8540756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  60%|██████    | 60/100 [00:07<00:05,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:06,875] Trial 59 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  61%|██████    | 61/100 [00:07<00:05,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,006] Trial 60 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  62%|██████▏   | 62/100 [00:07<00:05,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,152] Trial 61 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  63%|██████▎   | 63/100 [00:07<00:05,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,277] Trial 62 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  64%|██████▍   | 64/100 [00:07<00:04,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,399] Trial 63 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  65%|██████▌   | 65/100 [00:07<00:04,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,524] Trial 64 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  66%|██████▌   | 66/100 [00:08<00:04,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,656] Trial 65 finished with value: 0.8557282913165265 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  67%|██████▋   | 67/100 [00:08<00:04,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,787] Trial 66 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  68%|██████▊   | 68/100 [00:08<00:04,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:07,929] Trial 67 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.85909:  69%|██████▉   | 69/100 [00:08<00:04,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:08,058] Trial 68 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  70%|███████   | 70/100 [00:08<00:04,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:08,201] Trial 69 finished with value: 0.8591036414565828 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  71%|███████   | 71/100 [00:08<00:04,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:08,381] Trial 70 finished with value: 0.8406302521008403 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 90, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  72%|███████▏  | 72/100 [00:08<00:03,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:08,503] Trial 71 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  73%|███████▎  | 73/100 [00:09<00:03,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:08,645] Trial 72 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  74%|███████▍  | 74/100 [00:09<00:03,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:08,797] Trial 73 finished with value: 0.8573949579831932 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  75%|███████▌  | 75/100 [00:09<00:03,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:08,951] Trial 74 finished with value: 0.8591036414565828 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  76%|███████▌  | 76/100 [00:09<00:03,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:09,114] Trial 75 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 99, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  77%|███████▋  | 77/100 [00:09<00:03,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:09,269] Trial 76 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  78%|███████▊  | 78/100 [00:09<00:03,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:09,411] Trial 77 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.859104:  79%|███████▉  | 79/100 [00:09<00:03,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:09,573] Trial 78 finished with value: 0.8506862745098038 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 97, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 69 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  80%|████████  | 80/100 [00:10<00:03,  6.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:09,717] Trial 79 finished with value: 0.8607703081232494 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  81%|████████  | 81/100 [00:10<00:02,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:09,859] Trial 80 finished with value: 0.8439635854341736 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  82%|████████▏ | 82/100 [00:10<00:02,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:10,001] Trial 81 finished with value: 0.8607703081232494 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  83%|████████▎ | 83/100 [00:10<00:02,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:10,133] Trial 82 finished with value: 0.8607703081232494 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  84%|████████▍ | 84/100 [00:10<00:02,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:10,266] Trial 83 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  85%|████████▌ | 85/100 [00:10<00:02,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:10,407] Trial 84 finished with value: 0.8591036414565828 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  86%|████████▌ | 86/100 [00:10<00:02,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:10,566] Trial 85 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  87%|████████▋ | 87/100 [00:11<00:01,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:10,733] Trial 86 finished with value: 0.8591036414565828 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  88%|████████▊ | 88/100 [00:11<00:01,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:10,886] Trial 87 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  89%|████████▉ | 89/100 [00:11<00:01,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:11,050] Trial 88 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  90%|█████████ | 90/100 [00:11<00:01,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:11,216] Trial 89 finished with value: 0.8574229691876752 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  91%|█████████ | 91/100 [00:11<00:01,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:11,384] Trial 90 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 96, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  92%|█████████▏| 92/100 [00:11<00:01,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:11,536] Trial 91 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  93%|█████████▎| 93/100 [00:12<00:01,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:11,683] Trial 92 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 85, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  94%|█████████▍| 94/100 [00:12<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:11,826] Trial 93 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  95%|█████████▌| 95/100 [00:12<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:11,970] Trial 94 finished with value: 0.8607703081232494 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  96%|█████████▌| 96/100 [00:12<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,133] Trial 95 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  97%|█████████▋| 97/100 [00:12<00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,318] Trial 96 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  98%|█████████▊| 98/100 [00:12<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,475] Trial 97 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077:  99%|█████████▉| 99/100 [00:13<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,627] Trial 98 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 95, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 79. Best value: 0.86077: 100%|██████████| 100/100 [00:13<00:00,  7.59it/s]\n",
      "[I 2025-11-06 03:26:12,774] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with TPESampler\n",
      "Best trial: 79. Best value: 0.86077: 100%|██████████| 100/100 [00:13<00:00,  7.59it/s]\n",
      "[I 2025-11-06 03:26:12,774] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,771] Trial 99 finished with value: 0.8607703081232494 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 79 with value: 0.8607703081232494.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using TPESampler: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}\n",
      "Best accuracy: 0.8608, at trial: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.847325:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,809] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.848992:   4%|▍         | 4/100 [00:00<00:03, 28.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,844] Trial 1 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:26:12,879] Trial 2 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:26:12,915] Trial 3 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:26:12,950] Trial 4 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.848992:   6%|▌         | 6/100 [00:00<00:03, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:12,985] Trial 5 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.8507:   6%|▌         | 6/100 [00:00<00:03, 28.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,020] Trial 6 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.8507:  10%|█         | 10/100 [00:00<00:03, 28.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,056] Trial 7 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-11-06 03:26:13,092] Trial 8 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-11-06 03:26:13,128] Trial 9 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-11-06 03:26:13,165] Trial 10 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.8507:  12%|█▏        | 12/100 [00:00<00:03, 27.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,202] Trial 11 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  12%|█▏        | 12/100 [00:00<00:03, 27.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,240] Trial 12 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  16%|█▌        | 16/100 [00:00<00:02, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,277] Trial 13 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,303] Trial 14 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,340] Trial 15 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,377] Trial 16 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  18%|█▊        | 18/100 [00:00<00:02, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,415] Trial 17 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  18%|█▊        | 18/100 [00:00<00:02, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,452] Trial 18 finished with value: 0.8288515406162464 and parameters: {'algorithm': 'brute', 'n_neighbors': 4, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  22%|██▏       | 22/100 [00:00<00:02, 27.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,491] Trial 19 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,529] Trial 20 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,556] Trial 21 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,593] Trial 22 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  25%|██▌       | 25/100 [00:00<00:02, 29.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,620] Trial 23 finished with value: 0.850686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,647] Trial 24 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  25%|██▌       | 25/100 [00:00<00:02, 29.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,674] Trial 25 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  29%|██▉       | 29/100 [00:01<00:02, 29.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,711] Trial 26 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,748] Trial 27 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,765] Trial 28 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,802] Trial 29 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  30%|███       | 30/100 [00:01<00:02, 29.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,840] Trial 30 finished with value: 0.850686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  32%|███▏      | 32/100 [00:01<00:02, 30.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,877] Trial 31 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  35%|███▌      | 35/100 [00:01<00:02, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:13,914] Trial 32 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:13,962] Trial 33 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,003] Trial 34 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,033] Trial 35 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 32, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  36%|███▌      | 36/100 [00:01<00:02, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,071] Trial 36 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  38%|███▊      | 38/100 [00:01<00:02, 28.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,108] Trial 37 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 23, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  41%|████      | 41/100 [00:01<00:02, 28.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,146] Trial 38 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 36, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,183] Trial 39 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,210] Trial 40 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,250] Trial 41 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  42%|████▏     | 42/100 [00:01<00:02, 28.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,288] Trial 42 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  44%|████▍     | 44/100 [00:01<00:02, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,328] Trial 43 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  47%|████▋     | 47/100 [00:01<00:01, 27.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,365] Trial 44 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,403] Trial 45 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,440] Trial 46 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,478] Trial 47 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 16, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  48%|████▊     | 48/100 [00:01<00:01, 27.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,515] Trial 48 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  54%|█████▍    | 54/100 [00:01<00:01, 27.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,573] Trial 49 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,611] Trial 50 finished with value: 0.8254901960784313 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,642] Trial 51 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,669] Trial 52 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,697] Trial 53 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  55%|█████▌    | 55/100 [00:01<00:01, 27.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,725] Trial 54 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,753] Trial 55 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 49, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  60%|██████    | 60/100 [00:02<00:01, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,785] Trial 56 finished with value: 0.850686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,827] Trial 57 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,855] Trial 58 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,896] Trial 59 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,924] Trial 60 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  62%|██████▏   | 62/100 [00:02<00:01, 29.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:14,953] Trial 61 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:14,982] Trial 62 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  67%|██████▋   | 67/100 [00:02<00:01, 29.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,014] Trial 63 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,046] Trial 64 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,084] Trial 65 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,112] Trial 66 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,150] Trial 67 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  69%|██████▉   | 69/100 [00:02<00:01, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,188] Trial 68 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  73%|███████▎  | 73/100 [00:02<00:00, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,225] Trial 69 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,254] Trial 70 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,294] Trial 71 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,332] Trial 72 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,369] Trial 73 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  75%|███████▌  | 75/100 [00:02<00:00, 28.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,407] Trial 74 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,456] Trial 75 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,495] Trial 76 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,532] Trial 77 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,570] Trial 78 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  81%|████████  | 81/100 [00:02<00:00, 27.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,608] Trial 79 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,636] Trial 80 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  84%|████████▍ | 84/100 [00:03<00:00, 26.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,685] Trial 81 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,727] Trial 82 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,764] Trial 83 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,803] Trial 84 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  87%|████████▋ | 87/100 [00:03<00:00, 26.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,841] Trial 85 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,879] Trial 86 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  90%|█████████ | 90/100 [00:03<00:00, 25.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:15,910] Trial 87 finished with value: 0.850686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:15,959] Trial 88 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 19, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:16,002] Trial 89 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:16,033] Trial 90 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'brute', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  91%|█████████ | 91/100 [00:03<00:00, 25.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,075] Trial 91 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  96%|█████████▌| 96/100 [00:03<00:00, 25.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,114] Trial 92 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:16,152] Trial 93 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:16,190] Trial 94 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:16,229] Trial 95 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:16,260] Trial 96 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367:  97%|█████████▋| 97/100 [00:03<00:00, 25.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,299] Trial 97 finished with value: 0.850686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.852367: 100%|██████████| 100/100 [00:03<00:00, 27.93it/s]\n",
      "[I 2025-11-06 03:26:16,357] A new study created in memory with name: Support Vector Machine Model Fine Tuning with TPESampler\n",
      "Best trial: 12. Best value: 0.852367: 100%|██████████| 100/100 [00:03<00:00, 27.93it/s]\n",
      "[I 2025-11-06 03:26:16,357] A new study created in memory with name: Support Vector Machine Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,337] Trial 98 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:26:16,354] Trial 99 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using TPESampler: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   4%|▍         | 4/100 [00:00<00:02, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,391] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:16,416] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:16,451] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:16,475] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   4%|▍         | 4/100 [00:00<00:02, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,511] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   6%|▌         | 6/100 [00:00<00:02, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,539] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:16,575] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.771835:  10%|█         | 10/100 [00:00<00:02, 32.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,601] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:16,638] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:16,674] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:16,701] Trial 10 finished with value: 0.7718347338935574 and parameters: {'kernel': 'poly', 'C': 0.0021291805287692966, 'degree': 5}. Best is trial 10 with value: 0.7718347338935574.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.771835:  12%|█▏        | 12/100 [00:00<00:02, 32.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,729] Trial 11 finished with value: 0.7718347338935574 and parameters: {'kernel': 'poly', 'C': 0.0021085512855092427, 'degree': 5}. Best is trial 10 with value: 0.7718347338935574.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.790294:  13%|█▎        | 13/100 [00:00<00:02, 32.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,756] Trial 12 finished with value: 0.7902941176470588 and parameters: {'kernel': 'poly', 'C': 0.0030343529095853763, 'degree': 5}. Best is trial 12 with value: 0.7902941176470588.\n",
      "[I 2025-11-06 03:26:16,783] Trial 13 finished with value: 0.7902941176470588 and parameters: {'kernel': 'poly', 'C': 0.0030833342416828552, 'degree': 5}. Best is trial 12 with value: 0.7902941176470588.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.837227:  18%|█▊        | 18/100 [00:00<00:02, 33.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,810] Trial 14 finished with value: 0.8154341736694677 and parameters: {'kernel': 'poly', 'C': 0.004499680933767338, 'degree': 5}. Best is trial 14 with value: 0.8154341736694677.\n",
      "[I 2025-11-06 03:26:16,837] Trial 15 finished with value: 0.8171148459383752 and parameters: {'kernel': 'poly', 'C': 0.004080251178358777, 'degree': 4}. Best is trial 15 with value: 0.8171148459383752.\n",
      "[I 2025-11-06 03:26:16,866] Trial 16 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.007999452977705724, 'degree': 3}. Best is trial 16 with value: 0.8355462184873949.\n",
      "[I 2025-11-06 03:26:16,893] Trial 17 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009851506433650771, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:16,920] Trial 18 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.00976912882165916, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.837227:  20%|██        | 20/100 [00:00<00:02, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,948] Trial 19 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.009563854514148548, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.837227:  21%|██        | 21/100 [00:00<00:02, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:16,975] Trial 20 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00011585594234321437, 'degree': 2}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,002] Trial 21 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.006732534117889711, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,019] Trial 22 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009628531956521132, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,035] Trial 23 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009954618519931012, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,062] Trial 24 finished with value: 0.8288375350140054 and parameters: {'kernel': 'poly', 'C': 0.0059581346138133625, 'degree': 4}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,088] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0037433095612438585}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,105] Trial 26 finished with value: 0.835532212885154 and parameters: {'kernel': 'poly', 'C': 0.006171605058256973, 'degree': 2}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,131] Trial 27 finished with value: 0.5956302521008403 and parameters: {'kernel': 'poly', 'C': 0.0008478772686135207, 'degree': 4}. Best is trial 17 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.837227:  30%|███       | 30/100 [00:00<00:01, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,148] Trial 28 finished with value: 0.8070728291316526 and parameters: {'kernel': 'poly', 'C': 0.0025815325463280866, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,174] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0015388727422125698}. Best is trial 17 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.837227:  31%|███       | 31/100 [00:00<00:01, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,201] Trial 30 finished with value: 0.8338655462184873 and parameters: {'kernel': 'poly', 'C': 0.004837775947425763, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,218] Trial 31 finished with value: 0.8338655462184873 and parameters: {'kernel': 'poly', 'C': 0.009130640392183169, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  35%|███▌      | 35/100 [00:00<00:01, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,246] Trial 32 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.006901785891356755, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-11-06 03:26:17,273] Trial 33 finished with value: 0.8405882352941175 and parameters: {'kernel': 'poly', 'C': 0.009922745041727202, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,290] Trial 34 finished with value: 0.8238235294117645 and parameters: {'kernel': 'poly', 'C': 0.0055110877060886975, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,316] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00773898695334506}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  38%|███▊      | 38/100 [00:01<00:01, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,352] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005131855034712691}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,370] Trial 37 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009810323221255414, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,396] Trial 38 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.007203642503010532}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  40%|████      | 40/100 [00:01<00:01, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,423] Trial 39 finished with value: 0.8070588235294117 and parameters: {'kernel': 'poly', 'C': 0.0033399318860387593, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  45%|████▌     | 45/100 [00:01<00:01, 40.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,449] Trial 40 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0014582841621375497}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,466] Trial 41 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.00993824372973719, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,493] Trial 42 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007623399953065999, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,521] Trial 43 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.005719587919802942, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,537] Trial 44 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.008282062240761345, 'degree': 2}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  46%|████▌     | 46/100 [00:01<00:01, 40.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,565] Trial 45 finished with value: 0.8321848739495797 and parameters: {'kernel': 'poly', 'C': 0.00407772545215666, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,601] Trial 46 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007243510897530972}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  47%|████▋     | 47/100 [00:01<00:01, 40.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,629] Trial 47 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.006517584165480652, 'degree': 2}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  52%|█████▏    | 52/100 [00:01<00:01, 39.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,656] Trial 48 finished with value: 0.822142857142857 and parameters: {'kernel': 'poly', 'C': 0.005037187241321775, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,673] Trial 49 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009810624915759214, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,700] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00038214412785407076}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,727] Trial 51 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.008724882959588344, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,755] Trial 52 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009937772238136338, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  54%|█████▍    | 54/100 [00:01<00:01, 38.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,783] Trial 53 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.00795065710253696, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,809] Trial 54 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.006782145040738353, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.840588:  55%|█████▌    | 55/100 [00:01<00:01, 38.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,840] Trial 55 finished with value: 0.8321848739495797 and parameters: {'kernel': 'poly', 'C': 0.004507308749010253, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.842241:  59%|█████▉    | 59/100 [00:01<00:01, 36.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,868] Trial 56 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.008282894366622563, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,904] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005809302849933278}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,934] Trial 58 finished with value: 0.8070728291316526 and parameters: {'kernel': 'poly', 'C': 0.0025811624051328354, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-11-06 03:26:17,961] Trial 59 finished with value: 0.8422408963585436 and parameters: {'kernel': 'poly', 'C': 0.007083582159710286, 'degree': 5}. Best is trial 59 with value: 0.8422408963585436.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: 0.843936:  62%|██████▏   | 62/100 [00:01<00:01, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:17,991] Trial 60 finished with value: 0.8439215686274512 and parameters: {'kernel': 'poly', 'C': 0.007333742730493635, 'degree': 5}. Best is trial 60 with value: 0.8439215686274512.\n",
      "[I 2025-11-06 03:26:18,018] Trial 61 finished with value: 0.8439355742296918 and parameters: {'kernel': 'poly', 'C': 0.007517219003413869, 'degree': 5}. Best is trial 61 with value: 0.8439355742296918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 61. Best value: 0.843936:  62%|██████▏   | 62/100 [00:01<00:01, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,049] Trial 62 finished with value: 0.8372268907563025 and parameters: {'kernel': 'poly', 'C': 0.006792947383159986, 'degree': 5}. Best is trial 61 with value: 0.8439355742296918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.845602:  67%|██████▋   | 67/100 [00:01<00:00, 36.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,080] Trial 63 finished with value: 0.8053781512605042 and parameters: {'kernel': 'poly', 'C': 0.0036879097359798843, 'degree': 5}. Best is trial 61 with value: 0.8439355742296918.\n",
      "[I 2025-11-06 03:26:18,097] Trial 64 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.006572588012017085, 'degree': 5}. Best is trial 61 with value: 0.8439355742296918.\n",
      "[I 2025-11-06 03:26:18,125] Trial 65 finished with value: 0.8456022408963587 and parameters: {'kernel': 'poly', 'C': 0.007460188396385473, 'degree': 5}. Best is trial 65 with value: 0.8456022408963587.\n",
      "[I 2025-11-06 03:26:18,143] Trial 66 finished with value: 0.8154341736694677 and parameters: {'kernel': 'poly', 'C': 0.004414993991519198, 'degree': 5}. Best is trial 65 with value: 0.8456022408963587.\n",
      "[I 2025-11-06 03:26:18,170] Trial 67 finished with value: 0.8271848739495796 and parameters: {'kernel': 'poly', 'C': 0.005337240697702612, 'degree': 5}. Best is trial 65 with value: 0.8456022408963587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.845602:  70%|███████   | 70/100 [00:01<00:00, 37.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,197] Trial 68 finished with value: 0.8456022408963587 and parameters: {'kernel': 'poly', 'C': 0.007388511820807228, 'degree': 5}. Best is trial 65 with value: 0.8456022408963587.\n",
      "[I 2025-11-06 03:26:18,227] Trial 69 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.007885015502918166, 'degree': 5}. Best is trial 65 with value: 0.8456022408963587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.845602:  71%|███████   | 71/100 [00:01<00:00, 37.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,255] Trial 70 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.007559038769553499}. Best is trial 65 with value: 0.8456022408963587.\n",
      "[I 2025-11-06 03:26:18,272] Trial 71 finished with value: 0.8439495798319328 and parameters: {'kernel': 'poly', 'C': 0.00844317900753262, 'degree': 5}. Best is trial 65 with value: 0.8456022408963587.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.845616:  75%|███████▌  | 75/100 [00:02<00:00, 38.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,300] Trial 72 finished with value: 0.8271708683473389 and parameters: {'kernel': 'poly', 'C': 0.006011136569235095, 'degree': 5}. Best is trial 65 with value: 0.8456022408963587.\n",
      "[I 2025-11-06 03:26:18,327] Trial 73 finished with value: 0.8456162464985993 and parameters: {'kernel': 'poly', 'C': 0.008364135788078878, 'degree': 5}. Best is trial 73 with value: 0.8456162464985993.\n",
      "[I 2025-11-06 03:26:18,355] Trial 74 finished with value: 0.8422408963585436 and parameters: {'kernel': 'poly', 'C': 0.0072543743468552, 'degree': 5}. Best is trial 73 with value: 0.8456162464985993.\n",
      "[I 2025-11-06 03:26:18,383] Trial 75 finished with value: 0.8238375350140055 and parameters: {'kernel': 'poly', 'C': 0.005113322642067386, 'degree': 5}. Best is trial 73 with value: 0.8456162464985993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  79%|███████▉  | 79/100 [00:02<00:00, 38.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,400] Trial 76 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.00853675785145888, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,427] Trial 77 finished with value: 0.8439495798319328 and parameters: {'kernel': 'poly', 'C': 0.008406692175155293, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,454] Trial 78 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.006113188547700477}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  79%|███████▉  | 79/100 [00:02<00:00, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,482] Trial 79 finished with value: 0.8456162464985993 and parameters: {'kernel': 'poly', 'C': 0.008290965185698286, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  83%|████████▎ | 83/100 [00:02<00:00, 37.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,510] Trial 80 finished with value: 0.8439495798319328 and parameters: {'kernel': 'poly', 'C': 0.008476056093565044, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,541] Trial 81 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008636199479668158, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,571] Trial 82 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008859635459319526, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,600] Trial 83 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008637382620282139, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  85%|████████▌ | 85/100 [00:02<00:00, 37.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,628] Trial 84 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008582477953352227, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,656] Trial 85 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0001058987042386954, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  87%|████████▋ | 87/100 [00:02<00:00, 36.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,684] Trial 86 finished with value: 0.7449719887955182 and parameters: {'kernel': 'poly', 'C': 0.001281342686365661, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,702] Trial 87 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008881752436942987, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  91%|█████████ | 91/100 [00:02<00:00, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,728] Trial 88 finished with value: 0.5436414565826331 and parameters: {'kernel': 'rbf', 'C': 0.00883657628064751}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,757] Trial 89 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00014802229440888514, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,785] Trial 90 finished with value: 0.8305182072829131 and parameters: {'kernel': 'poly', 'C': 0.006298292623510285, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,804] Trial 91 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008989829508761106, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  93%|█████████▎| 93/100 [00:02<00:00, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,831] Trial 92 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008647036173285083, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,859] Trial 93 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.00912154845235886, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  95%|█████████▌| 95/100 [00:02<00:00, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,887] Trial 94 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008838650343940858, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,920] Trial 95 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.00906641557040225, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563:  99%|█████████▉| 99/100 [00:02<00:00, 36.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:18,962] Trial 96 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005589297067796269}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:18,979] Trial 97 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009202211700664584, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:26:19,010] Trial 98 finished with value: 0.8305182072829131 and parameters: {'kernel': 'poly', 'C': 0.006472105238798424, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 76. Best value: 0.84563: 100%|██████████| 100/100 [00:02<00:00, 37.28it/s]\n",
      "[I 2025-11-06 03:26:19,041] A new study created in memory with name: AdaBoost Model Fine Tuning with TPESampler\n",
      "Best trial: 76. Best value: 0.84563: 100%|██████████| 100/100 [00:02<00:00, 37.28it/s]\n",
      "[I 2025-11-06 03:26:19,041] A new study created in memory with name: AdaBoost Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,038] Trial 99 finished with value: 0.6308683473389356 and parameters: {'kernel': 'poly', 'C': 0.0005453999564954659, 'degree': 5}. Best is trial 76 with value: 0.8456302521008403.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using TPESampler: {'kernel': 'poly', 'C': 0.00853675785145888, 'degree': 5}\n",
      "Best accuracy: 0.8456, at trial: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,105] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   2%|▏         | 2/100 [00:00<00:09,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,241] Trial 1 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:19,286] Trial 2 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   5%|▌         | 5/100 [00:00<00:07, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,320] Trial 3 finished with value: 0.8490196078431372 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:19,425] Trial 4 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   5%|▌         | 5/100 [00:00<00:07, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,450] Trial 5 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   7%|▋         | 7/100 [00:00<00:07, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,588] Trial 6 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:19,644] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   9%|▉         | 9/100 [00:00<00:06, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,710] Trial 8 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:19,786] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  11%|█         | 11/100 [00:01<00:07, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:19,957] Trial 10 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 98, 'learning_rate': 0.026301587628514225}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:20,056] Trial 11 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 68, 'learning_rate': 0.1265897737239208}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  13%|█▎        | 13/100 [00:01<00:08, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:20,195] Trial 12 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 78, 'learning_rate': 0.19188668274684337}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:20,285] Trial 13 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 60, 'learning_rate': 0.026033163308986574}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  17%|█▋        | 17/100 [00:01<00:08, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:20,405] Trial 14 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 81, 'learning_rate': 0.37268656911274406}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:20,445] Trial 15 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 11, 'learning_rate': 0.058533073152161025}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:20,595] Trial 16 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 91, 'learning_rate': 0.01187451013407021}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  19%|█▉        | 19/100 [00:01<00:08,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:20,704] Trial 17 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 74, 'learning_rate': 0.2851114291790847}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:20,802] Trial 18 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 55, 'learning_rate': 0.05957319708513157}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:20,872] Trial 19 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 34, 'learning_rate': 0.43971771996181436}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  21%|██        | 21/100 [00:01<00:06, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:20,922] Trial 20 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 20, 'learning_rate': 0.001199787279804636}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:21,012] Trial 21 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 65, 'learning_rate': 0.2558114094477825}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  23%|██▎       | 23/100 [00:02<00:07, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:21,131] Trial 22 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 73, 'learning_rate': 0.09409697218623146}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:21,229] Trial 23 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 75, 'learning_rate': 0.31270970402981324}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  25%|██▌       | 25/100 [00:02<00:07,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:21,399] Trial 24 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 89, 'learning_rate': 0.6043826849048642}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:26:21,550] Trial 25 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 100, 'learning_rate': 0.18421410660731247}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  28%|██▊       | 28/100 [00:02<00:09,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:21,719] Trial 26 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 96, 'learning_rate': 0.07444634246579308}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:21,898] Trial 27 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 100, 'learning_rate': 0.014075114167247478}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  31%|███       | 31/100 [00:03<00:08,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:22,046] Trial 28 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 90, 'learning_rate': 0.16615521320951043}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:22,146] Trial 29 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 48, 'learning_rate': 0.9766289712820951}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:22,235] Trial 30 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 40, 'learning_rate': 0.526644097111549}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  33%|███▎      | 33/100 [00:03<00:08,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:22,322] Trial 31 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 70, 'learning_rate': 0.23436732632306187}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:22,471] Trial 32 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 82, 'learning_rate': 0.09486058845824513}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  35%|███▌      | 35/100 [00:03<00:07,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:22,569] Trial 33 finished with value: 0.8321848739495799 and parameters: {'n_estimators': 58, 'learning_rate': 0.037662549048883213}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:22,668] Trial 34 finished with value: 0.845658263305322 and parameters: {'n_estimators': 50, 'learning_rate': 0.14377891834776593}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  37%|███▋      | 37/100 [00:03<00:07,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:22,798] Trial 35 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 85, 'learning_rate': 0.3152506662360831}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:22,947] Trial 36 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 93, 'learning_rate': 0.6968302533622741}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  39%|███▉      | 39/100 [00:04<00:05, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:23,005] Trial 37 finished with value: 0.8422689075630252 and parameters: {'n_estimators': 32, 'learning_rate': 0.11903360375250044}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:23,055] Trial 38 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 18, 'learning_rate': 0.0490020255679608}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:23,195] Trial 39 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 76, 'learning_rate': 0.2061841215095083}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  43%|████▎     | 43/100 [00:04<00:05,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:23,303] Trial 40 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 64, 'learning_rate': 0.49131428142108335}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:23,391] Trial 41 finished with value: 0.83890756302521 and parameters: {'n_estimators': 45, 'learning_rate': 0.866417200821414}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:23,481] Trial 42 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 49, 'learning_rate': 0.7629667864061842}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  45%|████▌     | 45/100 [00:04<00:05, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:23,549] Trial 43 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 28, 'learning_rate': 0.3415139190728523}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:23,637] Trial 44 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 70, 'learning_rate': 0.8906453700058113}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  47%|████▋     | 47/100 [00:04<00:05,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:23,777] Trial 45 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 86, 'learning_rate': 0.9764789451622008}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:23,925] Trial 46 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 80, 'learning_rate': 0.24411995750255241}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  49%|████▉     | 49/100 [00:05<00:05,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:24,045] Trial 47 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 60, 'learning_rate': 0.4147270310370101}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:24,175] Trial 48 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 95, 'learning_rate': 0.6207753616215793}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  51%|█████     | 51/100 [00:05<00:05,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:24,265] Trial 49 finished with value: 0.8439775910364145 and parameters: {'n_estimators': 43, 'learning_rate': 0.16769103513875397}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:24,373] Trial 50 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 56, 'learning_rate': 0.11077990501142669}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  53%|█████▎    | 53/100 [00:05<00:05,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:24,506] Trial 51 finished with value: 0.850672268907563 and parameters: {'n_estimators': 78, 'learning_rate': 0.19804074772706937}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:24,614] Trial 52 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 65, 'learning_rate': 0.2711382285491887}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:24,652] Trial 53 finished with value: 0.8422829131652663 and parameters: {'n_estimators': 10, 'learning_rate': 0.4152162051617404}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  57%|█████▋    | 57/100 [00:05<00:03, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:24,751] Trial 54 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 72, 'learning_rate': 0.022891739799804765}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:24,800] Trial 55 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 17, 'learning_rate': 0.08051529683625983}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:24,919] Trial 56 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 78, 'learning_rate': 0.15226910253398476}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  59%|█████▉    | 59/100 [00:06<00:04,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:25,057] Trial 57 finished with value: 0.8439495798319326 and parameters: {'n_estimators': 82, 'learning_rate': 0.5371124824656728}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:25,157] Trial 58 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 52, 'learning_rate': 0.19386962438226799}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  61%|██████    | 61/100 [00:06<00:04,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:25,318] Trial 59 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 88, 'learning_rate': 0.0021850156068446663}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:25,442] Trial 60 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 67, 'learning_rate': 0.05130118765228393}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  63%|██████▎   | 63/100 [00:06<00:04,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:25,570] Trial 61 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 76, 'learning_rate': 0.19358349002407318}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:25,690] Trial 62 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 62, 'learning_rate': 0.29894162403934665}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  66%|██████▌   | 66/100 [00:06<00:03,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:25,799] Trial 63 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 61, 'learning_rate': 0.3184573222147383}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:25,856] Trial 64 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 24, 'learning_rate': 0.3907634801065466}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:25,975] Trial 65 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 70, 'learning_rate': 0.25672144565223515}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  68%|██████▊   | 68/100 [00:07<00:03,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:26,074] Trial 66 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 53, 'learning_rate': 0.644959459425353}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:26,184] Trial 67 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 73, 'learning_rate': 0.018979977396270355}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  71%|███████   | 71/100 [00:07<00:02, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:26,303] Trial 68 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 62, 'learning_rate': 0.006992934972302666}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:26,386] Trial 69 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 37, 'learning_rate': 0.13387206533559304}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:26,424] Trial 70 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 14, 'learning_rate': 0.0807187338766613}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.852353:  73%|███████▎  | 73/100 [00:07<00:02,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:26,562] Trial 71 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 79, 'learning_rate': 0.2154083220207688}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:26:26,707] Trial 72 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 84, 'learning_rate': 0.17789424466939782}. Best is trial 25 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  75%|███████▌  | 75/100 [00:07<00:02,  8.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:26,828] Trial 73 finished with value: 0.8557002801120449 and parameters: {'n_estimators': 100, 'learning_rate': 0.47987044663011336}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:26,947] Trial 74 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 100, 'learning_rate': 0.47583533640722525}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  76%|███████▌  | 76/100 [00:08<00:02,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:27,096] Trial 75 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 96, 'learning_rate': 0.30085171069429667}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:27,195] Trial 76 finished with value: 0.8523389355742296 and parameters: {'n_estimators': 67, 'learning_rate': 0.7158248090936833}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  79%|███████▉  | 79/100 [00:08<00:02,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:27,344] Trial 77 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 93, 'learning_rate': 0.7496791715555304}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:27,504] Trial 78 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 88, 'learning_rate': 0.5576502059126689}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  81%|████████  | 81/100 [00:08<00:02,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:27,616] Trial 79 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 67, 'learning_rate': 0.3645009136029902}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:27,796] Trial 80 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 98, 'learning_rate': 0.7905971215954257}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  83%|████████▎ | 83/100 [00:08<00:02,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:27,873] Trial 81 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 57, 'learning_rate': 0.44536730648327466}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:27,981] Trial 82 finished with value: 0.8405742296918767 and parameters: {'n_estimators': 74, 'learning_rate': 0.9361974013485613}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  85%|████████▌ | 85/100 [00:09<00:01,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:28,110] Trial 83 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 69, 'learning_rate': 0.2792615066754243}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:28,224] Trial 84 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 64, 'learning_rate': 0.6400498827218242}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  86%|████████▌ | 86/100 [00:09<00:01,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:28,364] Trial 85 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 92, 'learning_rate': 0.03840380294937569}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:28,425] Trial 86 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 29, 'learning_rate': 0.5058728420238217}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  89%|████████▉ | 89/100 [00:09<00:01,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:28,565] Trial 87 finished with value: 0.842282913165266 and parameters: {'n_estimators': 72, 'learning_rate': 0.3645032156733835}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:28,684] Trial 88 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 67, 'learning_rate': 0.2346349296089162}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  91%|█████████ | 91/100 [00:09<00:01,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:28,812] Trial 89 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 77, 'learning_rate': 0.09770639584336664}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:28,950] Trial 90 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 81, 'learning_rate': 0.06737215057623977}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  93%|█████████▎| 93/100 [00:10<00:00,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:29,028] Trial 91 finished with value: 0.850672268907563 and parameters: {'n_estimators': 64, 'learning_rate': 0.6307059506194986}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:29,105] Trial 92 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 62, 'learning_rate': 0.6013871504548516}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:29,183] Trial 93 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 58, 'learning_rate': 0.7251021221198122}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557:  97%|█████████▋| 97/100 [00:10<00:00, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:29,264] Trial 94 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 53, 'learning_rate': 0.46592652438999344}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:29,332] Trial 95 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 52, 'learning_rate': 0.43180896367977445}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:29,442] Trial 96 finished with value: 0.8489635854341737 and parameters: {'n_estimators': 71, 'learning_rate': 0.8626987480459354}. Best is trial 73 with value: 0.8557002801120449.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 73. Best value: 0.8557: 100%|██████████| 100/100 [00:10<00:00,  9.40it/s]\n",
      "[I 2025-11-06 03:26:29,684] A new study created in memory with name: Gradient Boosting Model Fine Tuning with TPESampler\n",
      "Best trial: 73. Best value: 0.8557: 100%|██████████| 100/100 [00:10<00:00,  9.40it/s]\n",
      "[I 2025-11-06 03:26:29,684] A new study created in memory with name: Gradient Boosting Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:29,522] Trial 97 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 46, 'learning_rate': 0.9717141621275407}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:29,602] Trial 98 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 46, 'learning_rate': 0.5383795828686457}. Best is trial 73 with value: 0.8557002801120449.\n",
      "[I 2025-11-06 03:26:29,680] Trial 99 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 55, 'learning_rate': 0.3596524469843851}. Best is trial 73 with value: 0.8557002801120449.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using TPESampler: {'n_estimators': 100, 'learning_rate': 0.47987044663011336}\n",
      "Best accuracy: 0.8557, at trial: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837241:   2%|▏         | 2/100 [00:00<00:09, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:29,751] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n",
      "[I 2025-11-06 03:26:29,877] Trial 1 finished with value: 0.8372408963585434 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-11-06 03:26:29,923] Trial 2 finished with value: 0.6844257703081233 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.8372408963585434.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837241:   6%|▌         | 6/100 [00:00<00:07, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:29,998] Trial 3 finished with value: 0.8019887955182072 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-11-06 03:26:30,093] Trial 4 finished with value: 0.6978151260504202 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-11-06 03:26:30,178] Trial 5 finished with value: 0.8103361344537815 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.8372408963585434.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:   9%|▉         | 9/100 [00:00<00:06, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:30,223] Trial 6 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-11-06 03:26:30,258] Trial 7 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 7 with value: 0.8439495798319326.\n",
      "[I 2025-11-06 03:26:30,335] Trial 8 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:   9%|▉         | 9/100 [00:00<00:06, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:30,432] Trial 9 finished with value: 0.8204341736694678 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:  11%|█         | 11/100 [00:01<00:09,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:30,736] Trial 10 finished with value: 0.8540056022408965 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.08691089486124967, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.9861142660861426}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:  11%|█         | 11/100 [00:01<00:09,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:31,081] Trial 11 finished with value: 0.8540056022408964 and parameters: {'max_features': 'log2', 'n_estimators': 97, 'learning_rate': 0.09888513616343735, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.995813023603747}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:  13%|█▎        | 13/100 [00:01<00:14,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:31,315] Trial 12 finished with value: 0.8556862745098041 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.023976227274240734, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.8555615028924779}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:  15%|█▌        | 15/100 [00:02<00:15,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:31,558] Trial 13 finished with value: 0.8490056022408965 and parameters: {'max_features': 'log2', 'n_estimators': 79, 'learning_rate': 0.019597196379450572, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.8369320744702511}. Best is trial 8 with value: 0.8557142857142856.\n",
      "[I 2025-11-06 03:26:31,741] Trial 14 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.012844059574698552, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.8548207254040888}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:  18%|█▊        | 18/100 [00:02<00:12,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:31,924] Trial 15 finished with value: 0.8557002801120449 and parameters: {'max_features': 'sqrt', 'n_estimators': 73, 'learning_rate': 0.031278455072893535, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.7136632120691078}. Best is trial 8 with value: 0.8557142857142856.\n",
      "[I 2025-11-06 03:26:32,021] Trial 16 finished with value: 0.8490056022408963 and parameters: {'max_features': 'sqrt', 'n_estimators': 46, 'learning_rate': 0.04434341112622502, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.5054945946218856}. Best is trial 8 with value: 0.8557142857142856.\n",
      "[I 2025-11-06 03:26:32,122] Trial 17 finished with value: 0.8540476190476192 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.007687329516325839, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6875366586759303}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.857423:  20%|██        | 20/100 [00:02<00:11,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:32,255] Trial 18 finished with value: 0.8574229691876752 and parameters: {'max_features': 'sqrt', 'n_estimators': 87, 'learning_rate': 0.047981562165459325, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.6903747941999199}. Best is trial 18 with value: 0.8574229691876752.\n",
      "[I 2025-11-06 03:26:32,377] Trial 19 finished with value: 0.8523949579831933 and parameters: {'max_features': 'sqrt', 'n_estimators': 89, 'learning_rate': 0.05849609053505989, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.6601698676289584}. Best is trial 18 with value: 0.8574229691876752.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.865784:  22%|██▏       | 22/100 [00:02<00:10,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:32,498] Trial 20 finished with value: 0.8657843137254903 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.013787870379812286, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.5161460692134067}. Best is trial 20 with value: 0.8657843137254903.\n",
      "[I 2025-11-06 03:26:32,655] Trial 21 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.012880373514060562, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.5303773315185901}. Best is trial 20 with value: 0.8657843137254903.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.865784:  24%|██▍       | 24/100 [00:03<00:09,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:32,768] Trial 22 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.02206736157554314, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.5426926844851822}. Best is trial 20 with value: 0.8657843137254903.\n",
      "[I 2025-11-06 03:26:32,880] Trial 23 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.008120134025166328, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.5570445354475513}. Best is trial 20 with value: 0.8657843137254903.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.865784:  26%|██▌       | 26/100 [00:03<00:07, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:32,973] Trial 24 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.017180322330833487, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.5633322207844776}. Best is trial 20 with value: 0.8657843137254903.\n",
      "[I 2025-11-06 03:26:33,004] Trial 25 finished with value: 0.8490336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.057181298482540804, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.6270450192142747}. Best is trial 20 with value: 0.8657843137254903.\n",
      "[I 2025-11-06 03:26:33,126] Trial 26 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.025190969920898042, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.5586526552527352}. Best is trial 20 with value: 0.8657843137254903.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.865784:  29%|██▉       | 29/100 [00:03<00:08,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:33,279] Trial 27 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.011625158724780779, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.5893740291315798}. Best is trial 20 with value: 0.8657843137254903.\n",
      "[I 2025-11-06 03:26:33,411] Trial 28 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.005589742705104939, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.5095048722678216}. Best is trial 20 with value: 0.8657843137254903.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.865784:  31%|███       | 31/100 [00:04<00:08,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:33,544] Trial 29 finished with value: 0.8573809523809525 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.027313128880679986, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.6570072117962636}. Best is trial 20 with value: 0.8657843137254903.\n",
      "[I 2025-11-06 03:26:33,697] Trial 30 finished with value: 0.8574089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.06422637576165698, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7811000969963324}. Best is trial 20 with value: 0.8657843137254903.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.865798:  33%|███▎      | 33/100 [00:04<00:08,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:33,830] Trial 31 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 98, 'learning_rate': 0.064268219678733, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7793644003515996}. Best is trial 20 with value: 0.8657843137254903.\n",
      "[I 2025-11-06 03:26:33,943] Trial 32 finished with value: 0.865798319327731 and parameters: {'max_features': 'sqrt', 'n_estimators': 88, 'learning_rate': 0.04672849394110595, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7919843658546906}. Best is trial 32 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.865798:  36%|███▌      | 36/100 [00:04<00:07,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:34,116] Trial 33 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.017027364129382213, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8122786472063286}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:34,211] Trial 34 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.04534628958346056, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7308877649798509}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:34,304] Trial 35 finished with value: 0.8523389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 68, 'learning_rate': 0.02865107866996682, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.7440281175908554}. Best is trial 32 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.865798:  38%|███▊      | 38/100 [00:04<00:06,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:34,387] Trial 36 finished with value: 0.8439495798319328 and parameters: {'max_features': None, 'n_estimators': 60, 'learning_rate': 0.017043841968654466, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8048665773517084}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:34,495] Trial 37 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.08021299192608095, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.5827900714147162}. Best is trial 32 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.865798:  40%|████      | 40/100 [00:05<00:07,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:34,608] Trial 38 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.03621940543594962, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.6302647942138906}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:34,757] Trial 39 finished with value: 0.8439635854341738 and parameters: {'max_features': None, 'n_estimators': 79, 'learning_rate': 0.046083854687159066, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.8836454504869727}. Best is trial 32 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.865798:  42%|████▏     | 42/100 [00:05<00:06,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:34,836] Trial 40 finished with value: 0.8473109243697479 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.009960813548726102, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.5208014800665194}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:34,989] Trial 41 finished with value: 0.8573809523809525 and parameters: {'max_features': 'sqrt', 'n_estimators': 87, 'learning_rate': 0.04848155042753175, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7221601788782247}. Best is trial 32 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.865798:  44%|████▍     | 44/100 [00:05<00:06,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:35,112] Trial 42 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.034748828338556616, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.7004729745264185}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:35,216] Trial 43 finished with value: 0.862450980392157 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.07036077957409849, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7692124523863746}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:35,311] Trial 44 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 70, 'learning_rate': 0.07373573250735048, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7580255835149641}. Best is trial 32 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.865798:  48%|████▊     | 48/100 [00:05<00:05,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:35,431] Trial 45 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.026219240016145326, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7793889058393713}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:35,524] Trial 46 finished with value: 0.8557002801120447 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.09782152832005259, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.8244923917789724}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:35,619] Trial 47 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.03804104838671349, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.8711640681706166}. Best is trial 32 with value: 0.865798319327731.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  50%|█████     | 50/100 [00:06<00:04, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:35,697] Trial 48 finished with value: 0.6693837535014007 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.001684850686429211, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.6168186680216196}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:35,796] Trial 49 finished with value: 0.8523529411764705 and parameters: {'max_features': 'log2', 'n_estimators': 38, 'learning_rate': 0.021679873827209692, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.9652742867089056}. Best is trial 32 with value: 0.865798319327731.\n",
      "[I 2025-11-06 03:26:35,879] Trial 50 finished with value: 0.8708123249299721 and parameters: {'max_features': 'sqrt', 'n_estimators': 96, 'learning_rate': 0.054180144140120005, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.6630138018155808}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  53%|█████▎    | 53/100 [00:06<00:04,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:36,004] Trial 51 finished with value: 0.8590896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 96, 'learning_rate': 0.05426206793852861, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.6647208219432589}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:36,121] Trial 52 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.07600266983711466, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.7388557481830393}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  56%|█████▌    | 56/100 [00:06<00:04, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:36,224] Trial 53 finished with value: 0.8473109243697478 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.041429012576456016, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7888996701160418}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:36,315] Trial 54 finished with value: 0.854033613445378 and parameters: {'max_features': 'sqrt', 'n_estimators': 96, 'learning_rate': 0.032230582471315466, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.7608712362641558}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:36,408] Trial 55 finished with value: 0.8641176470588234 and parameters: {'max_features': 'sqrt', 'n_estimators': 76, 'learning_rate': 0.05140414503917157, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7202858728190467}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  58%|█████▊    | 58/100 [00:07<00:04,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:36,521] Trial 56 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.06825932159386326, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.72090447860332}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:36,635] Trial 57 finished with value: 0.8473249299719889 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.003038408474883655, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.8429830091886441}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:36,719] Trial 58 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.0887943664537212, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.687919241175891}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  61%|██████    | 61/100 [00:07<00:04,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:36,833] Trial 59 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.055204686852344066, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7131860349255719}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:36,981] Trial 60 finished with value: 0.842282913165266 and parameters: {'max_features': None, 'n_estimators': 93, 'learning_rate': 0.005500815553529528, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6712303259815854}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  63%|██████▎   | 63/100 [00:07<00:04,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:37,089] Trial 61 finished with value: 0.8657843137254903 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.05236806369146034, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7106078209715436}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:37,218] Trial 62 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 88, 'learning_rate': 0.050231401035256494, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7291918501037301}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  65%|██████▌   | 65/100 [00:07<00:04,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:37,363] Trial 63 finished with value: 0.850672268907563 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.042018118275034225, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.643604632317173}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:37,477] Trial 64 finished with value: 0.8523669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.0638030932390806, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.7022610599768222}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  67%|██████▋   | 67/100 [00:08<00:04,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:37,670] Trial 65 finished with value: 0.8657983193277312 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.08438763559799105, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7481394344228249}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:37,827] Trial 66 finished with value: 0.8590896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.08679940108870791, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7563862374864693}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  69%|██████▉   | 69/100 [00:08<00:04,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:38,045] Trial 67 finished with value: 0.8590336134453782 and parameters: {'max_features': 'log2', 'n_estimators': 97, 'learning_rate': 0.09970675885126178, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.789973162504724}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:38,189] Trial 68 finished with value: 0.8473249299719889 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.07150498310081782, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7706604261357785}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  71%|███████   | 71/100 [00:08<00:04,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:38,323] Trial 69 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.057422889066578865, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.8169050827297789}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:38,458] Trial 70 finished with value: 0.8573809523809525 and parameters: {'max_features': 'sqrt', 'n_estimators': 87, 'learning_rate': 0.08156906680756895, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6778528192071884}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  73%|███████▎  | 73/100 [00:09<00:03,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:38,583] Trial 71 finished with value: 0.8641036414565827 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.04402919273279465, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.7049203445082161}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:38,728] Trial 72 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.062023005946969516, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.7425085225591311}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  75%|███████▌  | 75/100 [00:09<00:03,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:38,907] Trial 73 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 92, 'learning_rate': 0.02981423560274286, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.7089305426144833}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:39,053] Trial 74 finished with value: 0.8573949579831934 and parameters: {'max_features': 'sqrt', 'n_estimators': 98, 'learning_rate': 0.05185179718770824, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7999578702596333}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  77%|███████▋  | 77/100 [00:09<00:03,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:39,191] Trial 75 finished with value: 0.8641176470588234 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.041462720889086854, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.7490874911601403}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:39,325] Trial 76 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.04003101468012454, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.6485986156771009}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  79%|███████▉  | 79/100 [00:09<00:02,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:39,430] Trial 77 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 61, 'learning_rate': 0.00110480519741112, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7493922352543096}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:39,537] Trial 78 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.03353334354749079, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.6946760766301525}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  81%|████████  | 81/100 [00:10<00:02,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:39,665] Trial 79 finished with value: 0.8607563025210083 and parameters: {'max_features': None, 'n_estimators': 71, 'learning_rate': 0.047467440369737775, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.6849581858919055}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:39,812] Trial 80 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.020371383441077053, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.729063254520304}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  82%|████████▏ | 82/100 [00:10<00:02,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:40,020] Trial 81 finished with value: 0.8573669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 89, 'learning_rate': 0.06965271354737577, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7591283841773488}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  84%|████████▍ | 84/100 [00:10<00:02,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:40,356] Trial 82 finished with value: 0.8523809523809526 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.05910396505178538, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.7707538511193733}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:40,473] Trial 83 finished with value: 0.8607422969187676 and parameters: {'max_features': 'sqrt', 'n_estimators': 73, 'learning_rate': 0.03828458884149859, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7166917128824416}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  85%|████████▌ | 85/100 [00:10<00:02,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:40,579] Trial 84 finished with value: 0.8523669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.05084921293881153, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.7453583350797471}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:40,677] Trial 85 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.043443552588327536, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.7972235950368479}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  88%|████████▊ | 88/100 [00:11<00:01,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:40,853] Trial 86 finished with value: 0.8573809523809525 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.08111190603964645, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.8352454983709849}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:40,992] Trial 87 finished with value: 0.8523529411764705 and parameters: {'max_features': 'log2', 'n_estimators': 78, 'learning_rate': 0.015336059948457034, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6130281990066051}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  90%|█████████ | 90/100 [00:11<00:01,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:41,088] Trial 88 finished with value: 0.862450980392157 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.09045831330864404, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.7705854881657994}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:41,224] Trial 89 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 98, 'learning_rate': 0.02390437707105367, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.706281692153831}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  92%|█████████▏| 92/100 [00:11<00:01,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:41,393] Trial 90 finished with value: 0.850686274509804 and parameters: {'max_features': 'sqrt', 'n_estimators': 94, 'learning_rate': 0.00781680571236978, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.5681598014685998}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:41,525] Trial 91 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.06574054327021286, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7699074104450954}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  94%|█████████▍| 94/100 [00:12<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:41,670] Trial 92 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.09513366501772057, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.812040862512819}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:41,797] Trial 93 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 92, 'learning_rate': 0.07694880472323223, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.7374483638165427}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  96%|█████████▌| 96/100 [00:12<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:41,916] Trial 94 finished with value: 0.8657843137254903 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.08893297965656974, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.7800712765275872}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:42,042] Trial 95 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.05854558950697988, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.789819182907331}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812:  98%|█████████▊| 98/100 [00:12<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:42,189] Trial 96 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.03555713664974279, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7270910159859596}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:42,348] Trial 97 finished with value: 0.850658263305322 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.04580183146734926, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.7537590650531004}. Best is trial 50 with value: 0.8708123249299721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 50. Best value: 0.870812: 100%|██████████| 100/100 [00:12<00:00,  7.78it/s]\n",
      "Best trial: 50. Best value: 0.870812: 100%|██████████| 100/100 [00:12<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:42,496] Trial 98 finished with value: 0.845658263305322 and parameters: {'max_features': 'sqrt', 'n_estimators': 75, 'learning_rate': 0.07218572461419843, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8251584346921869}. Best is trial 50 with value: 0.8708123249299721.\n",
      "[I 2025-11-06 03:26:42,534] Trial 99 finished with value: 0.8422969187675069 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.0845796017372293, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.6782523593167542}. Best is trial 50 with value: 0.8708123249299721.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using TPESampler: {'max_features': 'sqrt', 'n_estimators': 96, 'learning_rate': 0.054180144140120005, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.6630138018155808}\n",
      "Best accuracy: 0.8708, at trial: 50\n",
      "TPE Base Models Training Time: 47.76 seconds\n",
      "TPE Base Models Training Time: 47.76 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_base_models_training_start = time.time()\n",
    "\n",
    "    # TPE Hyperparameter Tuning with Cross Validation\n",
    "    tpe_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    tpe_logistic_regression.fit(X_train, y_train)\n",
    "    tpe_decision_tree.fit(X_train, y_train)\n",
    "    tpe_random_forest.fit(X_train, y_train)\n",
    "    tpe_knn.fit(X_train, y_train)\n",
    "    tpe_svc.fit(X_train, y_train)\n",
    "    tpe_adaboost.fit(X_train, y_train)\n",
    "    tpe_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    tpe_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE base models training\n",
    "    tpe_base_models_training_time = tpe_base_models_training_end - tpe_base_models_training_start\n",
    "    print(f'TPE Base Models Training Time: {tpe_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping TPE base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:26:48,606] A new study created in memory with name: Logistic Regression Model Fine Tuning with GPSampler\n",
      "Best trial: 4. Best value: 0.843908:   6%|▌         | 6/100 [00:00<00:02, 36.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:48,632] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:26:48,657] Trial 1 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-11-06 03:26:48,691] Trial 2 finished with value: 0.5704481792717087 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-11-06 03:26:48,716] Trial 3 finished with value: 0.8288375350140056 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-11-06 03:26:48,741] Trial 4 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:26:48,776] Trial 5 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:26:48,826] Trial 6 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.843908:   9%|▉         | 9/100 [00:00<00:02, 30.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:48,861] Trial 7 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:26:48,887] Trial 8 finished with value: 0.8087254901960785 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-11-06 03:26:48,912] Trial 9 finished with value: 0.5888795518207283 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.843908:  10%|█         | 10/100 [00:03<00:02, 30.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:52,291] Trial 10 finished with value: 0.8422268907563024 and parameters: {'solver': 'sag', 'C': 0.018417084349358723}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.843908:  12%|█▏        | 12/100 [00:08<01:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:26:56,761] Trial 11 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 0.015696165881354737}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.843908:  12%|█▏        | 12/100 [00:11<01:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:00,240] Trial 12 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 1.074326851683653}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.843908:  14%|█▍        | 14/100 [00:13<02:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:02,535] Trial 13 finished with value: 0.8304901960784313 and parameters: {'solver': 'sag', 'C': 0.006083280540299024}. Best is trial 4 with value: 0.84390756302521.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.845616:  14%|█▍        | 14/100 [00:15<02:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:04,561] Trial 14 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.09010567835308779}. Best is trial 14 with value: 0.8456162464985993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.845616:  16%|█▌        | 16/100 [00:17<02:11,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:06,569] Trial 15 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 0.6008632954775631}. Best is trial 14 with value: 0.8456162464985993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.845616:  17%|█▋        | 17/100 [00:19<02:08,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:08,065] Trial 16 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 0.46070611208585377}. Best is trial 14 with value: 0.8456162464985993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.845616:  19%|█▉        | 19/100 [00:21<01:40,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:09,576] Trial 17 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 9.999999999999993}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-11-06 03:27:09,676] Trial 18 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 9.999999999999993}. Best is trial 14 with value: 0.8456162464985993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.845616:  21%|██        | 21/100 [00:21<01:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:09,800] Trial 19 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.050191213912528725}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-11-06 03:27:09,904] Trial 20 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 2.769173067714974}. Best is trial 14 with value: 0.8456162464985993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.847269:  23%|██▎       | 23/100 [00:21<00:35,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:10,024] Trial 21 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.1473353251482281}. Best is trial 21 with value: 0.8456302521008403.\n",
      "[I 2025-11-06 03:27:10,127] Trial 22 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.03738257527308778}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:27:10,210] Trial 23 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.0715869774323177}. Best is trial 22 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.847269:  26%|██▌       | 26/100 [00:21<00:19,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:10,345] Trial 24 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.22944176789209383}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:27:10,459] Trial 25 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 4.978284159295906}. Best is trial 22 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.847269:  28%|██▊       | 28/100 [00:22<00:14,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:10,601] Trial 26 finished with value: 0.835546218487395 and parameters: {'solver': 'sag', 'C': 0.003351695813870593}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:27:10,705] Trial 27 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03847872078500744}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:27:10,800] Trial 28 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cholesky', 'C': 0.140545846623691}. Best is trial 22 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.847269:  30%|███       | 30/100 [00:22<00:10,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:10,902] Trial 29 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 1.8759392041658183}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:27:10,994] Trial 30 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06782824069731738}. Best is trial 22 with value: 0.8472689075630251.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  34%|███▍      | 34/100 [00:22<00:07,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:11,106] Trial 31 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.03386908840269092}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:27:11,196] Trial 32 finished with value: 0.8456302521008403 and parameters: {'solver': 'sag', 'C': 0.16016997560597576}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-11-06 03:27:11,291] Trial 33 finished with value: 0.8472689075630253 and parameters: {'solver': 'newton-cholesky', 'C': 0.02891295150832041}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  36%|███▌      | 36/100 [00:22<00:07,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:11,422] Trial 34 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.025145170079241295}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:11,531] Trial 35 finished with value: 0.8472689075630253 and parameters: {'solver': 'lbfgs', 'C': 0.029343585104900878}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  38%|███▊      | 38/100 [00:23<00:06,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:11,628] Trial 36 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.24375322212703046}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:11,736] Trial 37 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 9.973531625144435}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  40%|████      | 40/100 [00:23<00:06,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:11,829] Trial 38 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.10704669971135193}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:11,947] Trial 39 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 1.1407558018759867}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  42%|████▏     | 42/100 [00:23<00:06,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:12,056] Trial 40 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.20546121451525162}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:12,178] Trial 41 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.08586395933072768}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  44%|████▍     | 44/100 [00:23<00:06,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:12,285] Trial 42 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.055778466933647936}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:12,398] Trial 43 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.046745732139246564}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  46%|████▌     | 46/100 [00:24<00:05,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:12,495] Trial 44 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.032772102424213925}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:12,608] Trial 45 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.03466313251170192}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  48%|████▊     | 48/100 [00:24<00:05,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:12,712] Trial 46 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.02462267397892108}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:12,836] Trial 47 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.045021639068542244}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  50%|█████     | 50/100 [00:24<00:05,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:12,936] Trial 48 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.03261333507552999}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:13,038] Trial 49 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 2.1472364783337987}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  52%|█████▏    | 52/100 [00:24<00:05,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:13,139] Trial 50 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.061998279409119075}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:13,246] Trial 51 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.13974878110132358}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  55%|█████▌    | 55/100 [00:24<00:04,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:13,351] Trial 52 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.045571823838192915}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:13,448] Trial 53 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 3.9691899518191813}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:13,538] Trial 54 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.049994212880943474}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  57%|█████▋    | 57/100 [00:25<00:04,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:13,651] Trial 55 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.10407653010263498}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:13,760] Trial 56 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026206480104668264}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  59%|█████▉    | 59/100 [00:25<00:04,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:13,859] Trial 57 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02637006917736786}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:13,962] Trial 58 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026424613981005117}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  61%|██████    | 61/100 [00:25<00:04,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:14,065] Trial 59 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026437290019611617}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:14,180] Trial 60 finished with value: 0.8456302521008403 and parameters: {'solver': 'sag', 'C': 0.24319806018481982}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  63%|██████▎   | 63/100 [00:25<00:03,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:14,278] Trial 61 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02643864825203037}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:14,381] Trial 62 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026412269884377188}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:14,478] Trial 63 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026380543262900475}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  66%|██████▌   | 66/100 [00:26<00:03,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:14,631] Trial 64 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026344082254932847}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:14,766] Trial 65 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026308791781855176}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  68%|██████▊   | 68/100 [00:26<00:03,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:14,887] Trial 66 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02626803713060258}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:15,015] Trial 67 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026387451518210002}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  70%|███████   | 70/100 [00:26<00:03,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:15,121] Trial 68 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026518631083500433}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:15,253] Trial 69 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.02654372715476297}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  71%|███████   | 71/100 [00:26<00:03,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:15,355] Trial 70 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026554445007632658}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:15,447] Trial 71 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.02656043582580038}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  74%|███████▍  | 74/100 [00:27<00:02,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:15,566] Trial 72 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026566313316824058}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:15,687] Trial 73 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cg', 'C': 0.31751141012738765}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  76%|███████▌  | 76/100 [00:27<00:02,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:15,808] Trial 74 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1953340999794254}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:15,951] Trial 75 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026783829681213553}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  78%|███████▊  | 78/100 [00:27<00:02,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:16,080] Trial 76 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026196664206369024}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:16,206] Trial 77 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026861132122876538}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  80%|████████  | 80/100 [00:27<00:02,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:16,378] Trial 78 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02653410301884969}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:16,507] Trial 79 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 6.93056057187548}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  82%|████████▏ | 82/100 [00:28<00:02,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:16,720] Trial 80 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02663270136857549}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:16,876] Trial 81 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.027071274944559735}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  84%|████████▍ | 84/100 [00:28<00:02,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:17,050] Trial 82 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026847532731474846}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:17,182] Trial 83 finished with value: 0.83890756302521 and parameters: {'solver': 'sag', 'C': 0.8477344030343167}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  86%|████████▌ | 86/100 [00:28<00:02,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:17,357] Trial 84 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.027171005094309777}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:17,487] Trial 85 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025468632258231552}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  88%|████████▊ | 88/100 [00:29<00:01,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:17,642] Trial 86 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02557041446964749}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:17,792] Trial 87 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02566178152866987}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  90%|█████████ | 90/100 [00:29<00:01,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:17,900] Trial 88 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025749612311445177}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:18,046] Trial 89 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025835839471059642}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  92%|█████████▏| 92/100 [00:29<00:01,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:18,180] Trial 90 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025928981632315763}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:18,319] Trial 91 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02601924445954526}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  94%|█████████▍| 94/100 [00:30<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:18,493] Trial 92 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026116608155004238}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:18,648] Trial 93 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026186421317371884}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  96%|█████████▌| 96/100 [00:30<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:18,776] Trial 94 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026264138637030202}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:18,928] Trial 95 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026301121688643132}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  97%|█████████▋| 97/100 [00:30<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:19,097] Trial 96 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.11365711415192098}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269:  99%|█████████▉| 99/100 [00:30<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:19,305] Trial 97 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.02490655061875848}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-11-06 03:27:19,427] Trial 98 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02707814779720893}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.847269: 100%|██████████| 100/100 [00:30<00:00,  3.23it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:27:19,563] A new study created in memory with name: Decision Tree Model Fine Tuning with GPSampler\n",
      "Best trial: 33. Best value: 0.847269: 100%|██████████| 100/100 [00:30<00:00,  3.23it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:27:19,563] A new study created in memory with name: Decision Tree Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:19,560] Trial 99 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.027047234336771284}. Best is trial 33 with value: 0.8472689075630253.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using GPSampler: {'solver': 'newton-cholesky', 'C': 0.02891295150832041}\n",
      "Best accuracy: 0.8473, at trial: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:   8%|▊         | 8/100 [00:00<00:02, 33.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:19,597] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[I 2025-11-06 03:27:19,621] Trial 1 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,656] Trial 2 finished with value: 0.807044817927171 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,681] Trial 3 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,696] Trial 4 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,710] Trial 5 finished with value: 0.8070448179271708 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,725] Trial 6 finished with value: 0.8272128851540617 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,739] Trial 7 finished with value: 0.8036974789915966 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,754] Trial 8 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:   9%|▉         | 9/100 [00:00<00:02, 33.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:19,769] Trial 9 finished with value: 0.8002941176470589 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:  11%|█         | 11/100 [00:00<00:02, 41.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:19,836] Trial 10 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:19,901] Trial 11 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:  12%|█▏        | 12/100 [00:00<00:02, 41.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:19,979] Trial 12 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:  14%|█▍        | 14/100 [00:00<00:02, 41.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,056] Trial 13 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:20,116] Trial 14 finished with value: 0.8204901960784312 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.842311:  16%|█▌        | 16/100 [00:00<00:03, 23.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,181] Trial 15 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-11-06 03:27:20,239] Trial 16 finished with value: 0.8255322128851541 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847311:  19%|█▉        | 19/100 [00:00<00:03, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,306] Trial 17 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 17 with value: 0.8439775910364145.\n",
      "[I 2025-11-06 03:27:20,371] Trial 18 finished with value: 0.8473109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 18 with value: 0.8473109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847311:  20%|██        | 20/100 [00:00<00:03, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,437] Trial 19 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.8473109243697479.\n",
      "[I 2025-11-06 03:27:20,497] Trial 20 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 18 with value: 0.8473109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.847311:  22%|██▏       | 22/100 [00:01<00:04, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,578] Trial 21 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 18 with value: 0.8473109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  23%|██▎       | 23/100 [00:01<00:04, 18.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,668] Trial 22 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 18 with value: 0.8473109243697479.\n",
      "[I 2025-11-06 03:27:20,731] Trial 23 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  25%|██▌       | 25/100 [00:01<00:04, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,786] Trial 24 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:20,844] Trial 25 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  27%|██▋       | 27/100 [00:01<00:04, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:20,895] Trial 26 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:20,946] Trial 27 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  29%|██▉       | 29/100 [00:01<00:04, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:21,002] Trial 28 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,058] Trial 29 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  31%|███       | 31/100 [00:01<00:03, 17.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:21,115] Trial 30 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,172] Trial 31 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  33%|███▎      | 33/100 [00:01<00:04, 15.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:21,288] Trial 32 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  35%|███▌      | 35/100 [00:01<00:04, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:21,344] Trial 33 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,400] Trial 34 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,464] Trial 35 finished with value: 0.7969467787114846 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  37%|███▋      | 37/100 [00:01<00:03, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:21,530] Trial 36 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  39%|███▉      | 39/100 [00:02<00:03, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:21,589] Trial 37 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,647] Trial 38 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,727] Trial 39 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  43%|████▎     | 43/100 [00:02<00:03, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:21,800] Trial 40 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,858] Trial 41 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,913] Trial 42 finished with value: 0.8104621848739495 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:21,975] Trial 43 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  47%|████▋     | 47/100 [00:02<00:03, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:22,038] Trial 44 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,104] Trial 45 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,174] Trial 46 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  49%|████▉     | 49/100 [00:02<00:03, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:22,244] Trial 47 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,346] Trial 48 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,423] Trial 49 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  53%|█████▎    | 53/100 [00:03<00:03, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:22,494] Trial 50 finished with value: 0.8389215686274509 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,567] Trial 51 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,646] Trial 52 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  55%|█████▌    | 55/100 [00:03<00:03, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:22,720] Trial 53 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,788] Trial 54 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:22,858] Trial 55 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  59%|█████▉    | 59/100 [00:03<00:03, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:22,935] Trial 56 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,014] Trial 57 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,093] Trial 58 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  61%|██████    | 61/100 [00:03<00:02, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:23,184] Trial 59 finished with value: 0.7987254901960783 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,256] Trial 60 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,335] Trial 61 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  65%|██████▌   | 65/100 [00:03<00:02, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:23,407] Trial 62 finished with value: 0.8222128851540618 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,479] Trial 63 finished with value: 0.8138375350140056 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,552] Trial 64 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  67%|██████▋   | 67/100 [00:04<00:02, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:23,629] Trial 65 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,702] Trial 66 finished with value: 0.8422969187675069 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,787] Trial 67 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  71%|███████   | 71/100 [00:04<00:02, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:23,868] Trial 68 finished with value: 0.8188235294117646 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:23,950] Trial 69 finished with value: 0.8255322128851541 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,032] Trial 70 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  73%|███████▎  | 73/100 [00:04<00:02, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:24,113] Trial 71 finished with value: 0.8020028011204481 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,194] Trial 72 finished with value: 0.7936274509803921 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,275] Trial 73 finished with value: 0.8372829131652659 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  77%|███████▋  | 77/100 [00:04<00:01, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:24,354] Trial 74 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,435] Trial 75 finished with value: 0.8372829131652659 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,515] Trial 76 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  79%|███████▉  | 79/100 [00:05<00:01, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:24,591] Trial 77 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,666] Trial 78 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,747] Trial 79 finished with value: 0.8422969187675069 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  83%|████████▎ | 83/100 [00:05<00:01, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:24,826] Trial 80 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,903] Trial 81 finished with value: 0.8020308123249299 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:24,986] Trial 82 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  85%|████████▌ | 85/100 [00:05<00:01, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:25,065] Trial 83 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,150] Trial 84 finished with value: 0.8171148459383752 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,243] Trial 85 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  89%|████████▉ | 89/100 [00:05<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:25,339] Trial 86 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,413] Trial 87 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,487] Trial 88 finished with value: 0.8322408963585433 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  91%|█████████ | 91/100 [00:06<00:00, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:25,570] Trial 89 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,648] Trial 90 finished with value: 0.8389495798319327 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,731] Trial 91 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  95%|█████████▌| 95/100 [00:06<00:00, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:25,803] Trial 92 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,881] Trial 93 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:25,961] Trial 94 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507:  97%|█████████▋| 97/100 [00:06<00:00, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:26,040] Trial 95 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:26,122] Trial 96 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:26,202] Trial 97 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.8507: 100%|██████████| 100/100 [00:06<00:00, 14.70it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:27:26,366] A new study created in memory with name: Random Forest Model Fine Tuning with GPSampler\n",
      "Best trial: 23. Best value: 0.8507: 100%|██████████| 100/100 [00:06<00:00, 14.70it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:27:26,366] A new study created in memory with name: Random Forest Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:26,283] Trial 98 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-11-06 03:27:26,363] Trial 99 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using GPSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}\n",
      "Best accuracy: 0.8507, at trial: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.845658:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:26,430] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.848992:   2%|▏         | 2/100 [00:00<00:07, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:26,525] Trial 1 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8489915966386554.\n",
      "[I 2025-11-06 03:27:26,611] Trial 2 finished with value: 0.8288655462184874 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8489915966386554.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   4%|▍         | 4/100 [00:00<00:07, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:26,686] Trial 3 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   6%|▌         | 6/100 [00:00<00:06, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:26,762] Trial 4 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:27:26,817] Trial 5 finished with value: 0.842282913165266 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:27:26,884] Trial 6 finished with value: 0.8355882352941176 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:   8%|▊         | 8/100 [00:00<00:07, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:27,021] Trial 7 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:27:27,159] Trial 8 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  10%|█         | 10/100 [00:00<00:08, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:27,265] Trial 9 finished with value: 0.8489775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  12%|█▏        | 12/100 [00:01<00:12,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:27,531] Trial 10 finished with value: 0.8456582633053223 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:27:27,716] Trial 11 finished with value: 0.8439635854341738 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 26, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  13%|█▎        | 13/100 [00:01<00:13,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:27,921] Trial 12 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  14%|█▍        | 14/100 [00:01<00:14,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:28,130] Trial 13 finished with value: 0.842296918767507 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 14, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  15%|█▌        | 15/100 [00:02<00:15,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:28,366] Trial 14 finished with value: 0.8490056022408965 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  16%|█▌        | 16/100 [00:02<00:16,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:28,605] Trial 15 finished with value: 0.8473529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  17%|█▋        | 17/100 [00:02<00:18,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:28,885] Trial 16 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  18%|█▊        | 18/100 [00:02<00:17,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:29,096] Trial 17 finished with value: 0.8490056022408965 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.852353:  19%|█▉        | 19/100 [00:02<00:17,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:29,299] Trial 18 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  20%|██        | 20/100 [00:03<00:18,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:29,555] Trial 19 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  21%|██        | 21/100 [00:03<00:18,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:29,816] Trial 20 finished with value: 0.8490196078431375 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  22%|██▏       | 22/100 [00:03<00:19,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:30,096] Trial 21 finished with value: 0.8573669467787115 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  23%|██▎       | 23/100 [00:04<00:19,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:30,379] Trial 22 finished with value: 0.8540476190476189 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 79, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  24%|██▍       | 24/100 [00:04<00:19,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:30,618] Trial 23 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  25%|██▌       | 25/100 [00:04<00:18,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:30,870] Trial 24 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  26%|██▌       | 26/100 [00:04<00:18,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:31,122] Trial 25 finished with value: 0.8473109243697478 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  27%|██▋       | 27/100 [00:05<00:19,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:31,434] Trial 26 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  28%|██▊       | 28/100 [00:05<00:18,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:31,659] Trial 27 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  29%|██▉       | 29/100 [00:05<00:19,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:31,962] Trial 28 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  30%|███       | 30/100 [00:05<00:18,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:32,225] Trial 29 finished with value: 0.850658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.857367:  31%|███       | 31/100 [00:06<00:18,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:32,507] Trial 30 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 21 with value: 0.8573669467787115.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  32%|███▏      | 32/100 [00:06<00:17,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:32,739] Trial 31 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  33%|███▎      | 33/100 [00:06<00:16,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:32,959] Trial 32 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  34%|███▍      | 34/100 [00:06<00:16,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:33,219] Trial 33 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 76, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  35%|███▌      | 35/100 [00:07<00:16,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:33,468] Trial 34 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  37%|███▋      | 37/100 [00:07<00:15,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:33,762] Trial 35 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-11-06 03:27:33,954] Trial 36 finished with value: 0.8422829131652663 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  38%|███▊      | 38/100 [00:07<00:15,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:34,224] Trial 37 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  39%|███▉      | 39/100 [00:08<00:16,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:34,521] Trial 38 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  40%|████      | 40/100 [00:08<00:16,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:34,797] Trial 39 finished with value: 0.8523389355742296 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  41%|████      | 41/100 [00:08<00:15,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:35,058] Trial 40 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.857395:  42%|████▏     | 42/100 [00:08<00:14,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:35,287] Trial 41 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  43%|████▎     | 43/100 [00:09<00:14,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:35,555] Trial 42 finished with value: 0.8590756302521008 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  44%|████▍     | 44/100 [00:09<00:14,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:35,842] Trial 43 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  45%|████▌     | 45/100 [00:09<00:14,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:36,119] Trial 44 finished with value: 0.8557142857142856 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  46%|████▌     | 46/100 [00:10<00:14,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:36,383] Trial 45 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  47%|████▋     | 47/100 [00:10<00:13,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:36,622] Trial 46 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  48%|████▊     | 48/100 [00:10<00:13,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:36,884] Trial 47 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  49%|████▉     | 49/100 [00:10<00:13,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:37,133] Trial 48 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  50%|█████     | 50/100 [00:11<00:13,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:37,435] Trial 49 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  51%|█████     | 51/100 [00:11<00:13,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:37,710] Trial 50 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  52%|█████▏    | 52/100 [00:11<00:12,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:37,969] Trial 51 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  53%|█████▎    | 53/100 [00:11<00:12,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:38,200] Trial 52 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  54%|█████▍    | 54/100 [00:12<00:12,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:38,472] Trial 53 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  55%|█████▌    | 55/100 [00:12<00:12,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:38,783] Trial 54 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  56%|█████▌    | 56/100 [00:12<00:12,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:39,064] Trial 55 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  57%|█████▋    | 57/100 [00:12<00:11,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:39,342] Trial 56 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.859076:  58%|█████▊    | 58/100 [00:13<00:11,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:39,624] Trial 57 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 42 with value: 0.8590756302521008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.860784:  59%|█████▉    | 59/100 [00:13<00:10,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:39,855] Trial 58 finished with value: 0.8607843137254904 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 58 with value: 0.8607843137254904.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.860784:  60%|██████    | 60/100 [00:13<00:10,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:40,074] Trial 59 finished with value: 0.8591036414565826 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 58 with value: 0.8607843137254904.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  61%|██████    | 61/100 [00:13<00:09,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:40,322] Trial 60 finished with value: 0.862450980392157 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  62%|██████▏   | 62/100 [00:14<00:09,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:40,603] Trial 61 finished with value: 0.8590896358543418 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  63%|██████▎   | 63/100 [00:14<00:09,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:40,871] Trial 62 finished with value: 0.8456442577030814 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  64%|██████▍   | 64/100 [00:14<00:09,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:41,184] Trial 63 finished with value: 0.8473389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  65%|██████▌   | 65/100 [00:15<00:09,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:41,488] Trial 64 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  66%|██████▌   | 66/100 [00:15<00:09,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:41,740] Trial 65 finished with value: 0.862450980392157 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  67%|██████▋   | 67/100 [00:15<00:08,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:41,996] Trial 66 finished with value: 0.8591036414565828 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  68%|██████▊   | 68/100 [00:15<00:08,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:42,269] Trial 67 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 69, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  69%|██████▉   | 69/100 [00:16<00:08,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:42,568] Trial 68 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  70%|███████   | 70/100 [00:16<00:08,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:42,833] Trial 69 finished with value: 0.8339495798319326 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 74, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  71%|███████   | 71/100 [00:16<00:08,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:43,140] Trial 70 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  72%|███████▏  | 72/100 [00:17<00:08,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:43,475] Trial 71 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  73%|███████▎  | 73/100 [00:17<00:07,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:43,695] Trial 72 finished with value: 0.8574089635854343 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 44, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  75%|███████▌  | 75/100 [00:17<00:06,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:43,982] Trial 73 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-11-06 03:27:44,172] Trial 74 finished with value: 0.8574089635854343 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  76%|███████▌  | 76/100 [00:18<00:06,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:44,494] Trial 75 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  77%|███████▋  | 77/100 [00:18<00:06,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:44,728] Trial 76 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 28, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  78%|███████▊  | 78/100 [00:18<00:05,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:44,992] Trial 77 finished with value: 0.8590896358543418 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  80%|████████  | 80/100 [00:19<00:04,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:45,278] Trial 78 finished with value: 0.8439635854341738 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-11-06 03:27:45,456] Trial 79 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  82%|████████▏ | 82/100 [00:19<00:03,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:45,658] Trial 80 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-11-06 03:27:45,836] Trial 81 finished with value: 0.8406022408963585 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  83%|████████▎ | 83/100 [00:19<00:03,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:46,097] Trial 82 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 45, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  84%|████████▍ | 84/100 [00:20<00:03,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:46,371] Trial 83 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  85%|████████▌ | 85/100 [00:20<00:03,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:46,623] Trial 84 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  86%|████████▌ | 86/100 [00:20<00:03,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:46,854] Trial 85 finished with value: 0.8439775910364145 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  87%|████████▋ | 87/100 [00:20<00:03,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:47,164] Trial 86 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  88%|████████▊ | 88/100 [00:21<00:03,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:47,445] Trial 87 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  89%|████████▉ | 89/100 [00:21<00:02,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:47,705] Trial 88 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  90%|█████████ | 90/100 [00:21<00:02,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:48,045] Trial 89 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  91%|█████████ | 91/100 [00:22<00:02,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:48,433] Trial 90 finished with value: 0.8339075630252101 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  92%|█████████▏| 92/100 [00:22<00:02,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:48,790] Trial 91 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  93%|█████████▎| 93/100 [00:22<00:02,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:49,098] Trial 92 finished with value: 0.8456582633053221 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  94%|█████████▍| 94/100 [00:23<00:02,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:49,481] Trial 93 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  95%|█████████▌| 95/100 [00:23<00:01,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:49,835] Trial 94 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  96%|█████████▌| 96/100 [00:23<00:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:50,209] Trial 95 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  97%|█████████▋| 97/100 [00:24<00:01,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:50,558] Trial 96 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  98%|█████████▊| 98/100 [00:24<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:50,821] Trial 97 finished with value: 0.8473249299719889 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451:  99%|█████████▉| 99/100 [00:24<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:51,166] Trial 98 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.862451: 100%|██████████| 100/100 [00:25<00:00,  3.98it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:27:51,487] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with GPSampler\n",
      "Best trial: 60. Best value: 0.862451: 100%|██████████| 100/100 [00:25<00:00,  3.98it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:27:51,487] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:51,482] Trial 99 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using GPSampler: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "Best accuracy: 0.8625, at trial: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.848992:   2%|▏         | 2/100 [00:00<00:05, 16.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:51,543] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[I 2025-11-06 03:27:51,604] Trial 1 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:27:51,652] Trial 2 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.848992:   5%|▌         | 5/100 [00:00<00:04, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:51,698] Trial 3 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:27:51,734] Trial 4 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.8507:   8%|▊         | 8/100 [00:00<00:03, 23.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:51,770] Trial 5 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:27:51,805] Trial 6 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-11-06 03:27:51,841] Trial 7 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-11-06 03:27:51,878] Trial 8 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.8507:   9%|▉         | 9/100 [00:00<00:03, 23.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:51,913] Trial 9 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  11%|█         | 11/100 [00:00<00:04, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:52,031] Trial 10 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  12%|█▏        | 12/100 [00:00<00:04, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:52,128] Trial 11 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:52,219] Trial 12 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  14%|█▍        | 14/100 [00:00<00:05, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:52,312] Trial 13 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  16%|█▌        | 16/100 [00:01<00:06, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:52,410] Trial 14 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:52,503] Trial 15 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  16%|█▌        | 16/100 [00:01<00:06, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:52,605] Trial 16 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  18%|█▊        | 18/100 [00:01<00:06, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:52,683] Trial 17 finished with value: 0.8271008403361346 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:52,802] Trial 18 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  20%|██        | 20/100 [00:01<00:06, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:52,900] Trial 19 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:53,007] Trial 20 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  24%|██▍       | 24/100 [00:01<00:07,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:53,191] Trial 21 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:53,296] Trial 22 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 22, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:53,383] Trial 23 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  26%|██▌       | 26/100 [00:02<00:07,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:53,514] Trial 24 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:53,610] Trial 25 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  28%|██▊       | 28/100 [00:02<00:07,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:53,715] Trial 26 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:53,823] Trial 27 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  31%|███       | 31/100 [00:02<00:07,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:53,936] Trial 28 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:54,028] Trial 29 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:54,126] Trial 30 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  33%|███▎      | 33/100 [00:02<00:07,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:54,262] Trial 31 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:54,368] Trial 32 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:54,459] Trial 33 finished with value: 0.850686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  36%|███▌      | 36/100 [00:03<00:06,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:54,564] Trial 34 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:54,676] Trial 35 finished with value: 0.845658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  37%|███▋      | 37/100 [00:03<00:06,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:54,779] Trial 36 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:54,869] Trial 37 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  40%|████      | 40/100 [00:03<00:07,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:55,062] Trial 38 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:55,180] Trial 39 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  42%|████▏     | 42/100 [00:03<00:06,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:55,293] Trial 40 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:55,400] Trial 41 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 11, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  44%|████▍     | 44/100 [00:04<00:06,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:55,510] Trial 42 finished with value: 0.8506862745098038 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:55,627] Trial 43 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  46%|████▌     | 46/100 [00:04<00:06,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:55,752] Trial 44 finished with value: 0.8473249299719889 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 11, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:55,893] Trial 45 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 9, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  48%|████▊     | 48/100 [00:04<00:06,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:55,992] Trial 46 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 12, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:56,125] Trial 47 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  49%|████▉     | 49/100 [00:04<00:05,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:56,231] Trial 48 finished with value: 0.8472969187675069 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 18, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:56,327] Trial 49 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  52%|█████▏    | 52/100 [00:05<00:05,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:56,437] Trial 50 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:56,553] Trial 51 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  54%|█████▍    | 54/100 [00:05<00:05,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:56,652] Trial 52 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:56,808] Trial 53 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  56%|█████▌    | 56/100 [00:05<00:04,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:56,901] Trial 54 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:57,008] Trial 55 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  59%|█████▉    | 59/100 [00:05<00:04,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:57,141] Trial 56 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:57,230] Trial 57 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:57,330] Trial 58 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  61%|██████    | 61/100 [00:06<00:04,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:57,443] Trial 59 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:57,558] Trial 60 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  63%|██████▎   | 63/100 [00:06<00:04,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:57,679] Trial 61 finished with value: 0.850658263305322 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:57,783] Trial 62 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  65%|██████▌   | 65/100 [00:06<00:03,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:57,885] Trial 63 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 24, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:57,987] Trial 64 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  68%|██████▊   | 68/100 [00:06<00:03,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:58,113] Trial 65 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:58,197] Trial 66 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:58,306] Trial 67 finished with value: 0.850658263305322 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  71%|███████   | 71/100 [00:07<00:02,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:58,429] Trial 68 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 25, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:58,522] Trial 69 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:58,616] Trial 70 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  74%|███████▍  | 74/100 [00:07<00:02,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:58,735] Trial 71 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:58,831] Trial 72 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:58,922] Trial 73 finished with value: 0.850672268907563 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  77%|███████▋  | 77/100 [00:07<00:02,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:59,041] Trial 74 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 16, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:59,141] Trial 75 finished with value: 0.8372549019607842 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 7, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:59,235] Trial 76 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  79%|███████▉  | 79/100 [00:07<00:02,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:59,347] Trial 77 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:59,455] Trial 78 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  81%|████████  | 81/100 [00:08<00:02,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:59,566] Trial 79 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:59,677] Trial 80 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 17, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  82%|████████▏ | 82/100 [00:08<00:01,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:59,782] Trial 81 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:27:59,869] Trial 82 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  85%|████████▌ | 85/100 [00:08<00:01,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:27:59,984] Trial 83 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:00,098] Trial 84 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  88%|████████▊ | 88/100 [00:08<00:01,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:00,219] Trial 85 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:00,304] Trial 86 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:00,403] Trial 87 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  90%|█████████ | 90/100 [00:09<00:01,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:00,541] Trial 88 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:00,657] Trial 89 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  93%|█████████▎| 93/100 [00:09<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:00,780] Trial 90 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:00,870] Trial 91 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:00,968] Trial 92 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  95%|█████████▌| 95/100 [00:09<00:00,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:01,086] Trial 93 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:01,205] Trial 94 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  97%|█████████▋| 97/100 [00:09<00:00,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:01,325] Trial 95 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 36, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:01,449] Trial 96 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367:  99%|█████████▉| 99/100 [00:10<00:00,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:01,570] Trial 97 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-11-06 03:28:01,697] Trial 98 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.852367: 100%|██████████| 100/100 [00:10<00:00,  9.63it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:28:01,875] A new study created in memory with name: Support Vector Machine Model Fine Tuning with GPSampler\n",
      "Best trial: 10. Best value: 0.852367: 100%|██████████| 100/100 [00:10<00:00,  9.63it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:28:01,875] A new study created in memory with name: Support Vector Machine Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:01,872] Trial 99 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using GPSampler: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   5%|▌         | 5/100 [00:00<00:02, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:01,909] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:28:01,934] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:28:01,970] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:28:01,995] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:28:02,031] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:28:02,056] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   6%|▌         | 6/100 [00:00<00:02, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:02,092] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   9%|▉         | 9/100 [00:00<00:02, 30.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:02,130] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:28:02,179] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-11-06 03:28:02,216] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:  10%|█         | 10/100 [00:00<00:02, 30.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:02,310] The parameter `degree` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.837227:  12%|█▏        | 12/100 [00:00<00:04, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:02,336] Trial 10 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 10 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:28:02,415] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:02,440] Trial 11 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 10 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.837227:  12%|█▏        | 12/100 [00:00<00:04, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:02,514] The parameter `degree` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  13%|█▎        | 13/100 [00:00<00:04, 18.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:02,538] Trial 12 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:02,606] The parameter `degree` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:02,632] Trial 13 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  17%|█▋        | 17/100 [00:01<00:05, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:02,746] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:02,772] Trial 14 finished with value: 0.8288375350140054 and parameters: {'kernel': 'poly', 'C': 0.00597387645685049, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:02,815] The parameter `degree` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:02,840] Trial 15 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:02,881] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:02,905] Trial 16 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  19%|█▉        | 19/100 [00:01<00:06, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:02,951] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:02,975] Trial 17 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,064] The parameter `degree` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,089] Trial 18 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.006835920115945186, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  21%|██        | 21/100 [00:01<00:06, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:03,162] The parameter `degree` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,187] Trial 19 finished with value: 0.781890756302521 and parameters: {'kernel': 'poly', 'C': 0.0028509818657600134, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,227] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,252] Trial 20 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,308] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,333] Trial 21 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  25%|██▌       | 25/100 [00:01<00:05, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:03,368] The parameter `degree` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,392] Trial 22 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,424] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,448] Trial 23 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,479] The parameter `degree` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,503] Trial 24 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,538] The parameter `degree` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,562] Trial 25 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  29%|██▉       | 29/100 [00:01<00:04, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:03,593] The parameter `degree` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,618] Trial 26 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,659] The parameter `degree` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,683] Trial 27 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,727] The parameter `degree` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,752] Trial 28 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  31%|███       | 31/100 [00:02<00:05, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:03,840] The parameter `degree` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,864] Trial 29 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:03,935] The parameter `degree` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:03,960] Trial 30 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007627560965647272, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  33%|███▎      | 33/100 [00:02<00:06, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:04,071] The parameter `degree` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,096] Trial 31 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.007626875156604568, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:04,188] The parameter `degree` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,212] Trial 32 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007618782999896072, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  35%|███▌      | 35/100 [00:02<00:06, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:04,327] The parameter `degree` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,351] Trial 33 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.0076256566924412005, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:04,413] The parameter `degree` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,437] Trial 34 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:04,522] The parameter `degree` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  37%|███▋      | 37/100 [00:02<00:07,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:04,546] Trial 35 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007613480023511459, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:04,706] The parameter `degree` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,731] Trial 36 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  40%|████      | 40/100 [00:03<00:06,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:04,781] The parameter `degree` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,806] Trial 37 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:04,849] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,875] Trial 38 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:04,916] The parameter `degree` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:04,930] Trial 39 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:04,972] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  43%|████▎     | 43/100 [00:03<00:05, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:04,996] Trial 40 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,043] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,068] Trial 41 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,148] The parameter `degree` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,174] Trial 42 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.007548764729168969, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  45%|████▌     | 45/100 [00:03<00:05, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:05,285] The parameter `degree` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,310] Trial 43 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.007553201827051025, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,357] The parameter `degree` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,382] Trial 44 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,471] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,485] Trial 45 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  49%|████▉     | 49/100 [00:03<00:04, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:05,556] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,580] Trial 46 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,632] The parameter `degree` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,646] Trial 47 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,720] The parameter `degree` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,744] Trial 48 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007498003679354188, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  51%|█████     | 51/100 [00:04<00:04, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:05,793] The parameter `degree` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,817] Trial 49 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,875] The parameter `degree` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,899] Trial 50 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:05,938] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:05,963] Trial 51 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  53%|█████▎    | 53/100 [00:04<00:04, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:06,041] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,065] Trial 52 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:06,158] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,183] Trial 53 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007464092121149379, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  56%|█████▌    | 56/100 [00:04<00:05,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:06,442] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,456] Trial 54 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007471019608817415, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:06,505] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,519] Trial 55 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:06,625] The parameter `degree` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  59%|█████▉    | 59/100 [00:04<00:03, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:06,649] Trial 56 finished with value: 0.8288235294117646 and parameters: {'kernel': 'poly', 'C': 0.0074733532552842845, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:06,689] The parameter `degree` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,713] Trial 57 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:06,754] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,768] Trial 58 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:06,821] The parameter `degree` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,834] Trial 59 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  61%|██████    | 61/100 [00:05<00:03, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:06,919] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:06,943] Trial 60 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,070] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:07,094] Trial 61 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  64%|██████▍   | 64/100 [00:05<00:03,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:07,161] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:07,175] Trial 62 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,223] The parameter `degree` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:07,247] Trial 63 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,337] The parameter `degree` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  66%|██████▌   | 66/100 [00:05<00:03, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:07,361] Trial 64 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,421] The parameter `degree` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:07,445] Trial 65 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,546] The parameter `degree` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  68%|██████▊   | 68/100 [00:05<00:03,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:07,570] Trial 66 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007478516560772253, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,629] The parameter `degree` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:07,645] Trial 67 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,770] The parameter `degree` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  70%|███████   | 70/100 [00:06<00:03,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:07,796] Trial 68 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007441543131830453, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:07,949] The parameter `degree` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:07,973] Trial 69 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  72%|███████▏  | 72/100 [00:06<00:02,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:08,040] The parameter `degree` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,064] Trial 70 finished with value: 0.8288235294117646 and parameters: {'kernel': 'poly', 'C': 0.007399318010479571, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:08,106] The parameter `degree` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,130] Trial 71 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:08,188] The parameter `degree` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,213] Trial 72 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  74%|███████▍  | 74/100 [00:06<00:02, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:08,254] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,268] Trial 73 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:08,415] The parameter `degree` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,439] Trial 74 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  76%|███████▌  | 76/100 [00:06<00:02,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:08,510] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,535] Trial 75 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:08,645] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,670] Trial 76 finished with value: 0.8439215686274512 and parameters: {'kernel': 'poly', 'C': 0.007355661756278554, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  78%|███████▊  | 78/100 [00:07<00:02,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:08,807] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,831] Trial 77 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007357042473988604, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:08,900] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:08,924] Trial 78 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  80%|████████  | 80/100 [00:07<00:02,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:09,218] The parameter `degree` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:09,232] Trial 79 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007314166121905914, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:09,411] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  81%|████████  | 81/100 [00:07<00:02,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:09,426] Trial 80 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007319261012209399, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:09,490] The parameter `degree` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:09,504] Trial 81 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  84%|████████▍ | 84/100 [00:07<00:02,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:09,653] The parameter `degree` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:09,677] Trial 82 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:09,754] The parameter `degree` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:09,778] Trial 83 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:09,841] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  86%|████████▌ | 86/100 [00:08<00:01,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:09,865] Trial 84 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:09,929] The parameter `degree` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:09,953] Trial 85 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  88%|████████▊ | 88/100 [00:08<00:01,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:10,120] The parameter `degree` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,143] Trial 86 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:10,251] The parameter `degree` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,276] Trial 87 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  90%|█████████ | 90/100 [00:08<00:01,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:10,376] The parameter `degree` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,402] Trial 88 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:10,501] The parameter `degree` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,525] Trial 89 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  92%|█████████▏| 92/100 [00:08<00:00,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:10,581] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,595] Trial 90 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:10,655] The parameter `degree` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,680] Trial 91 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  94%|█████████▍| 94/100 [00:09<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:10,800] The parameter `degree` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,825] Trial 92 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:10,938] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:10,962] Trial 93 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  96%|█████████▌| 96/100 [00:09<00:00,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:11,039] The parameter `degree` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:11,063] Trial 94 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007469861792921523, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:11,162] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:11,176] Trial 95 finished with value: 0.8456022408963587 and parameters: {'kernel': 'poly', 'C': 0.007478386134495245, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563:  97%|█████████▋| 97/100 [00:09<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:11,428] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:11,454] Trial 96 finished with value: 0.8439355742296918 and parameters: {'kernel': 'poly', 'C': 0.007488315454086649, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:11,604] The parameter `degree` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:11,628] Trial 97 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007500636310730785, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:28:11,753] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:28:11,779] Trial 98 finished with value: 0.8288235294117646 and parameters: {'kernel': 'poly', 'C': 0.007498430166188635, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:28:11,931] The parameter `degree` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.84563: 100%|██████████| 100/100 [00:10<00:00,  9.92it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:28:11,958] A new study created in memory with name: AdaBoost Model Fine Tuning with GPSampler\n",
      "Best trial: 12. Best value: 0.84563: 100%|██████████| 100/100 [00:10<00:00,  9.92it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:28:11,958] A new study created in memory with name: AdaBoost Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:11,955] Trial 99 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using GPSampler: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}\n",
      "Best accuracy: 0.8456, at trial: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:12,032] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   2%|▏         | 2/100 [00:00<00:09,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:12,158] Trial 1 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:28:12,214] Trial 2 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   4%|▍         | 4/100 [00:00<00:06, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:12,260] Trial 3 finished with value: 0.8490196078431372 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   6%|▌         | 6/100 [00:00<00:06, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:12,388] Trial 4 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:28:12,413] Trial 5 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   6%|▌         | 6/100 [00:00<00:06, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:12,539] Trial 6 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:   8%|▊         | 8/100 [00:00<00:07, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:12,625] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:28:12,681] Trial 8 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  10%|█         | 10/100 [00:00<00:07, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:12,787] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  10%|█         | 10/100 [00:01<00:07, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:13,170] Trial 10 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 96, 'learning_rate': 0.10760350038064395}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  12%|█▏        | 12/100 [00:01<00:14,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:13,418] Trial 11 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 79, 'learning_rate': 0.9741263394920423}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  13%|█▎        | 13/100 [00:01<00:17,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:13,765] Trial 12 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 82, 'learning_rate': 0.08311971700767475}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  14%|█▍        | 14/100 [00:02<00:17,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:14,009] Trial 13 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 39, 'learning_rate': 0.3756092410805447}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  15%|█▌        | 15/100 [00:02<00:18,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:14,274] Trial 14 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 58, 'learning_rate': 1.0}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  16%|█▌        | 16/100 [00:02<00:20,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:14,576] Trial 15 finished with value: 0.8473109243697478 and parameters: {'n_estimators': 100, 'learning_rate': 0.5181579440306674}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  17%|█▋        | 17/100 [00:02<00:20,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:14,814] Trial 16 finished with value: 0.850686274509804 and parameters: {'n_estimators': 81, 'learning_rate': 0.22170188252677445}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  18%|█▊        | 18/100 [00:03<00:21,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:15,115] Trial 17 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 81, 'learning_rate': 0.17542634718223402}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  19%|█▉        | 19/100 [00:03<00:23,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:15,473] Trial 18 finished with value: 0.843921568627451 and parameters: {'n_estimators': 100, 'learning_rate': 1.0}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  20%|██        | 20/100 [00:03<00:23,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:15,808] Trial 19 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 100, 'learning_rate': 0.04732611944746715}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  21%|██        | 21/100 [00:04<00:23,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:16,099] Trial 20 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 100, 'learning_rate': 0.07569433652217944}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  22%|██▏       | 22/100 [00:04<00:22,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:16,361] Trial 21 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 89, 'learning_rate': 0.05528172899756078}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  23%|██▎       | 23/100 [00:04<00:22,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:16,660] Trial 22 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.3878883295065908}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  24%|██▍       | 24/100 [00:04<00:21,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:16,929] Trial 23 finished with value: 0.850686274509804 and parameters: {'n_estimators': 82, 'learning_rate': 0.39692740736362625}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  25%|██▌       | 25/100 [00:05<00:20,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:17,156] Trial 24 finished with value: 0.8372408963585434 and parameters: {'n_estimators': 34, 'learning_rate': 1.0}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  26%|██▌       | 26/100 [00:05<00:19,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:17,400] Trial 25 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 73, 'learning_rate': 0.41616637544284435}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  27%|██▋       | 27/100 [00:05<00:22,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:17,811] Trial 26 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 100, 'learning_rate': 0.2653850737572907}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  28%|██▊       | 28/100 [00:06<00:21,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:18,110] Trial 27 finished with value: 0.850686274509804 and parameters: {'n_estimators': 84, 'learning_rate': 0.3924407785535902}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  29%|██▉       | 29/100 [00:06<00:19,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:18,314] Trial 28 finished with value: 0.8406162464985993 and parameters: {'n_estimators': 10, 'learning_rate': 0.2925619073282315}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  30%|███       | 30/100 [00:06<00:20,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:18,630] Trial 29 finished with value: 0.8439495798319328 and parameters: {'n_estimators': 100, 'learning_rate': 0.0400962976622918}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  31%|███       | 31/100 [00:06<00:20,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:18,951] Trial 30 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 83, 'learning_rate': 0.3717519038730115}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  32%|███▏      | 32/100 [00:07<00:21,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:19,331] Trial 31 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 88, 'learning_rate': 0.08335750841183492}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  33%|███▎      | 33/100 [00:07<00:22,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:19,678] Trial 32 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 69, 'learning_rate': 0.37708414066721957}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  34%|███▍      | 34/100 [00:08<00:21,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:19,991] Trial 33 finished with value: 0.842282913165266 and parameters: {'n_estimators': 89, 'learning_rate': 0.3186118531378612}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  35%|███▌      | 35/100 [00:08<00:22,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:20,395] Trial 34 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 100, 'learning_rate': 0.09069702155531724}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  36%|███▌      | 36/100 [00:08<00:22,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:20,765] Trial 35 finished with value: 0.845658263305322 and parameters: {'n_estimators': 86, 'learning_rate': 0.08237695207894867}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  37%|███▋      | 37/100 [00:09<00:22,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:21,113] Trial 36 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.14375817210094835}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  38%|███▊      | 38/100 [00:09<00:21,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:21,459] Trial 37 finished with value: 0.850658263305322 and parameters: {'n_estimators': 79, 'learning_rate': 0.5684475131575192}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  39%|███▉      | 39/100 [00:09<00:22,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:21,870] Trial 38 finished with value: 0.850658263305322 and parameters: {'n_estimators': 79, 'learning_rate': 0.5685092692914604}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  40%|████      | 40/100 [00:10<00:21,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:22,179] Trial 39 finished with value: 0.850672268907563 and parameters: {'n_estimators': 80, 'learning_rate': 0.5704396319856013}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  41%|████      | 41/100 [00:10<00:20,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:22,509] Trial 40 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 80, 'learning_rate': 0.5708696337390805}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  42%|████▏     | 42/100 [00:10<00:19,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:22,804] Trial 41 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 72, 'learning_rate': 0.550328728058182}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  43%|████▎     | 43/100 [00:11<00:19,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:23,190] Trial 42 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 87, 'learning_rate': 0.5630421585402817}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.850686:  44%|████▍     | 44/100 [00:11<00:20,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:23,583] Trial 43 finished with value: 0.850672268907563 and parameters: {'n_estimators': 86, 'learning_rate': 0.05115127042723974}. Best is trial 1 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  45%|████▌     | 45/100 [00:11<00:19,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:23,917] Trial 44 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 84, 'learning_rate': 0.04859910910941437}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  46%|████▌     | 46/100 [00:12<00:17,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:24,200] Trial 45 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 81, 'learning_rate': 0.03784729508577795}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  48%|████▊     | 48/100 [00:12<00:14,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:24,488] Trial 46 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 100, 'learning_rate': 0.0010000000000000002}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:28:24,654] Trial 47 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010000000000000002}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  49%|████▉     | 49/100 [00:13<00:15,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:25,005] Trial 48 finished with value: 0.8321848739495799 and parameters: {'n_estimators': 100, 'learning_rate': 0.023132225171388052}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  50%|█████     | 50/100 [00:13<00:15,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:25,364] Trial 49 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 86, 'learning_rate': 0.05871070128868415}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  51%|█████     | 51/100 [00:13<00:15,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:25,682] Trial 50 finished with value: 0.850686274509804 and parameters: {'n_estimators': 77, 'learning_rate': 0.06226970022406121}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  52%|█████▏    | 52/100 [00:14<00:15,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:26,021] Trial 51 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.06143909081102446}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  53%|█████▎    | 53/100 [00:14<00:15,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:26,395] Trial 52 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 75, 'learning_rate': 0.05979445496370857}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  54%|█████▍    | 54/100 [00:14<00:15,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:26,747] Trial 53 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 86, 'learning_rate': 0.0564113978622165}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  55%|█████▌    | 55/100 [00:15<00:14,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:27,015] Trial 54 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 55, 'learning_rate': 0.0010000000000000002}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  56%|█████▌    | 56/100 [00:15<00:13,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:27,326] Trial 55 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 59, 'learning_rate': 0.5454671531443763}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  57%|█████▋    | 57/100 [00:15<00:13,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:27,640] Trial 56 finished with value: 0.850686274509804 and parameters: {'n_estimators': 73, 'learning_rate': 0.08000582015366905}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  58%|█████▊    | 58/100 [00:16<00:14,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:28,040] Trial 57 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 73, 'learning_rate': 0.056512838303340966}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  59%|█████▉    | 59/100 [00:16<00:13,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:28,319] Trial 58 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 72, 'learning_rate': 0.05428230106182469}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  60%|██████    | 60/100 [00:16<00:12,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:28,574] Trial 59 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 68, 'learning_rate': 0.050142564851609235}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  61%|██████    | 61/100 [00:16<00:11,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:28,809] Trial 60 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 50, 'learning_rate': 0.5077441033906889}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  62%|██████▏   | 62/100 [00:17<00:10,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:29,112] Trial 61 finished with value: 0.8439775910364145 and parameters: {'n_estimators': 22, 'learning_rate': 0.3655804773227637}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  63%|██████▎   | 63/100 [00:17<00:10,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:29,378] Trial 62 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 71, 'learning_rate': 0.0730406918675398}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  64%|██████▍   | 64/100 [00:17<00:10,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:29,705] Trial 63 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 78, 'learning_rate': 0.052178930184457475}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  65%|██████▌   | 65/100 [00:18<00:10,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:30,016] Trial 64 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 69, 'learning_rate': 0.22701426797811253}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  66%|██████▌   | 66/100 [00:18<00:09,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:30,284] Trial 65 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 73, 'learning_rate': 0.09459936278398139}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  67%|██████▋   | 67/100 [00:18<00:09,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:30,578] Trial 66 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 100, 'learning_rate': 0.06480113553072854}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  68%|██████▊   | 68/100 [00:18<00:08,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:30,803] Trial 67 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 10, 'learning_rate': 0.4954342425034238}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  69%|██████▉   | 69/100 [00:19<00:08,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:31,078] Trial 68 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 89, 'learning_rate': 0.6546546408674782}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  70%|███████   | 70/100 [00:19<00:08,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:31,411] Trial 69 finished with value: 0.850658263305322 and parameters: {'n_estimators': 100, 'learning_rate': 0.49169389372411776}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  71%|███████   | 71/100 [00:19<00:08,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:31,731] Trial 70 finished with value: 0.8523389355742296 and parameters: {'n_estimators': 100, 'learning_rate': 0.5137519311666967}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  72%|███████▏  | 72/100 [00:20<00:08,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:32,040] Trial 71 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 100, 'learning_rate': 0.5373365902432213}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  73%|███████▎  | 73/100 [00:20<00:08,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:32,343] Trial 72 finished with value: 0.8506862745098038 and parameters: {'n_estimators': 100, 'learning_rate': 0.3795824458773077}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  74%|███████▍  | 74/100 [00:20<00:07,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:32,626] Trial 73 finished with value: 0.8506862745098038 and parameters: {'n_estimators': 100, 'learning_rate': 0.38069721088883307}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  75%|███████▌  | 75/100 [00:21<00:07,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:32,974] Trial 74 finished with value: 0.8490056022408963 and parameters: {'n_estimators': 100, 'learning_rate': 0.3827888293078718}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  76%|███████▌  | 76/100 [00:21<00:07,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:33,308] Trial 75 finished with value: 0.8439495798319326 and parameters: {'n_estimators': 91, 'learning_rate': 0.5164765468860938}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  77%|███████▋  | 77/100 [00:21<00:07,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:33,642] Trial 76 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 75, 'learning_rate': 0.04230105575960469}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  78%|███████▊  | 78/100 [00:21<00:06,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:33,935] Trial 77 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 63, 'learning_rate': 0.23596090704826675}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  79%|███████▉  | 79/100 [00:22<00:06,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:34,243] Trial 78 finished with value: 0.850686274509804 and parameters: {'n_estimators': 72, 'learning_rate': 0.2482958838230826}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  80%|████████  | 80/100 [00:22<00:06,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:34,604] Trial 79 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 72, 'learning_rate': 0.19372674952946614}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  81%|████████  | 81/100 [00:23<00:06,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:34,994] Trial 80 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 73, 'learning_rate': 0.280907662811928}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  82%|████████▏ | 82/100 [00:23<00:05,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:35,290] Trial 81 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 53, 'learning_rate': 0.17303281332145945}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  83%|████████▎ | 83/100 [00:23<00:05,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:35,616] Trial 82 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.26642994149369514}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  84%|████████▍ | 84/100 [00:24<00:05,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:36,020] Trial 83 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 83, 'learning_rate': 0.06013507883012529}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 44. Best value: 0.852353:  85%|████████▌ | 85/100 [00:24<00:05,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:36,405] Trial 84 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 100, 'learning_rate': 0.06317158828248719}. Best is trial 44 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  86%|████████▌ | 86/100 [00:24<00:05,  2.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:36,775] Trial 85 finished with value: 0.8540196078431371 and parameters: {'n_estimators': 100, 'learning_rate': 0.6460013719822092}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  87%|████████▋ | 87/100 [00:25<00:04,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:37,148] Trial 86 finished with value: 0.843921568627451 and parameters: {'n_estimators': 100, 'learning_rate': 1.0}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  88%|████████▊ | 88/100 [00:25<00:03,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:37,371] Trial 87 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 10, 'learning_rate': 0.13430649841558304}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  89%|████████▉ | 89/100 [00:25<00:03,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:37,657] Trial 88 finished with value: 0.8523389355742296 and parameters: {'n_estimators': 100, 'learning_rate': 0.6339260387444429}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  90%|█████████ | 90/100 [00:26<00:03,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:37,992] Trial 89 finished with value: 0.850658263305322 and parameters: {'n_estimators': 100, 'learning_rate': 0.6358961342343696}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  91%|█████████ | 91/100 [00:26<00:02,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:38,194] Trial 90 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.009714480187564422}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  92%|█████████▏| 92/100 [00:26<00:02,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:38,417] Trial 91 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 25, 'learning_rate': 0.5558488205750016}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.85402:  93%|█████████▎| 93/100 [00:26<00:01,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:38,697] Trial 92 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 61, 'learning_rate': 0.08686443109631407}. Best is trial 85 with value: 0.8540196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8557:  94%|█████████▍| 94/100 [00:27<00:01,  3.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:39,104] Trial 93 finished with value: 0.8557002801120447 and parameters: {'n_estimators': 100, 'learning_rate': 0.6457519690929153}. Best is trial 93 with value: 0.8557002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8557:  95%|█████████▌| 95/100 [00:27<00:01,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:39,457] Trial 94 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 53, 'learning_rate': 0.10340089632823472}. Best is trial 93 with value: 0.8557002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8557:  96%|█████████▌| 96/100 [00:27<00:01,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:39,770] Trial 95 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 61, 'learning_rate': 0.07250088083246777}. Best is trial 93 with value: 0.8557002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8557:  97%|█████████▋| 97/100 [00:28<00:01,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:40,399] Trial 96 finished with value: 0.8439775910364145 and parameters: {'n_estimators': 60, 'learning_rate': 0.07193248368715434}. Best is trial 93 with value: 0.8557002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8557:  98%|█████████▊| 98/100 [00:28<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:40,687] Trial 97 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 42, 'learning_rate': 0.1911859339344796}. Best is trial 93 with value: 0.8557002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8557:  99%|█████████▉| 99/100 [00:29<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:40,986] Trial 98 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 52, 'learning_rate': 0.24858593873152618}. Best is trial 93 with value: 0.8557002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8557: 100%|██████████| 100/100 [00:29<00:00,  3.41it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:28:41,277] A new study created in memory with name: Gradient Boosting Model Fine Tuning with GPSampler\n",
      "Best trial: 93. Best value: 0.8557: 100%|██████████| 100/100 [00:29<00:00,  3.41it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:28:41,277] A new study created in memory with name: Gradient Boosting Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:41,274] Trial 99 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 48, 'learning_rate': 0.12749544099180685}. Best is trial 93 with value: 0.8557002801120447.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using GPSampler: {'n_estimators': 100, 'learning_rate': 0.6457519690929153}\n",
      "Best accuracy: 0.8557, at trial: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.80028:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:41,362] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837241:   2%|▏         | 2/100 [00:00<00:12,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:41,541] Trial 1 finished with value: 0.8372408963585434 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.8372408963585434.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837241:   4%|▍         | 4/100 [00:00<00:09,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:41,608] Trial 2 finished with value: 0.6844257703081233 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-11-06 03:28:41,705] Trial 3 finished with value: 0.8019887955182072 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.8372408963585434.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837241:   6%|▌         | 6/100 [00:00<00:12,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:41,845] Trial 4 finished with value: 0.6978151260504202 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-11-06 03:28:42,026] Trial 5 finished with value: 0.8103361344537815 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.8372408963585434.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:   8%|▊         | 8/100 [00:01<00:10,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:42,124] Trial 6 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-11-06 03:28:42,181] Trial 7 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 7 with value: 0.8439495798319326.\n",
      "[I 2025-11-06 03:28:42,278] Trial 8 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.855714:  10%|█         | 10/100 [00:01<00:09,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:42,355] Trial 9 finished with value: 0.8204341736694678 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 8 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.860756:  10%|█         | 10/100 [00:01<00:09,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:42,804] Trial 10 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.019803074190325808, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7121615336796734}. Best is trial 10 with value: 0.8607563025210083.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.860756:  12%|█▏        | 12/100 [00:01<00:19,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:43,238] Trial 11 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 99, 'learning_rate': 0.007647731307876651, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.802312933947943}. Best is trial 10 with value: 0.8607563025210083.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.860756:  13%|█▎        | 13/100 [00:02<00:22,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:43,680] Trial 12 finished with value: 0.8590896358543416 and parameters: {'max_features': 'sqrt', 'n_estimators': 34, 'learning_rate': 0.05294574090813342, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.7163066381452272}. Best is trial 10 with value: 0.8607563025210083.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.860756:  14%|█▍        | 14/100 [00:02<00:24,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:44,036] Trial 13 finished with value: 0.8607563025210085 and parameters: {'max_features': None, 'n_estimators': 62, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.6536142037824885}. Best is trial 13 with value: 0.8607563025210085.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.860756:  15%|█▌        | 15/100 [00:03<00:28,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:44,566] Trial 14 finished with value: 0.850672268907563 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.024651721623397384, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.7096650513258991}. Best is trial 13 with value: 0.8607563025210085.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.860756:  16%|█▌        | 16/100 [00:03<00:29,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:44,928] Trial 15 finished with value: 0.8456302521008403 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.5}. Best is trial 13 with value: 0.8607563025210085.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.860756:  17%|█▋        | 17/100 [00:04<00:32,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:45,440] Trial 16 finished with value: 0.8473249299719889 and parameters: {'max_features': 'sqrt', 'n_estimators': 49, 'learning_rate': 0.012281741145542827, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.7394783396299751}. Best is trial 13 with value: 0.8607563025210085.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.860756:  18%|█▊        | 18/100 [00:04<00:32,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:45,834] Trial 17 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6982752543422941}. Best is trial 13 with value: 0.8607563025210085.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.860756:  19%|█▉        | 19/100 [00:04<00:30,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:46,174] Trial 18 finished with value: 0.8590476190476191 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 1.0}. Best is trial 13 with value: 0.8607563025210085.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  20%|██        | 20/100 [00:05<00:28,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:46,476] Trial 19 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 45, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  21%|██        | 21/100 [00:05<00:28,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:46,834] Trial 20 finished with value: 0.850672268907563 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.004843865585930926, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  22%|██▏       | 22/100 [00:05<00:24,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:47,066] Trial 21 finished with value: 0.8573949579831932 and parameters: {'max_features': None, 'n_estimators': 37, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  23%|██▎       | 23/100 [00:05<00:21,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:47,271] Trial 22 finished with value: 0.8372268907563024 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  24%|██▍       | 24/100 [00:06<00:24,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:47,658] Trial 23 finished with value: 0.8473109243697479 and parameters: {'max_features': 'sqrt', 'n_estimators': 72, 'learning_rate': 0.006138768215920103, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  25%|██▌       | 25/100 [00:06<00:27,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:48,156] Trial 24 finished with value: 0.8372268907563025 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.0025317914083876525, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  26%|██▌       | 26/100 [00:07<00:31,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:48,702] Trial 25 finished with value: 0.8473109243697478 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.0705027978162431, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  27%|██▋       | 27/100 [00:07<00:30,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:49,102] Trial 26 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.053378534659907474, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  28%|██▊       | 28/100 [00:08<00:26,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:49,367] Trial 27 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.04920084949812709, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  29%|██▉       | 29/100 [00:08<00:24,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:49,658] Trial 28 finished with value: 0.8489915966386554 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.030673800025129008, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  30%|███       | 30/100 [00:08<00:24,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:50,035] Trial 29 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  31%|███       | 31/100 [00:09<00:25,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:50,443] Trial 30 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.009260849640906389, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  32%|███▏      | 32/100 [00:09<00:24,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:50,764] Trial 31 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  33%|███▎      | 33/100 [00:09<00:25,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:51,207] Trial 32 finished with value: 0.8473249299719889 and parameters: {'max_features': 'log2', 'n_estimators': 32, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  34%|███▍      | 34/100 [00:10<00:24,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:51,564] Trial 33 finished with value: 0.8490196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.02445903989992873, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  35%|███▌      | 35/100 [00:10<00:21,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:51,800] Trial 34 finished with value: 0.8489915966386554 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.019851625689718547, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  36%|███▌      | 36/100 [00:10<00:20,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:52,104] Trial 35 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 79, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  37%|███▋      | 37/100 [00:11<00:18,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:52,329] Trial 36 finished with value: 0.8422408963585433 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.005508914823163481, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  38%|███▊      | 38/100 [00:11<00:16,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:52,533] Trial 37 finished with value: 0.8472969187675069 and parameters: {'max_features': 'sqrt', 'n_estimators': 33, 'learning_rate': 0.03464572305820764, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  39%|███▉      | 39/100 [00:11<00:16,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:52,831] Trial 38 finished with value: 0.8489915966386554 and parameters: {'max_features': 'sqrt', 'n_estimators': 60, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  40%|████      | 40/100 [00:11<00:16,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:53,078] Trial 39 finished with value: 0.850672268907563 and parameters: {'max_features': None, 'n_estimators': 87, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  41%|████      | 41/100 [00:12<00:17,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:53,450] Trial 40 finished with value: 0.8607422969187676 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.060615559739820295, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  42%|████▏     | 42/100 [00:12<00:17,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:53,743] Trial 41 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.015894545017235473, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  43%|████▎     | 43/100 [00:12<00:17,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:54,089] Trial 42 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.06591702826642064, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  44%|████▍     | 44/100 [00:13<00:29,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:55,126] Trial 43 finished with value: 0.8489775910364145 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.01564254492346166, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  45%|████▌     | 45/100 [00:14<00:25,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:55,456] Trial 44 finished with value: 0.6929131652661065 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  46%|████▌     | 46/100 [00:15<00:32,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:56,354] Trial 45 finished with value: 0.8473109243697478 and parameters: {'max_features': 'log2', 'n_estimators': 80, 'learning_rate': 0.00436407084121933, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  47%|████▋     | 47/100 [00:15<00:28,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:56,736] Trial 46 finished with value: 0.835546218487395 and parameters: {'max_features': 'log2', 'n_estimators': 84, 'learning_rate': 0.0038606823051978737, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  48%|████▊     | 48/100 [00:16<00:29,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:57,395] Trial 47 finished with value: 0.7936134453781513 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.006453978797381782, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  49%|████▉     | 49/100 [00:16<00:26,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:57,819] Trial 48 finished with value: 0.8489915966386553 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.014345246413095392, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  50%|█████     | 50/100 [00:17<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:58,481] Trial 49 finished with value: 0.8456302521008403 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.01593914767085272, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  51%|█████     | 51/100 [00:17<00:26,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:58,950] Trial 50 finished with value: 0.8490196078431375 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.03817014473834525, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  52%|█████▏    | 52/100 [00:17<00:22,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:59,264] Trial 51 finished with value: 0.8590896358543418 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.0317834431155916, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  53%|█████▎    | 53/100 [00:18<00:19,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:59,572] Trial 52 finished with value: 0.825518207282913 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.048354208944067376, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  54%|█████▍    | 54/100 [00:18<00:17,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:28:59,861] Trial 53 finished with value: 0.8574089635854343 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  55%|█████▌    | 55/100 [00:18<00:17,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:00,246] Trial 54 finished with value: 0.8540476190476192 and parameters: {'max_features': None, 'n_estimators': 37, 'learning_rate': 0.06565802541722043, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  56%|█████▌    | 56/100 [00:19<00:16,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:00,578] Trial 55 finished with value: 0.850658263305322 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.03152580031150816, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  57%|█████▋    | 57/100 [00:19<00:15,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:00,914] Trial 56 finished with value: 0.850672268907563 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.024485525268659176, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  58%|█████▊    | 58/100 [00:19<00:14,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:01,248] Trial 57 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.01026130589896256, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  59%|█████▉    | 59/100 [00:20<00:15,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:01,686] Trial 58 finished with value: 0.8523529411764705 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.06459324566923343, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.862437:  60%|██████    | 60/100 [00:20<00:14,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:02,053] Trial 59 finished with value: 0.8523529411764704 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 19 with value: 0.8624369747899159.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  61%|██████    | 61/100 [00:21<00:15,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:02,534] Trial 60 finished with value: 0.8641176470588234 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.05215365129804328, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  62%|██████▏   | 62/100 [00:21<00:15,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:02,907] Trial 61 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.033803664562853226, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  63%|██████▎   | 63/100 [00:22<00:24,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:04,153] Trial 62 finished with value: 0.8523249299719889 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  64%|██████▍   | 64/100 [00:23<00:21,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:04,637] Trial 63 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.016110117064028533, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  65%|██████▌   | 65/100 [00:23<00:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:05,052] Trial 64 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 86, 'learning_rate': 0.06831347968699793, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  66%|██████▌   | 66/100 [00:24<00:18,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:05,569] Trial 65 finished with value: 0.8574089635854343 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.04463075349943418, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  67%|██████▋   | 67/100 [00:25<00:20,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:06,351] Trial 66 finished with value: 0.8422689075630252 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.005514290846083999, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  68%|██████▊   | 68/100 [00:25<00:16,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:06,682] Trial 67 finished with value: 0.8573809523809525 and parameters: {'max_features': None, 'n_estimators': 54, 'learning_rate': 0.06063393253978083, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  69%|██████▉   | 69/100 [00:25<00:15,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:07,073] Trial 68 finished with value: 0.8254621848739495 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.003121004868317477, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  70%|███████   | 70/100 [00:26<00:15,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:07,691] Trial 69 finished with value: 0.8540056022408965 and parameters: {'max_features': 'sqrt', 'n_estimators': 73, 'learning_rate': 0.00494000171643232, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7380341703489416}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  71%|███████   | 71/100 [00:26<00:14,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:08,138] Trial 70 finished with value: 0.8624229691876751 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.055495580645387385, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.762024233035087}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  72%|███████▏  | 72/100 [00:27<00:13,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:08,628] Trial 71 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 68, 'learning_rate': 0.01651532255187687, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.7045089317221163}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  73%|███████▎  | 73/100 [00:27<00:13,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:09,081] Trial 72 finished with value: 0.8489915966386554 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.009327035446639775, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  74%|███████▍  | 74/100 [00:28<00:12,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:09,548] Trial 73 finished with value: 0.8490056022408965 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  75%|███████▌  | 75/100 [00:28<00:11,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:10,023] Trial 74 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.014534209826690979, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5766970497371116}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  76%|███████▌  | 76/100 [00:29<00:11,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:10,439] Trial 75 finished with value: 0.8573809523809522 and parameters: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.7729036856857565}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  77%|███████▋  | 77/100 [00:29<00:10,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:10,861] Trial 76 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  78%|███████▊  | 78/100 [00:30<00:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:11,358] Trial 77 finished with value: 0.8590896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 72, 'learning_rate': 0.07675900499447898, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.7827915544744448}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  79%|███████▉  | 79/100 [00:30<00:10,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:11,963] Trial 78 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.027876602230264363, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.6768013328113138}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  80%|████████  | 80/100 [00:31<00:09,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:12,358] Trial 79 finished with value: 0.8372549019607842 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  81%|████████  | 81/100 [00:31<00:08,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:12,783] Trial 80 finished with value: 0.8506722689075629 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.03762999451134458, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.750305009357086}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  82%|████████▏ | 82/100 [00:31<00:07,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:13,181] Trial 81 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 32, 'learning_rate': 0.07506050232161923, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  83%|████████▎ | 83/100 [00:32<00:08,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:13,730] Trial 82 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.02122546573204557, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9622658401204434}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  84%|████████▍ | 84/100 [00:32<00:07,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:14,231] Trial 83 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.051199140740849566, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  85%|████████▌ | 85/100 [00:33<00:07,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:14,696] Trial 84 finished with value: 0.8540616246498601 and parameters: {'max_features': None, 'n_estimators': 78, 'learning_rate': 0.04801856826308168, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  86%|████████▌ | 86/100 [00:33<00:06,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:15,155] Trial 85 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 78, 'learning_rate': 0.062221487420524364, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  87%|████████▋ | 87/100 [00:34<00:06,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:15,640] Trial 86 finished with value: 0.8641036414565827 and parameters: {'max_features': None, 'n_estimators': 78, 'learning_rate': 0.051917132248507795, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.6325024941144618}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  88%|████████▊ | 88/100 [00:34<00:06,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:16,200] Trial 87 finished with value: 0.850672268907563 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.04538043254459475, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  89%|████████▉ | 89/100 [00:35<00:05,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:16,805] Trial 88 finished with value: 0.8523529411764704 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.028177872016607715, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.7120933257393698}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  90%|█████████ | 90/100 [00:36<00:05,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:17,333] Trial 89 finished with value: 0.8557282913165267 and parameters: {'max_features': None, 'n_estimators': 73, 'learning_rate': 0.07266820874804247, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.6960377969119598}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 60. Best value: 0.864118:  91%|█████████ | 91/100 [00:36<00:04,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:17,834] Trial 90 finished with value: 0.8540196078431374 and parameters: {'max_features': 'log2', 'n_estimators': 84, 'learning_rate': 0.04390221020456657, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.7585876429714971}. Best is trial 60 with value: 0.8641176470588234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  92%|█████████▏| 92/100 [00:36<00:03,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:18,221] Trial 91 finished with value: 0.8674789915966385 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  93%|█████████▎| 93/100 [00:37<00:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:18,955] Trial 92 finished with value: 0.8607282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  94%|█████████▍| 94/100 [00:38<00:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:19,288] Trial 93 finished with value: 0.865798319327731 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  95%|█████████▌| 95/100 [00:38<00:02,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:19,631] Trial 94 finished with value: 0.8607422969187676 and parameters: {'max_features': 'log2', 'n_estimators': 71, 'learning_rate': 0.07635730322742852, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  96%|█████████▌| 96/100 [00:39<00:02,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:20,737] Trial 95 finished with value: 0.850658263305322 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  97%|█████████▋| 97/100 [00:39<00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:21,073] Trial 96 finished with value: 0.8456162464985993 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  98%|█████████▊| 98/100 [00:40<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:21,597] Trial 97 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 53, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479:  99%|█████████▉| 99/100 [00:40<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:22,225] Trial 98 finished with value: 0.8473249299719889 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.004848165753392966, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.8679376491252244}. Best is trial 91 with value: 0.8674789915966385.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 91. Best value: 0.867479: 100%|██████████| 100/100 [00:41<00:00,  2.41it/s]\n",
      "Best trial: 91. Best value: 0.867479: 100%|██████████| 100/100 [00:41<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:22,702] Trial 99 finished with value: 0.8473389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 19, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 91 with value: 0.8674789915966385.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using GPSampler: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}\n",
      "Best accuracy: 0.8675, at trial: 91\n",
      "GP Base Models Training Time: 154.42 seconds\n",
      "GP Base Models Training Time: 154.42 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_base_models_training_start = time.time()\n",
    "\n",
    "    # GP Hyperparameter Tuning with Cross Validation\n",
    "    gp_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    gp_logistic_regression.fit(X_train, y_train)\n",
    "    gp_decision_tree.fit(X_train, y_train)\n",
    "    gp_random_forest.fit(X_train, y_train)\n",
    "    gp_knn.fit(X_train, y_train)\n",
    "    gp_svc.fit(X_train, y_train)\n",
    "    gp_adaboost.fit(X_train, y_train)\n",
    "    gp_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    gp_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP base models training\n",
    "    gp_base_models_training_time = gp_base_models_training_end - gp_base_models_training_start\n",
    "    print(f'GP Base Models Training Time: {gp_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping GP base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:46,752] A new study created in memory with name: Logistic Regression Model Fine Tuning with CmaEsSampler\n",
      "Best trial: 2. Best value: 0.845588:   5%|▌         | 5/100 [00:00<00:03, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:46,791] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:29:46,817] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:46,865] Trial 1 finished with value: 0.84390756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.02205741280502818}. Best is trial 1 with value: 0.84390756302521.\n",
      "[W 2025-11-06 03:29:46,868] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:46,902] Trial 2 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.02802913837564577}. Best is trial 2 with value: 0.8455882352941175.\n",
      "[W 2025-11-06 03:29:46,905] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:46,941] Trial 3 finished with value: 0.8405882352941176 and parameters: {'solver': 'sag', 'C': 0.36204298853974154}. Best is trial 2 with value: 0.8455882352941175.\n",
      "[W 2025-11-06 03:29:46,944] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:46,967] Trial 4 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.00011850115518950796}. Best is trial 2 with value: 0.8455882352941175.\n",
      "[W 2025-11-06 03:29:46,970] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.84563:  12%|█▏        | 12/100 [00:00<00:03, 27.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:46,994] Trial 5 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.07655750872937357}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-11-06 03:29:46,997] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,022] Trial 6 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.03395851947833526}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-11-06 03:29:47,024] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,058] Trial 7 finished with value: 0.8305182072829131 and parameters: {'solver': 'newton-cg', 'C': 0.002988698359265086}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-11-06 03:29:47,060] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,094] Trial 8 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.12666361299777856}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-11-06 03:29:47,098] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,135] Trial 9 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.160329040179619}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,137] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,162] Trial 10 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.2125150037725021}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,164] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,187] Trial 11 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.020759772615306444}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,190] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.84563:  20%|██        | 20/100 [00:00<00:02, 32.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:47,225] Trial 12 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.1050060268493344}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,228] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,252] Trial 13 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.9738305134854172}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,254] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,278] Trial 14 finished with value: 0.8439495798319328 and parameters: {'solver': 'sag', 'C': 0.22468358511032036}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,280] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,303] Trial 15 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1279230260153545}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,306] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,329] Trial 16 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 0.4821800303373954}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,332] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,355] Trial 17 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.07746664121935645}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,357] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,381] Trial 18 finished with value: 0.8405882352941176 and parameters: {'solver': 'lbfgs', 'C': 0.33363800555855094}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,383] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,406] Trial 19 finished with value: 0.8405882352941176 and parameters: {'solver': 'sag', 'C': 0.30257851486990706}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,408] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.847283:  27%|██▋       | 27/100 [00:00<00:02, 32.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:47,432] Trial 20 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.07854266350187925}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,435] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,459] Trial 21 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 0.5168408542929493}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-11-06 03:29:47,461] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,497] Trial 22 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.060767189669359116}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:29:47,502] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,539] Trial 23 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1772466311693593}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:29:47,542] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,566] Trial 24 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.015897051082828156}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:29:47,568] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,593] Trial 25 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.03851774266987595}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:29:47,596] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,619] Trial 26 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.04838292296476062}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:29:47,622] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  35%|███▌      | 35/100 [00:01<00:01, 35.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:47,645] Trial 27 finished with value: 0.84390756302521 and parameters: {'solver': 'sag', 'C': 0.019268687553882072}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:29:47,648] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,672] Trial 28 finished with value: 0.8472969187675069 and parameters: {'solver': 'newton-cholesky', 'C': 0.08248633845203973}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-11-06 03:29:47,675] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,699] Trial 29 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06267356648505741}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-11-06 03:29:47,701] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,725] Trial 30 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.11774032747566768}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-11-06 03:29:47,728] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,753] Trial 31 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.04748647170395856}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-11-06 03:29:47,755] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,779] Trial 32 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.07344552654374271}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-11-06 03:29:47,783] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,807] Trial 33 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.03780757000240508}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-11-06 03:29:47,809] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,834] Trial 34 finished with value: 0.8489495798319329 and parameters: {'solver': 'newton-cholesky', 'C': 0.05851500684973518}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:47,836] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  41%|████      | 41/100 [00:01<00:01, 31.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:47,871] Trial 35 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.10614080148388617}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:47,874] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,909] Trial 36 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.04223167409928886}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:47,912] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,947] Trial 37 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.04654048430698835}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:47,949] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:47,984] Trial 38 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.03195952845707616}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:47,987] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,023] Trial 39 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.051364396056088106}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,027] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,053] Trial 40 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.03997924012395359}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,056] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  49%|████▉     | 49/100 [00:01<00:01, 34.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:48,082] Trial 41 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.04573213023521467}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,085] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,110] Trial 42 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05137907460083155}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,113] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,137] Trial 43 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.04407162639792366}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,140] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,164] Trial 44 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.060165740040896726}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,168] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,191] Trial 45 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.04945517657402623}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,194] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,218] Trial 46 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06753724588567601}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,220] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,244] Trial 47 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.056299241104257394}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,247] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,272] Trial 48 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.07673301964056288}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,275] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  56%|█████▌    | 56/100 [00:01<00:01, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:48,299] Trial 49 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.048117186206091137}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,302] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,338] Trial 50 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.059797234749209456}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,341] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,376] Trial 51 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.054167656458341505}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,378] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,402] Trial 52 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05974075314901565}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,405] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,439] Trial 53 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06349875945154873}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,441] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,465] Trial 54 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.053745731416729094}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,467] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,491] Trial 55 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05539587839612086}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,494] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  64%|██████▍   | 64/100 [00:01<00:01, 34.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:48,518] Trial 56 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.06001991804146136}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,521] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,545] Trial 57 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.05913531392888549}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,548] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,571] Trial 58 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05505764597902148}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,574] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,597] Trial 59 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.06280341165901325}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,599] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,623] Trial 60 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05533985807757942}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,626] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,649] Trial 61 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05414968013063547}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,652] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,676] Trial 62 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.056834098381984895}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,679] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,703] Trial 63 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.06221763939657786}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,705] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  71%|███████   | 71/100 [00:02<00:00, 33.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:48,742] Trial 64 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05772079167845554}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,746] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,781] Trial 65 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.060644659352029895}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,783] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,807] Trial 66 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05879445728173621}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,809] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,843] Trial 67 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.0544345917956727}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,845] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,869] Trial 68 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05585631475689836}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,872] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,896] Trial 69 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05661024089258117}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,898] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,921] Trial 70 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.058293096879936224}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,923] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  78%|███████▊  | 78/100 [00:02<00:00, 33.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:48,948] Trial 71 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05477785575189903}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,950] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:48,974] Trial 72 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05367862621189727}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:48,977] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,001] Trial 73 finished with value: 0.8489495798319329 and parameters: {'solver': 'sag', 'C': 0.058898725658782874}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,003] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,026] Trial 74 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05639606205205592}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,028] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,062] Trial 75 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05210165422854395}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,065] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,099] Trial 76 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05579554518606102}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,102] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,137] Trial 77 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05658729754857017}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,140] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  85%|████████▌ | 85/100 [00:02<00:00, 33.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:49,175] Trial 78 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05720671130689813}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,177] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,211] Trial 79 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.05956530398980257}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,215] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,249] Trial 80 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05812126818398885}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,252] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,276] Trial 81 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.060921300324001434}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,278] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,301] Trial 82 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.057687388878169175}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,303] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,327] Trial 83 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05763161365481594}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,329] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,353] Trial 84 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.058839403512141016}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,356] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  92%|█████████▏| 92/100 [00:02<00:00, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:49,379] Trial 85 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.05998588705875748}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,381] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,405] Trial 86 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.057985048425705156}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,407] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,430] Trial 87 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05947164228752938}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,432] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,456] Trial 88 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.06236889344961841}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,460] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,484] Trial 89 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05827137589941837}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,486] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,521] Trial 90 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.05931052073982035}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,526] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,562] Trial 91 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06192109817460178}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,566] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895:  99%|█████████▉| 99/100 [00:03<00:00, 32.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:49,591] Trial 92 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.060138108968675226}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,593] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,627] Trial 93 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.060197400854050634}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,629] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,653] Trial 94 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.05973548570489035}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,656] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,681] Trial 95 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.06006007940193424}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,684] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,718] Trial 96 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.060776304279112604}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,721] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,745] Trial 97 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.060685004727382}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,747] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,771] Trial 98 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.06176450579647688}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-11-06 03:29:49,773] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.84895: 100%|██████████| 100/100 [00:03<00:00, 32.86it/s]\n",
      "[I 2025-11-06 03:29:49,799] A new study created in memory with name: Decision Tree Model Fine Tuning with CmaEsSampler\n",
      "Best trial: 34. Best value: 0.84895: 100%|██████████| 100/100 [00:03<00:00, 32.86it/s]\n",
      "[I 2025-11-06 03:29:49,799] A new study created in memory with name: Decision Tree Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:49,796] Trial 99 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.061084058496037166}. Best is trial 34 with value: 0.8489495798319329.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using CmaEsSampler: {'solver': 'newton-cholesky', 'C': 0.05851500684973518}\n",
      "Best accuracy: 0.8489, at trial: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.827185:   9%|▉         | 9/100 [00:00<00:01, 53.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:49,813] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,816] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,817] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,831] Trial 1 finished with value: 0.813781512605042 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,833] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,834] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,847] Trial 2 finished with value: 0.8037254901960784 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,850] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,851] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,864] Trial 3 finished with value: 0.8238795518207285 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,867] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,868] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,882] Trial 4 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,885] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,886] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,910] Trial 5 finished with value: 0.8087394957983193 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,913] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,914] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,928] Trial 6 finished with value: 0.805392156862745 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,931] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,932] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,947] Trial 7 finished with value: 0.7935994397759103 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,953] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,955] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:49,982] Trial 8 finished with value: 0.8205042016806724 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:49,985] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:49,987] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.84395:  20%|██        | 20/100 [00:00<00:01, 48.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:50,014] Trial 9 finished with value: 0.8171148459383752 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:29:50,017] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,018] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,032] Trial 10 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,035] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,036] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,050] Trial 11 finished with value: 0.8288515406162464 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,054] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,055] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,081] Trial 12 finished with value: 0.8087114845938375 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,084] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,085] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,098] Trial 13 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,101] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,102] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,115] Trial 14 finished with value: 0.8305602240896357 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,118] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,119] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,133] Trial 15 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,135] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,136] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,149] Trial 16 finished with value: 0.8204901960784314 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,152] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,152] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,166] Trial 17 finished with value: 0.8288795518207281 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,169] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,170] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,183] Trial 18 finished with value: 0.8087394957983193 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,186] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,187] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,202] Trial 19 finished with value: 0.8204901960784312 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,205] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,206] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.84395:  30%|███       | 30/100 [00:00<00:01, 49.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:50,220] Trial 20 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,222] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,223] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,237] Trial 21 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,240] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,242] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,255] Trial 22 finished with value: 0.82890756302521 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,257] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,258] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,272] Trial 23 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,274] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,275] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,289] Trial 24 finished with value: 0.8221428571428572 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,293] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,294] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,310] Trial 25 finished with value: 0.8154481792717085 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,313] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,314] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,329] Trial 26 finished with value: 0.8321848739495799 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,332] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,333] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,348] Trial 27 finished with value: 0.7969467787114846 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,351] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,352] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,367] Trial 28 finished with value: 0.8271988795518206 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,371] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,373] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,400] Trial 29 finished with value: 0.8154481792717088 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,403] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,404] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,418] Trial 30 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.8439495798319326.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.843978:  42%|████▏     | 42/100 [00:00<00:01, 53.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:29:50,422] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,423] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,438] Trial 31 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,440] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,441] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,455] Trial 32 finished with value: 0.8272268907563024 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,458] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,459] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,473] Trial 33 finished with value: 0.793641456582633 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8439495798319326.\n",
      "[W 2025-11-06 03:29:50,475] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,477] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,490] Trial 34 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,493] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,494] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,507] Trial 35 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,511] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,512] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,525] Trial 36 finished with value: 0.8288515406162464 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,527] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,528] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,542] Trial 37 finished with value: 0.8204901960784314 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,544] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,545] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,559] Trial 38 finished with value: 0.8171288515406163 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,561] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,562] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,575] Trial 39 finished with value: 0.8238235294117647 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,578] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,579] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,592] Trial 40 finished with value: 0.8087254901960783 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,595] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,596] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,610] Trial 41 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,613] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,614] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.843978:  47%|████▋     | 47/100 [00:00<00:00, 53.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:50,628] Trial 42 finished with value: 0.8238375350140055 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,631] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,632] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,646] Trial 43 finished with value: 0.8137254901960784 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,648] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,650] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,664] Trial 44 finished with value: 0.7969467787114846 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,666] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,667] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,681] Trial 45 finished with value: 0.8187675070028011 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,683] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,684] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:50,697] Trial 46 finished with value: 0.8171148459383752 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:50,700] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:50,701] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:51,211] Trial 47 finished with value: 0.8104621848739495 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,214] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,216] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,230] Trial 48 finished with value: 0.8019887955182072 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,233] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,234] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,258] Trial 49 finished with value: 0.8272128851540617 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,261] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,262] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,286] Trial 50 finished with value: 0.8204901960784314 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,289] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,290] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,304] Trial 51 finished with value: 0.8221708683473388 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,308] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,309] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,323] Trial 52 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,325] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,326] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,340] Trial 53 finished with value: 0.8120308123249298 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,342] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,343] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,357] Trial 54 finished with value: 0.8137254901960784 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,360] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,361] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,375] Trial 55 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,377] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,378] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,391] Trial 56 finished with value: 0.8255322128851541 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,394] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,395] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,408] Trial 57 finished with value: 0.8154481792717085 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,411] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.843978:  68%|██████▊   | 68/100 [00:01<00:00, 37.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:29:51,412] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,426] Trial 58 finished with value: 0.818795518207283 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,428] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,429] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,442] Trial 59 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,444] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,445] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,458] Trial 60 finished with value: 0.8255322128851541 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,461] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,462] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,475] Trial 61 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,477] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,478] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,491] Trial 62 finished with value: 0.793641456582633 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,493] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,494] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,507] Trial 63 finished with value: 0.8154481792717085 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,510] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,511] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,525] Trial 64 finished with value: 0.8154481792717085 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,528] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,529] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,543] Trial 65 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,545] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,546] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,559] Trial 66 finished with value: 0.7902380952380953 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,562] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,564] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,580] Trial 67 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,584] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,585] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,611] Trial 68 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 34 with value: 0.8439775910364145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 78. Best value: 0.847339:  79%|███████▉  | 79/100 [00:02<00:00, 43.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:29:51,615] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,616] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,629] Trial 69 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8439775910364145.\n",
      "[W 2025-11-06 03:29:51,633] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,634] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,649] Trial 70 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,653] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,654] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,670] Trial 71 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,673] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,674] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,688] Trial 72 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,691] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,692] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,706] Trial 73 finished with value: 0.7851820728291317 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,710] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,711] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,724] Trial 74 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,727] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,728] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,742] Trial 75 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,745] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,746] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,760] Trial 76 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,763] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,765] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,779] Trial 77 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 70 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:29:51,783] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,784] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,798] Trial 78 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,801] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,802] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 78. Best value: 0.847339:  91%|█████████ | 91/100 [00:02<00:00, 49.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:51,816] Trial 79 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,819] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,820] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,834] Trial 80 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,837] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,838] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,853] Trial 81 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,856] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,857] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,870] Trial 82 finished with value: 0.82890756302521 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,873] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,874] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,887] Trial 83 finished with value: 0.8204901960784314 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,889] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,890] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,903] Trial 84 finished with value: 0.8171148459383752 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,906] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,907] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,920] Trial 85 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,923] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,924] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,937] Trial 86 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,940] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,941] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,954] Trial 87 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,957] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,958] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,972] Trial 88 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,975] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,976] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:51,990] Trial 89 finished with value: 0.8473109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:51,992] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:51,993] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,007] Trial 90 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:52,009] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,010] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 93. Best value: 0.8507: 100%|██████████| 100/100 [00:02<00:00, 41.58it/s] \n",
      "[I 2025-11-06 03:29:52,206] A new study created in memory with name: Random Forest Model Fine Tuning with CmaEsSampler\n",
      "Best trial: 93. Best value: 0.8507: 100%|██████████| 100/100 [00:02<00:00, 41.58it/s]\n",
      "[I 2025-11-06 03:29:52,206] A new study created in memory with name: Random Forest Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:52,023] Trial 91 finished with value: 0.8238375350140055 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:52,026] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,027] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,041] Trial 92 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 78 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:29:52,045] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,046] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,071] Trial 93 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 93 with value: 0.850700280112045.\n",
      "[W 2025-11-06 03:29:52,075] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,077] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,091] Trial 94 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 93 with value: 0.850700280112045.\n",
      "[W 2025-11-06 03:29:52,096] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,097] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,112] Trial 95 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 93 with value: 0.850700280112045.\n",
      "[W 2025-11-06 03:29:52,115] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,117] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,132] Trial 96 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 93 with value: 0.850700280112045.\n",
      "[W 2025-11-06 03:29:52,136] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,137] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,152] Trial 97 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 93 with value: 0.850700280112045.\n",
      "[W 2025-11-06 03:29:52,155] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,157] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,183] Trial 98 finished with value: 0.8321848739495799 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 93 with value: 0.850700280112045.\n",
      "[W 2025-11-06 03:29:52,187] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,188] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,203] Trial 99 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 93 with value: 0.850700280112045.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using CmaEsSampler: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}\n",
      "Best accuracy: 0.8507, at trial: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.854034:   2%|▏         | 2/100 [00:00<00:08, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:52,272] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[W 2025-11-06 03:29:52,275] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,276] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,371] Trial 1 finished with value: 0.8540336134453781 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8540336134453781.\n",
      "[W 2025-11-06 03:29:52,374] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,375] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:   5%|▌         | 5/100 [00:00<00:09, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:52,490] Trial 2 finished with value: 0.8523669467787114 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8540336134453781.\n",
      "[W 2025-11-06 03:29:52,492] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,493] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,587] Trial 3 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:52,591] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,591] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,686] Trial 4 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:52,689] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,690] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:   8%|▊         | 8/100 [00:00<00:08, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:52,815] Trial 5 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 79, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:52,818] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,819] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,894] Trial 6 finished with value: 0.8490056022408965 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 29, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:52,896] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,897] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:52,971] Trial 7 finished with value: 0.8507002801120447 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:52,974] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:52,974] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:  10%|█         | 10/100 [00:00<00:08, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:53,078] Trial 8 finished with value: 0.8523809523809526 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,081] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,082] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:53,176] Trial 9 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,179] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,180] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:  12%|█▏        | 12/100 [00:01<00:09,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:53,308] Trial 10 finished with value: 0.8490196078431372 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 65, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,312] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,313] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:53,463] Trial 11 finished with value: 0.8490196078431371 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,466] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,467] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:  14%|█▍        | 14/100 [00:01<00:09,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:53,595] Trial 12 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 73, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,597] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,598] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:53,703] Trial 13 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,707] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,708] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:  16%|█▌        | 16/100 [00:01<00:09,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:53,803] Trial 14 finished with value: 0.8473529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,805] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,806] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:53,942] Trial 15 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:53,946] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:53,948] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:  18%|█▊        | 18/100 [00:01<00:08,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:54,013] Trial 16 finished with value: 0.8439495798319328 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 23, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:54,016] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,017] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:54,131] Trial 17 finished with value: 0.842282913165266 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:54,134] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,135] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:  20%|██        | 20/100 [00:02<00:08,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:54,229] Trial 18 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:54,232] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,233] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:54,337] Trial 19 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:54,341] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,342] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.854048:  22%|██▏       | 22/100 [00:02<00:09,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:54,487] Trial 20 finished with value: 0.8490056022408963 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:54,490] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,491] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:54,626] Trial 21 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:54,629] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,631] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.854062:  24%|██▍       | 24/100 [00:02<00:08,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:54,755] Trial 22 finished with value: 0.850700280112045 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:29:54,759] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,760] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:54,856] Trial 23 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:54,860] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:54,861] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.854062:  26%|██▌       | 26/100 [00:02<00:10,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:55,027] Trial 24 finished with value: 0.8406442577030813 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 77, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,033] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,035] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:55,173] Trial 25 finished with value: 0.8523809523809526 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,177] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,179] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.854062:  28%|██▊       | 28/100 [00:03<00:11,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:55,368] Trial 26 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,375] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,379] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:55,526] Trial 27 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,530] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,532] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.854062:  31%|███       | 31/100 [00:03<00:08,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:55,647] Trial 28 finished with value: 0.8439775910364146 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 41, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,650] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,651] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:55,705] Trial 29 finished with value: 0.8456442577030814 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,708] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,710] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:55,815] Trial 30 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,818] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,819] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.857367:  33%|███▎      | 33/100 [00:03<00:07,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:55,924] Trial 31 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 47, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.8540616246498601.\n",
      "[W 2025-11-06 03:29:55,928] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:55,929] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:56,034] Trial 32 finished with value: 0.8573669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,039] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,041] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.857367:  35%|███▌      | 35/100 [00:04<00:07,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:56,159] Trial 33 finished with value: 0.8473669467787113 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 45, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,163] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,164] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:56,280] Trial 34 finished with value: 0.8506862745098038 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,284] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,285] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.857367:  37%|███▋      | 37/100 [00:04<00:06,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:56,371] Trial 35 finished with value: 0.83890756302521 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 26, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,375] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,377] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:56,462] Trial 36 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 31, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,466] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,468] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.857367:  39%|███▉      | 39/100 [00:04<00:07,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:56,614] Trial 37 finished with value: 0.8557142857142856 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,618] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,619] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:56,745] Trial 38 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,749] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,751] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.857367:  40%|████      | 40/100 [00:04<00:07,  8.28it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 368, in __init__\n",
      "    self._wlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 368, in __init__\n",
      "    self._wlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "Best trial: 32. Best value: 0.857367:  40%|████      | 40/100 [00:04<00:07,  8.28it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 368, in __init__\n",
      "    self._wlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 368, in __init__\n",
      "    self._wlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "Best trial: 32. Best value: 0.857367:  41%|████      | 41/100 [00:04<00:07,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:56,836] Trial 39 finished with value: 0.8540056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 32, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:56,840] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:56,841] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,033] Trial 40 failed with parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 76, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-06 03:29:57,036] Trial 40 failed with value nan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.857367:  42%|████▏     | 42/100 [00:04<00:07,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:29:57,039] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,041] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:57,179] Trial 41 finished with value: 0.8473529411764705 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 55, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:57,183] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,185] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  44%|████▍     | 44/100 [00:05<00:07,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:57,341] Trial 42 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8573669467787116.\n",
      "[W 2025-11-06 03:29:57,345] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,347] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:57,453] Trial 43 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:57,457] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,458] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  46%|████▌     | 46/100 [00:05<00:06,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:57,553] Trial 44 finished with value: 0.8422829131652663 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 28, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:57,557] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,558] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:57,643] Trial 45 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 28, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:57,645] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,647] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  48%|████▊     | 48/100 [00:05<00:06,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:57,772] Trial 46 finished with value: 0.8439635854341736 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:57,775] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,776] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:57,881] Trial 47 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:57,886] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:57,887] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  50%|█████     | 50/100 [00:06<00:06,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:58,057] Trial 48 finished with value: 0.8523809523809526 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:58,061] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,063] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:58,210] Trial 49 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 52, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:58,216] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,217] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  52%|█████▏    | 52/100 [00:06<00:06,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:58,333] Trial 50 finished with value: 0.8557002801120447 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:58,337] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,339] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:58,445] Trial 51 finished with value: 0.8557563025210084 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 44, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:58,449] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,450] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  53%|█████▎    | 53/100 [00:06<00:05,  8.34it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 363, in __init__\n",
      "    self._rlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 368, in __init__\n",
      "    self._wlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "Best trial: 43. Best value: 0.857395:  53%|█████▎    | 53/100 [00:06<00:05,  8.34it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 363, in __init__\n",
      "    self._rlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 903, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 368, in __init__\n",
      "    self._wlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(\n",
      "Best trial: 43. Best value: 0.857395:  54%|█████▍    | 54/100 [00:06<00:05,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:58,547] Trial 52 finished with value: 0.8439495798319326 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 29, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:58,552] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,554] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,673] Trial 53 failed with parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 4} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-06 03:29:58,675] Trial 53 failed with value nan.\n",
      "[W 2025-11-06 03:29:58,679] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,680] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  56%|█████▌    | 56/100 [00:06<00:05,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:58,797] Trial 54 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:58,800] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,801] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:58,896] Trial 55 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 35, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:58,899] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:58,900] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  58%|█████▊    | 58/100 [00:06<00:05,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:59,005] Trial 56 finished with value: 0.8406022408963585 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 42, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:59,008] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,009] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:59,148] Trial 57 finished with value: 0.8456582633053221 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:59,151] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,153] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  60%|██████    | 60/100 [00:07<00:04,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:59,258] Trial 58 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 44, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:59,262] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,263] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:59,389] Trial 59 finished with value: 0.8490056022408965 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:59,393] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,394] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  61%|██████    | 61/100 [00:07<00:05,  7.76it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 486, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 363, in __init__\n",
      "    self._rlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "Best trial: 43. Best value: 0.857395:  61%|██████    | 61/100 [00:07<00:05,  7.76it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 486, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 363, in __init__\n",
      "    self._rlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "Best trial: 43. Best value: 0.857395:  62%|██████▏   | 62/100 [00:07<00:05,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:59,537] Trial 60 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:59,540] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,542] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,690] Trial 61 failed with parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-06 03:29:59,692] Trial 61 failed with value nan.\n",
      "[W 2025-11-06 03:29:59,696] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,697] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  64%|██████▍   | 64/100 [00:07<00:04,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:29:59,783] Trial 62 finished with value: 0.8288375350140056 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 29, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:59,787] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,788] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:29:59,913] Trial 63 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:29:59,917] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:29:59,918] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  66%|██████▌   | 66/100 [00:08<00:04,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:00,056] Trial 64 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:00,060] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:00,062] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:00,228] Trial 65 finished with value: 0.8490336134453781 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:00,231] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:00,233] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  68%|██████▊   | 68/100 [00:08<00:03,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:00,317] Trial 66 finished with value: 0.8288935574229692 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 30, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:00,321] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:00,322] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:00,426] Trial 67 finished with value: 0.8473389355742297 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 47, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:00,430] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:00,432] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  70%|███████   | 70/100 [00:08<00:03,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:00,548] Trial 68 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:00,551] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:00,553] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:00,710] Trial 69 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:00,713] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:00,714] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  72%|███████▏  | 72/100 [00:08<00:03,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:00,850] Trial 70 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:00,854] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:00,855] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:01,002] Trial 71 finished with value: 0.8490196078431372 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:01,006] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:01,007] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  74%|███████▍  | 74/100 [00:09<00:03,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:01,091] Trial 72 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 33, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:01,094] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:01,096] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:01,253] Trial 73 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:01,257] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:01,259] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  76%|███████▌  | 76/100 [00:09<00:03,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:01,386] Trial 74 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 33, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:01,391] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:01,393] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:01,519] Trial 75 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:01,523] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:01,524] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  78%|███████▊  | 78/100 [00:09<00:03,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:01,760] Trial 76 finished with value: 0.8523809523809526 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 67, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:01,764] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:01,765] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:01,901] Trial 77 finished with value: 0.8490196078431372 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:01,905] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:01,906] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  80%|████████  | 80/100 [00:09<00:02,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:02,063] Trial 78 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:02,067] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:02,068] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:02,183] Trial 79 finished with value: 0.8523949579831932 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:02,186] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:02,188] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 0.857395:  82%|████████▏ | 82/100 [00:10<00:02,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:02,313] Trial 80 finished with value: 0.8473109243697478 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:02,316] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:02,317] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:02,422] Trial 81 finished with value: 0.8557422969187677 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:02,427] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:02,428] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  84%|████████▍ | 84/100 [00:10<00:02,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:02,610] Trial 82 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 43 with value: 0.8573949579831932.\n",
      "[W 2025-11-06 03:30:02,613] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:02,614] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:02,729] Trial 83 finished with value: 0.8574089635854343 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:02,735] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:02,736] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  86%|████████▌ | 86/100 [00:10<00:02,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:02,893] Trial 84 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:02,897] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:02,898] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:03,036] Trial 85 finished with value: 0.8473249299719887 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,039] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,040] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  88%|████████▊ | 88/100 [00:11<00:01,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:03,146] Trial 86 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 47, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,149] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,150] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:03,265] Trial 87 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,268] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,269] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  89%|████████▉ | 89/100 [00:11<00:01,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:03,374] Trial 88 finished with value: 0.8557142857142856 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,379] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,380] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  91%|█████████ | 91/100 [00:11<00:01,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:03,579] Trial 89 finished with value: 0.8439915966386554 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,583] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,585] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:03,701] Trial 90 finished with value: 0.840644257703081 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 45, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,705] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,707] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  93%|█████████▎| 93/100 [00:11<00:00,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:03,834] Trial 91 finished with value: 0.850700280112045 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,838] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,840] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:03,957] Trial 92 finished with value: 0.8557422969187677 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:03,960] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:03,962] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  94%|█████████▍| 94/100 [00:11<00:00,  7.52it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 486, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 363, in __init__\n",
      "    self._rlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "Best trial: 83. Best value: 0.857409:  94%|█████████▍| 94/100 [00:11<00:00,  7.52it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 486, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 2070, in __call__\n",
      "    next(output)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1675, in _get_outputs\n",
      "    self._start(iterator, pre_dispatch)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1658, in _start\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1540, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/parallel.py\", line 1437, in _dispatch\n",
      "    job = self._backend.submit(batch, callback=batch_tracker)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 339, in submit\n",
      "    return self._get_pool().apply_async(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/_parallel_backends.py\", line 507, in _get_pool\n",
      "    self._pool = ThreadPool(self._n_jobs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 930, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/pool.py\", line 196, in __init__\n",
      "    self._change_notifier = self._ctx.SimpleQueue()\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 338, in SimpleQueue\n",
      "    return SimpleQueue(reducers=reducers, ctx=self.get_context())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/queues.py\", line 198, in __init__\n",
      "    super().__init__(ctx=ctx)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/multiprocessing/queues.py\", line 363, in __init__\n",
      "    self._rlock = ctx.Lock()\n",
      "                  ^^^^^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py\", line 362, in Lock\n",
      "    return Lock()\n",
      "           ^^^^^^\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 192, in __init__\n",
      "    super().__init__(SEMAPHORE, 1, 1)\n",
      "  File \"/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py\", line 72, in __init__\n",
      "    self._semlock = _SemLock(\n",
      "                    ^^^^^^^^^\n",
      "OSError: [Errno 122] Disk quota exceeded\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "Best trial: 83. Best value: 0.857409:  95%|█████████▌| 95/100 [00:12<00:00,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:04,087] Trial 93 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:04,092] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:04,094] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:04,231] Trial 94 failed with parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 56, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-11-06 03:30:04,233] Trial 94 failed with value nan.\n",
      "[W 2025-11-06 03:30:04,236] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:04,237] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  97%|█████████▋| 97/100 [00:12<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:04,383] Trial 95 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 76, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:04,386] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:04,387] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:04,503] Trial 96 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:04,507] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:04,509] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409:  99%|█████████▉| 99/100 [00:12<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:04,657] Trial 97 finished with value: 0.845658263305322 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 58, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:04,662] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:04,663] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:04,800] Trial 98 finished with value: 0.8523809523809526 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 83 with value: 0.8574089635854343.\n",
      "[W 2025-11-06 03:30:04,803] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:04,805] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.857409: 100%|██████████| 100/100 [00:12<00:00,  7.86it/s]\n",
      "[I 2025-11-06 03:30:04,924] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with CmaEsSampler\n",
      "Best trial: 83. Best value: 0.857409: 100%|██████████| 100/100 [00:12<00:00,  7.86it/s]\n",
      "[I 2025-11-06 03:30:04,924] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:04,921] Trial 99 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 52, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 83 with value: 0.8574089635854343.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using CmaEsSampler: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7}\n",
      "Best accuracy: 0.8574, at trial: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.849006:   4%|▍         | 4/100 [00:00<00:04, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:04,970] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-11-06 03:30:04,973] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,009] Trial 1 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-11-06 03:30:05,012] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,057] Trial 2 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-11-06 03:30:05,060] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,106] Trial 3 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-11-06 03:30:05,109] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.849006:   5%|▌         | 5/100 [00:00<00:04, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,136] Trial 4 finished with value: 0.8271008403361346 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-11-06 03:30:05,139] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.850672:   9%|▉         | 9/100 [00:00<00:03, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,186] Trial 5 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 1}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-11-06 03:30:05,191] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,237] Trial 6 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-11-06 03:30:05,241] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,267] Trial 7 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 2}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-11-06 03:30:05,271] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,301] Trial 8 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,305] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.850672:  11%|█         | 11/100 [00:00<00:03, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,350] Trial 9 finished with value: 0.850672268907563 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,353] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,377] Trial 10 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,380] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.850672:  15%|█▌        | 15/100 [00:00<00:03, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,414] Trial 11 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,417] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,451] Trial 12 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,454] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,478] Trial 13 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,481] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,515] Trial 14 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,518] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.850672:  17%|█▋        | 17/100 [00:00<00:03, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,552] Trial 15 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 1}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,555] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,589] Trial 16 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,593] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  21%|██        | 21/100 [00:00<00:03, 26.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,618] Trial 17 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,621] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,654] Trial 18 finished with value: 0.850672268907563 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:05,657] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,691] Trial 19 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,694] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,741] Trial 20 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,745] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,770] Trial 21 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,773] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,818] Trial 22 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  27%|██▋       | 27/100 [00:01<00:02, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:05,822] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,846] Trial 23 finished with value: 0.850686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,850] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,875] Trial 24 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,879] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,913] Trial 25 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,916] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:05,950] Trial 26 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,954] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  29%|██▉       | 29/100 [00:01<00:02, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:05,977] Trial 27 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:05,981] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,004] Trial 28 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,008] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  33%|███▎      | 33/100 [00:01<00:02, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,032] Trial 29 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,035] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,059] Trial 30 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,063] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,097] Trial 31 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,100] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,134] Trial 32 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,137] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  35%|███▌      | 35/100 [00:01<00:02, 28.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,183] Trial 33 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,185] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,219] Trial 34 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,222] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  40%|████      | 40/100 [00:01<00:01, 30.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,256] Trial 35 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,258] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,282] Trial 36 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,285] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,309] Trial 37 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,312] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,336] Trial 38 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,338] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,362] Trial 39 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,365] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  42%|████▏     | 42/100 [00:01<00:01, 30.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,399] Trial 40 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,402] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,426] Trial 41 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,428] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  46%|████▌     | 46/100 [00:01<00:01, 30.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,462] Trial 42 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,466] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,490] Trial 43 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,493] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,527] Trial 44 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,530] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,554] Trial 45 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,559] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  47%|████▋     | 47/100 [00:01<00:01, 29.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,605] Trial 46 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,609] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  52%|█████▏    | 52/100 [00:01<00:01, 27.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,664] Trial 47 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,668] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,703] Trial 48 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,707] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,742] Trial 49 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,745] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,769] Trial 50 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,773] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,798] Trial 51 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,801] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  53%|█████▎    | 53/100 [00:01<00:01, 27.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,846] Trial 52 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,850] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  58%|█████▊    | 58/100 [00:02<00:01, 27.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:06,884] Trial 53 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,887] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,922] Trial 54 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,925] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,950] Trial 55 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,953] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:06,987] Trial 56 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:06,990] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,024] Trial 57 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,027] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  59%|█████▉    | 59/100 [00:02<00:01, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,051] Trial 58 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,054] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  63%|██████▎   | 63/100 [00:02<00:01, 26.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,089] Trial 59 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,093] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,140] Trial 60 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,144] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,179] Trial 61 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,183] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,217] Trial 62 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,221] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  65%|██████▌   | 65/100 [00:02<00:01, 27.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,255] Trial 63 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,258] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,281] Trial 64 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,284] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,318] Trial 65 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,321] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,355] Trial 66 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,358] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,391] Trial 67 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,394] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,428] Trial 68 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,431] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  72%|███████▏  | 72/100 [00:02<00:00, 29.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,455] Trial 69 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,458] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,482] Trial 70 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,484] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,508] Trial 71 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,513] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  75%|███████▌  | 75/100 [00:02<00:00, 27.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,560] Trial 72 finished with value: 0.850686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,564] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,609] Trial 73 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,612] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,638] Trial 74 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,641] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  78%|███████▊  | 78/100 [00:02<00:00, 27.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,675] Trial 75 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,678] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,713] Trial 76 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,715] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,740] Trial 77 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,743] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  82%|████████▏ | 82/100 [00:02<00:00, 28.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,767] Trial 78 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,771] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,795] Trial 79 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,798] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,843] Trial 80 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,846] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,870] Trial 81 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,873] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  84%|████████▍ | 84/100 [00:03<00:00, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,907] Trial 82 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,910] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:07,945] Trial 83 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,949] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  87%|████████▋ | 87/100 [00:03<00:00, 27.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:07,974] Trial 84 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:07,978] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,024] Trial 85 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,027] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,062] Trial 86 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,066] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  89%|████████▉ | 89/100 [00:03<00:00, 27.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,112] Trial 87 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,114] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,148] Trial 88 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,152] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  93%|█████████▎| 93/100 [00:03<00:00, 27.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,176] Trial 89 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,180] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,215] Trial 90 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,220] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,255] Trial 91 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,258] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,282] Trial 92 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,285] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367:  95%|█████████▌| 95/100 [00:03<00:00, 27.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,319] Trial 93 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,322] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,356] Trial 94 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,358] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.852367: 100%|██████████| 100/100 [00:03<00:00, 27.94it/s]\n",
      "[I 2025-11-06 03:30:08,506] A new study created in memory with name: Support Vector Machine Model Fine Tuning with CmaEsSampler\n",
      "Best trial: 19. Best value: 0.852367: 100%|██████████| 100/100 [00:03<00:00, 27.94it/s]\n",
      "[I 2025-11-06 03:30:08,506] A new study created in memory with name: Support Vector Machine Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,382] Trial 95 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,385] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,408] Trial 96 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,413] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,439] Trial 97 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,442] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,476] Trial 98 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:08,479] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,503] Trial 99 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using CmaEsSampler: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   1%|          | 1/100 [00:00<00:03, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,540] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,543] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   5%|▌         | 5/100 [00:00<00:04, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,599] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000865808466690932}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,603] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,638] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0009528924787594206}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,641] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,676] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002651575859618515}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,679] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,705] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010702593573937491}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,708] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,743] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0013648551870204498}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,746] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,770] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009741063383591005}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,773] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:08,775] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:  12%|█▏        | 12/100 [00:00<00:02, 30.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,800] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00035536968608811256, 'degree': 5}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,803] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:08,805] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,830] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0016819495611083031, 'degree': 2}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,832] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,856] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0018375880092626332}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,859] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,894] Trial 10 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0020594834365669262}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,896] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:08,898] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,923] Trial 11 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0008036660590116804, 'degree': 3}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,926] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:  14%|█▍        | 14/100 [00:00<00:02, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:08,959] Trial 12 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015484212122073447}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:30:08,963] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:08,998] Trial 13 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.004325242884695832}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.718151:  18%|█▊        | 18/100 [00:00<00:02, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:09,001] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,003] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,026] Trial 14 finished with value: 0.5385994397759104 and parameters: {'kernel': 'poly', 'C': 0.0022625707493004244, 'degree': 2}. Best is trial 14 with value: 0.5385994397759104.\n",
      "[W 2025-11-06 03:30:09,029] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,053] Trial 15 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0017640869367327792}. Best is trial 14 with value: 0.5385994397759104.\n",
      "[W 2025-11-06 03:30:09,055] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,057] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,081] Trial 16 finished with value: 0.7181512605042017 and parameters: {'kernel': 'poly', 'C': 0.0031705200615514424, 'degree': 2}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-11-06 03:30:09,085] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,087] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,123] Trial 17 finished with value: 0.64093837535014 and parameters: {'kernel': 'poly', 'C': 0.001531664733418209, 'degree': 3}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-11-06 03:30:09,127] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.718151:  19%|█▉        | 19/100 [00:00<00:02, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:09,175] Trial 18 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004213260002115004}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-11-06 03:30:09,179] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  25%|██▌       | 25/100 [00:00<00:02, 29.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:09,214] Trial 19 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.003937407690960455}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-11-06 03:30:09,217] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,219] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,243] Trial 20 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.0015463764498834167, 'degree': 5}. Best is trial 20 with value: 0.7516946778711484.\n",
      "[W 2025-11-06 03:30:09,246] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,248] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,272] Trial 21 finished with value: 0.8204761904761904 and parameters: {'kernel': 'poly', 'C': 0.004656263801984052, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,275] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,309] Trial 22 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0013377781050154692}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,312] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,314] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,338] Trial 23 finished with value: 0.7903081232492998 and parameters: {'kernel': 'poly', 'C': 0.0024960236634973096, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,340] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,374] Trial 24 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006124837057596774}. Best is trial 21 with value: 0.8204761904761904.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:09,377] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,413] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001224735277924092}. Best is trial 21 with value: 0.8204761904761904.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  30%|███       | 30/100 [00:01<00:02, 28.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:09,415] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,440] Trial 26 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0018560190113149195}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,443] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,489] Trial 27 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00034645689676284766}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,492] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,517] Trial 28 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.004908712635519084}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,520] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,544] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0010486904393518669}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,547] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  31%|███       | 31/100 [00:01<00:02, 28.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:09,582] Trial 30 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0034407015907837787}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,585] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  36%|███▌      | 36/100 [00:01<00:02, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:09,631] Trial 31 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006216718417477061}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,634] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,669] Trial 32 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0014139694325885457}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,673] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,707] Trial 33 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005485682290781676}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,710] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,735] Trial 34 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0011235958186075275}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,738] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,763] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0029863087716820937}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,766] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  38%|███▊      | 38/100 [00:01<00:02, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:09,790] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006578423719111183}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,794] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,818] Trial 37 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00040296678905901224}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,821] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,822] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  43%|████▎     | 43/100 [00:01<00:01, 31.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:09,847] Trial 38 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00012428354273999503, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,850] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,885] Trial 39 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005486766842278361}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,888] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,890] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,914] Trial 40 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0002504512814532343, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,917] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:09,919] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,943] Trial 41 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00022297422161775347, 'degree': 3}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,946] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:09,971] Trial 42 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0004175850864536596}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:09,974] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  45%|████▌     | 45/100 [00:01<00:01, 31.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,008] Trial 43 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00018268201190564155}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,010] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,044] Trial 44 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009777458483130996}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,047] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  49%|████▉     | 49/100 [00:01<00:01, 31.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:10,048] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,072] Trial 45 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0011801408167297345, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,074] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,076] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,100] Trial 46 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0007335381696036133, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,103] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,137] Trial 47 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00019462947879376056}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,140] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,176] Trial 48 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0018602754514397218}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,180] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  50%|█████     | 50/100 [00:01<00:01, 31.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,216] Trial 49 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00014577705498660268}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,220] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  56%|█████▌    | 56/100 [00:01<00:01, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,254] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013881861015164923}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,258] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,260] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,284] Trial 51 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0004978928009492093, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,287] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,289] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,315] Trial 52 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0013746484283862841, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,318] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,319] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,344] Trial 53 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0006456709072415858, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,347] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,349] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,374] Trial 54 finished with value: 0.5419607843137255 and parameters: {'kernel': 'poly', 'C': 0.00040064924663028693, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,378] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,379] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,405] Trial 55 finished with value: 0.701358543417367 and parameters: {'kernel': 'poly', 'C': 0.0011711266636840346, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,409] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  57%|█████▋    | 57/100 [00:01<00:01, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,433] Trial 56 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00024255693132920944}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,436] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  62%|██████▏   | 62/100 [00:02<00:01, 30.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,470] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0011143711571493776}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,473] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,475] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,500] Trial 58 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0002053177521018289, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,504] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,527] Trial 59 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00463228439231072}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,531] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,532] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,557] Trial 60 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00023173598536067964, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,561] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,563] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,588] Trial 61 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00014638499390128256, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,590] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:10,592] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  63%|██████▎   | 63/100 [00:02<00:01, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,636] Trial 62 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00044388438395863867, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,639] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  67%|██████▋   | 67/100 [00:02<00:01, 26.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,673] Trial 63 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0035352281090840366}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,676] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,711] Trial 64 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006330195558208901}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,714] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,749] Trial 65 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0016935341727033935}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,754] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,822] Trial 66 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0008701158499912172}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,826] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  73%|███████▎  | 73/100 [00:02<00:01, 25.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:10,883] Trial 67 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0001661049745920624}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,887] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,923] Trial 68 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002891007001888575}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,927] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,961] Trial 69 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.000362279432414363}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:10,964] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:10,999] Trial 70 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007000923800626298}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,001] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,035] Trial 71 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017285110890269084}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,038] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,073] Trial 72 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00010956821422522963}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,077] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,079] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  80%|████████  | 80/100 [00:02<00:00, 28.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:11,105] Trial 73 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0008707416477194328, 'degree': 3}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,108] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,144] Trial 74 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00033401688760111763}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,148] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,149] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,174] Trial 75 finished with value: 0.6778431372549021 and parameters: {'kernel': 'poly', 'C': 0.0016314830283049855, 'degree': 3}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,178] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,179] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,204] Trial 76 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00026373825080236614, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,208] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,209] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,235] Trial 77 finished with value: 0.6023389355742297 and parameters: {'kernel': 'poly', 'C': 0.0005077277555356514, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,238] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,239] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,262] Trial 78 finished with value: 0.5453221288515406 and parameters: {'kernel': 'poly', 'C': 0.0007281552170449111, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,266] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,301] Trial 79 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0027756388290185135}. Best is trial 21 with value: 0.8204761904761904.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  86%|████████▌ | 86/100 [00:02<00:00, 29.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:11,306] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,308] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,334] Trial 80 finished with value: 0.7399299719887955 and parameters: {'kernel': 'poly', 'C': 0.001231286057882867, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,337] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,362] Trial 81 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0026743282368587072}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,365] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,388] Trial 82 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005452178621539995}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,391] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,425] Trial 83 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005300560241009997}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,427] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,429] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,452] Trial 84 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0009703753383087068, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,455] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,489] Trial 85 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001723956257070776}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,491] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.820476:  93%|█████████▎| 93/100 [00:03<00:00, 31.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:11,515] Trial 86 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000698339733628747}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,518] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,542] Trial 87 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013706374941728995}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,545] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,580] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004866464437218477}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,583] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,606] Trial 89 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007387576536983541}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,609] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,611] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,635] Trial 90 finished with value: 0.7047058823529412 and parameters: {'kernel': 'poly', 'C': 0.0011400833821732083, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,638] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,661] Trial 91 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0032819828374852844}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,664] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,688] Trial 92 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0016019965097149882}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,690] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,692] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,715] Trial 93 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.001541261031064544, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:11,718] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,752] Trial 94 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00120581367618869}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,756] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,758] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,785] Trial 95 finished with value: 0.7399439775910365 and parameters: {'kernel': 'poly', 'C': 0.0014330860009565277, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,789] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,791] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,817] Trial 96 finished with value: 0.7735294117647058 and parameters: {'kernel': 'poly', 'C': 0.0020908385326327927, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,821] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,887] Trial 97 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0030902614794853984}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-11-06 03:30:11,890] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:30:11,892] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 98. Best value: 0.833852: 100%|██████████| 100/100 [00:03<00:00, 29.03it/s]\n",
      "[I 2025-11-06 03:30:11,952] A new study created in memory with name: AdaBoost Model Fine Tuning with CmaEsSampler\n",
      "Best trial: 98. Best value: 0.833852: 100%|██████████| 100/100 [00:03<00:00, 29.03it/s]\n",
      "[I 2025-11-06 03:30:11,952] A new study created in memory with name: AdaBoost Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:11,918] Trial 98 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007082326034013085, 'degree': 2}. Best is trial 98 with value: 0.8338515406162464.\n",
      "[W 2025-11-06 03:30:11,922] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:11,948] Trial 99 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.004206127735212308}. Best is trial 98 with value: 0.8338515406162464.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using CmaEsSampler: {'kernel': 'poly', 'C': 0.007082326034013085, 'degree': 2}\n",
      "Best accuracy: 0.8339, at trial: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,047] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   2%|▏         | 2/100 [00:00<00:09, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,143] Trial 1 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 43, 'learning_rate': 0.025476088134515826}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:30:12,230] Trial 2 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 41, 'learning_rate': 0.029414796527869724}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   4%|▍         | 4/100 [00:00<00:09, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,336] Trial 3 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 60, 'learning_rate': 0.13653880096488336}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   6%|▌         | 6/100 [00:00<00:09, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,453] Trial 4 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 57, 'learning_rate': 0.0011072190527544395}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:30:12,529] Trial 5 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 36, 'learning_rate': 0.08721915368491258}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:   8%|▊         | 8/100 [00:00<00:07, 12.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,605] Trial 6 finished with value: 0.8490196078431371 and parameters: {'n_estimators': 39, 'learning_rate': 0.11322743764742889}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-11-06 03:30:12,651] Trial 7 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 13, 'learning_rate': 0.2334394218151809}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:   8%|▊         | 8/100 [00:00<00:07, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,747] Trial 8 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 43, 'learning_rate': 0.07399096721519229}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  10%|█         | 10/100 [00:00<00:07, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,823] Trial 9 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 46, 'learning_rate': 0.1484765386958742}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  10%|█         | 10/100 [00:01<00:07, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:12,992] Trial 10 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 63, 'learning_rate': 0.13319245398373342}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  12%|█▏        | 12/100 [00:01<00:09,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,109] Trial 11 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 55, 'learning_rate': 0.05581453477296136}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  12%|█▏        | 12/100 [00:01<00:09,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,195] Trial 12 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 44, 'learning_rate': 0.14935226414613875}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  14%|█▍        | 14/100 [00:01<00:08,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,312] Trial 13 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 49, 'learning_rate': 0.13842401731481163}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  14%|█▍        | 14/100 [00:01<00:08,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,428] Trial 14 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 53, 'learning_rate': 0.13195147366696638}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  16%|█▌        | 16/100 [00:01<00:08,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,526] Trial 15 finished with value: 0.8422689075630252 and parameters: {'n_estimators': 45, 'learning_rate': 0.8075854510810863}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  17%|█▋        | 17/100 [00:01<00:09,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,697] Trial 16 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 64, 'learning_rate': 0.04942512603468035}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  18%|█▊        | 18/100 [00:01<00:09,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,805] Trial 17 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 52, 'learning_rate': 0.6336609183426142}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  19%|█▉        | 19/100 [00:01<00:09,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:13,912] Trial 18 finished with value: 0.845658263305322 and parameters: {'n_estimators': 47, 'learning_rate': 0.10288801595611617}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  20%|██        | 20/100 [00:02<00:09,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,060] Trial 19 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 62, 'learning_rate': 0.43221559482885463}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  21%|██        | 21/100 [00:02<00:09,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,167] Trial 20 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 52, 'learning_rate': 0.7282689287680214}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  22%|██▏       | 22/100 [00:02<00:08,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,274] Trial 21 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 46, 'learning_rate': 0.10918100906664782}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  23%|██▎       | 23/100 [00:02<00:08,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,380] Trial 22 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 50, 'learning_rate': 0.06067154702689071}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-11-06 03:30:14,446] Trial 23 finished with value: 0.8422969187675069 and parameters: {'n_estimators': 29, 'learning_rate': 0.3170927675415055}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  25%|██▌       | 25/100 [00:02<00:07,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,563] Trial 24 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 48, 'learning_rate': 0.07602769676274204}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  27%|██▋       | 27/100 [00:02<00:06, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,652] Trial 25 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 34, 'learning_rate': 0.07278225797241931}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-11-06 03:30:14,728] Trial 26 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 29, 'learning_rate': 0.06516576033789111}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  27%|██▋       | 27/100 [00:02<00:06, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,845] Trial 27 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 61, 'learning_rate': 0.30611471590890166}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  29%|██▉       | 29/100 [00:03<00:07,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:14,962] Trial 28 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 72, 'learning_rate': 0.8577176564263388}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  30%|███       | 30/100 [00:03<00:07,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,110] Trial 29 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 68, 'learning_rate': 0.13342575965110032}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  31%|███       | 31/100 [00:03<00:07,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,218] Trial 30 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 48, 'learning_rate': 0.31831534584679094}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  32%|███▏      | 32/100 [00:03<00:07,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,344] Trial 31 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 72, 'learning_rate': 0.5770983224907398}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  33%|███▎      | 33/100 [00:03<00:07,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,460] Trial 32 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 53, 'learning_rate': 0.20833137086749112}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  34%|███▍      | 34/100 [00:03<00:07,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,579] Trial 33 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 70, 'learning_rate': 0.3112044025276943}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  35%|███▌      | 35/100 [00:03<00:07,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,719] Trial 34 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 63, 'learning_rate': 0.09290634866187134}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  36%|███▌      | 36/100 [00:03<00:07,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,847] Trial 35 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 54, 'learning_rate': 0.28673317197139264}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  37%|███▋      | 37/100 [00:04<00:07,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:15,964] Trial 36 finished with value: 0.8338655462184874 and parameters: {'n_estimators': 72, 'learning_rate': 0.031143252490389673}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  38%|███▊      | 38/100 [00:04<00:07,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,070] Trial 37 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 59, 'learning_rate': 0.23147137953568783}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  39%|███▉      | 39/100 [00:04<00:06,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,177] Trial 38 finished with value: 0.8439495798319326 and parameters: {'n_estimators': 59, 'learning_rate': 0.3272954464732462}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  40%|████      | 40/100 [00:04<00:06,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,295] Trial 39 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 62, 'learning_rate': 0.3020274012286614}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  41%|████      | 41/100 [00:04<00:06,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,416] Trial 40 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 50, 'learning_rate': 0.25914640700655756}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  42%|████▏     | 42/100 [00:04<00:06,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,523] Trial 41 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 68, 'learning_rate': 0.3673818935425286}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  43%|████▎     | 43/100 [00:04<00:06,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,650] Trial 42 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 65, 'learning_rate': 0.8382368194270798}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  43%|████▎     | 43/100 [00:04<00:06,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,747] Trial 43 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 57, 'learning_rate': 0.723009850506859}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  45%|████▌     | 45/100 [00:04<00:06,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:16,884] Trial 44 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 63, 'learning_rate': 0.2265048895530469}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  46%|████▌     | 46/100 [00:05<00:06,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,011] Trial 45 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 55, 'learning_rate': 0.13722410621042982}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  47%|████▋     | 47/100 [00:05<00:06,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,118] Trial 46 finished with value: 0.8439915966386554 and parameters: {'n_estimators': 64, 'learning_rate': 0.1318415087841612}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  48%|████▊     | 48/100 [00:05<00:06,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,255] Trial 47 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 66, 'learning_rate': 0.2676831117999835}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  49%|████▉     | 49/100 [00:05<00:06,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,382] Trial 48 finished with value: 0.842282913165266 and parameters: {'n_estimators': 58, 'learning_rate': 0.5224639056265394}. Best is trial 6 with value: 0.8490196078431371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  50%|█████     | 50/100 [00:05<00:06,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,530] Trial 49 finished with value: 0.850686274509804 and parameters: {'n_estimators': 61, 'learning_rate': 0.46684762630779697}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  51%|█████     | 51/100 [00:05<00:06,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,637] Trial 50 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 53, 'learning_rate': 0.6928423423430802}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:17,723] Trial 51 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 63, 'learning_rate': 0.32969172842538436}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  53%|█████▎    | 53/100 [00:05<00:04,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,799] Trial 52 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 54, 'learning_rate': 0.6678262122957844}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  55%|█████▌    | 55/100 [00:06<00:04, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:17,876] Trial 53 finished with value: 0.8372408963585434 and parameters: {'n_estimators': 52, 'learning_rate': 0.8307476099841097}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:17,982] Trial 54 finished with value: 0.842282913165266 and parameters: {'n_estimators': 53, 'learning_rate': 0.6591045772773171}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  57%|█████▋    | 57/100 [00:06<00:04,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:18,113] Trial 55 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 61, 'learning_rate': 0.9971948754002546}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:18,242] Trial 56 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 58, 'learning_rate': 0.4430766714194921}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  59%|█████▉    | 59/100 [00:06<00:04,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:18,338] Trial 57 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 53, 'learning_rate': 0.34517772412828807}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:18,454] Trial 58 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 57, 'learning_rate': 0.2615695769939464}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  61%|██████    | 61/100 [00:06<00:04,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:18,592] Trial 59 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 61, 'learning_rate': 0.280822261432388}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:18,709] Trial 60 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 57, 'learning_rate': 0.23003895798447352}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  63%|██████▎   | 63/100 [00:07<00:04,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:18,858] Trial 61 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 64, 'learning_rate': 0.11723273364843288}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:19,005] Trial 62 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 64, 'learning_rate': 0.09415611217211962}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  65%|██████▌   | 65/100 [00:07<00:04,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:19,134] Trial 63 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 57, 'learning_rate': 0.09177618111522291}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:19,260] Trial 64 finished with value: 0.850672268907563 and parameters: {'n_estimators': 62, 'learning_rate': 0.27023426061294153}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  67%|██████▋   | 67/100 [00:07<00:04,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:19,388] Trial 65 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 59, 'learning_rate': 0.36813638473923505}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:19,514] Trial 66 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 57, 'learning_rate': 0.42258730227581615}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  69%|██████▉   | 69/100 [00:07<00:03,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:19,632] Trial 67 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 56, 'learning_rate': 0.3625835356262582}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:19,738] Trial 68 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 63, 'learning_rate': 0.3019914100302694}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  71%|███████   | 71/100 [00:08<00:03,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:19,855] Trial 69 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 59, 'learning_rate': 0.17025592365121792}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:19,994] Trial 70 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 66, 'learning_rate': 0.5756562844391273}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  73%|███████▎  | 73/100 [00:08<00:03,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:20,121] Trial 71 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 62, 'learning_rate': 0.0727605228317948}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:20,269] Trial 72 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 68, 'learning_rate': 0.04487326581316685}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  75%|███████▌  | 75/100 [00:08<00:03,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:20,409] Trial 73 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 60, 'learning_rate': 0.22884454027300194}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:20,538] Trial 74 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 59, 'learning_rate': 0.516131352478289}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  77%|███████▋  | 77/100 [00:08<00:03,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:20,687] Trial 75 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 62, 'learning_rate': 0.5263862561025988}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:20,814] Trial 76 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 59, 'learning_rate': 0.5525903137332405}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  79%|███████▉  | 79/100 [00:09<00:02,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:20,942] Trial 77 finished with value: 0.842282913165266 and parameters: {'n_estimators': 58, 'learning_rate': 0.37948667713866246}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:21,072] Trial 78 finished with value: 0.8439495798319328 and parameters: {'n_estimators': 62, 'learning_rate': 0.2004902553082628}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  81%|████████  | 81/100 [00:09<00:02,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:21,210] Trial 79 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 63, 'learning_rate': 0.5314819153756561}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:21,358] Trial 80 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 66, 'learning_rate': 0.26031507026129513}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  83%|████████▎ | 83/100 [00:09<00:02,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:21,455] Trial 81 finished with value: 0.850672268907563 and parameters: {'n_estimators': 65, 'learning_rate': 0.21272336315252188}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:21,573] Trial 82 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 64, 'learning_rate': 0.31126184620901615}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  85%|████████▌ | 85/100 [00:09<00:01,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:21,671] Trial 83 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 69, 'learning_rate': 0.20859184674524234}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:21,769] Trial 84 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 64, 'learning_rate': 0.2952963738056541}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:21,868] Trial 85 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 68, 'learning_rate': 0.18339661914119132}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  88%|████████▊ | 88/100 [00:10<00:01,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:22,008] Trial 86 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 70, 'learning_rate': 0.12555761817179592}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:22,128] Trial 87 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 72, 'learning_rate': 0.10556224003616961}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  90%|█████████ | 90/100 [00:10<00:01,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:22,237] Trial 88 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 64, 'learning_rate': 0.45383816370626695}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:22,343] Trial 89 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 72, 'learning_rate': 0.10061770070204293}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  93%|█████████▎| 93/100 [00:10<00:00,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:22,449] Trial 90 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 70, 'learning_rate': 0.14034472329177175}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:22,546] Trial 91 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 72, 'learning_rate': 0.13904332187699184}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:22,641] Trial 92 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 74, 'learning_rate': 0.11532393108616165}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  95%|█████████▌| 95/100 [00:10<00:00,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:22,727] Trial 93 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 68, 'learning_rate': 0.03369669865716281}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:22,843] Trial 94 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 64, 'learning_rate': 0.12334087779500408}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686:  97%|█████████▋| 97/100 [00:11<00:00,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:22,939] Trial 95 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 74, 'learning_rate': 0.0763094919412178}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:23,045] Trial 96 finished with value: 0.8439495798319326 and parameters: {'n_estimators': 67, 'learning_rate': 0.49360103339127526}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:23,121] Trial 97 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 56, 'learning_rate': 0.07971074640810337}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 49. Best value: 0.850686: 100%|██████████| 100/100 [00:11<00:00,  8.79it/s]\n",
      "[I 2025-11-06 03:30:23,336] A new study created in memory with name: Gradient Boosting Model Fine Tuning with CmaEsSampler\n",
      "Best trial: 49. Best value: 0.850686: 100%|██████████| 100/100 [00:11<00:00,  8.79it/s]\n",
      "[I 2025-11-06 03:30:23,336] A new study created in memory with name: Gradient Boosting Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:23,216] Trial 98 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 67, 'learning_rate': 0.14787479529644731}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:30:23,333] Trial 99 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 78, 'learning_rate': 0.0730605101108252}. Best is trial 49 with value: 0.850686274509804.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using CmaEsSampler: {'n_estimators': 61, 'learning_rate': 0.46684762630779697}\n",
      "Best accuracy: 0.8507, at trial: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837283:   2%|▏         | 2/100 [00:00<00:14,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:23,442] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n",
      "[W 2025-11-06 03:30:23,445] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:23,611] Trial 1 finished with value: 0.8372829131652659 and parameters: {'max_features': None, 'n_estimators': 57, 'learning_rate': 0.008658084666909323, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8397600270730616}. Best is trial 1 with value: 0.8372829131652659.\n",
      "[W 2025-11-06 03:30:23,615] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.850672:   4%|▍         | 4/100 [00:00<00:12,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:23,781] Trial 2 finished with value: 0.850672268907563 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.009528924787594208, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.8029297907760695}. Best is trial 2 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:23,785] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:23,881] Trial 3 finished with value: 0.8473389355742296 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.026515758596185147, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7269530336476903}. Best is trial 2 with value: 0.850672268907563.\n",
      "[W 2025-11-06 03:30:23,884] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:23,979] Trial 4 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 24, 'learning_rate': 0.0010702593573937475, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7677248753915946}. Best is trial 2 with value: 0.850672268907563.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.852367:   6%|▌         | 6/100 [00:00<00:12,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:30:23,983] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:24,128] Trial 5 finished with value: 0.8523669467787116 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.019667141639294356, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.7115398922202714}. Best is trial 5 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:30:24,131] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.860742:   8%|▊         | 8/100 [00:00<00:09,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:24,206] Trial 6 finished with value: 0.8607422969187676 and parameters: {'max_features': 'log2', 'n_estimators': 47, 'learning_rate': 0.02340459441539314, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.7681058459555117}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,208] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:24,293] Trial 7 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.01959654330798669, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7131820938134579}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,296] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.860742:  11%|█         | 11/100 [00:01<00:09,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:24,410] Trial 8 finished with value: 0.8557422969187677 and parameters: {'max_features': 'sqrt', 'n_estimators': 29, 'learning_rate': 0.028171880519557702, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8047109221769}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,413] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:24,519] Trial 9 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.011695860437734951, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.757470058328777}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,522] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:24,586] Trial 10 finished with value: 0.8473109243697479 and parameters: {'max_features': None, 'n_estimators': 39, 'learning_rate': 0.028383837577968474, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.6849471195554869}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,589] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.860742:  14%|█▍        | 14/100 [00:01<00:08, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:24,714] Trial 11 finished with value: 0.842282913165266 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.02035236354978002, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.6581595791279604}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,717] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:24,781] Trial 12 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 21, 'learning_rate': 0.01109527446398915, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.8796300948308577}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,783] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:24,867] Trial 13 finished with value: 0.8473249299719889 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.007888502153464396, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.7318254959898127}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,870] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.860742:  16%|█▌        | 16/100 [00:01<00:08,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:24,974] Trial 14 finished with value: 0.8104201680672268 and parameters: {'max_features': None, 'n_estimators': 38, 'learning_rate': 0.021626444919470834, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.8336123999706819}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:24,977] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:25,092] Trial 15 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 59, 'learning_rate': 0.008586935724711935, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.7838167550736551}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-11-06 03:30:25,095] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  18%|█▊        | 18/100 [00:02<00:09,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:25,230] Trial 16 finished with value: 0.8624229691876751 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.04283041306883106, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7485715857899503}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:25,232] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:25,398] Trial 17 finished with value: 0.8372689075630252 and parameters: {'max_features': None, 'n_estimators': 51, 'learning_rate': 0.025433480559536526, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.8390730983309527}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:25,401] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  20%|██        | 20/100 [00:02<00:09,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:25,507] Trial 18 finished with value: 0.8372408963585434 and parameters: {'max_features': None, 'n_estimators': 41, 'learning_rate': 0.005445856297979574, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6969163745662916}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:25,511] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:25,626] Trial 19 finished with value: 0.8540476190476192 and parameters: {'max_features': None, 'n_estimators': 51, 'learning_rate': 0.04991304005209081, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.8470646739633084}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:25,628] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  22%|██▏       | 22/100 [00:02<00:09,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:25,713] Trial 20 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 30, 'learning_rate': 0.06797957532140565, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8, 'subsample': 0.782247050617837}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:25,715] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:25,860] Trial 21 finished with value: 0.8523389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.024621772912095313, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.8672361860778105}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:25,864] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  24%|██▍       | 24/100 [00:02<00:09,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:26,019] Trial 22 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.016911529799952252, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.768179219060934}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,022] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:26,146] Trial 23 finished with value: 0.8624089635854343 and parameters: {'max_features': 'log2', 'n_estimators': 68, 'learning_rate': 0.013559801466478005, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.9483788350483047}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,149] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  26%|██▌       | 26/100 [00:03<00:09,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:26,304] Trial 24 finished with value: 0.8406162464985993 and parameters: {'max_features': None, 'n_estimators': 54, 'learning_rate': 0.025035291815948223, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7927995879452765}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,307] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:26,422] Trial 25 finished with value: 0.8473249299719889 and parameters: {'max_features': 'sqrt', 'n_estimators': 50, 'learning_rate': 0.024267604417715305, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7502528483384223}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,425] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  28%|██▊       | 28/100 [00:03<00:09,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:26,560] Trial 26 finished with value: 0.8389495798319327 and parameters: {'max_features': None, 'n_estimators': 35, 'learning_rate': 0.02353430006430672, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.8222856462625217}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,563] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:26,649] Trial 27 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 42, 'learning_rate': 0.008944681347940117, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.7995437654667777}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,653] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  30%|███       | 30/100 [00:03<00:09,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:26,829] Trial 28 finished with value: 0.8271708683473389 and parameters: {'max_features': None, 'n_estimators': 57, 'learning_rate': 0.015475287214703573, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.9587276337644929}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,832] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:26,947] Trial 29 finished with value: 0.8624089635854343 and parameters: {'max_features': 'log2', 'n_estimators': 44, 'learning_rate': 0.05468223973539784, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.8434839220574248}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:26,951] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  32%|███▏      | 32/100 [00:03<00:09,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:27,058] Trial 30 finished with value: 0.8557422969187677 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.04721557638138007, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.8162621706818577}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:27,061] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:27,236] Trial 31 finished with value: 0.8490196078431371 and parameters: {'max_features': None, 'n_estimators': 82, 'learning_rate': 0.012487078263293256, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8068832095723781}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:27,240] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  33%|███▎      | 33/100 [00:04<00:09,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:27,396] Trial 32 finished with value: 0.8439915966386554 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.0074243721954836235, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 9, 'subsample': 0.8583363878790036}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:27,399] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.862423:  35%|███▌      | 35/100 [00:04<00:10,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:27,617] Trial 33 finished with value: 0.850658263305322 and parameters: {'max_features': None, 'n_estimators': 70, 'learning_rate': 0.030195011537138678, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.9844711637257849}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:27,620] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:27,745] Trial 34 finished with value: 0.830532212885154 and parameters: {'max_features': None, 'n_estimators': 35, 'learning_rate': 0.014261218623011112, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.9003671073041157}. Best is trial 16 with value: 0.8624229691876751.\n",
      "[W 2025-11-06 03:30:27,748] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  37%|███▋      | 37/100 [00:04<00:09,  6.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:27,834] Trial 35 finished with value: 0.8640896358543418 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.05226595259472592, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.9991876060272965}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:27,837] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:28,023] Trial 36 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.010074007554242733, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.9490517172982156}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:28,026] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  39%|███▉      | 39/100 [00:04<00:08,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:28,131] Trial 37 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 69, 'learning_rate': 0.020438189251986105, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7266059254724588}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:28,134] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:28,198] Trial 38 finished with value: 0.8557422969187677 and parameters: {'max_features': 'log2', 'n_estimators': 26, 'learning_rate': 0.044623064615367275, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.8473890675779719}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:28,201] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  41%|████      | 41/100 [00:05<00:07,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:28,347] Trial 39 finished with value: 0.8389495798319327 and parameters: {'max_features': None, 'n_estimators': 53, 'learning_rate': 0.019145926974305328, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7935841274067971}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:28,350] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:28,457] Trial 40 finished with value: 0.8540476190476192 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.011191353944835135, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.8450674137240759}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:28,460] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  42%|████▏     | 42/100 [00:05<00:07,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:28,555] Trial 41 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 56, 'learning_rate': 0.03935816867278889, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8733114346102921}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:28,559] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  43%|████▎     | 43/100 [00:05<00:07,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:28,787] Trial 42 finished with value: 0.8271848739495798 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.004570032846567148, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7976609376298097}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:28,790] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  46%|████▌     | 46/100 [00:05<00:07,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:29,006] Trial 43 finished with value: 0.8490196078431371 and parameters: {'max_features': None, 'n_estimators': 60, 'learning_rate': 0.03239601689836592, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.9220538782289509}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,010] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:29,095] Trial 44 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 30, 'learning_rate': 0.02935816005972826, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.8653914955103776}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,098] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:29,194] Trial 45 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.0427466053147217, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.9157513257139516}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,198] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  48%|████▊     | 48/100 [00:06<00:06,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:29,314] Trial 46 finished with value: 0.8489915966386554 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.07253182709960382, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.8256874185250296}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,317] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:29,422] Trial 47 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.01500340459326, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8658967220897321}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,425] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  50%|█████     | 50/100 [00:06<00:05,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:29,521] Trial 48 finished with value: 0.8573809523809525 and parameters: {'max_features': 'sqrt', 'n_estimators': 49, 'learning_rate': 0.06322838600511965, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.9200801519228388}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,523] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:29,639] Trial 49 finished with value: 0.8523529411764705 and parameters: {'max_features': 'log2', 'n_estimators': 48, 'learning_rate': 0.04316625981797534, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.8032197610209547}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,642] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  53%|█████▎    | 53/100 [00:06<00:04,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:29,797] Trial 50 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.02142436872194134, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.8849655850611482}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,801] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:29,896] Trial 51 finished with value: 0.850672268907563 and parameters: {'max_features': 'sqrt', 'n_estimators': 50, 'learning_rate': 0.03119896533147754, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.7186668914342719}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,899] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:29,943] Trial 52 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 19, 'learning_rate': 0.03296875402623301, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.9058170258318755}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:29,947] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  55%|█████▌    | 55/100 [00:06<00:05,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:30,021] Trial 53 finished with value: 0.8472969187675069 and parameters: {'max_features': 'sqrt', 'n_estimators': 47, 'learning_rate': 0.011346182428801177, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.9481767155367575}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,025] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:30,192] Trial 54 finished with value: 0.8423109243697479 and parameters: {'max_features': None, 'n_estimators': 43, 'learning_rate': 0.02340926581024176, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.8238981036425636}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,196] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  57%|█████▋    | 57/100 [00:07<00:04,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:30,261] Trial 55 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.040879139736173804, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.9780650479445078}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,264] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:30,400] Trial 56 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 52, 'learning_rate': 0.029954279041473093, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.8335861596081846}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,405] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  59%|█████▉    | 59/100 [00:07<00:04,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:30,542] Trial 57 finished with value: 0.8607282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.06475172987643131, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.8577720216610738}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,548] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:30,675] Trial 58 finished with value: 0.8523669467787116 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.05285325327254263, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.9318243885084503}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,679] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  62%|██████▏   | 62/100 [00:07<00:04,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:30,805] Trial 59 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 36, 'learning_rate': 0.06843629296046805, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.862291412507524}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,808] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:30,893] Trial 60 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 61, 'learning_rate': 0.01944200920708082, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.9573433375733671}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,896] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:30,971] Trial 61 finished with value: 0.8439635854341736 and parameters: {'max_features': None, 'n_estimators': 29, 'learning_rate': 0.049578499107360535, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.8960089812829797}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:30,974] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  64%|██████▍   | 64/100 [00:07<00:03,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:31,018] Trial 62 finished with value: 0.8523669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 23, 'learning_rate': 0.013124570038042854, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.8296837458087001}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,021] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:31,156] Trial 63 finished with value: 0.8372829131652659 and parameters: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.04306853688711735, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8943933862440844}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,161] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  66%|██████▌   | 66/100 [00:08<00:03,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:31,286] Trial 64 finished with value: 0.8506722689075629 and parameters: {'max_features': 'sqrt', 'n_estimators': 61, 'learning_rate': 0.05880740110136871, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.9160701702747904}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,290] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:31,415] Trial 65 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 41, 'learning_rate': 0.048377988891260514, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.9831236936928701}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,418] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  69%|██████▉   | 69/100 [00:08<00:03,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:31,514] Trial 66 finished with value: 0.8573809523809525 and parameters: {'max_features': 'sqrt', 'n_estimators': 44, 'learning_rate': 0.023081828156430118, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9094309416856194}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,517] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:31,572] Trial 67 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 26, 'learning_rate': 0.07368936476120232, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.8966067109980467}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,574] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:31,709] Trial 68 finished with value: 0.8607563025210085 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.08250749858608128, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.8535054158898279}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,712] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  71%|███████   | 71/100 [00:08<00:03,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:31,838] Trial 69 finished with value: 0.8489915966386554 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.018383233146271757, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.8986312087681515}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,841] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:31,955] Trial 70 finished with value: 0.8607422969187676 and parameters: {'max_features': 'log2', 'n_estimators': 69, 'learning_rate': 0.03537262682126209, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.8805216762988068}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:31,959] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  73%|███████▎  | 73/100 [00:08<00:03,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:32,094] Trial 71 finished with value: 0.8489915966386554 and parameters: {'max_features': 'sqrt', 'n_estimators': 42, 'learning_rate': 0.0827216567982708, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.8576540755822432}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:32,098] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:32,214] Trial 72 finished with value: 0.8607703081232494 and parameters: {'max_features': 'log2', 'n_estimators': 56, 'learning_rate': 0.03599298537694389, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.8621460153345597}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:32,219] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 35. Best value: 0.86409:  76%|███████▌  | 76/100 [00:09<00:02,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:32,326] Trial 73 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.07102595711763474, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8935810347746569}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:32,330] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:32,427] Trial 74 finished with value: 0.8573809523809522 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.01936393658752499, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7985892157035099}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:32,430] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:32,516] Trial 75 finished with value: 0.8506862745098038 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.041301300851329825, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.8328278732610988}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:32,518] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 77. Best value: 0.864104:  78%|███████▊  | 78/100 [00:09<00:02,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:32,643] Trial 76 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 50, 'learning_rate': 0.027425420638504255, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.8009781143093382}. Best is trial 35 with value: 0.8640896358543418.\n",
      "[W 2025-11-06 03:30:32,646] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:32,782] Trial 77 finished with value: 0.8641036414565827 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.03282635201492909, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.9343159030199746}. Best is trial 77 with value: 0.8641036414565827.\n",
      "[W 2025-11-06 03:30:32,785] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 77. Best value: 0.864104:  80%|████████  | 80/100 [00:09<00:02,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:32,869] Trial 78 finished with value: 0.85906162464986 and parameters: {'max_features': 'log2', 'n_estimators': 55, 'learning_rate': 0.03158871238402406, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.9968183407624807}. Best is trial 77 with value: 0.8641036414565827.\n",
      "[W 2025-11-06 03:30:32,872] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:33,007] Trial 79 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 65, 'learning_rate': 0.03170351469721376, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.8796195110871186}. Best is trial 77 with value: 0.8641036414565827.\n",
      "[W 2025-11-06 03:30:33,010] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 77. Best value: 0.864104:  82%|████████▏ | 82/100 [00:09<00:02,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:33,115] Trial 80 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 55, 'learning_rate': 0.019815032183409735, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.9845098927624698}. Best is trial 77 with value: 0.8641036414565827.\n",
      "[W 2025-11-06 03:30:33,118] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:33,264] Trial 81 finished with value: 0.8607422969187674 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.03756218291784091, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.9404207638525521}. Best is trial 77 with value: 0.8641036414565827.\n",
      "[W 2025-11-06 03:30:33,268] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 77. Best value: 0.864104:  83%|████████▎ | 83/100 [00:10<00:02,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:33,413] Trial 82 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 73, 'learning_rate': 0.02056126157505285, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9633742080806379}. Best is trial 77 with value: 0.8641036414565827.\n",
      "[W 2025-11-06 03:30:33,416] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  84%|████████▍ | 84/100 [00:10<00:02,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:33,622] Trial 83 finished with value: 0.865798319327731 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.022856792050204185, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9924962613321506}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:33,625] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  86%|████████▌ | 86/100 [00:10<00:02,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:33,842] Trial 84 finished with value: 0.8473249299719889 and parameters: {'max_features': None, 'n_estimators': 92, 'learning_rate': 0.08224655602166982, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.9566177028287248}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:33,845] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:34,000] Trial 85 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 90, 'learning_rate': 0.02883432469305406, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.8950490948188572}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:34,003] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  88%|████████▊ | 88/100 [00:10<00:01,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:34,098] Trial 86 finished with value: 0.8641176470588234 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.04104217950089744, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.8255196812719972}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:34,101] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:34,266] Trial 87 finished with value: 0.8523249299719889 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.05016556813479557, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.8857123888881717}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:34,270] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  90%|█████████ | 90/100 [00:11<00:01,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:34,445] Trial 88 finished with value: 0.8338655462184873 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.05802910221257318, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.99724482583219}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:34,448] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:34,593] Trial 89 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.027507531995424505, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.9139326803142345}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:34,596] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  92%|█████████▏| 92/100 [00:11<00:01,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:34,711] Trial 90 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.022486126162572895, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.954497122781575}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:34,715] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:34,851] Trial 91 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 91, 'learning_rate': 0.06288753718300157, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.871325327841098}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:34,854] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  94%|█████████▍| 94/100 [00:11<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:35,050] Trial 92 finished with value: 0.8473249299719887 and parameters: {'max_features': None, 'n_estimators': 67, 'learning_rate': 0.016923439062821108, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.9090291345291275}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:35,054] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:35,171] Trial 93 finished with value: 0.8506722689075629 and parameters: {'max_features': None, 'n_estimators': 47, 'learning_rate': 0.03408498707430489, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.8407909096889741}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:35,174] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  96%|█████████▌| 96/100 [00:12<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:35,350] Trial 94 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 85, 'learning_rate': 0.024806673707646224, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.9718561898013811}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:35,353] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:35,459] Trial 95 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 96, 'learning_rate': 0.0218042441155122, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.8230051830092059}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:35,462] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798:  98%|█████████▊| 98/100 [00:12<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:35,718] Trial 96 finished with value: 0.8473109243697479 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.03364953754028468, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8826159594240086}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:35,722] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:35,837] Trial 97 finished with value: 0.8540196078431371 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.027293229034520736, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.8427660396652336}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:35,840] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 83. Best value: 0.865798: 100%|██████████| 100/100 [00:12<00:00,  7.88it/s]\n",
      "Best trial: 83. Best value: 0.865798: 100%|██████████| 100/100 [00:12<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:30:35,945] Trial 98 finished with value: 0.8422829131652663 and parameters: {'max_features': None, 'n_estimators': 38, 'learning_rate': 0.04349836748023885, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7732668733058896}. Best is trial 83 with value: 0.865798319327731.\n",
      "[W 2025-11-06 03:30:35,948] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:30:36,023] Trial 99 finished with value: 0.8389215686274509 and parameters: {'max_features': None, 'n_estimators': 38, 'learning_rate': 0.030690857541559157, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.9305714525318121}. Best is trial 83 with value: 0.865798319327731.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using CmaEsSampler: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.022856792050204185, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9924962613321506}\n",
      "Best accuracy: 0.8658, at trial: 83\n",
      "CMA-ES Base Models Training Time: 49.52 seconds\n",
      "CMA-ES Base Models Training Time: 49.52 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_base_models_training_start = time.time()\n",
    "\n",
    "    # CMA-ES Hyperparameter Tuning with Cross Validation\n",
    "    cmaes_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    cmaes_logistic_regression.fit(X_train, y_train)\n",
    "    cmaes_decision_tree.fit(X_train, y_train)\n",
    "    cmaes_random_forest.fit(X_train, y_train)\n",
    "    cmaes_knn.fit(X_train, y_train)\n",
    "    cmaes_svc.fit(X_train, y_train)\n",
    "    cmaes_adaboost.fit(X_train, y_train)\n",
    "    cmaes_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES base models training\n",
    "    cmaes_base_models_training_time = cmaes_base_models_training_end - cmaes_base_models_training_start\n",
    "    print(f'CMA-ES Base Models Training Time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping CMA-ES base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:32:47,216] A new study created in memory with name: Logistic Regression Model Fine Tuning with QMCSampler\n",
      "Best trial: 2. Best value: 0.847255:   7%|▋         | 7/100 [00:00<00:02, 32.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:47,253] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:32:47,256] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,290] Trial 1 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cholesky', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:32:47,292] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,326] Trial 2 finished with value: 0.8472549019607843 and parameters: {'solver': 'newton-cholesky', 'C': 0.0316227766016838}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,328] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,362] Trial 3 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 0.5623413251903494}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,364] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,388] Trial 4 finished with value: 0.7986974789915966 and parameters: {'solver': 'sag', 'C': 0.0017782794100389236}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,390] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,413] Trial 5 finished with value: 0.8304901960784313 and parameters: {'solver': 'sag', 'C': 0.007498942093324564}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,415] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,440] Trial 6 finished with value: 0.8355462184873949 and parameters: {'solver': 'lbfgs', 'C': 2.371373705661655}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,442] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.847255:  15%|█▌        | 15/100 [00:00<00:02, 36.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:47,466] Trial 7 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.13335214321633232}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,467] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,491] Trial 8 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00042169650342858235}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,493] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,516] Trial 9 finished with value: 0.5989635854341737 and parameters: {'solver': 'newton-cg', 'C': 0.000865964323360066}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,518] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,542] Trial 10 finished with value: 0.8422689075630252 and parameters: {'solver': 'newton-cholesky', 'C': 0.27384196342643613}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,544] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,568] Trial 11 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 4.8696752516586255}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,569] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,593] Trial 12 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.015399265260594926}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,595] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,618] Trial 13 finished with value: 0.8338655462184874 and parameters: {'solver': 'newton-cholesky', 'C': 0.003651741272548378}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,620] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,644] Trial 14 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 1.1547819846894576}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,646] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.847255:  23%|██▎       | 23/100 [00:00<00:02, 36.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:47,670] Trial 15 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06493816315762112}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,672] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,696] Trial 16 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cholesky', 'C': 0.0002053525026457149}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,698] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,722] Trial 17 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.0002942727176209287}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,724] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,748] Trial 18 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.0930572040929699}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,750] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,774] Trial 19 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 1.6548170999431808}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,776] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,799] Trial 20 finished with value: 0.8321708683473389 and parameters: {'solver': 'lbfgs', 'C': 0.005232991146814949}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,802] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,825] Trial 21 finished with value: 0.84390756302521 and parameters: {'solver': 'sag', 'C': 0.022067340690845896}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,827] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,861] Trial 22 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.978305848598657}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,863] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.847255:  31%|███       | 31/100 [00:00<00:01, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:47,886] Trial 23 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.3924189758484537}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,888] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,912] Trial 24 finished with value: 0.7399719887955183 and parameters: {'solver': 'lbfgs', 'C': 0.0012409377607517208}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,914] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,938] Trial 25 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.0006042963902381332}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,940] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,964] Trial 26 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.19109529749704401}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,966] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:47,989] Trial 27 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 3.39820832894256}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:47,991] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,014] Trial 28 finished with value: 0.84390756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.010746078283213176}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:48,016] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,040] Trial 29 finished with value: 0.8321988795518207 and parameters: {'solver': 'newton-cg', 'C': 0.0025482967479793462}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:48,042] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,066] Trial 30 finished with value: 0.83890756302521 and parameters: {'solver': 'lbfgs', 'C': 0.8058421877614811}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-11-06 03:32:48,068] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.847269:  39%|███▉      | 39/100 [00:01<00:01, 38.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:48,091] Trial 31 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.045315836376008195}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,093] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,117] Trial 32 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00014330125702369644}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,118] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,142] Trial 33 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00017154378963428796}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,144] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,167] Trial 34 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05424690937011324}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,169] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,193] Trial 35 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.9646616199111994}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,195] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,218] Trial 36 finished with value: 0.8305182072829131 and parameters: {'solver': 'newton-cg', 'C': 0.0030505278902670284}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,220] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,244] Trial 37 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.01286396944936975}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,246] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,270] Trial 38 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 4.067944321083045}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,271] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.847269:  47%|████▋     | 47/100 [00:01<00:01, 37.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:48,295] Trial 39 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.22875732003183954}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,297] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,321] Trial 40 finished with value: 0.5385994397759104 and parameters: {'solver': 'newton-cg', 'C': 0.0007233941627366753}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,322] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,347] Trial 41 finished with value: 0.7701820728291316 and parameters: {'solver': 'lbfgs', 'C': 0.0014855080171727755}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,349] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,373] Trial 42 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.469758881670649}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,375] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,408] Trial 43 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 8.353625469578262}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,410] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,434] Trial 44 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.026416483203860926}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,435] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,459] Trial 45 finished with value: 0.8288095238095238 and parameters: {'solver': 'newton-cg', 'C': 0.00626433536656886}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,461] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,485] Trial 46 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cg', 'C': 1.9809567785503366}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,486] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.847269:  55%|█████▌    | 55/100 [00:01<00:01, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:48,510] Trial 47 finished with value: 0.8439495798319328 and parameters: {'solver': 'sag', 'C': 0.11139738599948026}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,512] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,535] Trial 48 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.0003522694651473105}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,537] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,561] Trial 49 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.0002458244068920199}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,563] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,587] Trial 50 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.07773650302387758}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,589] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,613] Trial 51 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 1.3823722273579002}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,615] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,638] Trial 52 finished with value: 0.8305042016806722 and parameters: {'solver': 'newton-cholesky', 'C': 0.004371444812611091}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,640] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,664] Trial 53 finished with value: 0.8422268907563024 and parameters: {'solver': 'newton-cg', 'C': 0.018434229924091116}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,666] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,690] Trial 54 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 5.829415347136073}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,692] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.847269:  63%|██████▎   | 63/100 [00:01<00:00, 38.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:48,715] Trial 55 finished with value: 0.8405882352941176 and parameters: {'solver': 'lbfgs', 'C': 0.32781211513934566}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,717] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,741] Trial 56 finished with value: 0.7114285714285714 and parameters: {'solver': 'newton-cg', 'C': 0.001036632928437698}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,743] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,766] Trial 57 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0005048065716667473}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,768] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,792] Trial 58 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cholesky', 'C': 0.15963385442879416}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,794] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,817] Trial 59 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 2.8387359647587527}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,819] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,843] Trial 60 finished with value: 0.8405602240896359 and parameters: {'solver': 'lbfgs', 'C': 0.008976871324473142}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,845] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,868] Trial 61 finished with value: 0.8204621848739496 and parameters: {'solver': 'newton-cholesky', 'C': 0.002128751661796374}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,870] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,894] Trial 62 finished with value: 0.83890756302521 and parameters: {'solver': 'lbfgs', 'C': 0.6731703824144981}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,896] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.847269:  71%|███████   | 71/100 [00:01<00:00, 39.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:48,920] Trial 63 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.03785515249258631}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,922] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,945] Trial 64 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00011970850304957301}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,947] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,971] Trial 65 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00013097472643005907}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,973] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:48,996] Trial 66 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.04141784514364404}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:48,998] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,022] Trial 67 finished with value: 0.83890756302521 and parameters: {'solver': 'sag', 'C': 0.7365250122712284}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,024] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,047] Trial 68 finished with value: 0.8254901960784313 and parameters: {'solver': 'lbfgs', 'C': 0.0023290965924605465}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,049] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,073] Trial 69 finished with value: 0.8405602240896359 and parameters: {'solver': 'sag', 'C': 0.009821718891880384}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,074] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,098] Trial 70 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 3.105900223624704}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,100] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 31. Best value: 0.847269:  79%|███████▉  | 79/100 [00:02<00:00, 38.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:49,124] Trial 71 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.17465760476621184}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,125] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,149] Trial 72 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.0005523158417307104}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,151] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,174] Trial 73 finished with value: 0.7198319327731093 and parameters: {'solver': 'sag', 'C': 0.0011341944035027575}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,176] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,200] Trial 74 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cg', 'C': 0.3586637624484768}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,202] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,226] Trial 75 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.378043838892169}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,228] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,251] Trial 76 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.02016914554730331}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,253] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,278] Trial 77 finished with value: 0.8304901960784313 and parameters: {'solver': 'newton-cg', 'C': 0.004782858141653791}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,280] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,304] Trial 78 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 1.512472545310622}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,306] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.847269:  87%|████████▋ | 87/100 [00:02<00:00, 39.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:49,330] Trial 79 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.08505258154439958}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,332] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,356] Trial 80 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.00026895987855750467}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,358] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,382] Trial 81 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00038542288686231087}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,384] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,407] Trial 82 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.12188141848422895}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,409] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,433] Trial 83 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 2.167392169568416}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,435] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,458] Trial 84 finished with value: 0.8288095238095238 and parameters: {'solver': 'lbfgs', 'C': 0.006853895838650084}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-11-06 03:32:49,460] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,483] Trial 85 finished with value: 0.8472689075630253 and parameters: {'solver': 'lbfgs', 'C': 0.028902639100224517}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,485] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,509] Trial 86 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 9.139816994654893}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,511] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 85. Best value: 0.847269:  95%|█████████▌| 95/100 [00:02<00:00, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:49,535] Trial 87 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 0.5139696800771514}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,536] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,560] Trial 88 finished with value: 0.7835994397759103 and parameters: {'solver': 'newton-cholesky', 'C': 0.001625314837311866}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,562] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,586] Trial 89 finished with value: 0.5553641456582633 and parameters: {'solver': 'newton-cg', 'C': 0.0007914755439411164}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,588] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,611] Trial 90 finished with value: 0.8456302521008403 and parameters: {'solver': 'sag', 'C': 0.2502865431174607}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,613] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,637] Trial 91 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 4.450794062355996}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,639] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,663] Trial 92 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.014074646633398432}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,665] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,689] Trial 93 finished with value: 0.835546218487395 and parameters: {'solver': 'sag', 'C': 0.0033376246942920405}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,691] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,714] Trial 94 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 1.0554496008786018}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-11-06 03:32:49,716] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 95. Best value: 0.847283: 100%|██████████| 100/100 [00:02<00:00, 38.08it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:32:49,845] A new study created in memory with name: Decision Tree Model Fine Tuning with QMCSampler\n",
      "Best trial: 95. Best value: 0.847283: 100%|██████████| 100/100 [00:02<00:00, 38.08it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:32:49,845] A new study created in memory with name: Decision Tree Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:49,740] Trial 95 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05935229272296987}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:32:49,742] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,765] Trial 96 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00018768842935762206}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:32:49,767] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,791] Trial 97 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00015678788438269704}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:32:49,793] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,817] Trial 98 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.04958068241684656}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-11-06 03:32:49,819] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,843] Trial 99 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.8816830667755706}. Best is trial 95 with value: 0.8472829131652662.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using QMCSampler: {'solver': 'newton-cholesky', 'C': 0.05935229272296987}\n",
      "Best accuracy: 0.8473, at trial: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.827227:   5%|▌         | 5/100 [00:00<00:01, 60.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:49,859] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:32:49,861] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,862] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,876] Trial 1 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:32:49,877] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,878] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,892] Trial 2 finished with value: 0.815420168067227 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:32:49,894] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,895] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,908] Trial 3 finished with value: 0.8238655462184873 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-11-06 03:32:49,910] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,911] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,925] Trial 4 finished with value: 0.8272268907563024 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:49,927] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,928] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.827227:  13%|█▎        | 13/100 [00:00<00:01, 61.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:49,942] Trial 5 finished with value: 0.8154481792717088 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:49,943] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,944] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,958] Trial 6 finished with value: 0.7768347338935574 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:49,960] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,961] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,975] Trial 7 finished with value: 0.8120868347338934 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:49,977] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,978] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:49,991] Trial 8 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:49,993] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:49,994] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,008] Trial 9 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:50,010] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,011] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,024] Trial 10 finished with value: 0.8171288515406163 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:50,026] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,027] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,040] Trial 11 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:50,042] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,043] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,057] Trial 12 finished with value: 0.8003361344537815 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:50,059] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.828894:  17%|█▋        | 17/100 [00:00<00:01, 60.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:32:50,061] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,074] Trial 13 finished with value: 0.8086834733893558 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-11-06 03:32:50,076] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,077] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,092] Trial 14 finished with value: 0.8288935574229692 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,095] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,096] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,111] Trial 15 finished with value: 0.8171848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,113] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,114] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,130] Trial 16 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,132] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,133] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.828894:  24%|██▍       | 24/100 [00:00<00:01, 59.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,147] Trial 17 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,149] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,150] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,164] Trial 18 finished with value: 0.8104621848739495 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,166] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,167] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,180] Trial 19 finished with value: 0.8238655462184873 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,182] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,183] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,197] Trial 20 finished with value: 0.8272268907563024 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,199] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,200] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,213] Trial 21 finished with value: 0.8137675070028012 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,215] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,216] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,230] Trial 22 finished with value: 0.8054201680672269 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,232] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,233] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,246] Trial 23 finished with value: 0.8238375350140055 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-11-06 03:32:50,248] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,249] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,263] Trial 24 finished with value: 0.8389215686274509 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 24 with value: 0.8389215686274509.\n",
      "[W 2025-11-06 03:32:50,265] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,266] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,279] Trial 25 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,281] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,282] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,296] Trial 26 finished with value: 0.8120448179271709 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,298] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,299] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,312] Trial 27 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,314] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,316] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,329] Trial 28 finished with value: 0.8171428571428571 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,331] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,332] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,346] Trial 29 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.8423109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.842311:  36%|███▌      | 36/100 [00:00<00:01, 58.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:32:50,348] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,349] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,363] Trial 30 finished with value: 0.8070308123249299 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,365] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,366] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,380] Trial 31 finished with value: 0.8221988795518207 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,383] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,384] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,398] Trial 32 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,400] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,401] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,416] Trial 33 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,419] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,421] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,435] Trial 34 finished with value: 0.8221568627450979 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,438] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,439] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,455] Trial 35 finished with value: 0.812156862745098 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,457] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,458] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  41%|████      | 41/100 [00:00<00:01, 57.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,474] Trial 36 finished with value: 0.8137254901960784 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,476] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,477] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,492] Trial 37 finished with value: 0.7919607843137254 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,494] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,495] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,509] Trial 38 finished with value: 0.8205322128851542 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,511] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,512] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,525] Trial 39 finished with value: 0.805392156862745 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-11-06 03:32:50,527] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,528] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,542] Trial 40 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,544] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,545] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  48%|████▊     | 48/100 [00:00<00:00, 57.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,561] Trial 41 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,563] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,564] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,578] Trial 42 finished with value: 0.8322408963585433 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,581] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,581] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,595] Trial 43 finished with value: 0.7885854341736694 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,597] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,598] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,612] Trial 44 finished with value: 0.8137535014005601 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,614] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,615] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,628] Trial 45 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,630] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,631] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,644] Trial 46 finished with value: 0.8087254901960785 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,646] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,648] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,661] Trial 47 finished with value: 0.8221708683473388 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,664] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,665] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  53%|█████▎    | 53/100 [00:00<00:00, 58.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,678] Trial 48 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,680] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,681] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,694] Trial 49 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,696] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,697] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,712] Trial 50 finished with value: 0.8154761904761905 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,714] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,715] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,728] Trial 51 finished with value: 0.8205042016806722 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,730] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,731] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,745] Trial 52 finished with value: 0.8087254901960785 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,747] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,748] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  60%|██████    | 60/100 [00:01<00:00, 58.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,762] Trial 53 finished with value: 0.8389215686274512 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,764] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,765] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,778] Trial 54 finished with value: 0.8154621848739495 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,780] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,781] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,795] Trial 55 finished with value: 0.8288795518207284 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,797] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,798] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,812] Trial 56 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,814] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,815] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,829] Trial 57 finished with value: 0.8389495798319327 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,831] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,832] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,846] Trial 58 finished with value: 0.8322268907563025 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,848] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,849] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,862] Trial 59 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,864] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,865] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  65%|██████▌   | 65/100 [00:01<00:00, 59.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,879] Trial 60 finished with value: 0.8222128851540618 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,881] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,882] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,895] Trial 61 finished with value: 0.8255322128851541 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,898] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,899] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,913] Trial 62 finished with value: 0.8070308123249299 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,914] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,915] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,929] Trial 63 finished with value: 0.8087394957983193 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,931] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,932] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,946] Trial 64 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,948] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,949] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  72%|███████▏  | 72/100 [00:01<00:00, 59.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:50,962] Trial 65 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,964] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,965] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,979] Trial 66 finished with value: 0.8154201680672267 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,980] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,982] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:50,995] Trial 67 finished with value: 0.8254901960784313 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:50,998] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:50,999] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,012] Trial 68 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,014] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,015] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,029] Trial 69 finished with value: 0.8356162464985996 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,031] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,032] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,045] Trial 70 finished with value: 0.8138375350140056 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,047] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,048] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,062] Trial 71 finished with value: 0.8221988795518207 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,064] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,065] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,078] Trial 72 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  77%|███████▋  | 77/100 [00:01<00:00, 59.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:32:51,080] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,081] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,095] Trial 73 finished with value: 0.7935854341736694 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,096] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,098] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,111] Trial 74 finished with value: 0.810392156862745 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,114] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,115] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,128] Trial 75 finished with value: 0.8188795518207282 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,130] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,131] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,145] Trial 76 finished with value: 0.8272128851540617 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,147] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,148] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,162] Trial 77 finished with value: 0.8255322128851541 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 40. Best value: 0.847311:  84%|████████▍ | 84/100 [00:01<00:00, 59.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:32:51,164] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,165] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,179] Trial 78 finished with value: 0.795266106442577 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,180] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,182] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,195] Trial 79 finished with value: 0.8087254901960783 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,197] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,198] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,212] Trial 80 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,214] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,215] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,229] Trial 81 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,231] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,232] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,246] Trial 82 finished with value: 0.8154761904761905 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,248] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,249] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,262] Trial 83 finished with value: 0.8322408963585433 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,265] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,266] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 88. Best value: 0.847339:  89%|████████▉ | 89/100 [00:01<00:00, 59.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:51,281] Trial 84 finished with value: 0.8171008403361345 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,284] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,285] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,300] Trial 85 finished with value: 0.7919187675070029 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,302] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,304] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,319] Trial 86 finished with value: 0.8205322128851542 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,321] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,322] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,335] Trial 87 finished with value: 0.8321848739495797 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-11-06 03:32:51,337] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,338] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,352] Trial 88 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,354] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,355] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 88. Best value: 0.847339:  96%|█████████▌| 96/100 [00:01<00:00, 58.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:51,369] Trial 89 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,371] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,372] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,386] Trial 90 finished with value: 0.815420168067227 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,387] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,389] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,402] Trial 91 finished with value: 0.7868627450980392 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,404] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,405] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,418] Trial 92 finished with value: 0.818795518207283 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,421] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,422] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,435] Trial 93 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,438] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,439] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,452] Trial 94 finished with value: 0.8238515406162465 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,454] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,455] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,469] Trial 95 finished with value: 0.8087254901960783 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,470] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,471] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 88. Best value: 0.847339: 100%|██████████| 100/100 [00:01<00:00, 59.14it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:32:51,538] A new study created in memory with name: Random Forest Model Fine Tuning with QMCSampler\n",
      "Best trial: 88. Best value: 0.847339: 100%|██████████| 100/100 [00:01<00:00, 59.14it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:32:51,538] A new study created in memory with name: Random Forest Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:51,485] Trial 96 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,487] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,488] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,501] Trial 97 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,503] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,504] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,518] Trial 98 finished with value: 0.8221428571428572 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-11-06 03:32:51,520] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,521] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,535] Trial 99 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 88 with value: 0.8473389355742297.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using QMCSampler: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
      "Best accuracy: 0.8473, at trial: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.845658:   2%|▏         | 2/100 [00:00<00:05, 19.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:51,593] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[W 2025-11-06 03:32:51,595] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,596] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:51,640] Trial 1 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[W 2025-11-06 03:32:51,642] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,643] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.850658:   3%|▎         | 3/100 [00:00<00:04, 19.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:51,737] Trial 2 finished with value: 0.850658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.850658263305322.\n",
      "[W 2025-11-06 03:32:51,739] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,740] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.850658:   4%|▍         | 4/100 [00:00<00:08, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:51,875] Trial 3 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.850658263305322.\n",
      "[W 2025-11-06 03:32:51,877] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,878] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.8507:   6%|▌         | 6/100 [00:00<00:07, 11.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:51,953] Trial 4 finished with value: 0.8439635854341738 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 32, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.850658263305322.\n",
      "[W 2025-11-06 03:32:51,955] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:51,956] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:52,030] Trial 5 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.850700280112045.\n",
      "[W 2025-11-06 03:32:52,032] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,033] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.852381:   9%|▉         | 9/100 [00:00<00:09, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:52,157] Trial 6 finished with value: 0.8523809523809526 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,159] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,160] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:52,275] Trial 7 finished with value: 0.842296918767507 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,277] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,278] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:52,332] Trial 8 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 21, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,334] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,335] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.852381:  11%|█         | 11/100 [00:01<00:07, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:52,399] Trial 9 finished with value: 0.8456302521008403 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 27, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,402] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,403] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:52,537] Trial 10 finished with value: 0.8406442577030813 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,539] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,541] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.852381:  14%|█▍        | 14/100 [00:01<00:08, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:52,686] Trial 11 finished with value: 0.8439635854341736 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 95, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,689] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,690] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:52,774] Trial 12 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,776] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,777] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:52,851] Trial 13 finished with value: 0.8473109243697479 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-11-06 03:32:52,853] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,854] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.854048:  17%|█▋        | 17/100 [00:01<00:08,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:52,979] Trial 14 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.8540336134453781.\n",
      "[W 2025-11-06 03:32:52,981] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:52,982] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:53,076] Trial 15 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:32:53,078] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,079] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:53,133] Trial 16 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 15, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:32:53,136] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,137] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.854048:  19%|█▉        | 19/100 [00:01<00:07, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:53,191] Trial 17 finished with value: 0.8507002801120448 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 18, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:32:53,193] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,194] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:53,299] Trial 18 finished with value: 0.8489775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:32:53,301] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,302] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.855714:  22%|██▏       | 22/100 [00:02<00:07, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:53,427] Trial 19 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-11-06 03:32:53,429] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,430] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:53,514] Trial 20 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-11-06 03:32:53,517] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,518] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:53,613] Trial 21 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-11-06 03:32:53,615] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,616] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.855714:  24%|██▍       | 24/100 [00:02<00:08,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:53,750] Trial 22 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 98, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-11-06 03:32:53,752] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,753] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:53,868] Trial 23 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-11-06 03:32:53,871] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,872] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:53,949] Trial 24 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 29, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.8557142857142856.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.855714:  27%|██▋       | 27/100 [00:02<00:07, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:32:53,951] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:53,952] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:54,017] Trial 25 finished with value: 0.8405882352941175 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 24, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-11-06 03:32:54,019] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,020] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:54,146] Trial 26 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-11-06 03:32:54,148] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,149] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  30%|███       | 30/100 [00:02<00:07,  9.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:54,284] Trial 27 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,286] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,287] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:54,381] Trial 28 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,383] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,384] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:54,459] Trial 29 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 35, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,461] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,462] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  33%|███▎      | 33/100 [00:03<00:07,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:54,577] Trial 30 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,579] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,580] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:54,686] Trial 31 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,688] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,689] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:54,744] Trial 32 finished with value: 0.8473109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 12, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,746] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,747] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  35%|███▌      | 35/100 [00:03<00:05, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:54,802] Trial 33 finished with value: 0.845672268907563 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 14, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,804] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,805] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:54,899] Trial 34 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:54,901] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:54,902] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  38%|███▊      | 38/100 [00:03<00:05, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:55,027] Trial 35 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,029] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,030] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:55,105] Trial 36 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,108] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,109] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:55,203] Trial 37 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,205] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,206] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  41%|████      | 41/100 [00:03<00:06,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:55,341] Trial 38 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,343] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,345] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:55,460] Trial 39 finished with value: 0.8523389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,462] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,463] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:55,517] Trial 40 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 25, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,518] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,519] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  43%|████▎     | 43/100 [00:04<00:05, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:55,594] Trial 41 finished with value: 0.8473109243697478 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 31, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,596] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,597] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:55,722] Trial 42 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,724] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,725] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  45%|████▌     | 45/100 [00:04<00:05,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:55,869] Trial 43 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,871] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,872] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:55,990] Trial 44 finished with value: 0.845672268907563 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 54, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:55,992] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:55,993] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  47%|████▋     | 47/100 [00:04<00:05,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:56,078] Trial 45 finished with value: 0.8288795518207281 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 42, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,080] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,082] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:56,218] Trial 46 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,220] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,221] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  50%|█████     | 50/100 [00:04<00:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:56,325] Trial 47 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,327] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,328] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:56,382] Trial 48 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 19, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,384] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,385] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:56,439] Trial 49 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 17, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,441] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,442] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  52%|█████▏    | 52/100 [00:05<00:04,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:56,547] Trial 50 finished with value: 0.8574089635854343 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,549] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,550] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:56,675] Trial 51 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,677] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,678] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  54%|█████▍    | 54/100 [00:05<00:04, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:56,762] Trial 52 finished with value: 0.8439915966386554 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 39, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,764] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,765] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:56,850] Trial 53 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,852] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,853] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  56%|█████▌    | 56/100 [00:05<00:04,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:56,987] Trial 54 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:56,989] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:56,990] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:57,105] Trial 55 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:57,108] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,110] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.85909:  59%|█████▉    | 59/100 [00:05<00:04, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:57,199] Trial 56 finished with value: 0.830546218487395 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:57,201] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,202] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:57,266] Trial 57 finished with value: 0.8372268907563024 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 22, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:57,268] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,269] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:57,383] Trial 58 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-11-06 03:32:57,385] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,386] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  62%|██████▏   | 62/100 [00:06<00:03, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:57,512] Trial 59 finished with value: 0.8607703081232494 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:57,514] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,515] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:57,599] Trial 60 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:57,601] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,602] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:57,676] Trial 61 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:57,678] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,679] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  65%|██████▌   | 65/100 [00:06<00:03,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:57,804] Trial 62 finished with value: 0.8456442577030812 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 79, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:57,806] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,807] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:57,901] Trial 63 finished with value: 0.8456442577030814 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:57,904] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,905] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:57,958] Trial 64 finished with value: 0.8389635854341737 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 11, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:57,961] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:57,961] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  67%|██████▋   | 67/100 [00:06<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:58,016] Trial 65 finished with value: 0.8490336134453781 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 12, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,018] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,019] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:58,145] Trial 66 finished with value: 0.8439915966386554 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,147] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,148] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  70%|███████   | 70/100 [00:06<00:02, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:58,283] Trial 67 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 80, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,285] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,287] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:58,361] Trial 68 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,363] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,364] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:58,459] Trial 69 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,461] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,463] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  73%|███████▎  | 73/100 [00:07<00:02,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:58,598] Trial 70 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,600] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,601] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:58,715] Trial 71 finished with value: 0.8473529411764705 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,718] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,719] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:58,784] Trial 72 finished with value: 0.8356022408963586 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 23, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,786] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,787] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  75%|███████▌  | 75/100 [00:07<00:02, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:58,861] Trial 73 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 29, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,863] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,865] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:58,991] Trial 74 finished with value: 0.8389635854341735 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 74, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:58,993] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:58,994] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  77%|███████▋  | 77/100 [00:07<00:02,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:59,129] Trial 75 finished with value: 0.8490056022408965 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 97, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,131] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,132] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:59,247] Trial 76 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,249] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,250] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  79%|███████▉  | 79/100 [00:07<00:02,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:59,335] Trial 77 finished with value: 0.8423249299719888 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 40, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,338] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,339] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:59,464] Trial 78 finished with value: 0.8540336134453781 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,466] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,467] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  82%|████████▏ | 82/100 [00:08<00:01, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:59,581] Trial 79 finished with value: 0.8506862745098038 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,583] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,584] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:59,639] Trial 80 finished with value: 0.8439915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 17, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,641] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,642] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:59,696] Trial 81 finished with value: 0.8523249299719888 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 20, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,698] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,700] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  84%|████████▍ | 84/100 [00:08<00:01,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:32:59,805] Trial 82 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,807] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,808] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:32:59,943] Trial 83 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:32:59,945] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:32:59,946] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  86%|████████▌ | 86/100 [00:08<00:01,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:00,021] Trial 84 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,022] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,023] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:00,139] Trial 85 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,141] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,142] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  88%|████████▊ | 88/100 [00:08<00:01,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:00,287] Trial 86 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,289] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,290] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:00,414] Trial 87 finished with value: 0.8389495798319327 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 77, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,416] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,417] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  91%|█████████ | 91/100 [00:09<00:00,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:00,492] Trial 88 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 32, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,493] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,494] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:00,559] Trial 89 finished with value: 0.8372689075630252 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 26, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,562] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,563] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:00,677] Trial 90 finished with value: 0.845658263305322 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,680] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,681] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  94%|█████████▍| 94/100 [00:09<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:00,837] Trial 91 finished with value: 0.8473249299719889 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 94, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,840] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,841] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:00,938] Trial 92 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:00,940] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:00,941] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,015] Trial 93 finished with value: 0.8490196078431375 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:01,017] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:01,018] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  97%|█████████▋| 97/100 [00:09<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:01,173] Trial 94 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:01,176] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:01,177] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,272] Trial 95 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:01,274] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:01,276] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,330] Trial 96 finished with value: 0.845672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 14, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:01,333] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:01,334] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077:  99%|█████████▉| 99/100 [00:09<00:00, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:01,389] Trial 97 finished with value: 0.8389635854341735 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 13, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:01,391] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:01,392] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,498] Trial 98 finished with value: 0.8490196078431371 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-11-06 03:33:01,501] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:01,502] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.86077: 100%|██████████| 100/100 [00:10<00:00,  9.91it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:01,631] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with QMCSampler\n",
      "Best trial: 59. Best value: 0.86077: 100%|██████████| 100/100 [00:10<00:00,  9.91it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:01,631] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:01,628] Trial 99 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using QMCSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}\n",
      "Best accuracy: 0.8608, at trial: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.847339:   5%|▌         | 5/100 [00:00<00:03, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:01,665] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-11-06 03:33:01,667] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,691] Trial 1 finished with value: 0.8355042016806724 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-11-06 03:33:01,693] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,727] Trial 2 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-11-06 03:33:01,729] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,764] Trial 3 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 3 with value: 0.8473389355742296.\n",
      "[W 2025-11-06 03:33:01,767] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,792] Trial 4 finished with value: 0.8389215686274509 and parameters: {'algorithm': 'brute', 'n_neighbors': 15, 'p': 2}. Best is trial 3 with value: 0.8473389355742296.\n",
      "[W 2025-11-06 03:33:01,794] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.849006:   6%|▌         | 6/100 [00:00<00:03, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:01,831] Trial 5 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 5 with value: 0.8490056022408963.\n",
      "[W 2025-11-06 03:33:01,832] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  12%|█▏        | 12/100 [00:00<00:02, 31.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:01,867] Trial 6 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:01,869] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,892] Trial 7 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:01,894] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,918] Trial 8 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'brute', 'n_neighbors': 9, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:01,921] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,955] Trial 9 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 11, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:01,958] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:01,982] Trial 10 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:01,984] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,018] Trial 11 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:02,020] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.84902:  13%|█▎        | 13/100 [00:00<00:02, 31.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:02,055] Trial 12 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 23, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:02,058] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  19%|█▉        | 19/100 [00:00<00:02, 31.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:02,071] Trial 13 finished with value: 0.8456302521008403 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-11-06 03:33:02,074] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,107] Trial 14 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,109] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,144] Trial 15 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,146] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,180] Trial 16 finished with value: 0.8304901960784313 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,181] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,205] Trial 17 finished with value: 0.8372549019607842 and parameters: {'algorithm': 'brute', 'n_neighbors': 7, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,207] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,241] Trial 18 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,243] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  26%|██▌       | 26/100 [00:00<00:02, 30.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:02,277] Trial 19 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,279] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,312] Trial 20 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 19, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,314] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,338] Trial 21 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,340] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,374] Trial 22 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,377] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,401] Trial 23 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,402] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,416] Trial 24 finished with value: 0.8506862745098038 and parameters: {'algorithm': 'brute', 'n_neighbors': 13, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,418] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,452] Trial 25 finished with value: 0.8338795518207283 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,454] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  33%|███▎      | 33/100 [00:01<00:01, 33.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:02,488] Trial 26 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,489] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,503] Trial 27 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,505] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,529] Trial 28 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,531] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,555] Trial 29 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,558] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,583] Trial 30 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,586] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,621] Trial 31 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,624] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,658] Trial 32 finished with value: 0.8288515406162464 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 4, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,660] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  40%|████      | 40/100 [00:01<00:01, 33.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:02,693] Trial 33 finished with value: 0.835532212885154 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,695] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,729] Trial 34 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,731] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,765] Trial 35 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,767] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,791] Trial 36 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,794] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,818] Trial 37 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,821] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,845] Trial 38 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,847] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,872] Trial 39 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,875] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  47%|████▋     | 47/100 [00:01<00:01, 32.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:02,909] Trial 40 finished with value: 0.8473249299719889 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 11, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,911] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,936] Trial 41 finished with value: 0.8422549019607842 and parameters: {'algorithm': 'brute', 'n_neighbors': 14, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,938] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,972] Trial 42 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:02,974] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:02,999] Trial 43 finished with value: 0.845658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,001] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,035] Trial 44 finished with value: 0.850658263305322 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,037] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,061] Trial 45 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,063] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,097] Trial 46 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,099] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  54%|█████▍    | 54/100 [00:01<00:01, 31.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:03,145] Trial 47 finished with value: 0.842282913165266 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,147] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,181] Trial 48 finished with value: 0.8405742296918767 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 8, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,183] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,216] Trial 49 finished with value: 0.8221288515406162 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,218] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,242] Trial 50 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,245] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,269] Trial 51 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,271] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,305] Trial 52 finished with value: 0.8405742296918767 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 18, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,307] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,341] Trial 53 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 24, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,343] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  60%|██████    | 60/100 [00:01<00:01, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:03,377] Trial 54 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,379] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,403] Trial 55 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,406] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,439] Trial 56 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,441] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,475] Trial 57 finished with value: 0.8422549019607842 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 9, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,477] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,501] Trial 58 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,504] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,550] Trial 59 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,552] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  66%|██████▌   | 66/100 [00:02<00:01, 29.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:03,587] Trial 60 finished with value: 0.8406162464985995 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,589] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,623] Trial 61 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 15, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,625] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,659] Trial 62 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,661] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,696] Trial 63 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,698] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,722] Trial 64 finished with value: 0.8271008403361346 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,723] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,757] Trial 65 finished with value: 0.8338655462184874 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 4, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,759] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  73%|███████▎  | 73/100 [00:02<00:00, 30.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:03,793] Trial 66 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,795] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,829] Trial 67 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,831] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,865] Trial 68 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 16, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,867] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,890] Trial 69 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,892] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,916] Trial 70 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,918] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,932] Trial 71 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,934] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:03,967] Trial 72 finished with value: 0.8372549019607842 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:03,969] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  80%|████████  | 80/100 [00:02<00:00, 31.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:04,003] Trial 73 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,005] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,019] Trial 74 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,021] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,056] Trial 75 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,058] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,104] Trial 76 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,107] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,133] Trial 77 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,135] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,160] Trial 78 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,163] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,189] Trial 79 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,191] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  87%|████████▋ | 87/100 [00:02<00:00, 30.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:04,226] Trial 80 finished with value: 0.8254901960784313 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,228] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,252] Trial 81 finished with value: 0.8372268907563025 and parameters: {'algorithm': 'brute', 'n_neighbors': 8, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,254] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,287] Trial 82 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,289] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,323] Trial 83 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,325] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,349] Trial 84 finished with value: 0.842282913165266 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,351] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,386] Trial 85 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,388] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,422] Trial 86 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,424] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367:  94%|█████████▍| 94/100 [00:03<00:00, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:04,458] Trial 87 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,460] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,494] Trial 88 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,495] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,519] Trial 89 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'brute', 'n_neighbors': 11, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,521] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,555] Trial 90 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,557] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,591] Trial 91 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,593] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,616] Trial 92 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,618] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,652] Trial 93 finished with value: 0.8456302521008403 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 17, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,654] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.852367: 100%|██████████| 100/100 [00:03<00:00, 31.58it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:04,799] A new study created in memory with name: Support Vector Machine Model Fine Tuning with QMCSampler\n",
      "Best trial: 14. Best value: 0.852367: 100%|██████████| 100/100 [00:03<00:00, 31.58it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:04,799] A new study created in memory with name: Support Vector Machine Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:04,688] Trial 94 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,690] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,704] Trial 95 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 29, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,706] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,720] Trial 96 finished with value: 0.8304901960784313 and parameters: {'algorithm': 'brute', 'n_neighbors': 5, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,722] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,745] Trial 97 finished with value: 0.8338655462184874 and parameters: {'algorithm': 'brute', 'n_neighbors': 4, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,747] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,781] Trial 98 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-11-06 03:33:04,783] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,797] Trial 99 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using QMCSampler: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   2%|▏         | 2/100 [00:00<00:04, 22.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:04,823] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:33:04,826] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,862] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:33:04,864] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,888] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0010000000000000002}. Best is trial 0 with value: 0.5352380952380952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.535238:   7%|▋         | 7/100 [00:00<00:02, 31.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:33:04,890] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,924] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.003162277660168382}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:33:04,926] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,950] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003162277660168384}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:33:04,952] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:04,976] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005623413251903495}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:33:04,979] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,013] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005623413251903492}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-11-06 03:33:05,015] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,017] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.766779:   9%|▉         | 9/100 [00:00<00:02, 33.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,041] Trial 7 finished with value: 0.7667787114845938 and parameters: {'kernel': 'poly', 'C': 0.0017782794100389236, 'degree': 5}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-11-06 03:33:05,044] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,045] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,069] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00017782794100389232, 'degree': 2}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-11-06 03:33:05,071] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.837227:  14%|█▍        | 14/100 [00:00<00:02, 32.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,096] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023713737056616573}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-11-06 03:33:05,099] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,134] Trial 10 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002371373705661656}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-11-06 03:33:05,137] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,138] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,162] Trial 11 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007498942093324564, 'degree': 3}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,166] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,201] Trial 12 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007498942093324562}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,203] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,227] Trial 13 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00042169650342858235}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,229] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,230] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.837227:  16%|█▌        | 16/100 [00:00<00:02, 33.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,254] Trial 14 finished with value: 0.8321988795518207 and parameters: {'kernel': 'poly', 'C': 0.004216965034285825, 'degree': 2}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,256] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,280] Trial 15 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013335214321633251}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,282] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,284] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.837227:  21%|██        | 21/100 [00:00<00:02, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,297] Trial 16 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0001333521432163326, 'degree': 2}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,300] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,301] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,325] Trial 17 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00015399265260594933, 'degree': 3}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,327] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,361] Trial 18 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015399265260594922}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,363] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,397] Trial 19 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004869675251658635}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,400] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,402] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,425] Trial 20 finished with value: 0.5905882352941176 and parameters: {'kernel': 'poly', 'C': 0.00048696752516586337, 'degree': 5}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,428] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,429] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,453] Trial 21 finished with value: 0.6023389355742297 and parameters: {'kernel': 'poly', 'C': 0.000865964323360066, 'degree': 4}. Best is trial 11 with value: 0.8372268907563024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.837227:  23%|██▎       | 23/100 [00:00<00:02, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:33:05,455] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,491] Trial 22 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.008659643233600654}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,493] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,495] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.837227:  29%|██▉       | 29/100 [00:00<00:02, 34.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,520] Trial 23 finished with value: 0.8003501400560223 and parameters: {'kernel': 'poly', 'C': 0.0027384196342643626, 'degree': 4}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,523] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,546] Trial 24 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002738419634264362}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,548] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,572] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0002053525026457149}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,574] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,598] Trial 26 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0020535250264571477}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,600] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,623] Trial 27 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0064938163157621165}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,626] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,650] Trial 28 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006493816315762115}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,652] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.837227:  31%|███       | 31/100 [00:00<00:01, 34.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,675] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000365174127254838}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,677] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,701] Trial 30 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.003651741272548378}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,703] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.837227:  36%|███▌      | 36/100 [00:01<00:01, 35.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,737] Trial 31 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0011547819846894588}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,739] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,763] Trial 32 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00011547819846894585}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,765] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,799] Trial 33 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00012409377607517218}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,801] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,825] Trial 34 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0012409377607517208}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,827] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,851] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.003924189758484535}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,853] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 38. Best value: 0.837227:  39%|███▉      | 39/100 [00:01<00:01, 35.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,877] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003924189758484538}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,879] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,903] Trial 37 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006978305848598669}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-11-06 03:33:05,905] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,906] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,930] Trial 38 finished with value: 0.8372268907563025 and parameters: {'kernel': 'poly', 'C': 0.006978305848598664, 'degree': 5}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:05,932] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 38. Best value: 0.837227:  44%|████▍     | 44/100 [00:01<00:01, 35.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:05,965] Trial 39 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002206734069084591}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:05,967] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,968] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:05,992] Trial 40 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00022067340690845924, 'degree': 5}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:05,994] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:05,995] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,020] Trial 41 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0002942727176209287, 'degree': 3}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:06,022] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,047] Trial 42 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.002942727176209285}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:06,049] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,074] Trial 43 finished with value: 0.5973109243697479 and parameters: {'kernel': 'rbf', 'C': 0.009305720409296997}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:06,076] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 46. Best value: 0.838894:  47%|████▋     | 47/100 [00:01<00:01, 35.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,110] Trial 44 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009305720409296995}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:06,112] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,114] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,127] Trial 45 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005232991146814953, 'degree': 2}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-11-06 03:33:06,129] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,130] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,155] Trial 46 finished with value: 0.8388935574229691 and parameters: {'kernel': 'poly', 'C': 0.005232991146814949, 'degree': 2}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-11-06 03:33:06,157] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.838922:  52%|█████▏    | 52/100 [00:01<00:01, 36.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,181] Trial 47 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0016548170999431827}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-11-06 03:33:06,184] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,209] Trial 48 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00016548170999431823}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-11-06 03:33:06,211] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,237] Trial 49 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00014330125702369644}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-11-06 03:33:06,239] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,264] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0014330125702369636}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-11-06 03:33:06,266] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,268] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,291] Trial 51 finished with value: 0.8389215686274509 and parameters: {'kernel': 'poly', 'C': 0.0045315836376008225, 'degree': 2}. Best is trial 51 with value: 0.8389215686274509.\n",
      "[W 2025-11-06 03:33:06,294] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,296] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  55%|█████▌    | 55/100 [00:01<00:01, 36.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,321] Trial 52 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00045315836376008217, 'degree': 2}. Best is trial 51 with value: 0.8389215686274509.\n",
      "[W 2025-11-06 03:33:06,323] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,324] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,348] Trial 53 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0008058421877614828, 'degree': 2}. Best is trial 51 with value: 0.8389215686274509.\n",
      "[W 2025-11-06 03:33:06,350] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,351] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,365] Trial 54 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,367] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,368] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  60%|██████    | 60/100 [00:01<00:01, 37.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,392] Trial 55 finished with value: 0.7936694677871149 and parameters: {'kernel': 'poly', 'C': 0.0025482967479793484, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,394] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,419] Trial 56 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002548296747979348}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,421] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,445] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00019109529749704405}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,448] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,449] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,473] Trial 58 finished with value: 0.7701400560224089 and parameters: {'kernel': 'poly', 'C': 0.0019109529749704425, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,476] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,499] Trial 59 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.006042963902381333}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,502] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,503] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  63%|██████▎   | 63/100 [00:01<00:00, 37.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,527] Trial 60 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0006042963902381332, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,529] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,530] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,553] Trial 61 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00033982083289425634, 'degree': 2}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,555] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,557] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,580] Trial 62 finished with value: 0.8070588235294117 and parameters: {'kernel': 'poly', 'C': 0.003398208328942561, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,582] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  67%|██████▋   | 67/100 [00:01<00:00, 37.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,606] Trial 63 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010746078283213184}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,608] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,632] Trial 64 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00010746078283213182}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,635] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,659] Trial 65 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0001113973859994803}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,661] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,695] Trial 66 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001113973859994803}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,697] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  70%|███████   | 70/100 [00:01<00:00, 35.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,732] Trial 67 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0035226946514731027}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,735] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,759] Trial 68 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003522694651473105}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,761] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,796] Trial 69 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006264335366568858}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,798] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  73%|███████▎  | 73/100 [00:02<00:00, 32.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,833] Trial 70 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00626433536656886}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,837] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,883] Trial 71 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001980956778550341}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,888] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,924] Trial 72 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0001980956778550342}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,927] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,928] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  77%|███████▋  | 77/100 [00:02<00:00, 33.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:06,953] Trial 73 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00026416483203860934, 'degree': 3}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,955] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,979] Trial 74 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0026416483203860943}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,981] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,982] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:06,995] Trial 75 finished with value: 0.8338655462184873 and parameters: {'kernel': 'poly', 'C': 0.008353625469578265, 'degree': 3}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:06,997] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:06,998] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,012] Trial 76 finished with value: 0.5905882352941176 and parameters: {'kernel': 'poly', 'C': 0.000835362546957827, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,014] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,015] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  82%|████████▏ | 82/100 [00:02<00:00, 35.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,039] Trial 77 finished with value: 0.5771988795518208 and parameters: {'kernel': 'poly', 'C': 0.0004697588816706495, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,040] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,041] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,066] Trial 78 finished with value: 0.8204761904761904 and parameters: {'kernel': 'poly', 'C': 0.004697588816706496, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,068] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,092] Trial 79 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0014855080171727755}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,093] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,094] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,118] Trial 80 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00014855080171727767, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,121] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,144] Trial 81 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00017154378963428796}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,147] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  85%|████████▌ | 85/100 [00:02<00:00, 35.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,170] Trial 82 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0017154378963428801}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,172] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,206] Trial 83 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005424690937011328}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,208] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,209] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,232] Trial 84 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005424690937011332, 'degree': 2}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,234] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  89%|████████▉ | 89/100 [00:02<00:00, 34.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,268] Trial 85 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009646616199111995}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,270] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,294] Trial 86 finished with value: 0.6157983193277311 and parameters: {'kernel': 'rbf', 'C': 0.009646616199111998}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,296] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,320] Trial 87 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0030505278902670284}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,323] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,357] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00030505278902670253}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,360] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  92%|█████████▏| 92/100 [00:02<00:00, 34.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,385] Trial 89 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002287573200318398}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,387] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,388] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,412] Trial 90 finished with value: 0.7819187675070027 and parameters: {'kernel': 'poly', 'C': 0.0022875732003183966, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,414] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,439] Trial 91 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.007233941627366754}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,441] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  96%|█████████▌| 96/100 [00:02<00:00, 34.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,477] Trial 92 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007233941627366753}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,480] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,482] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,507] Trial 93 finished with value: 0.5453221288515406 and parameters: {'kernel': 'poly', 'C': 0.0004067944321083049, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,509] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,533] Trial 94 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0040679443210830495}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,535] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,536] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,560] Trial 95 finished with value: 0.7231512605042016 and parameters: {'kernel': 'poly', 'C': 0.0012863969449369757, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,562] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,563] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255:  99%|█████████▉| 99/100 [00:02<00:00, 34.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,587] Trial 96 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00012863969449369766, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,589] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,624] Trial 97 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00011970850304957301}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,627] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:33:07,628] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:07,654] Trial 98 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0011970850304957315, 'degree': 2}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-11-06 03:33:07,657] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 54. Best value: 0.842255: 100%|██████████| 100/100 [00:02<00:00, 34.68it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:07,684] A new study created in memory with name: AdaBoost Model Fine Tuning with QMCSampler\n",
      "Best trial: 54. Best value: 0.842255: 100%|██████████| 100/100 [00:02<00:00, 34.68it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:07,684] A new study created in memory with name: AdaBoost Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,682] Trial 99 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00378551524925863}. Best is trial 54 with value: 0.8422549019607842.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using QMCSampler: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}\n",
      "Best accuracy: 0.8423, at trial: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,759] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   2%|▏         | 2/100 [00:00<00:05, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,794] Trial 1 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010000000000000002}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-11-06 03:33:07,870] Trial 2 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 55, 'learning_rate': 0.0316227766016838}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.848992:   4%|▍         | 4/100 [00:00<00:07, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:07,986] Trial 3 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 78, 'learning_rate': 0.005623413251903492}. Best is trial 0 with value: 0.8489915966386553.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:   6%|▌         | 6/100 [00:00<00:07, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:08,052] Trial 4 finished with value: 0.850686274509804 and parameters: {'n_estimators': 32, 'learning_rate': 0.1778279410038923}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:08,138] Trial 5 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 44, 'learning_rate': 0.013335214321633242}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:   8%|▊         | 8/100 [00:00<00:09, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:08,287] Trial 6 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 89, 'learning_rate': 0.4216965034285823}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:08,405] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 66, 'learning_rate': 0.002371373705661656}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:08,450] Trial 8 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 21, 'learning_rate': 0.07498942093324559}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  11%|█         | 11/100 [00:00<00:07, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:08,495] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 27, 'learning_rate': 0.008659643233600654}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:08,591] Trial 10 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 72, 'learning_rate': 0.27384196342643613}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  13%|█▎        | 13/100 [00:01<00:07, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:08,716] Trial 11 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 95, 'learning_rate': 0.0015399265260594922}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:08,782] Trial 12 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 49, 'learning_rate': 0.04869675251658632}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:08,857] Trial 13 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 38, 'learning_rate': 0.003651741272548378}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  17%|█▋        | 17/100 [00:01<00:07, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:08,983] Trial 14 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 83, 'learning_rate': 0.11547819846894583}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,089] Trial 15 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 61, 'learning_rate': 0.020535250264571463}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,124] Trial 16 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 15, 'learning_rate': 0.6493816315762113}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,169] Trial 17 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 18, 'learning_rate': 0.025482967479793468}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  19%|█▉        | 19/100 [00:01<00:06, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:09,276] Trial 18 finished with value: 0.83890756302521 and parameters: {'n_estimators': 64, 'learning_rate': 0.8058421877614819}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,402] Trial 19 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 86, 'learning_rate': 0.004531583637600819}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  21%|██        | 21/100 [00:01<00:06, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:09,479] Trial 20 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 41, 'learning_rate': 0.14330125702369628}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,574] Trial 21 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 52, 'learning_rate': 0.001910952974970441}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  25%|██▌       | 25/100 [00:02<00:06, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:09,720] Trial 22 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 98, 'learning_rate': 0.060429639023813285}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,817] Trial 23 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 75, 'learning_rate': 0.010746078283213176}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,872] Trial 24 finished with value: 0.842282913165266 and parameters: {'n_estimators': 29, 'learning_rate': 0.33982083289425596}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:09,917] Trial 25 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029427271762092824}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  29%|██▉       | 29/100 [00:02<00:06, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:10,023] Trial 26 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 69, 'learning_rate': 0.0930572040929699}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,139] Trial 27 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 92, 'learning_rate': 0.016548170999431816}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,194] Trial 28 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 46, 'learning_rate': 0.5232991146814947}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  31%|███       | 31/100 [00:02<00:06, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:10,249] Trial 29 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 35, 'learning_rate': 0.006978305848598664}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,397] Trial 30 finished with value: 0.850686274509804 and parameters: {'n_estimators': 81, 'learning_rate': 0.220673406908459}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  35%|███▌      | 35/100 [00:02<00:04, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:10,473] Trial 31 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 58, 'learning_rate': 0.0012409377607517198}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,510] Trial 32 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 12, 'learning_rate': 0.039241897584845364}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,546] Trial 33 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 14, 'learning_rate': 0.006264335366568854}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,632] Trial 34 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 59, 'learning_rate': 0.1980956778550338}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  37%|███▋      | 37/100 [00:03<00:05, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:10,758] Trial 35 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 82, 'learning_rate': 0.0011139738599948022}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,814] Trial 36 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 37, 'learning_rate': 0.03522694651473102}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:10,879] Trial 37 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 48, 'learning_rate': 0.0026416483203860917}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  41%|████      | 41/100 [00:03<00:05, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:11,026] Trial 38 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 93, 'learning_rate': 0.08353625469578259}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,133] Trial 39 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 71, 'learning_rate': 0.014855080171727746}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,190] Trial 40 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 25, 'learning_rate': 0.469758881670649}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  43%|████▎     | 43/100 [00:03<00:04, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:11,246] Trial 41 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 31, 'learning_rate': 0.0017154378963428786}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,352] Trial 42 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 76, 'learning_rate': 0.05424690937011326}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  45%|████▌     | 45/100 [00:03<00:05, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:11,479] Trial 43 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 99, 'learning_rate': 0.00964661619911199}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,575] Trial 44 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 54, 'learning_rate': 0.3050527890267024}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,651] Trial 45 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 42, 'learning_rate': 0.02287573200318396}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  49%|████▉     | 49/100 [00:04<00:04, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:11,788] Trial 46 finished with value: 0.850658263305322 and parameters: {'n_estimators': 88, 'learning_rate': 0.7233941627366745}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,894] Trial 47 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 65, 'learning_rate': 0.004067944321083046}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,929] Trial 48 finished with value: 0.835546218487395 and parameters: {'n_estimators': 19, 'learning_rate': 0.12863969449369742}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:11,975] Trial 49 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 17, 'learning_rate': 0.005048065716667474}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  51%|█████     | 51/100 [00:04<00:04, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:12,082] Trial 50 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 62, 'learning_rate': 0.1596338544287943}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:12,219] Trial 51 finished with value: 0.8389075630252101 and parameters: {'n_estimators': 85, 'learning_rate': 0.02838735964758755}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  53%|█████▎    | 53/100 [00:04<00:04, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:12,295] Trial 52 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 39, 'learning_rate': 0.8976871324473146}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:12,393] Trial 53 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 51, 'learning_rate': 0.011970850304957308}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.850686:  57%|█████▋    | 57/100 [00:05<00:04, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:12,560] Trial 54 finished with value: 0.8506862745098038 and parameters: {'n_estimators': 96, 'learning_rate': 0.3785515249258632}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:12,677] Trial 55 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 73, 'learning_rate': 0.002128751661796374}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:12,724] Trial 56 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 28, 'learning_rate': 0.06731703824144986}. Best is trial 4 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.852353:  59%|█████▉    | 59/100 [00:05<00:03, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:12,779] Trial 57 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 22, 'learning_rate': 0.018434229924091106}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-11-06 03:33:12,885] Trial 58 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 68, 'learning_rate': 0.5829415347136077}. Best is trial 58 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.852353:  61%|██████    | 61/100 [00:05<00:03, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:13,023] Trial 59 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 91, 'learning_rate': 0.003278121151393461}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:33:13,099] Trial 60 finished with value: 0.8490196078431371 and parameters: {'n_estimators': 45, 'learning_rate': 0.10366329284376985}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:33:13,166] Trial 61 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 34, 'learning_rate': 0.0013823722273579005}. Best is trial 58 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.852353:  65%|██████▌   | 65/100 [00:05<00:02, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:13,272] Trial 62 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 79, 'learning_rate': 0.0437144481261109}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:33:13,369] Trial 63 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 56, 'learning_rate': 0.007773650302387762}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:33:13,404] Trial 64 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 11, 'learning_rate': 0.24582440689201987}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:33:13,439] Trial 65 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 12, 'learning_rate': 0.01567878843826971}. Best is trial 58 with value: 0.8523529411764705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  69%|██████▉   | 69/100 [00:06<00:02, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:13,515] Trial 66 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 57, 'learning_rate': 0.4958068241684657}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:33:13,641] Trial 67 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 80, 'learning_rate': 0.0027881266654131345}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-11-06 03:33:13,707] Trial 68 finished with value: 0.8540336134453781 and parameters: {'n_estimators': 34, 'learning_rate': 0.08816830667755711}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  71%|███████   | 71/100 [00:06<00:02, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:13,793] Trial 69 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 46, 'learning_rate': 0.0011757432659207114}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:13,919] Trial 70 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 91, 'learning_rate': 0.037180266639144754}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  73%|███████▎  | 73/100 [00:06<00:02, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:14,036] Trial 71 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 69, 'learning_rate': 0.006611690262414818}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,091] Trial 72 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 23, 'learning_rate': 0.20908000412787187}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,170] Trial 73 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 29, 'learning_rate': 0.004293510210083484}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  77%|███████▋  | 77/100 [00:06<00:02, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:14,287] Trial 74 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 74, 'learning_rate': 0.13577271421051842}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,404] Trial 75 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 97, 'learning_rate': 0.024144182212566402}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,479] Trial 76 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 51, 'learning_rate': 0.7635060803383348}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  79%|███████▉  | 79/100 [00:07<00:02, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:14,554] Trial 77 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 40, 'learning_rate': 0.010181517217181822}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,690] Trial 78 finished with value: 0.842282913165266 and parameters: {'n_estimators': 86, 'learning_rate': 0.321967844425138}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  83%|████████▎ | 83/100 [00:07<00:01, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:14,798] Trial 79 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 63, 'learning_rate': 0.0018105582430271226}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,843] Trial 80 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 17, 'learning_rate': 0.05725487884358381}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,878] Trial 81 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 20, 'learning_rate': 0.0022467900918126454}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:14,994] Trial 82 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 66, 'learning_rate': 0.07104974114426789}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  85%|████████▌ | 85/100 [00:07<00:01, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:15,151] Trial 83 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 88, 'learning_rate': 0.01263462917654469}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:15,207] Trial 84 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 43, 'learning_rate': 0.39954205589498876}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:15,282] Trial 85 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 54, 'learning_rate': 0.029961427410043647}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  89%|████████▉ | 89/100 [00:07<00:01, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:15,448] Trial 86 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 100, 'learning_rate': 0.9474635256553756}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:15,544] Trial 87 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 77, 'learning_rate': 0.005327978945865643}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:15,610] Trial 88 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 32, 'learning_rate': 0.16848548794358392}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  91%|█████████ | 91/100 [00:08<00:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:15,665] Trial 89 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.008204696109024995}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:15,781] Trial 90 finished with value: 0.850672268907563 and parameters: {'n_estimators': 71, 'learning_rate': 0.2594552721404016}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  93%|█████████▎| 93/100 [00:08<00:00, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:15,908] Trial 91 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 94, 'learning_rate': 0.0014590242156305613}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:15,986] Trial 92 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 49, 'learning_rate': 0.04613839682733216}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:16,061] Trial 93 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 37, 'learning_rate': 0.003459891660869934}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034:  97%|█████████▋| 97/100 [00:08<00:00, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:16,157] Trial 94 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 83, 'learning_rate': 0.10941138105771861}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:16,252] Trial 95 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 60, 'learning_rate': 0.019456400615886365}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:16,288] Trial 96 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 14, 'learning_rate': 0.6152654101490374}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:16,312] Trial 97 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 13, 'learning_rate': 0.0025028654311746077}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 68. Best value: 0.854034: 100%|██████████| 100/100 [00:08<00:00, 11.31it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:16,526] A new study created in memory with name: Gradient Boosting Model Fine Tuning with QMCSampler\n",
      "Best trial: 68. Best value: 0.854034: 100%|██████████| 100/100 [00:08<00:00, 11.31it/s]\n",
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:33:16,526] A new study created in memory with name: Gradient Boosting Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:16,398] Trial 98 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 59, 'learning_rate': 0.0791475543941116}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-11-06 03:33:16,524] Trial 99 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 81, 'learning_rate': 0.014074646633398432}. Best is trial 68 with value: 0.8540336134453781.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using QMCSampler: {'n_estimators': 34, 'learning_rate': 0.08816830667755711}\n",
      "Best accuracy: 0.8540, at trial: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.854006:   3%|▎         | 3/100 [00:00<00:05, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:16,612] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n",
      "[W 2025-11-06 03:33:16,614] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:16,637] Trial 1 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 0 with value: 0.800280112044818.\n",
      "[W 2025-11-06 03:33:16,640] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:16,754] Trial 2 finished with value: 0.8540056022408965 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.010000000000000004, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.75}. Best is trial 2 with value: 0.8540056022408965.\n",
      "[W 2025-11-06 03:33:16,757] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:   5%|▌         | 5/100 [00:00<00:09, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:16,893] Trial 3 finished with value: 0.8372689075630252 and parameters: {'max_features': None, 'n_estimators': 78, 'learning_rate': 0.003162277660168382, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.875}. Best is trial 2 with value: 0.8540056022408965.\n",
      "[W 2025-11-06 03:33:16,896] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:17,021] Trial 4 finished with value: 0.8607563025210083 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.03162277660168381, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,023] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:   7%|▋         | 7/100 [00:00<00:09,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:17,128] Trial 5 finished with value: 0.8405882352941175 and parameters: {'max_features': None, 'n_estimators': 44, 'learning_rate': 0.005623413251903492, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.5625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,130] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:17,215] Trial 6 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.05623413251903493, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.8125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,218] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  10%|█         | 10/100 [00:00<00:08, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:17,343] Trial 7 finished with value: 0.7935294117647059 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.0017782794100389236, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,345] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:17,401] Trial 8 finished with value: 0.8473389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 21, 'learning_rate': 0.01778279410038924, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.6875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,403] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:17,458] Trial 9 finished with value: 0.7717366946778712 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.004216965034285825, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.65625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,460] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  11%|█         | 11/100 [00:01<00:07, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:17,625] Trial 10 finished with value: 0.8355742296918767 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.04216965034285825, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.90625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,628] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  14%|█▍        | 14/100 [00:01<00:09,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:17,906] Trial 11 finished with value: 0.7902380952380953 and parameters: {'max_features': None, 'n_estimators': 95, 'learning_rate': 0.0013335214321633238, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.78125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,908] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:17,962] Trial 12 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.013335214321633242, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.53125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:17,964] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:18,008] Trial 13 finished with value: 0.6593277310924369 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.002371373705661656, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.71875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,010] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  18%|█▊        | 18/100 [00:01<00:10,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:18,276] Trial 14 finished with value: 0.8389215686274509 and parameters: {'max_features': None, 'n_estimators': 83, 'learning_rate': 0.023713737056616564, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.96875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,278] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:18,343] Trial 15 finished with value: 0.8439495798319328 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.007498942093324564, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.84375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,345] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:18,380] Trial 16 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 15, 'learning_rate': 0.07498942093324566, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.59375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,382] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:18,436] Trial 17 finished with value: 0.7970028011204482 and parameters: {'max_features': None, 'n_estimators': 18, 'learning_rate': 0.008659643233600654, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.984375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,438] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  20%|██        | 20/100 [00:02<00:08,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:18,593] Trial 18 finished with value: 0.8573949579831932 and parameters: {'max_features': None, 'n_estimators': 64, 'learning_rate': 0.08659643233600657, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.734375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,596] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:18,753] Trial 19 finished with value: 0.8372408963585434 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.0027384196342643626, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.609375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,756] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  21%|██        | 21/100 [00:02<00:09,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:18,891] Trial 20 finished with value: 0.8473109243697479 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.027384196342643632, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.859375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:18,894] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  23%|██▎       | 23/100 [00:02<00:11,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:19,150] Trial 21 finished with value: 0.6525070028011204 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.0015399265260594922, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.921875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:19,154] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:19,294] Trial 22 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 98, 'learning_rate': 0.015399265260594926, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.671875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:19,297] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  26%|██▌       | 26/100 [00:03<00:08,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:19,433] Trial 23 finished with value: 0.8472969187675069 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.004869675251658635, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.546875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:19,437] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:19,502] Trial 24 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 29, 'learning_rate': 0.04869675251658634, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.796875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:19,505] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:19,581] Trial 25 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 24, 'learning_rate': 0.0020535250264571477, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.828125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:19,584] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.860756:  27%|██▋       | 27/100 [00:03<00:08,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:19,691] Trial 26 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.020535250264571474, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.578125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:19,695] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  29%|██▉       | 29/100 [00:03<00:11,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:20,050] Trial 27 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.0064938163157621165, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.703125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-11-06 03:33:20,054] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:20,200] Trial 28 finished with value: 0.8624369747899159 and parameters: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.06493816315762117, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:20,207] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  31%|███       | 31/100 [00:03<00:11,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:20,340] Trial 29 finished with value: 0.7935994397759104 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.003651741272548378, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:20,343] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:20,519] Trial 30 finished with value: 0.850686274509804 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.03651741272548378, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:20,522] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  34%|███▍      | 34/100 [00:04<00:08,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:20,721] Trial 31 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.0011547819846894588, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:20,725] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:20,791] Trial 32 finished with value: 0.8120868347338934 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.01154781984689459, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:20,794] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:20,893] Trial 33 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.003398208328942561, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.9609375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:20,896] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  36%|███▌      | 36/100 [00:04<00:09,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:21,024] Trial 34 finished with value: 0.8523249299719888 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.03398208328942562, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.7109375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,028] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:21,186] Trial 35 finished with value: 0.642563025210084 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.0010746078283213173, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.5859375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,189] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  38%|███▊      | 38/100 [00:04<00:08,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:21,295] Trial 36 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 37, 'learning_rate': 0.010746078283213186, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.8359375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,299] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:21,376] Trial 37 finished with value: 0.6223669467787115 and parameters: {'max_features': 'log2', 'n_estimators': 48, 'learning_rate': 0.001910952974970441, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8984375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,379] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  40%|████      | 40/100 [00:05<00:08,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:21,536] Trial 38 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 93, 'learning_rate': 0.019109529749704413, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.6484375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,540] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:21,727] Trial 39 finished with value: 0.8490196078431371 and parameters: {'max_features': None, 'n_estimators': 71, 'learning_rate': 0.006042963902381328, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.5234375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,731] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  42%|████▏     | 42/100 [00:05<00:08,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:21,900] Trial 40 finished with value: 0.8422969187675069 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.06042963902381334, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.7734375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,905] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:21,993] Trial 41 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 31, 'learning_rate': 0.0014330125702369636, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.8671875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:21,996] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  44%|████▍     | 44/100 [00:05<00:09,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:22,305] Trial 42 finished with value: 0.8472969187675069 and parameters: {'max_features': None, 'n_estimators': 76, 'learning_rate': 0.014330125702369625, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.6171875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:22,308] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:22,485] Trial 43 finished with value: 0.8389355742296918 and parameters: {'max_features': None, 'n_estimators': 99, 'learning_rate': 0.004531583637600819, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7421875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:22,489] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  46%|████▌     | 46/100 [00:06<00:09,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:22,656] Trial 44 finished with value: 0.8439775910364145 and parameters: {'max_features': 'log2', 'n_estimators': 54, 'learning_rate': 0.045315836376008195, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.9921875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:22,659] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:22,744] Trial 45 finished with value: 0.8523669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 42, 'learning_rate': 0.008058421877614822, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8046875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:22,747] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  47%|████▋     | 47/100 [00:06<00:09,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:23,018] Trial 46 finished with value: 0.8439495798319328 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.08058421877614824, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.5546875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:23,022] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  50%|█████     | 50/100 [00:06<00:07,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:23,393] Trial 47 finished with value: 0.8338375350140055 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.0025482967479793462, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.6796875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:23,397] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:23,442] Trial 48 finished with value: 0.8489915966386554 and parameters: {'max_features': 'sqrt', 'n_estimators': 19, 'learning_rate': 0.02548296747979348, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.9296875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:23,445] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:23,512] Trial 49 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.0029427271762092824, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.5390625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:23,515] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  51%|█████     | 51/100 [00:07<00:07,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:23,653] Trial 50 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.02942727176209283, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.7890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:23,656] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  53%|█████▎    | 53/100 [00:07<00:08,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:23,945] Trial 51 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.009305720409296989, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.9140625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:23,948] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:24,005] Trial 52 finished with value: 0.8523389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.09305720409296998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.6640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:24,008] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  54%|█████▍    | 54/100 [00:07<00:07,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:24,180] Trial 53 finished with value: 0.8540056022408964 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.005232991146814949, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.6015625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:24,184] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  56%|█████▌    | 56/100 [00:08<00:08,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:24,650] Trial 54 finished with value: 0.8372268907563025 and parameters: {'max_features': None, 'n_estimators': 96, 'learning_rate': 0.052329911468149505, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.8515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:24,653] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:24,769] Trial 55 finished with value: 0.7801680672268908 and parameters: {'max_features': 'log2', 'n_estimators': 73, 'learning_rate': 0.0016548170999431814, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.9765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:24,772] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  58%|█████▊    | 58/100 [00:08<00:07,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:24,920] Trial 56 finished with value: 0.8322268907563025 and parameters: {'max_features': None, 'n_estimators': 28, 'learning_rate': 0.01654817099943183, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7265625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:24,923] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:24,970] Trial 57 finished with value: 0.8120308123249298 and parameters: {'max_features': 'log2', 'n_estimators': 22, 'learning_rate': 0.006978305848598664, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.6328125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:24,973] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  59%|█████▉    | 59/100 [00:08<00:07,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:25,264] Trial 58 finished with value: 0.8439495798319328 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.06978305848598666, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.8828125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:25,268] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  61%|██████    | 61/100 [00:09<00:07,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:25,599] Trial 59 finished with value: 0.8422408963585435 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.002206734069084591, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7578125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:25,604] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:25,720] Trial 60 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 45, 'learning_rate': 0.022067340690845913, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.5078125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:25,724] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  63%|██████▎   | 63/100 [00:09<00:05,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:25,854] Trial 61 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 34, 'learning_rate': 0.0012409377607517198, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:25,857] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:25,975] Trial 62 finished with value: 0.8456162464985993 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.0124093776075172, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9453125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:25,978] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  66%|██████▌   | 66/100 [00:09<00:04,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:26,246] Trial 63 finished with value: 0.8204481792717087 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.003924189758484535, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.8203125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:26,250] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:26,288] Trial 64 finished with value: 0.8490196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.03924189758484538, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9, 'subsample': 0.5703125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:26,290] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:26,368] Trial 65 finished with value: 0.6156582633053221 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.00626433536656886, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.72265625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:26,372] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  67%|██████▋   | 67/100 [00:10<00:04,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:26,543] Trial 66 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.06264335366568861, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.97265625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:26,548] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  70%|███████   | 70/100 [00:10<00:04,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:26,813] Trial 67 finished with value: 0.8288235294117646 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.001980956778550339, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.84765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:26,817] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:26,875] Trial 68 finished with value: 0.8556722689075631 and parameters: {'max_features': 'log2', 'n_estimators': 34, 'learning_rate': 0.019809567785503402, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.59765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:26,877] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:27,005] Trial 69 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.001113973859994803, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.66015625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:27,009] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  73%|███████▎  | 73/100 [00:11<00:04,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:27,536] Trial 70 finished with value: 0.8573669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 91, 'learning_rate': 0.011139738599948034, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.91015625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:27,538] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:27,634] Trial 71 finished with value: 0.8388935574229691 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.0035226946514731027, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.78515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:27,636] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:27,704] Trial 72 finished with value: 0.8540476190476192 and parameters: {'max_features': 'log2', 'n_estimators': 23, 'learning_rate': 0.03522694651473104, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.53515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:27,707] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  75%|███████▌  | 75/100 [00:11<00:03,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:27,775] Trial 73 finished with value: 0.5369187675070027 and parameters: {'max_features': 'log2', 'n_estimators': 29, 'learning_rate': 0.0026416483203860943, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.56640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:27,778] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:27,937] Trial 74 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.026416483203860936, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.81640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:27,941] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  77%|███████▋  | 77/100 [00:11<00:03,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:28,150] Trial 75 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 97, 'learning_rate': 0.008353625469578265, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.94140625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:28,153] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:28,342] Trial 76 finished with value: 0.8523809523809526 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.08353625469578266, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.69140625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:28,346] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  79%|███████▉  | 79/100 [00:12<00:03,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:28,454] Trial 77 finished with value: 0.8355182072829133 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.004697588816706496, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.50390625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:28,459] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:28,569] Trial 78 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 86, 'learning_rate': 0.04697588816706495, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.75390625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:28,572] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  82%|████████▏ | 82/100 [00:12<00:02,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:28,759] Trial 79 finished with value: 0.7381652661064425 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.0014855080171727755, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.87890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:28,764] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:28,836] Trial 80 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.01485508017172776, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.62890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:28,839] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:28,908] Trial 81 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 20, 'learning_rate': 0.0017154378963428801, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.76953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:28,911] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  83%|████████▎ | 83/100 [00:12<00:02,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:29,037] Trial 82 finished with value: 0.850658263305322 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.017154378963428803, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.51953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:29,040] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  86%|████████▌ | 86/100 [00:13<00:02,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:29,486] Trial 83 finished with value: 0.8573529411764707 and parameters: {'max_features': 'log2', 'n_estimators': 88, 'learning_rate': 0.005424690937011328, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.64453125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:29,492] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:29,600] Trial 84 finished with value: 0.8355462184873949 and parameters: {'max_features': None, 'n_estimators': 43, 'learning_rate': 0.05424690937011329, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.89453125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:29,603] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:29,670] Trial 85 finished with value: 0.8473109243697479 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.009646616199111998, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.83203125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:29,673] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  88%|████████▊ | 88/100 [00:13<00:02,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:30,064] Trial 86 finished with value: 0.8523669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.09646616199112, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.58203125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:30,068] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:30,247] Trial 87 finished with value: 0.8422549019607842 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.003050527890267026, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.70703125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:30,251] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  90%|█████████ | 90/100 [00:13<00:01,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:30,390] Trial 88 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.030505278902670276, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.95703125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:30,394] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:30,484] Trial 89 finished with value: 0.7650560224089636 and parameters: {'max_features': 'sqrt', 'n_estimators': 26, 'learning_rate': 0.0040679443210830495, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.92578125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:30,487] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  92%|█████████▏| 92/100 [00:14<00:01,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:30,644] Trial 90 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.04067944321083049, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.67578125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:30,648] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:30,781] Trial 91 finished with value: 0.7650700280112045 and parameters: {'max_features': 'log2', 'n_estimators': 94, 'learning_rate': 0.0012863969449369746, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.55078125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:30,785] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  93%|█████████▎| 93/100 [00:14<00:01,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:30,992] Trial 92 finished with value: 0.8372829131652659 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.01286396944936975, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.80078125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:30,997] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  94%|█████████▍| 94/100 [00:14<00:01,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:31,195] Trial 93 finished with value: 0.7365126050420168 and parameters: {'max_features': None, 'n_estimators': 37, 'learning_rate': 0.0022875732003183966, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.98828125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:31,199] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  97%|█████████▋| 97/100 [00:15<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:31,428] Trial 94 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 83, 'learning_rate': 0.02287573200318397, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.73828125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:31,431] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:31,548] Trial 95 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.007233941627366754, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.61328125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:31,551] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:31,609] Trial 96 finished with value: 0.8389075630252101 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.0723394162736675, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.86328125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:31,613] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437:  98%|█████████▊| 98/100 [00:15<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:31,669] Trial 97 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 13, 'learning_rate': 0.0018434229924091112, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.80859375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:31,672] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.862437: 100%|██████████| 100/100 [00:15<00:00,  6.41it/s]\n",
      "Best trial: 28. Best value: 0.862437: 100%|██████████| 100/100 [00:15<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:31,933] Trial 98 finished with value: 0.8339075630252101 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.018434229924091116, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.55859375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-11-06 03:33:31,937] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:33:32,116] Trial 99 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 81, 'learning_rate': 0.005829415347136074, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.68359375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using QMCSampler: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.06493816315762117, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.953125}\n",
      "Best accuracy: 0.8624, at trial: 28\n",
      "QMC Base Models Training Time: 45.28 seconds\n",
      "QMC Base Models Training Time: 45.28 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_base_models_training_start = time.time()\n",
    "\n",
    "    # QMC Hyperparameter Tuning with Cross Validation\n",
    "    qmc_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    qmc_logistic_regression.fit(X_train, y_train)\n",
    "    qmc_decision_tree.fit(X_train, y_train)\n",
    "    qmc_random_forest.fit(X_train, y_train)\n",
    "    qmc_knn.fit(X_train, y_train)\n",
    "    qmc_svc.fit(X_train, y_train)\n",
    "    qmc_adaboost.fit(X_train, y_train)\n",
    "    qmc_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    qmc_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC base models training\n",
    "    qmc_base_models_training_time = qmc_base_models_training_end - qmc_base_models_training_start\n",
    "    print(f'QMC Base Models Training Time: {qmc_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping QMC base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5 Save Every Best Model Config for each Tuning Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # Base Models Storage for all sampler types\n",
    "    base_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    print(\"Skipping base models storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Meta Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters to be tuned are:\n",
    "- Selection of the number and type of base models used\n",
    "- Number of layers in the neural network: 1 - 5\n",
    "- Number of neurons per layer: 10 - 100\n",
    "- Learning rate behavior: Constant or Adaptive\n",
    "- Learning rate value: 0.0001 - 0.01\n",
    "- L2 Regularization value: 0.0001 - 0.01\n",
    "\n",
    "Unchanged Preset hyperparameters:\n",
    "- Activation function: ReLU\n",
    "- Optimizer (Solver): Adam\n",
    "- Epochs (Max Iter): 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:45,373] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (TPESampler)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]1%|          | 1/100 [00:00<01:24,  1.18it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 0. Best value: 0.893333:   1%|          | 1/100 [00:00<01:24,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:46,221] Trial 0 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.8933333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:   2%|▏         | 2/100 [00:02<01:50,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:47,548] Trial 1 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:   3%|▎         | 3/100 [00:02<01:32,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:48,292] Trial 2 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.913333:   4%|▍         | 4/100 [00:03<01:31,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:49,237] Trial 3 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:   5%|▌         | 5/100 [00:04<01:25,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:50,049] Trial 4 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:   6%|▌         | 6/100 [00:06<01:45,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:51,598] Trial 5 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:   7%|▋         | 7/100 [00:07<01:43,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:52,710] Trial 6 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:   8%|▊         | 8/100 [00:07<01:20,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:53,051] Trial 7 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-11-06 03:33:53,055] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  10%|█         | 10/100 [00:08<01:03,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:54,093] Trial 9 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  11%|█         | 11/100 [00:10<01:16,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:55,418] Trial 10 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 97, 'n_neurons_1': 57, 'n_neurons_2': 12, 'n_neurons_3': 80, 'n_neurons_4': 51, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003208447516296125, 'alpha': 0.007589158830942278}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  12%|█▏        | 12/100 [00:11<01:22,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:56,581] Trial 11 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 41, 'n_neurons_1': 53, 'n_neurons_2': 61, 'n_neurons_3': 13, 'n_neurons_4': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00892580765546968, 'alpha': 0.00010551338661221168}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  13%|█▎        | 13/100 [00:12<01:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:57,580] Trial 12 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 38, 'n_neurons_1': 63, 'n_neurons_2': 54, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006014159993267655, 'alpha': 0.0005887056496896425}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  14%|█▍        | 14/100 [00:13<01:21,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:58,491] Trial 13 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 74, 'n_neurons_1': 35, 'n_neurons_2': 95, 'n_neurons_3': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.00320620354288407, 'alpha': 0.00013097299418390814}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  15%|█▌        | 15/100 [00:13<01:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:58,759] Trial 14 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 95, 'n_neurons_1': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003315160212342877, 'alpha': 0.0012168175617744631}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  16%|█▌        | 16/100 [00:14<01:06,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:33:59,668] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.0033223368433343654, 'alpha': 0.0029823866652916474}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  17%|█▋        | 17/100 [00:15<01:10,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:00,664] Trial 16 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 82, 'n_neurons_1': 39, 'n_neurons_2': 39, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003018707978070198, 'alpha': 0.0002454976370143814}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-11-06 03:34:00,671] Trial 17 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  19%|█▉        | 19/100 [00:16<00:51,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:01,392] Trial 18 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 64, 'n_neurons_1': 13, 'n_neurons_2': 12, 'n_neurons_3': 53, 'n_neurons_4': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.002864606135208948, 'alpha': 0.0015290978918466775}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  20%|██        | 20/100 [00:17<01:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:02,679] Trial 19 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 30, 'n_neurons_1': 27, 'n_neurons_2': 66, 'n_neurons_3': 97, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010433696140601224, 'alpha': 0.0006396960337634612}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  21%|██        | 21/100 [00:18<01:05,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:03,603] Trial 20 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 50, 'n_neurons_1': 75, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005296194612580273, 'alpha': 0.00024394910764863182}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  22%|██▏       | 22/100 [00:19<01:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:04,377] Trial 21 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 14, 'n_neurons_1': 99, 'learning_rate': 'constant', 'learning_rate_init': 0.0001663812934756619, 'alpha': 0.0005352734344501655}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.913333:  23%|██▎       | 23/100 [00:19<00:58,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:05,016] Trial 22 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.00018623425762056534, 'alpha': 0.0003228057126209593}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.913333:  24%|██▍       | 24/100 [00:20<01:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:05,901] Trial 23 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.00011031180732171066, 'alpha': 0.0008179557364087852}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.913333:  25%|██▌       | 25/100 [00:21<00:55,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:06,520] Trial 24 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.000484924317931866, 'alpha': 0.00015738880416764237}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  26%|██▌       | 26/100 [00:21<00:44,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:06,787] Trial 25 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 47, 'n_neurons_1': 49, 'n_neurons_2': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.00016709866638149333, 'alpha': 0.0002071439048860868}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  28%|██▊       | 28/100 [00:22<00:35,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:07,450] Trial 26 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 32, 'n_neurons_1': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.00023831981033568882, 'alpha': 0.00040424714072528315}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-11-06 03:34:07,637] Trial 27 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.00048369780845884897, 'alpha': 0.009981522498542091}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  29%|██▉       | 29/100 [00:23<00:46,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:08,650] Trial 28 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 87, 'n_neurons_1': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0019318457372413356, 'alpha': 0.0007997305061372874}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  31%|███       | 31/100 [00:24<00:37,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:09,502] Trial 29 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 75, 'n_neurons_1': 83, 'n_neurons_2': 75, 'learning_rate': 'constant', 'learning_rate_init': 0.00012196284069809992, 'alpha': 0.0015058443176973145}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-11-06 03:34:09,673] Trial 30 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 51, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00043215732695647255, 'alpha': 0.003660271220481242}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  32%|███▏      | 32/100 [00:25<00:45,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:10,628] Trial 31 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 91, 'n_neurons_1': 96, 'n_neurons_2': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009909270338294563, 'alpha': 0.004779482375568828}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  33%|███▎      | 33/100 [00:26<00:49,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:11,515] Trial 32 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 78, 'n_neurons_1': 84, 'n_neurons_2': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007916142458258908, 'alpha': 0.0003966825592349007}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:  34%|███▍      | 34/100 [00:27<00:59,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:12,811] Trial 33 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 64, 'n_neurons_1': 93, 'n_neurons_2': 48, 'n_neurons_3': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006345180356624574, 'alpha': 0.004381062590838585}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  35%|███▌      | 35/100 [00:28<00:56,  1.15it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:13,600] Trial 34 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 87, 'n_neurons_1': 89, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009673822566822346, 'alpha': 0.006975298150281811}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  36%|███▌      | 36/100 [00:28<00:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:14,244] Trial 35 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 11, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009932528403801714, 'alpha': 0.0065492673581785225}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  37%|███▋      | 37/100 [00:29<00:50,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:15,032] Trial 36 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 79, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006589674416219878, 'alpha': 0.009568062274076004}. Best is trial 34 with value: 0.92.\n",
      "[I 2025-11-06 03:34:15,037] Trial 37 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  39%|███▉      | 39/100 [00:30<00:37,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:15,863] Trial 38 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 89, 'n_neurons_1': 64, 'learning_rate': 'constant', 'learning_rate_init': 0.004337205751765981, 'alpha': 0.005553677700940058}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  40%|████      | 40/100 [00:31<00:35,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:16,391] Trial 39 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 57, 'learning_rate': 'constant', 'learning_rate_init': 0.002296770663563441, 'alpha': 0.00033097809507205776}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  41%|████      | 41/100 [00:31<00:36,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:17,064] Trial 40 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 27, 'n_neurons_1': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007529961636668803, 'alpha': 0.0004722401115646432}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  42%|████▏     | 42/100 [00:32<00:41,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:18,060] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 84, 'n_neurons_1': 90, 'n_neurons_2': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013146096325693194, 'alpha': 0.007948016896128481}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  43%|████▎     | 43/100 [00:33<00:46,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:19,117] Trial 42 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 68, 'n_neurons_1': 89, 'n_neurons_2': 35, 'n_neurons_3': 36, 'n_neurons_4': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00026230005608814913, 'alpha': 0.0031317472957561876}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  44%|████▍     | 44/100 [00:34<00:48,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:20,123] Trial 43 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 80, 'n_neurons_1': 100, 'n_neurons_2': 18, 'n_neurons_3': 79, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0044870695325926364, 'alpha': 0.0023612063597962143}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  45%|████▌     | 45/100 [00:35<00:50,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:21,137] Trial 44 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 73, 'n_neurons_1': 88, 'n_neurons_2': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013989976029613608, 'alpha': 0.005765080296796242}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  46%|████▌     | 46/100 [00:36<00:52,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:22,267] Trial 45 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 92, 'n_neurons_1': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00022701578690288932, 'alpha': 0.007565088492394309}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  47%|████▋     | 47/100 [00:37<00:51,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:23,236] Trial 46 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 39, 'n_neurons_2': 54, 'n_neurons_3': 48, 'n_neurons_4': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.0011654509593241012, 'alpha': 0.004034476108008478}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.92:  48%|████▊     | 48/100 [00:38<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:24,149] Trial 47 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 95, 'n_neurons_1': 42, 'n_neurons_2': 73, 'n_neurons_3': 48, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.008223595532794357, 'alpha': 0.0007420219810523565}. Best is trial 34 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  49%|████▉     | 49/100 [00:39<00:45,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:24,924] Trial 48 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 27, 'n_neurons_2': 54, 'n_neurons_3': 19, 'n_neurons_4': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.001309154548856503, 'alpha': 0.0035828763425142765}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  50%|█████     | 50/100 [00:40<00:42,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:25,685] Trial 49 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 30, 'n_neurons_2': 57, 'n_neurons_3': 11, 'n_neurons_4': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.0012331609263303506, 'alpha': 0.0038503158613785796}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  51%|█████     | 51/100 [00:41<00:47,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:26,920] Trial 50 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 22, 'n_neurons_2': 50, 'n_neurons_3': 24, 'n_neurons_4': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0019045528689328756, 'alpha': 0.0019196949309771528}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  52%|█████▏    | 52/100 [00:42<00:45,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:27,778] Trial 51 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 32, 'n_neurons_2': 73, 'n_neurons_3': 69, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.0008888922253442748, 'alpha': 0.005507458985176902}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  53%|█████▎    | 53/100 [00:43<00:49,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:29,082] Trial 52 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 100, 'n_neurons_1': 56, 'n_neurons_2': 85, 'n_neurons_3': 31, 'n_neurons_4': 77, 'learning_rate': 'constant', 'learning_rate_init': 0.0006830337207026296, 'alpha': 0.002628341351008899}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  54%|█████▍    | 54/100 [00:44<00:45,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:29,912] Trial 53 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 69, 'n_neurons_1': 20, 'n_neurons_2': 65, 'n_neurons_3': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.002635449240764298, 'alpha': 0.0034346088839236123}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  55%|█████▌    | 55/100 [00:45<00:44,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:30,896] Trial 54 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 22, 'n_neurons_2': 65, 'n_neurons_3': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.0025103641490036377, 'alpha': 0.0032763281781949347}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  56%|█████▌    | 56/100 [00:46<00:40,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:31,647] Trial 55 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 81, 'n_neurons_1': 15, 'n_neurons_2': 58, 'n_neurons_3': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.0037587604828844415, 'alpha': 0.004704959179189596}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  57%|█████▋    | 57/100 [00:47<00:40,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:32,661] Trial 56 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 71, 'n_neurons_1': 10, 'n_neurons_2': 44, 'n_neurons_3': 23, 'n_neurons_4': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.001738519846432184, 'alpha': 0.0019123153815179537}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 48. Best value: 0.926667:  58%|█████▊    | 58/100 [00:48<00:45,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:34,043] Trial 57 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 61, 'n_neurons_1': 21, 'n_neurons_2': 79, 'n_neurons_3': 61, 'n_neurons_4': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0014790376600689837, 'alpha': 0.006733216607779298}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  59%|█████▉    | 59/100 [00:49<00:41,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:34,939] Trial 58 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 65, 'n_neurons_1': 22, 'n_neurons_2': 78, 'n_neurons_3': 63, 'n_neurons_4': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0014985832946412024, 'alpha': 0.006842833604554675}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  60%|██████    | 60/100 [00:51<00:48,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:36,633] Trial 59 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 62, 'n_neurons_1': 38, 'n_neurons_2': 84, 'n_neurons_3': 79, 'n_neurons_4': 45, 'learning_rate': 'constant', 'learning_rate_init': 0.00110058143232529, 'alpha': 0.0036523301750849622}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  61%|██████    | 61/100 [00:52<00:45,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:37,643] Trial 60 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 60, 'n_neurons_1': 33, 'n_neurons_2': 92, 'n_neurons_3': 61, 'learning_rate': 'constant', 'learning_rate_init': 0.0013538171719334733, 'alpha': 0.00852553311334376}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  62%|██████▏   | 62/100 [00:53<00:39,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:38,429] Trial 61 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 94, 'n_neurons_1': 19, 'n_neurons_2': 67, 'n_neurons_3': 48, 'n_neurons_4': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.0023293602944271558, 'alpha': 0.005006730740085471}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  63%|██████▎   | 63/100 [00:53<00:37,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:39,359] Trial 62 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 54, 'n_neurons_1': 27, 'n_neurons_2': 81, 'n_neurons_3': 74, 'n_neurons_4': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0029029864773756292, 'alpha': 0.0010165331107409047}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  64%|██████▍   | 64/100 [00:54<00:34,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:40,189] Trial 63 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 87, 'n_neurons_1': 42, 'n_neurons_2': 52, 'n_neurons_3': 54, 'learning_rate': 'constant', 'learning_rate_init': 0.005354054962872982, 'alpha': 0.006077863904162559}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  65%|██████▌   | 65/100 [00:55<00:33,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:41,123] Trial 64 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 41, 'n_neurons_1': 50, 'n_neurons_2': 100, 'n_neurons_3': 24, 'n_neurons_4': 59, 'learning_rate': 'constant', 'learning_rate_init': 0.003484773940509281, 'alpha': 0.0038539609679911}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  66%|██████▌   | 66/100 [00:56<00:32,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:42,138] Trial 65 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 77, 'n_neurons_1': 18, 'n_neurons_2': 69, 'n_neurons_3': 41, 'n_neurons_4': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0015472211648853856, 'alpha': 0.002673399932106842}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 48. Best value: 0.926667:  67%|██████▋   | 67/100 [00:58<00:37,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:43,649] Trial 66 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 79, 'n_neurons_1': 28, 'n_neurons_2': 60, 'n_neurons_3': 34, 'learning_rate': 'constant', 'learning_rate_init': 0.0011112985418838246, 'alpha': 0.007209998008569902}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  68%|██████▊   | 68/100 [00:59<00:36,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:44,791] Trial 67 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 71, 'n_neurons_1': 35, 'n_neurons_2': 90, 'n_neurons_3': 59, 'n_neurons_4': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0008167299345988546, 'alpha': 0.008489209693183047}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  69%|██████▉   | 69/100 [01:00<00:37,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:46,207] Trial 68 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 89, 'n_neurons_1': 25, 'n_neurons_2': 63, 'n_neurons_3': 87, 'n_neurons_4': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.0020517575229661287, 'alpha': 0.0012878728241735062}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  70%|███████   | 70/100 [01:02<00:40,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:47,856] Trial 69 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 91, 'n_neurons_1': 25, 'n_neurons_2': 64, 'n_neurons_3': 94, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.0005954014713954824, 'alpha': 0.0012605791745745733}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  71%|███████   | 71/100 [01:04<00:40,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:49,396] Trial 70 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 91, 'n_neurons_1': 24, 'n_neurons_2': 64, 'n_neurons_3': 93, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.0005614023396212621, 'alpha': 0.0014240502794364998}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  72%|███████▏  | 72/100 [01:05<00:39,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:50,851] Trial 71 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 24, 'n_neurons_2': 61, 'n_neurons_3': 92, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.0005543268632811366, 'alpha': 0.0012868795829601406}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  73%|███████▎  | 73/100 [01:07<00:40,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:52,475] Trial 72 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 90, 'n_neurons_1': 15, 'n_neurons_2': 64, 'n_neurons_3': 89, 'n_neurons_4': 22, 'learning_rate': 'constant', 'learning_rate_init': 0.00041709150743938513, 'alpha': 0.001502365881978286}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  74%|███████▍  | 74/100 [01:08<00:36,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:53,700] Trial 73 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 93, 'n_neurons_1': 24, 'n_neurons_2': 55, 'n_neurons_3': 86, 'n_neurons_4': 34, 'learning_rate': 'constant', 'learning_rate_init': 0.0009298533690228349, 'alpha': 0.001057803393559123}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 48. Best value: 0.926667:  75%|███████▌  | 75/100 [01:10<00:40,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:55,872] Trial 74 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 89, 'n_neurons_1': 19, 'n_neurons_2': 69, 'n_neurons_3': 98, 'n_neurons_4': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0005823487001377769, 'alpha': 0.0012061055006652444}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  76%|███████▌  | 76/100 [01:11<00:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:57,211] Trial 75 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 97, 'n_neurons_1': 11, 'n_neurons_2': 46, 'n_neurons_3': 85, 'n_neurons_4': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0003839685051642684, 'alpha': 0.0016157482345397257}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  77%|███████▋  | 77/100 [01:13<00:33,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:58,421] Trial 76 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 30, 'n_neurons_2': 54, 'n_neurons_3': 95, 'n_neurons_4': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.002028763053045197, 'alpha': 0.001866511305401431}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  78%|███████▊  | 78/100 [01:14<00:30,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:34:59,655] Trial 77 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 96, 'n_neurons_1': 23, 'n_neurons_2': 64, 'n_neurons_3': 100, 'learning_rate': 'constant', 'learning_rate_init': 0.0011519451609888337, 'alpha': 0.0022224132607716056}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  79%|███████▉  | 79/100 [01:15<00:29,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:01,063] Trial 78 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 92, 'n_neurons_1': 15, 'n_neurons_2': 71, 'n_neurons_3': 84, 'n_neurons_4': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0007429117326979484, 'alpha': 0.0009115238402021778}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  80%|████████  | 80/100 [01:16<00:27,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:02,355] Trial 79 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 84, 'n_neurons_1': 26, 'n_neurons_2': 61, 'n_neurons_3': 17, 'n_neurons_4': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.001422966596524268, 'alpha': 0.00065745943871332}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  81%|████████  | 81/100 [01:18<00:24,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:03,451] Trial 80 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 81, 'n_neurons_1': 20, 'n_neurons_2': 79, 'n_neurons_3': 93, 'learning_rate': 'constant', 'learning_rate_init': 0.0017515831475788145, 'alpha': 0.0026179557142997447}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  82%|████████▏ | 82/100 [01:19<00:23,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:04,851] Trial 81 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 25, 'n_neurons_2': 61, 'n_neurons_3': 92, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.0005440535338187535, 'alpha': 0.0012566670346775635}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 48. Best value: 0.926667:  83%|████████▎ | 83/100 [01:21<00:24,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:06,672] Trial 82 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 31, 'n_neurons_2': 58, 'n_neurons_3': 90, 'n_neurons_4': 21, 'learning_rate': 'constant', 'learning_rate_init': 0.0005206210774613656, 'alpha': 0.0012711756618388507}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  84%|████████▍ | 84/100 [01:22<00:23,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:08,104] Trial 83 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 98, 'n_neurons_1': 35, 'n_neurons_2': 50, 'n_neurons_3': 95, 'n_neurons_4': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.0003533790071043151, 'alpha': 0.004258341290015358}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  85%|████████▌ | 85/100 [01:23<00:20,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:09,328] Trial 84 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 91, 'n_neurons_1': 16, 'n_neurons_2': 62, 'n_neurons_3': 49, 'n_neurons_4': 48, 'learning_rate': 'constant', 'learning_rate_init': 0.0006331868942186587, 'alpha': 0.0016743600764750472}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  86%|████████▌ | 86/100 [01:25<00:21,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:11,126] Trial 85 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 41, 'n_neurons_2': 40, 'n_neurons_3': 81, 'n_neurons_4': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0009866607900127227, 'alpha': 0.0013868351464163316}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  87%|████████▋ | 87/100 [01:26<00:18,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:12,371] Trial 86 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 78, 'n_neurons_1': 61, 'n_neurons_2': 56, 'n_neurons_3': 76, 'n_neurons_4': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.00047603999807970806, 'alpha': 0.0011144330641395693}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  88%|████████▊ | 88/100 [01:28<00:15,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:13,425] Trial 87 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 89, 'n_neurons_1': 21, 'n_neurons_2': 67, 'n_neurons_3': 88, 'n_neurons_4': 36, 'learning_rate': 'constant', 'learning_rate_init': 0.002071721120744836, 'alpha': 0.0030264327545598273}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  89%|████████▉ | 89/100 [01:29<00:14,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:14,787] Trial 88 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 95, 'n_neurons_1': 29, 'n_neurons_2': 51, 'n_neurons_3': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.0011951264905624866, 'alpha': 0.0008922869259110254}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  90%|█████████ | 90/100 [01:30<00:12,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:15,956] Trial 89 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 82, 'n_neurons_1': 13, 'n_neurons_2': 72, 'n_neurons_3': 69, 'n_neurons_4': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.0008289743753212096, 'alpha': 0.006244017814293066}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  91%|█████████ | 91/100 [01:31<00:11,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:17,043] Trial 90 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 72, 'n_neurons_1': 25, 'n_neurons_2': 77, 'n_neurons_3': 45, 'n_neurons_4': 23, 'learning_rate': 'constant', 'learning_rate_init': 0.0006993455892242821, 'alpha': 0.0014034230529410595}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  92%|█████████▏| 92/100 [01:32<00:09,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:18,311] Trial 91 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 90, 'n_neurons_1': 17, 'n_neurons_2': 64, 'n_neurons_3': 89, 'n_neurons_4': 21, 'learning_rate': 'constant', 'learning_rate_init': 0.00042416407391679693, 'alpha': 0.0017145697376241948}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  93%|█████████▎| 93/100 [01:34<00:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:19,373] Trial 92 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 87, 'n_neurons_1': 13, 'n_neurons_2': 58, 'n_neurons_3': 30, 'n_neurons_4': 29, 'learning_rate': 'constant', 'learning_rate_init': 0.0002839305806808841, 'alpha': 0.001379472376646836}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  94%|█████████▍| 94/100 [01:35<00:07,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:20,775] Trial 93 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 93, 'n_neurons_1': 71, 'n_neurons_2': 66, 'n_neurons_3': 83, 'n_neurons_4': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0004152762830761419, 'alpha': 0.000903424041005334}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  95%|█████████▌| 95/100 [01:36<00:06,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:21,937] Trial 94 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 90, 'n_neurons_1': 24, 'n_neurons_2': 62, 'n_neurons_3': 100, 'n_neurons_4': 18, 'learning_rate': 'constant', 'learning_rate_init': 0.0016177634395885027, 'alpha': 0.0011416668909980123}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  96%|█████████▌| 96/100 [01:38<00:05,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:23,687] Trial 95 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 33, 'n_neurons_2': 69, 'n_neurons_3': 95, 'n_neurons_4': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.000605779892312205, 'alpha': 0.005283279149635479}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  97%|█████████▋| 97/100 [01:39<00:04,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:24,977] Trial 96 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 91, 'n_neurons_1': 21, 'n_neurons_2': 75, 'n_neurons_3': 57, 'n_neurons_4': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0025909910236028115, 'alpha': 0.0033846435556330622}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  98%|█████████▊| 98/100 [01:40<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:25,524] Trial 97 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 75, 'n_neurons_1': 28, 'n_neurons_2': 59, 'n_neurons_3': 88, 'n_neurons_4': 52, 'learning_rate': 'constant', 'learning_rate_init': 0.00048768958666471835, 'alpha': 0.004350873110909635}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667:  99%|█████████▉| 99/100 [01:41<00:01,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:26,466] Trial 98 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 56, 'n_neurons_1': 17, 'n_neurons_2': 53, 'n_neurons_3': 51, 'n_neurons_4': 96, 'learning_rate': 'constant', 'learning_rate_init': 0.0008729573266831821, 'alpha': 0.002203966060603315}. Best is trial 48 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 0.926667: 100%|██████████| 100/100 [01:41<00:00,  1.02s/it]\n",
      "Best trial: 48. Best value: 0.926667: 100%|██████████| 100/100 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:27,187] Trial 99 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 50, 'n_neurons_1': 14, 'n_neurons_2': 63, 'n_neurons_3': 65, 'learning_rate': 'constant', 'learning_rate_init': 0.0003508288171595581, 'alpha': 0.0028045095817954718}. Best is trial 48 with value: 0.9266666666666666.\n",
      "\n",
      "Selected Base Models for Stacking using TPESampler:\n",
      "- Logistic Regression\n",
      "- Random Forest\n",
      "- K-Nearest Neighbors\n",
      "- Support Vector Machine\n",
      "Best Hyperparameters for Meta Model (MLP) using TPESampler: {'learning_rate': 'constant', 'learning_rate_init': 0.001309154548856503, 'alpha': 0.0035828763425142765, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (86, 27, 54, 19, 38), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9267, at trial: 48\n",
      "TPE base models training time: 47.76 seconds\n",
      "TPE SEl-NNML Training Time: 102.66 seconds\n",
      "Total TPE Training Time (Base + Meta): 150.42 seconds\n",
      "TPE base models training time: 47.76 seconds\n",
      "TPE SEl-NNML Training Time: 102.66 seconds\n",
      "Total TPE Training Time (Base + Meta): 150.42 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    tpe_sel_nnml, tpe_meta_study = meta_model_tuning(base_models['TPE'], X_train, y_train, X_test, y_test, sampler='TPESampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    tpe_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE SEl-NNML training\n",
    "    tpe_meta_model_training_time = tpe_meta_model_training_end - tpe_meta_model_training_start\n",
    "    print(f'TPE base models training time: {tpe_base_models_training_time:.2f} seconds')\n",
    "    print(f'TPE SEl-NNML Training Time: {tpe_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total TPE Training Time (Base + Meta): {tpe_base_models_training_time + tpe_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    tpe_meta_history = tpe_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    tpe_meta_history.columns = ['iteration', 'score']\n",
    "    tpe_meta_history['iteration'] = tpe_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping TPE meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:178: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:35:35,373] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (GPSampler)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]1%|          | 1/100 [00:01<01:45,  1.06s/it]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 0. Best value: 0.906667:   1%|          | 1/100 [00:01<01:45,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:36,437] Trial 0 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9066666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.913333:   2%|▏         | 2/100 [00:02<01:50,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:37,617] Trial 1 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 1 with value: 0.9133333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:   3%|▎         | 3/100 [00:02<01:20,  1.20it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:38,091] Trial 2 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:   4%|▍         | 4/100 [00:03<01:09,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:38,641] Trial 3 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:   5%|▌         | 5/100 [00:03<01:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:39,173] Trial 4 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:   6%|▌         | 6/100 [00:04<01:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:40,284] Trial 5 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:   7%|▋         | 7/100 [00:05<01:14,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:41,080] Trial 6 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:   8%|▊         | 8/100 [00:06<01:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:41,499] Trial 7 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-11-06 03:35:41,501] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  10%|█         | 10/100 [00:06<00:47,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:42,200] Trial 9 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:42,274] The parameter `n_layers` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,275] The parameter `n_neurons_0` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,276] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,278] The parameter `learning_rate_init` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,279] The parameter `alpha` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  11%|█         | 11/100 [00:07<00:47,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:42,774] Trial 10 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020133650202440474, 'alpha': 0.0002808915139812627}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:42,825] The parameter `n_layers` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,827] The parameter `n_neurons_0` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,827] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,828] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,829] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,830] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,832] The parameter `learning_rate_init` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:42,833] The parameter `alpha` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  12%|█▏        | 12/100 [00:08<01:04,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:44,049] Trial 11 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 39, 'n_neurons_2': 77, 'n_neurons_3': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.0013696739838480055, 'alpha': 0.00015393931002140855}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:44,092] The parameter `n_layers` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,094] The parameter `n_neurons_0` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,095] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,096] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,097] The parameter `learning_rate_init` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,098] The parameter `alpha` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  13%|█▎        | 13/100 [00:09<01:05,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:44,856] Trial 12 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 34, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.0060826539606401225, 'alpha': 0.0018292676411745708}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:44,905] The parameter `n_layers` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,907] The parameter `n_neurons_0` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,908] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,909] The parameter `n_neurons_2` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,910] The parameter `n_neurons_3` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,911] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,913] The parameter `learning_rate_init` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:44,914] The parameter `alpha` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  14%|█▍        | 14/100 [00:10<01:14,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:45,996] Trial 13 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 55, 'n_neurons_1': 62, 'n_neurons_2': 54, 'n_neurons_3': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0001118489555166451, 'alpha': 0.001954090133022007}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:46,040] The parameter `n_layers` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,042] The parameter `n_neurons_0` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,043] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,044] The parameter `learning_rate_init` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,045] The parameter `alpha` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  15%|█▌        | 15/100 [00:11<01:12,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:46,817] Trial 14 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.000549942648034561, 'alpha': 0.00010737748632897979}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:46,861] The parameter `n_layers` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,862] The parameter `n_neurons_0` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,863] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,864] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,865] The parameter `n_neurons_3` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,866] The parameter `n_neurons_4` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,867] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,868] The parameter `learning_rate_init` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:46,869] The parameter `alpha` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  16%|█▌        | 16/100 [00:12<01:20,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:48,047] Trial 15 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 48, 'n_neurons_1': 97, 'n_neurons_2': 97, 'n_neurons_3': 87, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004303720019143252, 'alpha': 0.00021826570038901196}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:48,090] The parameter `n_layers` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,091] The parameter `n_neurons_0` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,093] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,094] The parameter `n_neurons_2` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,095] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,096] The parameter `learning_rate_init` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,097] The parameter `alpha` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  17%|█▋        | 17/100 [00:13<01:09,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:48,599] Trial 16 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 95, 'n_neurons_1': 73, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009552294429449873, 'alpha': 0.00019061980918553997}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:48,643] The parameter `n_layers` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,645] The parameter `n_neurons_0` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,646] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,647] The parameter `n_neurons_2` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,648] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,649] The parameter `learning_rate_init` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:48,650] The parameter `alpha` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  18%|█▊        | 18/100 [00:14<01:11,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:49,531] Trial 17 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 77, 'n_neurons_2': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.0003865304288032154, 'alpha': 0.004156447611486069}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:49,574] The parameter `n_layers` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,576] The parameter `n_neurons_0` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,577] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,578] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,579] The parameter `n_neurons_3` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,580] The parameter `n_neurons_4` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,581] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,581] The parameter `learning_rate_init` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:49,582] The parameter `alpha` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  19%|█▉        | 19/100 [00:15<01:08,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:50,327] Trial 18 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 93, 'n_neurons_2': 56, 'n_neurons_3': 55, 'n_neurons_4': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0039046790191830895, 'alpha': 0.0060257440920984265}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:50,372] The parameter `n_layers` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:50,373] The parameter `n_neurons_0` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:50,374] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:50,375] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:50,376] The parameter `learning_rate_init` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:50,377] The parameter `alpha` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  20%|██        | 20/100 [00:15<01:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:50,982] Trial 19 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 18, 'learning_rate': 'constant', 'learning_rate_init': 0.0008534852819566894, 'alpha': 0.0012169963323841}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:51,021] The parameter `n_layers` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,023] The parameter `n_neurons_0` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,025] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,025] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,026] The parameter `learning_rate_init` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,027] The parameter `alpha` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  21%|██        | 21/100 [00:16<00:59,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:51,663] Trial 20 finished with value: 0.5266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 63, 'n_neurons_1': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005252684100000482, 'alpha': 0.00017952338368491265}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:51,710] The parameter `n_layers` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,712] The parameter `n_neurons_0` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,713] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,714] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,714] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,715] The parameter `learning_rate_init` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:51,716] The parameter `alpha` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  22%|██▏       | 22/100 [00:17<00:58,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:52,377] Trial 21 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 80, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0011553385460530909, 'alpha': 0.0012057860169848358}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:52,423] The parameter `n_layers` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:52,425] The parameter `n_neurons_0` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:52,426] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:52,427] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:52,428] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:52,429] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:52,430] The parameter `learning_rate_init` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:52,430] The parameter `alpha` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  23%|██▎       | 23/100 [00:18<01:20,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:54,127] Trial 22 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 76, 'n_neurons_1': 98, 'n_neurons_2': 56, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0007549928546183039, 'alpha': 0.00014352011136230925}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:54,175] The parameter `n_layers` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,177] The parameter `n_neurons_0` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,178] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,179] The parameter `learning_rate_init` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,181] The parameter `alpha` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  24%|██▍       | 24/100 [00:19<01:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:54,939] Trial 23 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.000657515339012736, 'alpha': 0.000222120498838994}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:54,986] The parameter `n_layers` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,987] The parameter `n_neurons_0` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,988] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,989] The parameter `learning_rate_init` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:54,990] The parameter `alpha` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  25%|██▌       | 25/100 [00:20<01:08,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:55,697] Trial 24 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020911960669713066, 'alpha': 0.00036296754488993613}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:55,749] The parameter `n_layers` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,751] The parameter `n_neurons_0` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,753] The parameter `n_neurons_1` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,754] The parameter `n_neurons_2` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,755] The parameter `n_neurons_3` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,756] The parameter `n_neurons_4` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,757] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,758] The parameter `learning_rate_init` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:55,759] The parameter `alpha` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  26%|██▌       | 26/100 [00:21<01:16,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:57,012] Trial 25 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 77, 'n_neurons_1': 60, 'n_neurons_2': 65, 'n_neurons_3': 48, 'n_neurons_4': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010685306331940677, 'alpha': 0.00017066532063900338}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:57,079] The parameter `n_layers` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,081] The parameter `n_neurons_0` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,082] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,084] The parameter `learning_rate_init` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,085] The parameter `alpha` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  27%|██▋       | 27/100 [00:22<01:05,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:57,585] Trial 26 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 13, 'learning_rate': 'constant', 'learning_rate_init': 0.0008878664758716851, 'alpha': 0.00015691639471778163}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:57,653] The parameter `n_layers` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,655] The parameter `n_neurons_0` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,656] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,657] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,658] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,659] The parameter `learning_rate_init` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:57,660] The parameter `alpha` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  28%|██▊       | 28/100 [00:23<01:03,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:58,446] Trial 27 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 53, 'n_neurons_1': 25, 'n_neurons_2': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001862890387420621, 'alpha': 0.00012319923739394199}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:58,491] The parameter `n_layers` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:58,492] The parameter `n_neurons_0` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:58,493] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:58,494] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:58,495] The parameter `learning_rate_init` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:58,495] The parameter `alpha` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  29%|██▉       | 29/100 [00:23<00:54,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:35:58,952] Trial 28 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.0002117721540886054, 'alpha': 0.00013840044764106221}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:35:59,002] The parameter `n_layers` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:59,004] The parameter `n_neurons_0` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:59,005] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:59,006] The parameter `n_neurons_2` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:59,007] The parameter `n_neurons_3` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:59,008] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:59,008] The parameter `learning_rate_init` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:35:59,009] The parameter `alpha` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  30%|███       | 30/100 [00:24<01:04,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:00,218] Trial 29 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 12, 'n_neurons_1': 63, 'n_neurons_2': 95, 'n_neurons_3': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008250984684608617, 'alpha': 0.0012337682181468137}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:00,283] The parameter `n_layers` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,285] The parameter `n_neurons_0` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,286] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,287] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,288] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,289] The parameter `n_neurons_4` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,290] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,291] The parameter `learning_rate_init` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:00,292] The parameter `alpha` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  31%|███       | 31/100 [00:25<01:02,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:01,110] Trial 30 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 97, 'n_neurons_2': 92, 'n_neurons_3': 27, 'n_neurons_4': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.00015448485924752335, 'alpha': 0.0023228092500006277}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:01,179] The parameter `n_layers` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,181] The parameter `n_neurons_0` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,181] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,182] The parameter `learning_rate_init` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,183] The parameter `alpha` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  32%|███▏      | 32/100 [00:26<00:59,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:01,902] Trial 31 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004255366449682059, 'alpha': 0.00036619258793526205}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:01,955] The parameter `n_layers` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,956] The parameter `n_neurons_0` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,957] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,958] The parameter `learning_rate_init` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:01,959] The parameter `alpha` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  33%|███▎      | 33/100 [00:27<00:55,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:02,605] Trial 32 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002952174928235019, 'alpha': 0.004045403638787863}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:02,649] The parameter `n_layers` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,651] The parameter `n_neurons_0` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,652] The parameter `n_neurons_1` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,653] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,654] The parameter `learning_rate_init` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,655] The parameter `alpha` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  34%|███▍      | 34/100 [00:27<00:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:02,808] Trial 33 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006687062061347505, 'alpha': 0.0005546719086332962}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:02,855] The parameter `n_layers` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,857] The parameter `n_neurons_0` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,858] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,859] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,860] The parameter `n_neurons_3` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,861] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,863] The parameter `learning_rate_init` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:02,864] The parameter `alpha` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  35%|███▌      | 35/100 [00:28<00:53,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:04,082] Trial 34 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 94, 'n_neurons_2': 88, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001607858173371064, 'alpha': 0.006384190143734895}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:04,150] The parameter `n_layers` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,153] The parameter `n_neurons_0` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,155] The parameter `n_neurons_1` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,156] The parameter `n_neurons_2` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,158] The parameter `learning_rate` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,159] The parameter `learning_rate_init` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,161] The parameter `alpha` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  36%|███▌      | 36/100 [00:29<00:48,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:04,672] Trial 35 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 39, 'n_neurons_2': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.006467909772210833, 'alpha': 0.00015225562752457967}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:04,725] The parameter `n_layers` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,727] The parameter `n_neurons_0` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,728] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,729] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,730] The parameter `learning_rate_init` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:04,731] The parameter `alpha` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  38%|███▊      | 38/100 [00:30<00:48,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:05,513] Trial 36 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 96, 'n_neurons_1': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007886622327732802, 'alpha': 0.00038585269984779924}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-11-06 03:36:05,561] Trial 37 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:05,628] The parameter `n_layers` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:05,629] The parameter `n_neurons_0` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:05,631] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:05,632] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:05,633] The parameter `learning_rate_init` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:05,634] The parameter `alpha` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  39%|███▉      | 39/100 [00:30<00:34,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:06,147] Trial 38 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 78, 'learning_rate': 'constant', 'learning_rate_init': 0.00015219914267510963, 'alpha': 0.0009746318720288899}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:06,194] The parameter `n_layers` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,195] The parameter `n_neurons_0` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,196] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,197] The parameter `learning_rate_init` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,198] The parameter `alpha` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  40%|████      | 40/100 [00:31<00:34,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:06,726] Trial 39 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005033035864411288, 'alpha': 0.00017144863541673278}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:06,780] The parameter `n_layers` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,781] The parameter `n_neurons_0` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,782] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,783] The parameter `learning_rate_init` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:06,784] The parameter `alpha` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  42%|████▏     | 42/100 [00:32<00:32,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:07,256] Trial 40 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.00014730368526805275, 'alpha': 0.002523122072859775}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-11-06 03:36:07,304] Trial 41 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:07,374] The parameter `n_layers` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:07,376] The parameter `n_neurons_0` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:07,377] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:07,377] The parameter `learning_rate_init` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:07,378] The parameter `alpha` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  43%|████▎     | 43/100 [00:32<00:29,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:08,175] Trial 42 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.00014780033831850363, 'alpha': 0.00940327542674712}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:08,226] The parameter `n_layers` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:08,228] The parameter `n_neurons_0` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:08,229] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:08,230] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:08,231] The parameter `learning_rate_init` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:08,231] The parameter `alpha` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  44%|████▍     | 44/100 [00:33<00:33,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:09,075] Trial 43 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0032118582525883237, 'alpha': 0.0005656127243812504}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:09,116] The parameter `n_layers` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:09,118] The parameter `n_neurons_0` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:09,119] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:09,120] The parameter `learning_rate_init` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:09,121] The parameter `alpha` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  46%|████▌     | 46/100 [00:34<00:35,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:09,902] Trial 44 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0064969387159423365, 'alpha': 0.0001668764162919581}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-11-06 03:36:09,964] Trial 45 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:10,031] The parameter `n_layers` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,033] The parameter `n_neurons_0` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,034] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,035] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,036] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,036] The parameter `learning_rate_init` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,037] The parameter `alpha` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  47%|████▋     | 47/100 [00:35<00:30,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:10,855] Trial 46 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 11, 'n_neurons_1': 52, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019880193364014637, 'alpha': 0.003105201294430152}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:10,898] The parameter `n_layers` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,899] The parameter `n_neurons_0` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,901] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,902] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,903] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,904] The parameter `learning_rate_init` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:10,905] The parameter `alpha` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  48%|████▊     | 48/100 [00:36<00:28,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:11,315] Trial 47 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 44, 'n_neurons_2': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.008441994772287123, 'alpha': 0.00010575695778888723}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:11,369] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,371] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,372] The parameter `n_neurons_1` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,374] The parameter `n_neurons_2` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,375] The parameter `n_neurons_3` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,376] The parameter `n_neurons_4` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,377] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,378] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:11,379] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  49%|████▉     | 49/100 [00:36<00:33,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:12,246] Trial 48 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 13, 'n_neurons_1': 91, 'n_neurons_2': 58, 'n_neurons_3': 100, 'n_neurons_4': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001112232774304946, 'alpha': 0.0018146683984526406}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:12,298] The parameter `n_layers` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,300] The parameter `n_neurons_0` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,302] The parameter `n_neurons_1` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,303] The parameter `n_neurons_2` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,304] The parameter `n_neurons_3` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,305] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,305] The parameter `learning_rate_init` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,306] The parameter `alpha` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  51%|█████     | 51/100 [00:37<00:31,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:12,846] Trial 49 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 51, 'n_neurons_1': 67, 'n_neurons_2': 63, 'n_neurons_3': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007958348774085428, 'alpha': 0.006032920019762461}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-11-06 03:36:12,890] Trial 50 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:12,953] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,954] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,955] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,956] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,957] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,958] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:12,958] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  52%|█████▏    | 52/100 [00:38<00:28,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:13,961] Trial 51 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 66, 'n_neurons_1': 35, 'n_neurons_2': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0014699827002313925, 'alpha': 0.00014304387745680657}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:14,024] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,025] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,026] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,027] The parameter `n_neurons_2` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,028] The parameter `n_neurons_3` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,029] The parameter `n_neurons_4` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,030] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,030] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:14,031] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  53%|█████▎    | 53/100 [00:39<00:32,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:14,950] Trial 52 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 99, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.006635205362126859, 'alpha': 0.004416461875953999}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:15,026] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,028] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,029] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,030] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,031] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,032] The parameter `n_neurons_4` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,033] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,035] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:15,036] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  54%|█████▍    | 54/100 [00:40<00:35,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:15,962] Trial 53 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 65, 'n_neurons_2': 48, 'n_neurons_3': 94, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0005661437715302432, 'alpha': 0.004179329972699849}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:16,018] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,020] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,022] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,024] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,025] The parameter `n_neurons_3` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,026] The parameter `n_neurons_4` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,028] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,029] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,030] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  55%|█████▌    | 55/100 [00:41<00:35,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:16,779] Trial 54 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 23, 'n_neurons_1': 64, 'n_neurons_2': 44, 'n_neurons_3': 98, 'n_neurons_4': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0006755212335411566, 'alpha': 0.00035222010634042685}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:16,828] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,830] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,831] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,832] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:16,833] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  56%|█████▌    | 56/100 [00:41<00:31,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:17,286] Trial 55 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009846313836604142, 'alpha': 0.0012908132395505268}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:17,353] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:17,355] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:17,356] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:17,358] The parameter `n_neurons_2` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:17,359] The parameter `n_neurons_3` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:17,360] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:17,361] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:17,362] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  57%|█████▋    | 57/100 [00:43<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:18,340] Trial 56 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 95, 'n_neurons_1': 87, 'n_neurons_2': 32, 'n_neurons_3': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0016306068743545592, 'alpha': 0.00028660621978595627}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:18,402] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:18,404] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:18,405] The parameter `n_neurons_1` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:18,405] The parameter `n_neurons_2` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:18,406] The parameter `n_neurons_3` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:18,408] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:18,409] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:18,410] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  58%|█████▊    | 58/100 [00:43<00:34,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:19,188] Trial 57 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 42, 'n_neurons_2': 20, 'n_neurons_3': 71, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010973041007839744, 'alpha': 0.005062476271565486}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:19,248] The parameter `n_layers` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,249] The parameter `n_neurons_0` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,250] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,251] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,252] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,253] The parameter `learning_rate_init` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,254] The parameter `alpha` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  59%|█████▉    | 59/100 [00:44<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:19,939] Trial 58 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 89, 'n_neurons_2': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.003237982605211301, 'alpha': 0.001740279894124974}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:19,986] The parameter `n_layers` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,988] The parameter `n_neurons_0` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,989] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,990] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,992] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,993] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,994] The parameter `learning_rate_init` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:19,995] The parameter `alpha` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  60%|██████    | 60/100 [00:45<00:28,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:20,437] Trial 59 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 29, 'n_neurons_1': 22, 'n_neurons_2': 11, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0007498076102892463, 'alpha': 0.006431575749069943}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:20,483] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:20,485] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:20,486] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:20,487] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:20,487] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:20,488] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  61%|██████    | 61/100 [00:45<00:25,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:20,972] Trial 60 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005305513421197475, 'alpha': 0.007925766022280026}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:21,025] The parameter `n_layers` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,027] The parameter `n_neurons_0` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,028] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,029] The parameter `learning_rate_init` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,030] The parameter `alpha` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  62%|██████▏   | 62/100 [00:46<00:25,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:21,700] Trial 61 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0008284599389099161, 'alpha': 0.009121476646815571}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:21,763] The parameter `n_layers` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,764] The parameter `n_neurons_0` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,765] The parameter `n_neurons_1` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,766] The parameter `n_neurons_2` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,767] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,768] The parameter `learning_rate_init` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:21,769] The parameter `alpha` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  64%|██████▍   | 64/100 [00:47<00:21,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:22,746] Trial 62 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 39, 'n_neurons_1': 67, 'n_neurons_2': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018033983912317568, 'alpha': 0.0002012822076129274}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:22,792] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,793] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,794] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,795] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,796] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:36:22,907] Trial 63 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0062169420588097215, 'alpha': 0.000886999307004117}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  64%|██████▍   | 64/100 [00:47<00:21,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-06 03:36:22,965] The parameter `n_layers` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,967] The parameter `n_neurons_0` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,968] The parameter `n_neurons_1` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,969] The parameter `n_neurons_2` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,969] The parameter `n_neurons_3` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,970] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,971] The parameter `learning_rate_init` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:22,972] The parameter `alpha` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  65%|██████▌   | 65/100 [00:48<00:24,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:23,879] Trial 64 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 25, 'n_neurons_1': 27, 'n_neurons_2': 13, 'n_neurons_3': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0001504544604259194, 'alpha': 0.000174289707961261}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:23,923] The parameter `n_layers` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:23,924] The parameter `n_neurons_0` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:23,925] The parameter `n_neurons_1` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:23,926] The parameter `n_neurons_2` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:23,927] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:23,928] The parameter `learning_rate_init` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:23,929] The parameter `alpha` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  66%|██████▌   | 66/100 [00:49<00:22,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:24,459] Trial 65 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 43, 'n_neurons_2': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.003970276908151301, 'alpha': 0.0018021908442002565}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:24,514] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:24,516] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:24,517] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:24,518] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:24,519] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  67%|██████▋   | 67/100 [00:49<00:23,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:25,260] Trial 66 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00035789472410260544, 'alpha': 0.004096401906445582}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:25,337] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,339] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,340] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,341] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,342] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,343] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,344] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,345] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  68%|██████▊   | 68/100 [00:50<00:22,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:25,896] Trial 67 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 26, 'n_neurons_1': 29, 'n_neurons_2': 43, 'n_neurons_3': 54, 'learning_rate': 'constant', 'learning_rate_init': 0.0008415296693542193, 'alpha': 0.003125661016787662}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:25,949] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,951] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,952] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,953] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:25,954] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  69%|██████▉   | 69/100 [00:51<00:22,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:26,726] Trial 68 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010552488419684378, 'alpha': 0.0011593831134486484}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:26,780] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:26,782] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:26,783] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:26,784] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:26,785] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  70%|███████   | 70/100 [00:51<00:17,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:26,973] Trial 69 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 50, 'learning_rate': 'constant', 'learning_rate_init': 0.0003455305583136833, 'alpha': 0.0005682877914899338}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:27,024] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,026] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,027] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,028] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,029] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  71%|███████   | 71/100 [00:52<00:19,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:27,808] Trial 70 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017358982432215278, 'alpha': 0.006040245096887873}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:27,862] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,863] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,864] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,865] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,866] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,867] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:27,868] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  72%|███████▏  | 72/100 [00:53<00:18,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:28,498] Trial 71 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 71, 'n_neurons_1': 81, 'n_neurons_2': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014917025634138866, 'alpha': 0.0030965560706362177}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:28,553] The parameter `n_layers` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:28,555] The parameter `n_neurons_0` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:28,556] The parameter `n_neurons_1` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:28,558] The parameter `n_neurons_2` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:28,559] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:28,561] The parameter `learning_rate_init` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:28,562] The parameter `alpha` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  73%|███████▎  | 73/100 [00:53<00:17,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:29,085] Trial 72 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 35, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0005154581987502424, 'alpha': 0.009397893033412784}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:29,137] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:29,139] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:29,140] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:29,141] The parameter `n_neurons_2` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:29,142] The parameter `n_neurons_3` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:29,143] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:29,144] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:29,145] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  74%|███████▍  | 74/100 [00:54<00:19,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:30,091] Trial 73 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 19, 'n_neurons_2': 23, 'n_neurons_3': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00037169809679792504, 'alpha': 0.00022220160448344761}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:30,142] The parameter `n_layers` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,143] The parameter `n_neurons_0` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,144] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,146] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,147] The parameter `n_neurons_3` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,148] The parameter `n_neurons_4` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,149] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,150] The parameter `learning_rate_init` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:30,151] The parameter `alpha` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  75%|███████▌  | 75/100 [00:55<00:19,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:30,942] Trial 74 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 17, 'n_neurons_1': 57, 'n_neurons_2': 47, 'n_neurons_3': 99, 'n_neurons_4': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005382874466428148, 'alpha': 0.004306695255529367}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:30,998] The parameter `n_layers` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,000] The parameter `n_neurons_0` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,001] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,002] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,003] The parameter `learning_rate_init` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,004] The parameter `alpha` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  76%|███████▌  | 76/100 [00:56<00:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:31,852] Trial 75 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 25, 'n_neurons_1': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.001390674140149984, 'alpha': 0.0003630431002952846}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:31,907] The parameter `n_layers` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,908] The parameter `n_neurons_0` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,909] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,911] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,912] The parameter `n_neurons_3` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,913] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,914] The parameter `learning_rate_init` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:31,914] The parameter `alpha` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  77%|███████▋  | 77/100 [00:57<00:19,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:32,817] Trial 76 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 27, 'n_neurons_1': 39, 'n_neurons_2': 48, 'n_neurons_3': 56, 'learning_rate': 'constant', 'learning_rate_init': 0.001664332465507855, 'alpha': 0.000377799263089713}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:32,873] The parameter `n_layers` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:32,874] The parameter `n_neurons_0` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:32,875] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:32,876] The parameter `n_neurons_2` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:32,877] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:32,878] The parameter `learning_rate_init` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:32,879] The parameter `alpha` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  78%|███████▊  | 78/100 [00:58<00:20,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:33,836] Trial 77 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 24, 'n_neurons_1': 53, 'n_neurons_2': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001857074616553881, 'alpha': 0.0001338905547392675}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:33,885] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,887] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,888] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,889] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,890] The parameter `n_neurons_3` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,890] The parameter `n_neurons_4` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,891] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,892] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:33,893] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  79%|███████▉  | 79/100 [01:00<00:27,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:36,070] Trial 78 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 83, 'n_neurons_2': 33, 'n_neurons_3': 72, 'n_neurons_4': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.000666318433858052, 'alpha': 0.0004985819284806489}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:36,167] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,170] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,172] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,174] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,175] The parameter `n_neurons_3` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,177] The parameter `n_neurons_4` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,179] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,180] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:36,182] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  80%|████████  | 80/100 [01:02<00:27,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:37,589] Trial 79 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 97, 'n_neurons_2': 21, 'n_neurons_3': 76, 'n_neurons_4': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.0030355773144056086, 'alpha': 0.0014091143133651608}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:37,699] The parameter `n_layers` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,702] The parameter `n_neurons_0` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,703] The parameter `n_neurons_1` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,705] The parameter `n_neurons_2` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,707] The parameter `n_neurons_3` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,709] The parameter `n_neurons_4` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,710] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,712] The parameter `learning_rate_init` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:37,714] The parameter `alpha` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  81%|████████  | 81/100 [01:03<00:24,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:38,679] Trial 80 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 82, 'n_neurons_2': 28, 'n_neurons_3': 24, 'n_neurons_4': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011120667338401567, 'alpha': 0.0005219885398322653}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:38,732] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,733] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,734] The parameter `n_neurons_1` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,735] The parameter `n_neurons_2` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,736] The parameter `n_neurons_3` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,737] The parameter `n_neurons_4` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,737] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,738] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:38,739] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  82%|████████▏ | 82/100 [01:04<00:21,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:39,575] Trial 81 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 84, 'n_neurons_2': 49, 'n_neurons_3': 44, 'n_neurons_4': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010126066617091951, 'alpha': 0.0002913569554515852}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:39,627] The parameter `n_layers` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,629] The parameter `n_neurons_0` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,630] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,631] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,632] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,633] The parameter `n_neurons_4` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,634] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,634] The parameter `learning_rate_init` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:39,635] The parameter `alpha` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  83%|████████▎ | 83/100 [01:04<00:16,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:40,171] Trial 82 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 44, 'n_neurons_1': 59, 'n_neurons_2': 92, 'n_neurons_3': 66, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.00046753187944355057, 'alpha': 0.00018990838710732203}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:40,233] The parameter `n_layers` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:40,235] The parameter `n_neurons_0` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:40,236] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:40,237] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:40,238] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:40,239] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:40,240] The parameter `learning_rate_init` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:40,241] The parameter `alpha` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  84%|████████▍ | 84/100 [01:06<00:17,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:41,476] Trial 83 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 58, 'n_neurons_2': 91, 'n_neurons_3': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00031403516315342447, 'alpha': 0.0030753360921253873}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:41,533] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,534] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,536] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,537] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,537] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  85%|████████▌ | 85/100 [01:06<00:13,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:41,908] Trial 84 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004832406918522534, 'alpha': 0.0043905063473000955}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:41,958] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,959] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,961] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,962] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:41,963] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  86%|████████▌ | 86/100 [01:07<00:12,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:42,747] Trial 85 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003931793782370637, 'alpha': 0.00019945037385407478}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:42,797] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:42,799] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:42,800] The parameter `n_neurons_1` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:42,801] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:42,802] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:42,803] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  87%|████████▋ | 87/100 [01:08<00:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:43,780] Trial 86 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 75, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012174437001359676, 'alpha': 0.00031885858743643943}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:43,847] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:43,849] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:43,850] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:43,852] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:43,853] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:43,854] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  89%|████████▉ | 89/100 [01:09<00:10,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:44,658] Trial 87 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.0008394824228723079, 'alpha': 0.007844525502343443}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-11-06 03:36:44,708] Trial 88 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:44,803] The parameter `n_layers` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:44,805] The parameter `n_neurons_0` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:44,806] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:44,806] The parameter `learning_rate_init` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:44,807] The parameter `alpha` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  90%|█████████ | 90/100 [01:10<00:07,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:45,671] Trial 89 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001086977032427697, 'alpha': 0.005549422847797102}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:45,724] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,725] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,727] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,728] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,728] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,729] The parameter `n_neurons_4` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,730] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,731] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:45,732] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  91%|█████████ | 91/100 [01:11<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:47,028] Trial 90 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 61, 'n_neurons_1': 73, 'n_neurons_2': 93, 'n_neurons_3': 74, 'n_neurons_4': 23, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007051172552124139, 'alpha': 0.0029709029926915354}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:47,087] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,089] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,090] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,091] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,093] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,094] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,095] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,096] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,097] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  92%|█████████▏| 92/100 [01:12<00:07,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:47,935] Trial 91 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 94, 'n_neurons_1': 51, 'n_neurons_2': 20, 'n_neurons_3': 99, 'n_neurons_4': 86, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005492786568761941, 'alpha': 0.0010906266715261731}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:47,992] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,994] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,995] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,996] The parameter `n_neurons_2` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,998] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:47,999] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:48,000] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  93%|█████████▎| 93/100 [01:13<00:06,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:48,805] Trial 92 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 14, 'n_neurons_2': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.0004645135033311032, 'alpha': 0.0006256585548186114}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:48,855] The parameter `n_layers` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:48,857] The parameter `n_neurons_0` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:48,858] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:48,858] The parameter `n_neurons_2` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:48,859] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:48,860] The parameter `learning_rate_init` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:48,861] The parameter `alpha` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  94%|█████████▍| 94/100 [01:14<00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:49,509] Trial 93 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 93, 'n_neurons_1': 41, 'n_neurons_2': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0002813258539870692, 'alpha': 0.0008033023403902318}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:49,563] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:49,565] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:49,566] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:49,567] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:49,568] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  95%|█████████▌| 95/100 [01:15<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:50,305] Trial 94 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.006756033620862479, 'alpha': 0.0005306251107511992}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:50,368] The parameter `n_layers` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:50,370] The parameter `n_neurons_0` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:50,371] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:50,372] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:50,373] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:50,374] The parameter `learning_rate_init` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:50,375] The parameter `alpha` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  96%|█████████▌| 96/100 [01:16<00:03,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:51,333] Trial 95 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 11, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00019830125168914512, 'alpha': 0.0006749137054804921}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:51,381] The parameter `n_layers` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:51,383] The parameter `n_neurons_0` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:51,384] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:51,386] The parameter `learning_rate_init` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:51,386] The parameter `alpha` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 2. Best value: 0.92:  97%|█████████▋| 97/100 [01:16<00:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:52,292] Trial 96 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013619242560057148, 'alpha': 0.0031617020498319144}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:52,344] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,345] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,346] The parameter `n_neurons_1` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,347] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,348] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,349] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  98%|█████████▊| 98/100 [01:17<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:52,794] Trial 97 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 91, 'n_neurons_1': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0008792935556463842, 'alpha': 0.0013479763309946922}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:52,855] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,857] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,859] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,860] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:52,861] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92:  99%|█████████▉| 99/100 [01:18<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:53,650] Trial 98 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007612468242681232, 'alpha': 0.0006331784446999807}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-11-06 03:36:53,721] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:53,722] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:53,723] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:53,724] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:53,726] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:53,727] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:53,728] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.92: 100%|██████████| 100/100 [01:18<00:00,  1.27it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:53,982] Trial 99 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 24, 'n_neurons_1': 26, 'n_neurons_2': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0003479279724953084, 'alpha': 0.0019408817950172534}. Best is trial 2 with value: 0.92.\n",
      "\n",
      "Selected Base Models for Stacking using GPSampler:\n",
      "- Random Forest\n",
      "- K-Nearest Neighbors\n",
      "- Support Vector Machine\n",
      "Best Hyperparameters for Meta Model (MLP) using GPSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (39,), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9200, at trial: 2\n",
      "GP base models training time: 154.42 seconds\n",
      "GP SEl-NNML Training Time: 79.11 seconds\n",
      "Total GP Training Time (Base + Meta): 233.53 seconds\n",
      "GP base models training time: 154.42 seconds\n",
      "GP SEl-NNML Training Time: 79.11 seconds\n",
      "Total GP Training Time (Base + Meta): 233.53 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    gp_sel_nnml, gp_meta_study = meta_model_tuning(base_models['GP'], X_train, y_train, X_test, y_test, sampler='GPSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    gp_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP SEl-NNML training\n",
    "    gp_meta_model_training_time = gp_meta_model_training_end - gp_meta_model_training_start\n",
    "    print(f'GP base models training time: {gp_base_models_training_time:.2f} seconds')\n",
    "    print(f'GP SEl-NNML Training Time: {gp_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total GP Training Time (Base + Meta): {gp_base_models_training_time + gp_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    gp_meta_history = gp_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    gp_meta_history.columns = ['iteration', 'score']\n",
    "    gp_meta_history['iteration'] = gp_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping GP meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:54,566] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (CmaEsSampler)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 0. Best value: 0.913333:   1%|          | 1/100 [00:00<01:21,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:55,393] Trial 0 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9133333333333333.\n",
      "[W 2025-11-06 03:36:55,396] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,397] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,398] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,399] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,400] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,401] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,402] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,403] The parameter `n_neurons_1` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,403] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.913333:   2%|▏         | 2/100 [00:01<01:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:55,923] Trial 1 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.0005404052553935483, 'alpha': 0.000865808466690932}. Best is trial 0 with value: 0.9133333333333333.\n",
      "[W 2025-11-06 03:36:55,925] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,927] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,928] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,929] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,930] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,931] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,932] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,933] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:55,934] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.92:   4%|▍         | 4/100 [00:02<00:39,  2.42it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:56,379] Trial 2 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 72, 'n_neurons_1': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0004843830630951302, 'alpha': 0.0009528924787594206}. Best is trial 0 with value: 0.9133333333333333.\n",
      "[W 2025-11-06 03:36:56,381] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,383] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,384] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,385] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,386] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,387] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,388] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,389] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,390] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,391] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:36:56,562] Trial 3 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 16, 'n_neurons_2': 99, 'learning_rate': 'constant', 'learning_rate_init': 0.001284803071084827, 'alpha': 0.002651575859618515}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-11-06 03:36:56,565] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,566] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,568] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,569] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,570] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,571] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,572] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,574] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,575] The parameter `n_neurons_2` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:56,576] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.92:   5%|▌         | 5/100 [00:02<00:45,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:57,161] Trial 4 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 51, 'n_neurons_1': 76, 'n_neurons_2': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.0010997756098965073, 'alpha': 0.00010702593573937491}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-11-06 03:36:57,165] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,166] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,167] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,169] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,170] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,171] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,172] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,174] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,175] The parameter `n_neurons_2` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,176] The parameter `n_neurons_3` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,177] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.92:   6%|▌         | 6/100 [00:03<00:50,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:57,825] Trial 5 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 79, 'n_neurons_1': 92, 'n_neurons_2': 32, 'n_neurons_3': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00037679762657228646, 'alpha': 0.001966714163929435}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-11-06 03:36:57,828] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,829] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,830] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,831] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,832] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,833] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,834] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,835] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,836] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:57,837] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.92:   7%|▋         | 7/100 [00:04<00:59,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:58,670] Trial 6 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 29, 'n_neurons_1': 20, 'n_neurons_2': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045488589409482236, 'alpha': 0.0023404594415393147}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-11-06 03:36:58,673] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,674] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,675] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,676] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,676] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,677] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,678] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,679] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:58,680] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:   8%|▊         | 8/100 [00:04<01:04,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:59,498] Trial 7 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.00039738988185359975, 'alpha': 0.00195965433079867}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:36:59,501] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,502] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,503] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,504] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,505] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,506] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,506] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,507] The parameter `n_neurons_1` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:36:59,508] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:   9%|▉         | 9/100 [00:05<00:58,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:36:59,999] Trial 8 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 60, 'n_neurons_1': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.0022097738266210138, 'alpha': 0.00281718805195577}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:00,002] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,003] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,004] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,005] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,005] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,006] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,007] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,008] The parameter `n_neurons_1` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,009] The parameter `n_neurons_2` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,010] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  10%|█         | 10/100 [00:05<00:52,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:00,446] Trial 9 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 39, 'n_neurons_1': 25, 'n_neurons_2': 72, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000687058382524417, 'alpha': 0.002347234328323735}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:00,449] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,450] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,451] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,452] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,453] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,454] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,455] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,456] The parameter `n_neurons_1` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,457] The parameter `n_neurons_2` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:00,458] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  11%|█         | 11/100 [00:06<00:50,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:00,996] Trial 10 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 67, 'n_neurons_2': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045059656960865657, 'alpha': 0.0019115523482831308}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:00,999] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,000] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,001] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,002] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,003] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,003] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,004] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,005] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,006] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,007] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,008] The parameter `n_neurons_4` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,009] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  12%|█▏        | 12/100 [00:07<00:57,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:01,838] Trial 11 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 40, 'n_neurons_1': 72, 'n_neurons_2': 69, 'n_neurons_3': 30, 'n_neurons_4': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00048088918819572677, 'alpha': 0.005362153516964021}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:01,840] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,841] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,842] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,843] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,844] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,844] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,845] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,846] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,847] The parameter `n_neurons_2` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:01,848] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  13%|█▎        | 13/100 [00:07<00:53,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:02,357] Trial 12 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 34, 'n_neurons_1': 55, 'n_neurons_2': 62, 'learning_rate': 'constant', 'learning_rate_init': 0.0002431526991714598, 'alpha': 0.0010589630250931062}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:02,360] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:02,361] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:02,362] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:02,363] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:02,364] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:02,365] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:02,365] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:02,366] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  14%|█▍        | 14/100 [00:08<00:57,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:03,170] Trial 13 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0005623981944002484, 'alpha': 0.003255438587294327}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:03,172] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,173] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,174] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,175] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,176] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,177] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,178] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,178] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,179] The parameter `n_neurons_2` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,180] The parameter `n_neurons_3` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,181] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  15%|█▌        | 15/100 [00:09<00:58,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:03,889] Trial 14 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 55, 'n_neurons_1': 77, 'n_neurons_2': 73, 'n_neurons_3': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.0005310868515247862, 'alpha': 0.002783184377655115}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:03,892] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,893] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,894] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,895] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,896] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,896] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,897] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,898] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,899] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:03,900] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  16%|█▌        | 16/100 [00:10<01:04,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:04,836] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 37, 'n_neurons_1': 62, 'n_neurons_2': 13, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003006729898422152, 'alpha': 0.001357224079917557}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:04,838] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,839] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,840] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,841] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,842] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,843] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,844] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,845] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:04,846] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  17%|█▋        | 17/100 [00:10<00:57,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:05,352] Trial 16 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 57, 'n_neurons_1': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010837698399622907, 'alpha': 0.004894032800315717}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:05,355] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,357] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,358] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,359] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,360] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,361] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,362] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,363] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:05,364] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  18%|█▊        | 18/100 [00:11<01:02,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:06,265] Trial 17 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 32, 'n_neurons_1': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017753616891989718, 'alpha': 0.0007769943275524629}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:06,267] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,268] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,269] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,270] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,271] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,272] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,273] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,274] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,274] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:06,275] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  19%|█▉        | 19/100 [00:12<01:10,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:07,406] Trial 18 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 17, 'n_neurons_1': 87, 'n_neurons_2': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.0007702518191519437, 'alpha': 0.004392021066374217}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:07,409] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,410] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,411] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,412] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,413] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,413] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,414] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,415] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,416] The parameter `n_neurons_2` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,417] The parameter `n_neurons_3` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:07,418] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  21%|██        | 21/100 [00:13<00:51,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:08,267] Trial 19 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 38, 'n_neurons_1': 16, 'n_neurons_2': 68, 'n_neurons_3': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000958635766954727, 'alpha': 0.0039220535365231575}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:08,269] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,270] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,271] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,272] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,273] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,274] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,275] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,275] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,276] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:08,420] Trial 20 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 45, 'n_neurons_1': 72, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00047240353698056167, 'alpha': 0.0009687245180285073}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:08,423] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,424] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,425] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,426] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,427] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,427] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,428] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,429] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,430] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,431] The parameter `n_neurons_3` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,432] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  22%|██▏       | 22/100 [00:14<00:48,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:08,973] Trial 21 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 38, 'n_neurons_1': 100, 'n_neurons_2': 47, 'n_neurons_3': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0009517677877010948, 'alpha': 0.0014041165335022439}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:08,976] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,977] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,978] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,979] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,980] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,981] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,981] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,982] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:08,983] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  24%|██▍       | 24/100 [00:15<00:36,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:09,558] Trial 22 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 29, 'n_neurons_1': 18, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007268305048923238, 'alpha': 0.0014537517510195884}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:09,560] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,561] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,562] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,563] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,564] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,565] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,566] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,567] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,567] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,568] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:09,747] Trial 23 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 18, 'n_neurons_1': 50, 'n_neurons_2': 90, 'learning_rate': 'constant', 'learning_rate_init': 0.0006714237996470817, 'alpha': 0.0020488008695138116}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:09,750] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,751] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,752] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,753] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,753] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,754] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,755] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,756] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:09,757] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  25%|██▌       | 25/100 [00:16<00:44,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:10,603] Trial 24 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 36, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013562498573703612, 'alpha': 0.00066822736024688}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:10,607] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,608] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,609] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,610] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,611] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,612] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,612] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,613] The parameter `n_neurons_1` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:10,614] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  27%|██▋       | 27/100 [00:16<00:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:11,492] Trial 25 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 36, 'n_neurons_1': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.0003025819645478719, 'alpha': 0.0019943394552340743}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:11,495] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,496] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,497] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,497] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,498] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,499] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,500] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:11,501] Trial 26 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:11,502] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,503] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,504] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,505] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,506] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,507] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,508] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,509] The parameter `n_layers` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,510] The parameter `n_neurons_0` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,511] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,512] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,512] The parameter `learning_rate_init` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:11,513] The parameter `alpha` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  28%|██▊       | 28/100 [00:17<00:37,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:12,169] Trial 27 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 27, 'n_neurons_1': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00014304387745680657, 'alpha': 0.008887704677237365}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:12,171] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,172] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,173] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,174] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,175] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,175] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,176] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,177] The parameter `n_layers` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,178] The parameter `n_neurons_0` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,179] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,180] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,181] The parameter `n_neurons_3` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,182] The parameter `n_neurons_4` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,183] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,184] The parameter `learning_rate_init` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,184] The parameter `alpha` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  29%|██▉       | 29/100 [00:18<00:38,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:12,770] Trial 28 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 12, 'n_neurons_2': 44, 'n_neurons_3': 83, 'n_neurons_4': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005778055555902347, 'alpha': 0.008706203127734157}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:12,772] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,774] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,775] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,776] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,777] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,778] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,779] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,780] The parameter `n_layers` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,782] The parameter `n_neurons_0` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,783] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,784] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,785] The parameter `learning_rate_init` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:12,787] The parameter `alpha` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  30%|███       | 30/100 [00:19<00:45,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:13,711] Trial 29 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 50, 'n_neurons_1': 21, 'learning_rate': 'constant', 'learning_rate_init': 0.00028660621978595627, 'alpha': 0.0022049633175740767}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:13,713] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,714] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,715] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,716] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,716] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,717] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,718] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,719] The parameter `n_layers` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,720] The parameter `n_neurons_0` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,721] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,722] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,723] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,724] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,725] The parameter `learning_rate_init` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:13,725] The parameter `alpha` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  31%|███       | 31/100 [00:20<00:49,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:14,619] Trial 30 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 74, 'n_neurons_2': 29, 'n_neurons_3': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015129876174918638, 'alpha': 0.0006088188496927438}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:14,622] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,623] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,624] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,624] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,625] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,626] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,627] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,627] The parameter `n_layers` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,628] The parameter `n_neurons_0` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,629] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,630] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,631] The parameter `n_neurons_3` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,632] The parameter `n_neurons_4` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,632] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,633] The parameter `learning_rate_init` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:14,634] The parameter `alpha` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  32%|███▏      | 32/100 [00:20<00:49,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:15,349] Trial 31 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 54, 'n_neurons_1': 39, 'n_neurons_2': 67, 'n_neurons_3': 31, 'n_neurons_4': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.0002012822076129274, 'alpha': 0.00018951969347583955}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:15,351] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,352] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,353] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,354] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,355] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,355] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,356] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,357] The parameter `n_layers` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,358] The parameter `n_neurons_0` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,359] The parameter `n_neurons_1` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,360] The parameter `n_neurons_2` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,361] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,361] The parameter `learning_rate_init` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,362] The parameter `alpha` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  33%|███▎      | 33/100 [00:21<00:43,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:15,796] Trial 32 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 43, 'n_neurons_2': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.003970276908151301, 'alpha': 0.0018021908442002565}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:15,798] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,799] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,801] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,802] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,802] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,803] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,804] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,805] The parameter `n_layers` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,806] The parameter `n_neurons_0` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,807] The parameter `n_neurons_1` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,808] The parameter `n_neurons_2` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,808] The parameter `n_neurons_3` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,809] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,810] The parameter `learning_rate_init` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:15,811] The parameter `alpha` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  34%|███▍      | 34/100 [00:21<00:37,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:16,171] Trial 33 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 13, 'n_neurons_1': 32, 'n_neurons_2': 74, 'n_neurons_3': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00016381136253889315, 'alpha': 0.0007849188043830674}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:16,173] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,174] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,176] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,177] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,178] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,179] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,180] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,181] The parameter `n_layers` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,182] The parameter `n_neurons_0` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,183] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,184] The parameter `learning_rate_init` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,185] The parameter `alpha` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  35%|███▌      | 35/100 [00:22<00:40,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:16,935] Trial 34 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007299936670144685, 'alpha': 0.000179953627507624}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:16,937] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,938] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,939] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,940] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,941] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,942] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,943] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,944] The parameter `n_layers` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,945] The parameter `n_neurons_0` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,945] The parameter `learning_rate` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,946] The parameter `learning_rate_init` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:16,947] The parameter `alpha` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  36%|███▌      | 36/100 [00:22<00:37,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:17,452] Trial 35 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006619019399921065, 'alpha': 0.009220558632540494}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:17,454] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,456] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,457] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,458] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,459] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,461] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,461] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,462] The parameter `n_layers` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,463] The parameter `n_neurons_0` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,464] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,465] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,466] The parameter `learning_rate_init` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:17,466] The parameter `alpha` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  37%|███▋      | 37/100 [00:23<00:44,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:18,441] Trial 36 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 48, 'n_neurons_1': 56, 'learning_rate': 'constant', 'learning_rate_init': 0.001664332465507855, 'alpha': 0.000377799263089713}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:18,443] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,444] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,445] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,446] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,447] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,448] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,448] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,449] The parameter `n_layers` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,450] The parameter `n_neurons_0` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,451] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,452] The parameter `n_neurons_2` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,454] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,455] The parameter `learning_rate_init` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,456] The parameter `alpha` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  38%|███▊      | 38/100 [00:24<00:39,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:18,919] Trial 37 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 52, 'n_neurons_1': 47, 'n_neurons_2': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.008512435247428878, 'alpha': 0.0001772533479956596}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:18,921] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,922] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,922] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,923] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,924] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,925] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,926] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,927] The parameter `n_layers` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,928] The parameter `n_neurons_0` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,929] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,930] The parameter `n_neurons_2` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,930] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,931] The parameter `learning_rate_init` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:18,932] The parameter `alpha` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  39%|███▉      | 39/100 [00:25<00:49,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:20,139] Trial 38 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 89, 'n_neurons_2': 45, 'learning_rate': 'constant', 'learning_rate_init': 0.0005673993825415947, 'alpha': 0.0008420920578362944}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:20,141] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,142] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,143] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,144] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,144] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,145] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,146] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,147] The parameter `n_layers` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,148] The parameter `n_neurons_0` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,149] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,150] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,150] The parameter `n_neurons_3` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,151] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,152] The parameter `learning_rate_init` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:20,153] The parameter `alpha` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  42%|████▏     | 42/100 [00:27<00:33,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:21,585] Trial 39 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 58, 'n_neurons_2': 91, 'n_neurons_3': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00031403516315342447, 'alpha': 0.0030753360921253873}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:21,588] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,589] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,590] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,591] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,592] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,593] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,594] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:21,595] Trial 40 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:21,597] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,598] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,599] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,600] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,601] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,602] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,603] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,604] The parameter `n_layers` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,606] The parameter `n_neurons_0` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,607] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,608] The parameter `n_neurons_2` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,609] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,610] The parameter `learning_rate_init` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,611] The parameter `alpha` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:21,758] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 65, 'n_neurons_1': 11, 'n_neurons_2': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.0024734415258704863, 'alpha': 0.006998400016066854}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:21,760] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,761] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,762] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,763] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,764] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,765] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,766] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,767] The parameter `n_layers` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,768] The parameter `n_neurons_0` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,769] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,770] The parameter `n_neurons_2` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,771] The parameter `n_neurons_3` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,772] The parameter `n_neurons_4` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,773] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,774] The parameter `learning_rate_init` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:21,775] The parameter `alpha` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  43%|████▎     | 43/100 [00:27<00:33,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:22,382] Trial 42 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 57, 'n_neurons_1': 63, 'n_neurons_2': 46, 'n_neurons_3': 14, 'n_neurons_4': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.0004645135033311032, 'alpha': 0.0006256585548186114}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:22,384] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,385] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,386] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,387] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,388] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,389] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,389] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,390] The parameter `n_layers` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,391] The parameter `n_neurons_0` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,392] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,393] The parameter `n_neurons_2` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,394] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,395] The parameter `learning_rate_init` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:22,395] The parameter `alpha` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  44%|████▍     | 44/100 [00:28<00:37,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:23,298] Trial 43 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 11, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00019830125168914512, 'alpha': 0.0006749137054804921}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:23,301] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,302] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,302] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,303] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,304] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,305] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,306] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,307] The parameter `n_layers` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,307] The parameter `n_neurons_0` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,308] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,309] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,310] The parameter `n_neurons_3` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,311] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,312] The parameter `learning_rate_init` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:23,313] The parameter `alpha` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  45%|████▌     | 45/100 [00:29<00:40,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:24,215] Trial 44 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 51, 'n_neurons_1': 57, 'n_neurons_2': 50, 'n_neurons_3': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.00023112996897053792, 'alpha': 0.005291407907847561}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:24,218] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,219] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,220] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,220] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,221] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,222] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,223] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,224] The parameter `n_layers` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,225] The parameter `n_neurons_0` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,226] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,226] The parameter `learning_rate_init` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:24,227] The parameter `alpha` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  46%|████▌     | 46/100 [00:30<00:40,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:25,012] Trial 45 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000299478439928207, 'alpha': 0.00015808213238348277}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:25,013] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,015] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,016] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,017] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,018] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,019] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,020] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,021] The parameter `n_layers` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,022] The parameter `n_neurons_0` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,023] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,025] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,026] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,027] The parameter `learning_rate_init` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,028] The parameter `alpha` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  47%|████▋     | 47/100 [00:30<00:32,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:25,242] Trial 46 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 48, 'n_neurons_1': 91, 'n_neurons_2': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.0005746253963762425, 'alpha': 0.0015156184556529744}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:25,245] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,246] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,247] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,249] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,250] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,252] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,253] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,254] The parameter `n_layers` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,255] The parameter `n_neurons_0` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,257] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,258] The parameter `learning_rate_init` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:25,259] The parameter `alpha` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  48%|████▊     | 48/100 [00:31<00:35,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:26,095] Trial 47 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003279256370202935, 'alpha': 0.00018998186562844776}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:26,098] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,099] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,101] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,102] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,103] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,104] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,106] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,107] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,109] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,111] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,112] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,113] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  49%|████▉     | 49/100 [00:32<00:36,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:26,872] Trial 48 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 22, 'learning_rate': 'constant', 'learning_rate_init': 0.001566124214205962, 'alpha': 0.001588670096363}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:26,874] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,875] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,876] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,877] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,877] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,878] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,879] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,880] The parameter `n_layers` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,881] The parameter `n_neurons_0` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,882] The parameter `n_neurons_1` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,883] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,884] The parameter `learning_rate_init` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:26,885] The parameter `alpha` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  50%|█████     | 50/100 [00:33<00:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:27,751] Trial 49 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0021249187599503977, 'alpha': 0.007475831061488737}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:27,753] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,754] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,755] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,756] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,757] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,758] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,758] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,759] The parameter `n_layers` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,760] The parameter `n_neurons_0` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,761] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,762] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,763] The parameter `n_neurons_3` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,764] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,765] The parameter `learning_rate_init` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:27,766] The parameter `alpha` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  51%|█████     | 51/100 [00:34<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:28,626] Trial 50 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 49, 'n_neurons_1': 32, 'n_neurons_2': 84, 'n_neurons_3': 82, 'learning_rate': 'constant', 'learning_rate_init': 0.0015151698985443685, 'alpha': 0.0005271664874398606}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:28,627] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,628] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,629] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,630] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,631] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,632] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,633] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,634] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,634] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,635] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,636] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,637] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,638] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:28,639] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  52%|█████▏    | 52/100 [00:34<00:38,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:29,417] Trial 51 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 30, 'n_neurons_1': 99, 'n_neurons_2': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007087558145736653, 'alpha': 0.00022969454974259052}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:29,419] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,420] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,421] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,422] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,423] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,424] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,425] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,427] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,428] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,429] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,430] The parameter `n_neurons_2` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,431] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,432] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:29,433] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  53%|█████▎    | 53/100 [00:35<00:38,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:30,267] Trial 52 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 30, 'n_neurons_1': 20, 'n_neurons_2': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.002815357452964348, 'alpha': 0.00013511783615174891}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:30,269] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,270] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,271] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,272] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,273] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,273] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,274] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,275] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,276] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,277] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,278] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,278] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,279] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,280] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,281] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  54%|█████▍    | 54/100 [00:35<00:29,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:30,528] Trial 53 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 100, 'n_neurons_1': 41, 'n_neurons_2': 79, 'n_neurons_3': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005589258917257331, 'alpha': 0.009293235406855402}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:30,530] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,531] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,532] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,533] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,534] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,535] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,536] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,537] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,539] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,540] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,541] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,542] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:30,543] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  55%|█████▌    | 55/100 [00:36<00:33,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:31,527] Trial 54 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 29, 'learning_rate': 'constant', 'learning_rate_init': 0.00015094613753824642, 'alpha': 0.0006841661003247827}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:31,529] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,531] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,532] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,533] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,534] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,535] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,536] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,537] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,538] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,539] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,540] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,541] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  56%|█████▌    | 56/100 [00:37<00:29,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:31,986] Trial 55 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.008673717241575788, 'alpha': 0.00585560495923566}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:31,988] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,990] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,991] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,992] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,993] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,994] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,995] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,997] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,998] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:31,999] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:32,000] The parameter `n_neurons_2` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:32,001] The parameter `n_neurons_3` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:32,002] The parameter `n_neurons_4` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:32,003] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:32,005] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:32,006] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  57%|█████▋    | 57/100 [00:38<00:37,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:33,335] Trial 56 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 34, 'n_neurons_1': 21, 'n_neurons_2': 90, 'n_neurons_3': 96, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0012639059001467116, 'alpha': 0.0001492703392407429}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:33,337] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,338] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,339] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,340] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,341] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,342] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,342] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,343] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,344] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,345] The parameter `n_neurons_1` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,346] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,347] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,348] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  58%|█████▊    | 58/100 [00:39<00:31,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:33,846] Trial 57 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003934160224360252, 'alpha': 0.0020744533327664858}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:33,848] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,849] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,850] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,851] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,852] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,853] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,854] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,855] The parameter `n_layers` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,856] The parameter `n_neurons_0` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,857] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,858] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,859] The parameter `learning_rate_init` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:33,861] The parameter `alpha` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  60%|██████    | 60/100 [00:40<00:31,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:34,671] Trial 58 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010349883647557926, 'alpha': 0.00010298447122215186}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:34,673] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,674] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,675] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,676] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,677] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,678] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,678] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:34,679] Trial 59 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:34,681] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,682] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,682] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,683] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,684] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,685] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,686] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,687] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,688] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,689] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,690] The parameter `n_neurons_2` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,690] The parameter `n_neurons_3` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,691] The parameter `n_neurons_4` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,692] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,693] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:34,694] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  61%|██████    | 61/100 [00:40<00:22,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:35,351] Trial 60 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 78, 'n_neurons_1': 21, 'n_neurons_2': 79, 'n_neurons_3': 12, 'n_neurons_4': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0034738801863753908, 'alpha': 0.002325898471109331}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:35,353] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,354] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,354] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,355] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,356] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,357] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,358] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,359] The parameter `n_layers` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,360] The parameter `n_neurons_0` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,360] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,361] The parameter `learning_rate_init` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,362] The parameter `alpha` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  63%|██████▎   | 63/100 [00:41<00:20,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:35,869] Trial 61 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 49, 'learning_rate': 'constant', 'learning_rate_init': 0.0018925697547456676, 'alpha': 0.0006240060436145399}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:35,871] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,872] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,873] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,874] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,875] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,875] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,876] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:35,877] Trial 62 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:35,879] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,880] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,880] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,881] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,882] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,883] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,884] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,885] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,886] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,886] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,887] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,888] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,889] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:35,890] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  64%|██████▍   | 64/100 [00:41<00:16,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:36,434] Trial 63 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 54, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.003936572019640482, 'alpha': 0.00041756483518393106}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:36,436] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,438] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,439] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,440] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,441] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,442] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,443] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,444] The parameter `n_layers` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,445] The parameter `n_neurons_0` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,445] The parameter `n_neurons_1` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,446] The parameter `n_neurons_2` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,447] The parameter `n_neurons_3` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,448] The parameter `n_neurons_4` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,449] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,450] The parameter `learning_rate_init` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,451] The parameter `alpha` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  65%|██████▌   | 65/100 [00:42<00:14,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:36,719] Trial 64 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 55, 'n_neurons_2': 66, 'n_neurons_3': 73, 'n_neurons_4': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010849838825181713, 'alpha': 0.00014987631213878993}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:36,721] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,722] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,723] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,724] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,725] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,726] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,727] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,728] The parameter `n_layers` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,729] The parameter `n_neurons_0` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,730] The parameter `n_neurons_1` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,730] The parameter `n_neurons_2` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,731] The parameter `n_neurons_3` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,732] The parameter `n_neurons_4` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,733] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,734] The parameter `learning_rate_init` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:36,735] The parameter `alpha` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  66%|██████▌   | 66/100 [00:42<00:17,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:37,512] Trial 65 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 59, 'n_neurons_2': 74, 'n_neurons_3': 89, 'n_neurons_4': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.004262360980898247, 'alpha': 0.0001446204447457985}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:37,514] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,515] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,516] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,517] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,518] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,519] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,521] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,522] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,523] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,524] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,525] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,526] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,527] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  67%|██████▋   | 67/100 [00:43<00:16,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:37,991] Trial 66 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 81, 'learning_rate': 'constant', 'learning_rate_init': 0.001290408163534379, 'alpha': 0.0027441228904630938}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:37,993] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,994] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,995] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,996] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,997] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,998] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:37,999] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:38,000] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:38,000] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:38,001] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:38,002] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:38,003] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:38,004] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  68%|██████▊   | 68/100 [00:44<00:20,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:39,059] Trial 67 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014366494705598603, 'alpha': 0.0007537560974952886}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:39,062] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,063] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,065] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,066] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,067] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,068] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,069] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,070] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,071] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,073] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,074] The parameter `n_neurons_2` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,075] The parameter `n_neurons_3` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,076] The parameter `n_neurons_4` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,077] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,078] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,079] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  69%|██████▉   | 69/100 [00:44<00:18,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:39,516] Trial 68 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 26, 'n_neurons_1': 31, 'n_neurons_2': 98, 'n_neurons_3': 26, 'n_neurons_4': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.005514419516648056, 'alpha': 0.0007773390943180892}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:39,518] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,520] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,521] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,522] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,523] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,524] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,526] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,527] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,528] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,529] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,531] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:39,532] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  70%|███████   | 70/100 [00:45<00:19,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:40,306] Trial 69 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.004547437426011357, 'alpha': 0.0007274029320947825}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:40,308] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,309] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,310] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,311] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,312] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,313] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,314] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,315] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,316] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,317] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,318] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:40,319] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  71%|███████   | 71/100 [00:46<00:20,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:41,162] Trial 70 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007468121665987528, 'alpha': 0.00011986353489802667}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:41,164] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,165] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,166] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,167] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,168] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,169] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,170] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,171] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,172] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,173] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,174] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,175] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,176] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:41,176] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  73%|███████▎  | 73/100 [00:47<00:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:42,177] Trial 71 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 70, 'n_neurons_2': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002566619712518178, 'alpha': 0.0002533418305370726}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:42,179] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,180] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,181] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,182] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,183] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,183] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,184] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:42,185] Trial 72 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:42,186] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,187] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,188] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,189] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,190] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,191] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,192] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,193] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,194] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,195] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,195] The parameter `n_neurons_2` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,196] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,197] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:42,198] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  75%|███████▌  | 75/100 [00:48<00:16,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:43,143] Trial 73 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 81, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006431031596032392, 'alpha': 0.00045088555611044626}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:43,146] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,147] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,148] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,149] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,150] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,152] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,153] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:43,155] Trial 74 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:43,157] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,158] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,159] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,161] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,162] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,163] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,165] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,166] The parameter `n_layers` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,168] The parameter `n_neurons_0` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,169] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,171] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,172] The parameter `learning_rate_init` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:43,173] The parameter `alpha` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  76%|███████▌  | 76/100 [00:49<00:14,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:44,202] Trial 75 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.0016436531848333894, 'alpha': 0.00338662042319669}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:44,204] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,205] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,206] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,207] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,207] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,208] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,209] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,210] The parameter `n_layers` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,211] The parameter `n_neurons_0` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,212] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,212] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,213] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,215] The parameter `learning_rate_init` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:44,216] The parameter `alpha` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  77%|███████▋  | 77/100 [00:50<00:15,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:45,113] Trial 76 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 33, 'n_neurons_1': 35, 'n_neurons_2': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0004193874191709548, 'alpha': 0.001662139868133609}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:45,116] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,117] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,118] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,119] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,120] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,121] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,122] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,123] The parameter `n_layers` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,124] The parameter `n_neurons_0` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,125] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,127] The parameter `n_neurons_2` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,128] The parameter `n_neurons_3` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,129] The parameter `n_neurons_4` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,130] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,131] The parameter `learning_rate_init` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:45,132] The parameter `alpha` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  78%|███████▊  | 78/100 [00:51<00:18,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:46,532] Trial 77 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 60, 'n_neurons_1': 13, 'n_neurons_2': 67, 'n_neurons_3': 96, 'n_neurons_4': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002858640510403272, 'alpha': 0.00026551537824360454}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:46,534] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,535] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,536] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,537] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,538] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,539] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,539] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,540] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,541] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,542] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,543] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,544] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,545] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:46,546] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  79%|███████▉  | 79/100 [00:53<00:19,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:47,714] Trial 78 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 25, 'n_neurons_1': 77, 'n_neurons_2': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00011150059170836743, 'alpha': 0.0019228393487042126}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:47,716] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,717] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,718] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,719] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,719] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,720] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,721] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,722] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,723] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,724] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,725] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:47,726] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  81%|████████  | 81/100 [00:53<00:15,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:48,210] Trial 79 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.0003534445856055918, 'alpha': 0.0001441579965339067}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:48,213] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,214] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,215] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,216] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,217] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,217] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,218] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:48,219] Trial 80 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:48,221] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,221] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,222] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,223] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,224] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,225] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,226] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,226] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,227] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,228] The parameter `n_neurons_1` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,229] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,230] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,231] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  82%|████████▏ | 82/100 [00:54<00:10,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:48,694] Trial 81 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 58, 'n_neurons_1': 18, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004956134097083741, 'alpha': 0.002137093133753237}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:48,696] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,697] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,698] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,699] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,700] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,701] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,702] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,703] The parameter `n_layers` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,704] The parameter `n_neurons_0` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,705] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,706] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,707] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,708] The parameter `n_neurons_4` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,709] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,710] The parameter `learning_rate_init` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:48,711] The parameter `alpha` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  83%|████████▎ | 83/100 [00:55<00:10,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:49,570] Trial 82 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 81, 'n_neurons_1': 74, 'n_neurons_2': 13, 'n_neurons_3': 37, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.007480241960748882, 'alpha': 0.001281163276357022}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:49,572] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,574] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,575] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,576] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,577] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,578] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,578] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,579] The parameter `n_layers` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,580] The parameter `n_neurons_0` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,581] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,582] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,583] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,584] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,585] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,586] The parameter `learning_rate_init` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:49,587] The parameter `alpha` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  84%|████████▍ | 84/100 [00:56<00:11,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:50,562] Trial 83 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 83, 'n_neurons_2': 81, 'n_neurons_3': 37, 'n_neurons_4': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.0024541560696713445, 'alpha': 0.0004922655605142162}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:50,565] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,566] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,567] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,568] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,569] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,570] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,570] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,571] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,572] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,573] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,574] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:50,575] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  85%|████████▌ | 85/100 [00:56<00:10,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:51,078] Trial 84 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012562008177756832, 'alpha': 0.008543667186048135}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:51,080] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,081] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,082] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,083] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,084] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,085] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,085] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,086] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,087] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,088] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,089] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,090] The parameter `n_neurons_3` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,091] The parameter `n_neurons_4` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,092] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,093] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:51,093] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  86%|████████▌ | 86/100 [00:57<00:12,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:52,449] Trial 85 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 73, 'n_neurons_2': 99, 'n_neurons_3': 31, 'n_neurons_4': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015925446667814006, 'alpha': 0.002422828554185797}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:52,451] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,452] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,453] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,454] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,454] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,455] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,456] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,457] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,458] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,459] The parameter `n_neurons_1` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,460] The parameter `n_neurons_2` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,461] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,462] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:52,463] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  87%|████████▋ | 87/100 [00:58<00:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:53,544] Trial 86 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 76, 'n_neurons_2': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009176737380720279, 'alpha': 0.00010924071993869074}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:53,546] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,548] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,549] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,550] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,551] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,552] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,553] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,554] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,555] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,556] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,557] The parameter `n_neurons_2` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,558] The parameter `n_neurons_3` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,560] The parameter `n_neurons_4` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,561] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,562] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:53,563] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  88%|████████▊ | 88/100 [01:00<00:11,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:54,557] Trial 87 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 18, 'n_neurons_1': 54, 'n_neurons_2': 23, 'n_neurons_3': 39, 'n_neurons_4': 77, 'learning_rate': 'constant', 'learning_rate_init': 0.0006151096737070389, 'alpha': 0.0008296473623735454}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:54,559] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,560] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,560] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,561] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,562] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,563] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,564] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,565] The parameter `n_layers` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,566] The parameter `n_neurons_0` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,567] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,568] The parameter `n_neurons_2` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,569] The parameter `n_neurons_3` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,569] The parameter `n_neurons_4` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,570] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,571] The parameter `learning_rate_init` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:54,572] The parameter `alpha` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  89%|████████▉ | 89/100 [01:00<00:09,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:55,157] Trial 88 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 67, 'n_neurons_1': 65, 'n_neurons_2': 16, 'n_neurons_3': 57, 'n_neurons_4': 23, 'learning_rate': 'constant', 'learning_rate_init': 0.0022932719467128214, 'alpha': 0.00012115624400696192}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:55,159] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,160] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,161] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,162] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,163] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,164] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,164] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,165] The parameter `n_layers` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,166] The parameter `n_neurons_0` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,167] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,168] The parameter `learning_rate_init` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:55,169] The parameter `alpha` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  90%|█████████ | 90/100 [01:01<00:08,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:56,130] Trial 89 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.00011012601445612862, 'alpha': 0.0001459967993464517}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:56,132] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,133] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,134] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,134] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,135] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,136] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,137] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,138] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,139] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,139] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,140] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,141] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:56,142] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  91%|█████████ | 91/100 [01:02<00:08,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:57,108] Trial 90 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004202808250827565, 'alpha': 0.0020556880660352003}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:57,110] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,112] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,113] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,114] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,115] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,116] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,117] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,118] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,119] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,120] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,121] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,122] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:57,123] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  92%|█████████▏| 92/100 [01:03<00:07,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:58,015] Trial 91 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 84, 'n_neurons_1': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003195082233827963, 'alpha': 0.0032365614534194923}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:58,018] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,019] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,020] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,021] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,022] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,023] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,024] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,025] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,026] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,027] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,028] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,029] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,030] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  94%|█████████▍| 94/100 [01:04<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:37:58,557] Trial 92 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0015159866641908737, 'alpha': 0.0010392525381080842}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:58,559] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,560] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,561] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,562] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,563] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,563] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,564] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:37:58,565] Trial 93 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:37:58,566] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,567] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,568] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,569] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,570] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,571] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,572] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,573] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,574] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,574] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,575] The parameter `n_neurons_2` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,576] The parameter `n_neurons_3` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,577] The parameter `n_neurons_4` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,578] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,579] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:37:58,580] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  95%|█████████▌| 95/100 [01:05<00:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:00,078] Trial 94 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 39, 'n_neurons_2': 23, 'n_neurons_3': 37, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.0007892621240300501, 'alpha': 0.0027806214997722505}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:38:00,080] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,081] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,082] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,083] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,084] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,084] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,085] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,086] The parameter `n_layers` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,087] The parameter `n_neurons_0` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,088] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,089] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,089] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,090] The parameter `learning_rate_init` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:00,091] The parameter `alpha` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 7. Best value: 0.926667:  96%|█████████▌| 96/100 [01:06<00:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:01,420] Trial 95 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 61, 'n_neurons_2': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003464506976855204, 'alpha': 0.004467852431220893}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:38:01,422] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,423] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,424] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,425] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,426] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,427] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,427] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,428] The parameter `n_layers` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,429] The parameter `n_neurons_0` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,430] The parameter `n_neurons_1` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,431] The parameter `n_neurons_2` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,432] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,433] The parameter `learning_rate_init` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:01,434] The parameter `alpha` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  98%|█████████▊| 98/100 [01:07<00:01,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:02,002] Trial 96 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 100, 'n_neurons_2': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0018722107277466084, 'alpha': 0.0037265181101734106}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:38:02,004] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,005] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,006] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,007] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,009] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,010] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,011] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,012] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,013] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,015] The parameter `n_neurons_1` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,016] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,017] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,018] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:02,123] Trial 97 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 95, 'n_neurons_1': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00482911039455259, 'alpha': 0.00023561494581810438}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:38:02,126] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,127] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,128] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,129] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,131] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,132] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,133] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,134] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,135] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,137] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,138] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,139] The parameter `n_neurons_3` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,140] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,141] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,142] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667:  99%|█████████▉| 99/100 [01:07<00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:02,309] Trial 98 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 97, 'n_neurons_1': 16, 'n_neurons_2': 15, 'n_neurons_3': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.006493953298280694, 'alpha': 0.00031556759477955416}. Best is trial 7 with value: 0.9266666666666666.\n",
      "[W 2025-11-06 03:38:02,312] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,313] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,315] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,316] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,317] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,319] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,320] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,321] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,323] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,324] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,325] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:02,327] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.926667: 100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:02,818] Trial 99 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.0074755805269149074, 'alpha': 0.00012720839073892073}. Best is trial 7 with value: 0.9266666666666666.\n",
      "\n",
      "Selected Base Models for Stacking using CmaEsSampler:\n",
      "- Logistic Regression\n",
      "- Decision Tree\n",
      "- Random Forest\n",
      "- AdaBoost\n",
      "- Gradient Boosting\n",
      "Best Hyperparameters for Meta Model (MLP) using CmaEsSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.00039738988185359975, 'alpha': 0.00195965433079867, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (38, 32), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9267, at trial: 7\n",
      "CMA-ES base models training time: 49.52 seconds\n",
      "CMA-ES SEl-NNML Training Time: 69.11 seconds\n",
      "Total CMA-ES Training Time (Base + Meta): 118.62 seconds\n",
      "CMA-ES base models training time: 49.52 seconds\n",
      "CMA-ES SEl-NNML Training Time: 69.11 seconds\n",
      "Total CMA-ES Training Time (Base + Meta): 118.62 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    cmaes_sel_nnml, cmaes_meta_study = meta_model_tuning(base_models['CMA-ES'], X_train, y_train, X_test, y_test, sampler='CmaEsSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE) \n",
    "    cmaes_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES SEl-NNML training\n",
    "    cmaes_meta_model_training_time = cmaes_meta_model_training_end - cmaes_meta_model_training_start\n",
    "    print(f'CMA-ES base models training time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "    print(f'CMA-ES SEl-NNML Training Time: {cmaes_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total CMA-ES Training Time (Base + Meta): {cmaes_base_models_training_time + cmaes_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    cmaes_meta_history = cmaes_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    cmaes_meta_history.columns = ['iteration', 'score']\n",
    "    cmaes_meta_history['iteration'] = cmaes_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping CMA-ES meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/Work/heart/notebooks/src/model_tuning_algorithm.py:178: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-11-06 03:38:03,681] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (QMCSampler)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 0. Best value: 0.906667:   1%|          | 1/100 [00:00<01:17,  1.27it/s]/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 0. Best value: 0.906667:   1%|          | 1/100 [00:00<01:17,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:04,465] Trial 0 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9066666666666666.\n",
      "[W 2025-11-06 03:38:04,468] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,470] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,472] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,473] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,475] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,477] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,478] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,479] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:   2%|▏         | 2/100 [00:01<00:55,  1.77it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:04,877] Trial 1 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.00010000000000000009, 'alpha': 0.00010000000000000009}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:04,879] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,880] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,881] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,882] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,883] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,884] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,884] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,885] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,886] The parameter `n_neurons_2` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:04,887] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:   3%|▎         | 3/100 [00:02<01:08,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:05,744] Trial 2 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 55, 'n_neurons_1': 98, 'n_neurons_2': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0010000000000000002, 'alpha': 0.0010000000000000002}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:05,747] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,748] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,750] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,751] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,752] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,753] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,754] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,755] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,757] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,758] The parameter `n_neurons_3` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:05,759] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:   5%|▌         | 5/100 [00:02<00:39,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:06,051] Trial 3 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 16, 'n_neurons_2': 99, 'n_neurons_3': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0003162277660168384, 'alpha': 0.0003162277660168384}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:06,054] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,055] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,057] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,058] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,059] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,060] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,061] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,063] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,064] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:06,225] Trial 4 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 78, 'n_neurons_1': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.003162277660168382, 'alpha': 0.003162277660168382}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:06,227] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,228] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,229] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,230] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,231] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,232] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,233] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,234] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,235] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:   6%|▌         | 6/100 [00:03<00:47,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:06,911] Trial 5 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017782794100389236, 'alpha': 0.005623413251903492}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:06,913] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,914] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,916] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,917] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,918] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,919] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,920] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,921] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,922] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,923] The parameter `n_neurons_3` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,924] The parameter `n_neurons_4` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:06,925] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:   7%|▋         | 7/100 [00:03<00:49,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:07,489] Trial 6 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 89, 'n_neurons_1': 91, 'n_neurons_2': 38, 'n_neurons_3': 20, 'n_neurons_4': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017782794100389232, 'alpha': 0.0005623413251903495}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:07,492] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,493] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,495] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,496] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,497] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,498] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,499] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,500] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,502] The parameter `n_neurons_2` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,503] The parameter `n_neurons_3` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:07,504] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:   8%|▊         | 8/100 [00:04<00:53,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:08,196] Trial 7 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 21, 'n_neurons_1': 32, 'n_neurons_2': 55, 'n_neurons_3': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.005623413251903492, 'alpha': 0.0017782794100389236}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:08,198] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,199] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,200] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,201] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,201] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,202] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,203] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,204] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:   9%|▉         | 9/100 [00:05<00:53,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:08,805] Trial 8 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 66, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005623413251903495, 'alpha': 0.00017782794100389232}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:08,807] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,808] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,809] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,810] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,811] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,811] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,812] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:08,813] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  10%|█         | 10/100 [00:05<00:53,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:09,386] Trial 9 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.007498942093324564, 'alpha': 0.0007498942093324562}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:09,388] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,389] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,390] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,391] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,392] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,393] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,393] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,394] The parameter `n_neurons_1` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,395] The parameter `n_neurons_2` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,396] The parameter `n_neurons_3` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:09,397] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  11%|█         | 11/100 [00:06<01:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:10,600] Trial 10 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 67, 'n_neurons_3': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007498942093324562, 'alpha': 0.007498942093324564}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:10,602] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,603] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,604] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,605] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,606] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,607] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,608] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,610] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,611] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,612] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,613] The parameter `n_neurons_4` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:10,614] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  12%|█▏        | 12/100 [00:07<01:01,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:11,112] Trial 11 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 72, 'n_neurons_2': 69, 'n_neurons_3': 30, 'n_neurons_4': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002371373705661656, 'alpha': 0.00023713737056616573}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:11,114] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,116] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,117] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,118] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,119] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,120] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,121] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,122] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,123] The parameter `n_neurons_2` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,124] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  13%|█▎        | 13/100 [00:08<01:01,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:11,852] Trial 12 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 55, 'n_neurons_2': 62, 'learning_rate': 'constant', 'learning_rate_init': 0.00023713737056616573, 'alpha': 0.002371373705661656}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:11,855] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,856] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,857] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,857] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,859] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,859] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,860] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,861] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:11,862] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  14%|█▍        | 14/100 [00:08<00:56,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:12,368] Trial 13 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 27, 'n_neurons_1': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00042169650342858235, 'alpha': 0.0013335214321633251}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:12,370] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,371] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,372] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,373] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,373] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,374] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,375] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,376] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,377] The parameter `n_neurons_2` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,378] The parameter `n_neurons_3` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,378] The parameter `n_neurons_4` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:12,379] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  15%|█▌        | 15/100 [00:09<00:55,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:13,029] Trial 14 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 72, 'n_neurons_1': 73, 'n_neurons_2': 73, 'n_neurons_3': 42, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004216965034285825, 'alpha': 0.0001333521432163326}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:13,031] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,032] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,033] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,034] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,035] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,036] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,037] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,037] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,038] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,039] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  17%|█▋        | 17/100 [00:10<00:44,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:13,820] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 52, 'n_neurons_2': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001333521432163326, 'alpha': 0.004216965034285825}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:13,822] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,823] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,824] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,824] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,825] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,826] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,827] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,828] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:13,975] Trial 16 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013335214321633251, 'alpha': 0.00042169650342858235}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:13,977] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,978] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,979] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,980] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,981] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,981] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,982] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:13,983] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  18%|█▊        | 18/100 [00:10<00:45,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:14,561] Trial 17 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000865964323360066, 'alpha': 0.0020535250264571477}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:14,563] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,564] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,565] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,566] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,567] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,567] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,568] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,569] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,570] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:14,571] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  19%|█▉        | 19/100 [00:11<00:42,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:15,035] Trial 18 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 98, 'n_neurons_1': 87, 'n_neurons_2': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.008659643233600654, 'alpha': 0.0002053525026457149}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:15,037] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,038] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,039] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,040] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,040] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,041] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,042] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,043] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,044] The parameter `n_neurons_2` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,045] The parameter `n_neurons_3` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,046] The parameter `n_neurons_4` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,046] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  20%|██        | 20/100 [00:11<00:43,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:15,629] Trial 19 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 29, 'n_neurons_1': 16, 'n_neurons_2': 68, 'n_neurons_3': 12, 'n_neurons_4': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.0002738419634264362, 'alpha': 0.0064938163157621165}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:15,631] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,632] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,633] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,633] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,634] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,635] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,636] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,637] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:15,638] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  21%|██        | 21/100 [00:12<00:46,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:16,313] Trial 20 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0027384196342643626, 'alpha': 0.0006493816315762115}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:16,315] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,316] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,317] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,318] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,318] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,319] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,320] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,321] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,322] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,322] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  22%|██▏       | 22/100 [00:13<00:47,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:16,990] Trial 21 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 18, 'n_neurons_1': 47, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.004869675251658635, 'alpha': 0.000365174127254838}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:16,992] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,993] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,994] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,995] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,995] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,996] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,997] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,998] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,999] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:16,999] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:17,000] The parameter `n_neurons_4` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:17,001] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  23%|██▎       | 23/100 [00:14<01:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:18,329] Trial 22 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 64, 'n_neurons_1': 18, 'n_neurons_2': 39, 'n_neurons_3': 96, 'n_neurons_4': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00048696752516586337, 'alpha': 0.003651741272548378}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:18,332] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,333] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,334] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,334] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,335] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,336] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,337] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,338] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,339] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,339] The parameter `n_neurons_3` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,340] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  24%|██▍       | 24/100 [00:15<00:58,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:18,968] Trial 23 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 20, 'n_neurons_2': 23, 'n_neurons_3': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.0015399265260594922, 'alpha': 0.00011547819846894585}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:18,970] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,971] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,972] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,973] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,974] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,974] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,975] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,976] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:18,977] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  25%|██▌       | 25/100 [00:16<00:57,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:19,696] Trial 24 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 86, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015399265260594933, 'alpha': 0.0011547819846894588}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:19,699] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:19,700] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:19,701] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:19,701] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:19,702] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:19,703] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:19,704] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:19,705] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  26%|██▌       | 26/100 [00:16<00:52,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:20,268] Trial 25 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011547819846894588, 'alpha': 0.004869675251658635}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:20,270] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,271] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,272] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,272] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,273] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,274] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,275] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,276] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,276] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,277] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:20,278] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  27%|██▋       | 27/100 [00:17<00:53,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:21,077] Trial 26 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 69, 'n_neurons_1': 73, 'n_neurons_2': 51, 'n_neurons_3': 67, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011547819846894585, 'alpha': 0.00048696752516586337}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:21,078] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,079] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,080] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,081] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,082] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,083] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,084] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,085] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,086] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,087] The parameter `n_neurons_3` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,088] The parameter `n_neurons_4` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,089] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  28%|██▊       | 28/100 [00:17<00:48,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:21,626] Trial 27 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 46, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.003651741272548378, 'alpha': 0.0015399265260594922}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:21,628] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,629] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,629] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,630] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,631] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,632] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,633] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,634] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,634] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:21,635] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  29%|██▉       | 29/100 [00:18<00:54,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:22,622] Trial 28 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 92, 'n_neurons_1': 64, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.000365174127254838, 'alpha': 0.00015399265260594933}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:22,624] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,625] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,626] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,627] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,628] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,629] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,630] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,631] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:22,632] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  30%|███       | 30/100 [00:19<00:48,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:23,136] Trial 29 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002053525026457149, 'alpha': 0.0002738419634264362}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:23,138] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,139] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,140] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,141] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,141] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,142] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,143] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,144] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,145] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,146] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,147] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  31%|███       | 31/100 [00:20<00:47,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:23,827] Trial 30 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 81, 'n_neurons_1': 46, 'n_neurons_2': 22, 'n_neurons_3': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0020535250264571477, 'alpha': 0.0027384196342643626}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:23,829] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,830] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,831] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,832] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,833] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,834] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,834] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,835] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,836] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:23,837] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  32%|███▏      | 32/100 [00:20<00:44,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:24,391] Trial 31 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 12, 'n_neurons_1': 88, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006493816315762115, 'alpha': 0.000865964323360066}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:24,394] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,395] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,396] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,397] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,398] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,399] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,400] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,400] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  33%|███▎      | 33/100 [00:21<00:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:24,984] Trial 32 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0064938163157621165, 'alpha': 0.008659643233600654}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:24,986] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,987] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,988] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,989] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,990] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,991] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,992] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:24,992] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  34%|███▍      | 34/100 [00:21<00:40,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:25,521] Trial 33 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0025482967479793484, 'alpha': 0.0012409377607517208}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:25,523] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,524] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,525] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,526] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,527] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,528] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,529] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,530] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,531] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,532] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  36%|███▌      | 36/100 [00:22<00:31,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:25,734] Trial 34 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 79, 'n_neurons_1': 66, 'n_neurons_2': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002548296747979348, 'alpha': 0.00012409377607517218}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:25,736] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,737] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,738] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,740] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,741] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,742] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,743] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:25,744] Trial 35 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:25,745] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,747] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,748] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,749] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,750] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,751] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,752] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,753] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:25,754] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  37%|███▋      | 37/100 [00:22<00:23,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:26,200] Trial 36 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 35, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008058421877614828, 'alpha': 0.0003924189758484538}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:26,202] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,203] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,204] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,205] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,206] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,207] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,207] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,208] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,209] The parameter `n_neurons_2` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:26,210] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  38%|███▊      | 38/100 [00:23<00:29,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:27,015] Trial 37 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 22, 'n_neurons_1': 57, 'n_neurons_2': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00014330125702369644, 'alpha': 0.0006978305848598669}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:27,018] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,019] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,020] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,021] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,022] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,022] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,023] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,024] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,025] The parameter `n_neurons_2` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,026] The parameter `n_neurons_3` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,027] The parameter `n_neurons_4` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,028] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  39%|███▉      | 39/100 [00:24<00:33,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:27,753] Trial 38 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 68, 'n_neurons_1': 48, 'n_neurons_2': 56, 'n_neurons_3': 32, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.0014330125702369636, 'alpha': 0.006978305848598664}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:27,755] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,756] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,757] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,758] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,759] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,760] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,761] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,762] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,763] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,764] The parameter `n_neurons_3` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:27,765] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  40%|████      | 40/100 [00:24<00:31,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:28,234] Trial 39 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 45, 'n_neurons_1': 64, 'n_neurons_2': 52, 'n_neurons_3': 47, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045315836376008217, 'alpha': 0.00022067340690845924}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:28,236] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,237] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,238] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,239] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,240] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,241] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,241] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,242] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  41%|████      | 41/100 [00:25<00:31,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:28,795] Trial 40 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0045315836376008225, 'alpha': 0.002206734069084591}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:28,797] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,798] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,799] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,800] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,801] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,802] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,803] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,804] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:28,804] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  42%|████▏     | 42/100 [00:25<00:29,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:29,202] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 17, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00033982083289425634, 'alpha': 0.009305720409296997}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:29,205] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,206] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,207] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,208] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,208] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,209] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,210] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,211] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,212] The parameter `n_neurons_2` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,213] The parameter `n_neurons_3` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,214] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  43%|████▎     | 43/100 [00:26<00:31,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:29,900] Trial 42 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 62, 'n_neurons_1': 77, 'n_neurons_2': 13, 'n_neurons_3': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003398208328942561, 'alpha': 0.0009305720409296995}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:29,902] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,903] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,904] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,906] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,906] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,907] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,908] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,909] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,910] The parameter `n_neurons_2` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,911] The parameter `n_neurons_3` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,911] The parameter `n_neurons_4` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:29,912] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  44%|████▍     | 44/100 [00:26<00:34,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:30,638] Trial 43 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 32, 'n_neurons_2': 41, 'n_neurons_3': 26, 'n_neurons_4': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.00010746078283213182, 'alpha': 0.002942727176209285}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:30,640] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,640] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,641] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,642] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,643] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,644] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,645] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,645] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,646] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:30,647] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  45%|████▌     | 45/100 [00:27<00:34,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:31,302] Trial 44 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 62, 'n_neurons_2': 65, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010746078283213184, 'alpha': 0.0002942727176209287}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:31,305] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,306] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,307] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,308] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,309] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,309] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,310] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,311] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:31,312] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  46%|████▌     | 46/100 [00:28<00:35,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:32,027] Trial 45 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 51, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006042963902381333, 'alpha': 0.00016548170999431823}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:32,029] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,031] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,031] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,032] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,033] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,034] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,035] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,035] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,036] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,037] The parameter `n_neurons_3` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,038] The parameter `n_neurons_4` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,039] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  47%|████▋     | 47/100 [00:29<00:36,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:32,797] Trial 46 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 96, 'n_neurons_1': 42, 'n_neurons_2': 62, 'n_neurons_3': 67, 'n_neurons_4': 11, 'learning_rate': 'constant', 'learning_rate_init': 0.0006042963902381332, 'alpha': 0.0016548170999431827}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:32,799] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,800] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,801] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,802] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,803] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,804] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,805] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,806] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,807] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,808] The parameter `n_neurons_3` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:32,809] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  48%|████▊     | 48/100 [00:30<00:39,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:33,692] Trial 47 finished with value: 0.86 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 28, 'n_neurons_1': 52, 'n_neurons_2': 61, 'n_neurons_3': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019109529749704425, 'alpha': 0.0005232991146814953}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:33,694] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:33,695] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:33,695] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:33,696] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:33,697] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:33,698] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:33,699] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:33,700] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  50%|█████     | 50/100 [00:30<00:24,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:34,112] Trial 48 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.00019109529749704405, 'alpha': 0.005232991146814949}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:34,114] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,115] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,116] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,117] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,118] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,118] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,119] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,120] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:34,228] Trial 49 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.003924189758484535, 'alpha': 0.00019109529749704405}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:34,230] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,231] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,232] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,233] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,233] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,234] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,235] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,236] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,237] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,238] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  51%|█████     | 51/100 [00:31<00:24,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:34,767] Trial 50 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 33, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.0003924189758484538, 'alpha': 0.0019109529749704425}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:34,769] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,770] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,771] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,772] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,773] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,773] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,774] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,775] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,776] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,777] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,778] The parameter `n_neurons_4` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:34,779] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  52%|█████▏    | 52/100 [00:31<00:28,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:35,557] Trial 51 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 54, 'n_neurons_1': 34, 'n_neurons_2': 59, 'n_neurons_3': 67, 'n_neurons_4': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012409377607517208, 'alpha': 0.0006042963902381332}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:35,560] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,561] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,562] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,563] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,564] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,564] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,565] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,566] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:35,567] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  53%|█████▎    | 53/100 [00:32<00:28,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:36,199] Trial 52 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 22, 'learning_rate': 'constant', 'learning_rate_init': 0.00012409377607517218, 'alpha': 0.006042963902381333}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:36,201] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,202] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,203] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,203] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,204] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,205] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,206] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,207] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,208] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,209] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  54%|█████▍    | 54/100 [00:33<00:30,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:36,992] Trial 53 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 45, 'n_neurons_2': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006978305848598669, 'alpha': 0.003398208328942561}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:36,995] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,997] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,998] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:36,999] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,000] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,001] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,002] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,003] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,004] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,005] The parameter `n_neurons_3` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,006] The parameter `n_neurons_4` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,007] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  55%|█████▌    | 55/100 [00:33<00:29,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:37,660] Trial 54 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 80, 'n_neurons_2': 19, 'n_neurons_3': 16, 'n_neurons_4': 76, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006978305848598664, 'alpha': 0.00033982083289425634}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:37,663] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,665] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,666] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,667] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,669] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,670] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,671] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,673] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,674] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,676] The parameter `n_neurons_3` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:37,677] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  56%|█████▌    | 56/100 [00:34<00:32,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:38,585] Trial 55 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 19, 'n_neurons_1': 59, 'n_neurons_2': 89, 'n_neurons_3': 76, 'learning_rate': 'constant', 'learning_rate_init': 0.00022067340690845924, 'alpha': 0.0010746078283213184}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:38,587] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,588] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,589] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,589] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,590] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,591] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,592] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,593] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:38,593] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  57%|█████▋    | 57/100 [00:35<00:30,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:39,199] Trial 56 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 65, 'n_neurons_1': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002206734069084591, 'alpha': 0.00010746078283213182}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:39,201] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,202] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,203] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,204] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,205] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,206] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,207] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,208] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  58%|█████▊    | 58/100 [00:36<00:29,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:39,901] Trial 57 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 48, 'learning_rate': 'constant', 'learning_rate_init': 0.0002942727176209287, 'alpha': 0.00045315836376008217}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:39,903] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,905] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,906] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,907] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,908] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,909] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,910] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,911] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,912] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,913] The parameter `n_neurons_3` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:39,914] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  59%|█████▉    | 59/100 [00:36<00:24,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:40,213] Trial 58 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 93, 'n_neurons_1': 82, 'n_neurons_2': 100, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.002942727176209285, 'alpha': 0.0045315836376008225}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:40,216] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,217] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,217] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,218] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,219] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,220] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,221] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,222] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,223] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,224] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,225] The parameter `n_neurons_4` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:40,226] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  60%|██████    | 60/100 [00:37<00:30,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:41,358] Trial 59 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 25, 'n_neurons_1': 13, 'n_neurons_2': 11, 'n_neurons_3': 99, 'n_neurons_4': 48, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009305720409296995, 'alpha': 0.00014330125702369644}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:41,360] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,361] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,362] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,363] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,364] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,365] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,366] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,367] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,367] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  61%|██████    | 61/100 [00:38<00:26,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:41,906] Trial 60 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 65, 'learning_rate': 'constant', 'learning_rate_init': 0.009305720409296997, 'alpha': 0.0014330125702369636}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:41,910] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,912] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,913] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,914] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,915] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,916] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,917] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,918] The parameter `n_neurons_1` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:41,920] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  62%|██████▏   | 62/100 [00:38<00:26,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:42,574] Trial 61 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 14, 'n_neurons_1': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0016548170999431827, 'alpha': 0.0025482967479793484}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:42,577] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,578] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,580] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,581] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,582] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,583] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,585] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,586] The parameter `n_neurons_1` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,588] The parameter `n_neurons_2` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,590] The parameter `n_neurons_3` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:42,591] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  63%|██████▎   | 63/100 [00:39<00:25,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:43,310] Trial 62 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 59, 'n_neurons_1': 17, 'n_neurons_2': 47, 'n_neurons_3': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00016548170999431823, 'alpha': 0.0002548296747979348}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:43,314] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,315] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,317] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,318] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,320] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,321] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,322] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,323] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,324] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,325] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  64%|██████▍   | 64/100 [00:40<00:23,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:43,895] Trial 63 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 37, 'n_neurons_1': 89, 'n_neurons_2': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005232991146814949, 'alpha': 0.008058421877614822}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:43,897] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,898] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,899] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,900] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,901] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,902] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,903] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:43,904] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  66%|██████▌   | 66/100 [00:41<00:17,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:44,632] Trial 64 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 82, 'learning_rate': 'constant', 'learning_rate_init': 0.0005232991146814953, 'alpha': 0.0008058421877614828}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:44,635] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,636] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,637] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,638] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,638] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,639] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,640] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,642] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:44,751] Trial 65 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004371444812611091, 'alpha': 0.004697588816706496}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:44,755] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,756] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,758] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,759] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,761] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,762] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,763] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,765] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,766] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:44,767] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  67%|██████▋   | 67/100 [00:42<00:26,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:46,215] Trial 66 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 91, 'n_neurons_1': 89, 'n_neurons_2': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0004371444812611094, 'alpha': 0.0004697588816706495}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:46,217] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,218] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,219] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,220] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,222] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,223] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,223] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,225] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,226] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,227] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:46,228] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  68%|██████▊   | 68/100 [00:43<00:26,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:47,057] Trial 67 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 23, 'n_neurons_1': 82, 'n_neurons_2': 73, 'n_neurons_3': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013823722273579005, 'alpha': 0.0014855080171727755}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:47,060] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,061] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,063] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,064] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,065] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,066] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,067] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,069] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,070] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  69%|██████▉   | 69/100 [00:44<00:24,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:47,788] Trial 68 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 69, 'n_neurons_1': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013823722273579014, 'alpha': 0.00014855080171727767}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:47,791] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,792] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,793] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,794] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,795] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,796] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,797] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,799] The parameter `n_neurons_1` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:47,800] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  71%|███████   | 71/100 [00:44<00:19,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:48,162] Trial 69 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 12, 'n_neurons_1': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0007773650302387768, 'alpha': 0.00026416483203860934}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:48,165] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,166] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,167] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,168] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,169] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,170] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,171] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:48,173] Trial 70 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:48,174] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,175] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,176] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,177] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,178] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,179] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,180] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,182] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,183] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,184] The parameter `n_neurons_3` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,185] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  72%|███████▏  | 72/100 [00:44<00:12,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:48,583] Trial 71 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 34, 'n_neurons_1': 66, 'n_neurons_2': 73, 'n_neurons_3': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002458244068920199, 'alpha': 0.000835362546957827}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:48,586] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,587] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,588] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,589] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,590] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,591] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,593] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,594] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  73%|███████▎  | 73/100 [00:45<00:11,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:48,916] Trial 72 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0024582440689201977, 'alpha': 0.008353625469578265}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:48,919] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,920] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,920] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,921] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,922] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,923] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,924] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,925] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:48,926] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  74%|███████▍  | 74/100 [00:46<00:13,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:49,729] Trial 73 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 29, 'n_neurons_1': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018434229924091107, 'alpha': 0.001980956778550341}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:49,733] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,734] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,736] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,738] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,739] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,741] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,742] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,744] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,746] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,747] The parameter `n_neurons_3` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:49,748] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  75%|███████▌  | 75/100 [00:47<00:16,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:50,764] Trial 74 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 74, 'n_neurons_1': 30, 'n_neurons_2': 100, 'n_neurons_3': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0018434229924091127, 'alpha': 0.0001980956778550342}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:50,767] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,768] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,769] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,770] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,771] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,773] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,774] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,776] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,778] The parameter `n_neurons_2` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,779] The parameter `n_neurons_3` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,781] The parameter `n_neurons_4` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:50,782] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  76%|███████▌  | 76/100 [00:47<00:14,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:51,196] Trial 75 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 51, 'n_neurons_1': 62, 'n_neurons_2': 49, 'n_neurons_3': 75, 'n_neurons_4': 54, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005829415347136078, 'alpha': 0.00626433536656886}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:51,199] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,201] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,202] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,204] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,205] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,206] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,207] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,209] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,210] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,211] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  77%|███████▋  | 77/100 [00:47<00:12,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:51,556] Trial 76 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 26, 'n_neurons_2': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.0058294153471360795, 'alpha': 0.0006264335366568858}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:51,558] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,559] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,560] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,561] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,562] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,563] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,564] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,565] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:51,565] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  78%|███████▊  | 78/100 [00:48<00:12,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:52,195] Trial 77 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 51, 'learning_rate': 'constant', 'learning_rate_init': 0.001036632928437698, 'alpha': 0.0003522694651473105}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:52,198] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,199] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,200] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,201] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,201] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,202] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,203] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,204] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,205] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,206] The parameter `n_neurons_3` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,207] The parameter `n_neurons_4` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:52,208] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  79%|███████▉  | 79/100 [00:49<00:16,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:53,493] Trial 78 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 86, 'n_neurons_2': 83, 'n_neurons_3': 63, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00010366329284376988, 'alpha': 0.0035226946514731027}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:53,496] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,497] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,498] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,500] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,501] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,502] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,503] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,505] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,506] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:53,508] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  80%|████████  | 80/100 [00:50<00:14,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:54,059] Trial 79 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 17, 'n_neurons_1': 10, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003278121151393461, 'alpha': 0.0001113973859994803}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:54,061] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,063] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,064] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,065] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,066] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,067] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,068] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,069] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  81%|████████  | 81/100 [00:51<00:14,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:54,941] Trial 80 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.00032781211513934627, 'alpha': 0.001113973859994803}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:54,943] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,944] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,945] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,946] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,947] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,948] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,949] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:54,950] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  82%|████████▏ | 82/100 [00:51<00:11,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:55,315] Trial 81 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002128751661796374, 'alpha': 0.0009646616199111995}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:55,318] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,319] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,320] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,321] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,322] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,323] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,324] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,325] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,326] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,327] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:55,328] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  83%|████████▎ | 83/100 [00:53<00:15,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:56,850] Trial 82 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 83, 'n_neurons_2': 79, 'n_neurons_3': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00021287516617963755, 'alpha': 0.009646616199111998}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:56,853] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,854] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,855] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,856] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,858] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,859] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,860] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,862] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,863] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,864] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,865] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:56,867] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  85%|████████▌ | 85/100 [00:53<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:57,376] Trial 83 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 70, 'n_neurons_2': 66, 'n_neurons_3': 52, 'n_neurons_4': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.006731703824144984, 'alpha': 0.00030505278902670253}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:57,379] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,380] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,382] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,383] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,384] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,385] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,386] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:57,388] Trial 84 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:57,390] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,391] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,392] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,393] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,394] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,395] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,397] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,398] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,399] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:57,400] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  87%|████████▋ | 87/100 [00:54<00:08,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:58,344] Trial 85 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 59, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011970850304957301, 'alpha': 0.0017154378963428801}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:58,347] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,348] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,349] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,350] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,351] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,352] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,353] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:38:58,355] Trial 86 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:58,356] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,357] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,359] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,360] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,361] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,362] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,363] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,364] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,365] The parameter `n_neurons_2` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,366] The parameter `n_neurons_3` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:58,367] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  88%|████████▊ | 88/100 [00:55<00:06,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:59,103] Trial 87 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 31, 'n_neurons_2': 81, 'n_neurons_3': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.0003785515249258633, 'alpha': 0.005424690937011328}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:59,105] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,107] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,108] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,108] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,109] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,110] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,111] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,112] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,113] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  89%|████████▉ | 89/100 [00:56<00:06,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:38:59,894] Trial 88 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00378551524925863, 'alpha': 0.0005424690937011332}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:38:59,897] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,899] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,900] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,902] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,903] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,904] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,906] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:38:59,908] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  90%|█████████ | 90/100 [00:56<00:05,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:00,465] Trial 89 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 37, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005048065716667477, 'alpha': 0.00012863969449369766}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:00,467] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,469] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,470] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,471] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,471] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,472] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,473] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,475] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,476] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,477] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:00,478] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  91%|█████████ | 91/100 [00:57<00:06,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:01,499] Trial 90 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 39, 'n_neurons_2': 40, 'n_neurons_3': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.005048065716667474, 'alpha': 0.0012863969449369757}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:01,502] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,503] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,504] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,505] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,507] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,508] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,509] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,510] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,511] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,512] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,513] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:01,514] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  92%|█████████▏| 92/100 [00:58<00:06,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:02,438] Trial 91 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 70, 'n_neurons_2': 82, 'n_neurons_3': 94, 'n_neurons_4': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.00015963385442879435, 'alpha': 0.0004067944321083049}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:02,442] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,443] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,444] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,446] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,447] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,448] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,449] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,451] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,452] The parameter `n_neurons_2` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,453] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  93%|█████████▎| 93/100 [00:59<00:04,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:02,942] Trial 92 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 60, 'n_neurons_1': 33, 'n_neurons_2': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015963385442879423, 'alpha': 0.0040679443210830495}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:02,945] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,946] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,947] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,948] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,949] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,950] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,951] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,952] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:02,953] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  94%|█████████▍| 94/100 [01:00<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:03,689] Trial 93 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.00897687132447315, 'alpha': 0.007233941627366754}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:03,693] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,694] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,695] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,697] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,698] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,699] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,700] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,701] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,702] The parameter `n_neurons_2` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,704] The parameter `n_neurons_3` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,705] The parameter `n_neurons_4` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:03,706] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "Best trial: 1. Best value: 0.92:  95%|█████████▌| 95/100 [01:01<00:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:05,237] Trial 94 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 71, 'n_neurons_1': 54, 'n_neurons_2': 65, 'n_neurons_3': 79, 'n_neurons_4': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0008976871324473148, 'alpha': 0.0007233941627366753}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:05,240] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,241] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,242] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,243] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,244] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,245] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,246] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,247] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,248] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,249] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  96%|█████████▌| 96/100 [01:02<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:05,726] Trial 95 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0028387359647587583, 'alpha': 0.0022875732003183966}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:05,729] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,730] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,731] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,732] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,733] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,733] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,734] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:05,735] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  97%|█████████▋| 97/100 [01:02<00:02,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:06,520] Trial 96 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002838735964758755, 'alpha': 0.0002287573200318398}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:06,523] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:06,524] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:06,525] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:06,526] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:06,527] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:06,528] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:06,529] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:06,530] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92:  99%|█████████▉| 99/100 [01:03<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:07,279] Trial 97 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006264335366568858, 'alpha': 0.0005048065716667477}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:07,283] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,285] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,287] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,289] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,290] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,292] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,293] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,294] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,296] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,297] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-11-06 03:39:07,443] Trial 98 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 54, 'n_neurons_2': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.00626433536656886, 'alpha': 0.005048065716667474}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-11-06 03:39:07,446] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,447] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,448] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,449] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,449] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,450] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,451] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,452] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,453] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,454] The parameter `n_neurons_3` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-11-06 03:39:07,455] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.92: 100%|██████████| 100/100 [01:04<00:00,  1.55it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-06 03:39:08,223] Trial 99 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 44, 'n_neurons_1': 38, 'n_neurons_2': 72, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001980956778550342, 'alpha': 0.00015963385442879435}. Best is trial 1 with value: 0.92.\n",
      "\n",
      "Selected Base Models for Stacking using QMCSampler:\n",
      "- Logistic Regression\n",
      "- Support Vector Machine\n",
      "- AdaBoost\n",
      "Best Hyperparameters for Meta Model (MLP) using QMCSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.00010000000000000009, 'alpha': 0.00010000000000000009, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (10,), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9200, at trial: 1\n",
      "QMC base models training time: 45.28 seconds\n",
      "QMC SEl-NNML Training Time: 64.94 seconds\n",
      "Total QMC Training Time (Base + Meta): 110.22 seconds\n",
      "QMC base models training time: 45.28 seconds\n",
      "QMC SEl-NNML Training Time: 64.94 seconds\n",
      "Total QMC Training Time (Base + Meta): 110.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nawo/.conda/envs/mlkit/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    qmc_sel_nnml, qmc_meta_study = meta_model_tuning(base_models['QMC'], X_train, y_train, X_test, y_test, sampler='QMCSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    qmc_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC SEl-NNML training\n",
    "    qmc_meta_model_training_time = qmc_meta_model_training_end - qmc_meta_model_training_start\n",
    "    print(f'QMC base models training time: {qmc_base_models_training_time:.2f} seconds')\n",
    "    print(f'QMC SEl-NNML Training Time: {qmc_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total QMC Training Time (Base + Meta): {qmc_base_models_training_time + qmc_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    qmc_meta_history = qmc_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    qmc_meta_history.columns = ['iteration', 'score']\n",
    "    qmc_meta_history['iteration'] = qmc_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping QMC meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Best Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.05856966305534113, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPE</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 30, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.00853675785145888, 'break_ties': False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPE</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TPE</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Logistic Regress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GP</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.02891295150832041, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GP</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GP</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 30, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GP</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.009999999999999995, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GP</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GP</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Random Forest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.05851500684973518, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 30, 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.007082326034013085, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Logistic Regress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.05935229272296987, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QMC</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 30, 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.008058421877614822, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>QMC</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>QMC</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Logistic Regress...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampler              Model Name  \\\n",
       "0      TPE     Logistic Regression   \n",
       "1      TPE           Decision Tree   \n",
       "2      TPE           Random Forest   \n",
       "3      TPE     K-Nearest Neighbors   \n",
       "4      TPE  Support Vector Machine   \n",
       "5      TPE                AdaBoost   \n",
       "6      TPE       Gradient Boosting   \n",
       "7      TPE                SEL-NNML   \n",
       "8       GP     Logistic Regression   \n",
       "9       GP           Decision Tree   \n",
       "10      GP           Random Forest   \n",
       "11      GP     K-Nearest Neighbors   \n",
       "12      GP  Support Vector Machine   \n",
       "13      GP                AdaBoost   \n",
       "14      GP       Gradient Boosting   \n",
       "15      GP                SEL-NNML   \n",
       "16  CMA-ES     Logistic Regression   \n",
       "17  CMA-ES           Decision Tree   \n",
       "18  CMA-ES           Random Forest   \n",
       "19  CMA-ES     K-Nearest Neighbors   \n",
       "20  CMA-ES  Support Vector Machine   \n",
       "21  CMA-ES                AdaBoost   \n",
       "22  CMA-ES       Gradient Boosting   \n",
       "23  CMA-ES                SEL-NNML   \n",
       "24     QMC     Logistic Regression   \n",
       "25     QMC           Decision Tree   \n",
       "26     QMC           Random Forest   \n",
       "27     QMC     K-Nearest Neighbors   \n",
       "28     QMC  Support Vector Machine   \n",
       "29     QMC                AdaBoost   \n",
       "30     QMC       Gradient Boosting   \n",
       "31     QMC                SEL-NNML   \n",
       "\n",
       "                                 Best Hyperparameters  \n",
       "0   {'C': 0.05856966305534113, 'class_weight': Non...  \n",
       "1   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "2   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "3   {'algorithm': 'ball_tree', 'leaf_size': 30, 'm...  \n",
       "4   {'C': 0.00853675785145888, 'break_ties': False...  \n",
       "5   {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "6   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "7   {'cv': None, 'estimators': [('Logistic Regress...  \n",
       "8   {'C': 0.02891295150832041, 'class_weight': Non...  \n",
       "9   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "10  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "11  {'algorithm': 'ball_tree', 'leaf_size': 30, 'm...  \n",
       "12  {'C': 0.009999999999999995, 'break_ties': Fals...  \n",
       "13  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "14  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "15  {'cv': None, 'estimators': [('Random Forest', ...  \n",
       "16  {'C': 0.05851500684973518, 'class_weight': Non...  \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "18  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "19  {'algorithm': 'kd_tree', 'leaf_size': 30, 'met...  \n",
       "20  {'C': 0.007082326034013085, 'break_ties': Fals...  \n",
       "21  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "22  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "23  {'cv': None, 'estimators': [('Logistic Regress...  \n",
       "24  {'C': 0.05935229272296987, 'class_weight': Non...  \n",
       "25  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "26  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "27  {'algorithm': 'kd_tree', 'leaf_size': 30, 'met...  \n",
       "28  {'C': 0.008058421877614822, 'break_ties': Fals...  \n",
       "29  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "30  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "31  {'cv': None, 'estimators': [('Logistic Regress...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # All Models Storage for all sampler types\n",
    "    all_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting,\n",
    "            'SEL-NNML': tpe_sel_nnml\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting,\n",
    "            'SEL-NNML': gp_sel_nnml\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting,\n",
    "            'SEL-NNML': cmaes_sel_nnml\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting,\n",
    "            'SEL-NNML': qmc_sel_nnml\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save Every Best Model Config for each Tuning Method (Base + Meta) as CSV\n",
    "    all_model_hyperparameters = []\n",
    "    for sampler, models in all_models.items():\n",
    "        for model_name, model in models.items():\n",
    "            # Some meta models (e.g., stacking) may not have get_params, handle gracefully\n",
    "            params = model.get_params() if hasattr(model, 'get_params') else None\n",
    "            all_model_hyperparameters.append({\n",
    "                'Sampler': sampler,\n",
    "                'Model Name': model_name,\n",
    "                'Best Hyperparameters': params\n",
    "            })\n",
    "    all_model_hyperparameters_df = pd.DataFrame(all_model_hyperparameters)\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs('../artifacts/ds1/models', exist_ok=True)\n",
    "    \n",
    "    all_model_hyperparameters_df.to_csv('../artifacts/ds1/models/all_model_hyperparameters.csv', index=False)\n",
    "\n",
    "    # Show All Model Hyperparameters for all samplers\n",
    "    display(all_model_hyperparameters_df)\n",
    "else:\n",
    "    print(\"Skipping model storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Logistic Regression model tuned with TPE to ../artifacts/ds1/models/tpe/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with TPE to ../artifacts/ds1/models/tpe/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with TPE to ../artifacts/ds1/models/tpe/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with TPE to ../artifacts/ds1/models/tpe/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with TPE to ../artifacts/ds1/models/tpe/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with TPE to ../artifacts/ds1/models/tpe/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with TPE to ../artifacts/ds1/models/tpe/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with TPE to ../artifacts/ds1/models/tpe/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with GP to ../artifacts/ds1/models/gp/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with GP to ../artifacts/ds1/models/gp/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with GP to ../artifacts/ds1/models/gp/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with GP to ../artifacts/ds1/models/gp/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with GP to ../artifacts/ds1/models/gp/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with GP to ../artifacts/ds1/models/gp/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with GP to ../artifacts/ds1/models/gp/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with GP to ../artifacts/ds1/models/gp/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with QMC to ../artifacts/ds1/models/qmc/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with QMC to ../artifacts/ds1/models/qmc/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with QMC to ../artifacts/ds1/models/qmc/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with QMC to ../artifacts/ds1/models/qmc/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with QMC to ../artifacts/ds1/models/qmc/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with QMC to ../artifacts/ds1/models/qmc/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with QMC to ../artifacts/ds1/models/qmc/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with QMC to ../artifacts/ds1/models/qmc/sel-nnml_best_model.pkl\n",
      "Saved SEL-NNML model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with QMC to ../artifacts/ds1/models/qmc/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with QMC to ../artifacts/ds1/models/qmc/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with QMC to ../artifacts/ds1/models/qmc/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with QMC to ../artifacts/ds1/models/qmc/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with QMC to ../artifacts/ds1/models/qmc/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with QMC to ../artifacts/ds1/models/qmc/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with QMC to ../artifacts/ds1/models/qmc/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with QMC to ../artifacts/ds1/models/qmc/sel-nnml_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # Save Every Best Meta Model for each Tuning Method as .pkl\n",
    "    for sampler, models in all_models.items():\n",
    "        folder = sampler.lower().replace(\"-\", \"\")\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(f'../artifacts/ds1/models/{folder}', exist_ok=True)\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            filename = f'../artifacts/ds1/models/{folder}/{model_name.replace(\" \", \"_\").lower()}_best_model.pkl'\n",
    "            joblib.dump(model, filename)\n",
    "            print(f'Saved {model_name} model tuned with {sampler} to {filename}')\n",
    "else:\n",
    "    print(\"Skipping model saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Base Models Training Time (seconds)</th>\n",
       "      <th>Meta Model Training Time (seconds)</th>\n",
       "      <th>Total Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>47.763813</td>\n",
       "      <td>102.657846</td>\n",
       "      <td>150.421659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>154.417026</td>\n",
       "      <td>79.112374</td>\n",
       "      <td>233.529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>49.518511</td>\n",
       "      <td>69.105992</td>\n",
       "      <td>118.624503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QMC</td>\n",
       "      <td>45.283746</td>\n",
       "      <td>64.937510</td>\n",
       "      <td>110.221256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sampler  Base Models Training Time (seconds)  \\\n",
       "0     TPE                            47.763813   \n",
       "1      GP                           154.417026   \n",
       "2  CMA-ES                            49.518511   \n",
       "3     QMC                            45.283746   \n",
       "\n",
       "   Meta Model Training Time (seconds)  Total Training Time (seconds)  \n",
       "0                          102.657846                     150.421659  \n",
       "1                           79.112374                     233.529400  \n",
       "2                           69.105992                     118.624503  \n",
       "3                           64.937510                     110.221256  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # SAVE TRAIN TIME FOR EACH SAMPLER TYPE (BASE + META) IN A FILE\n",
    "    train_times = {\n",
    "        'Sampler': ['TPE', 'GP', 'CMA-ES', 'QMC'],\n",
    "        'Base Models Training Time (seconds)': [\n",
    "            tpe_base_models_training_time,\n",
    "            gp_base_models_training_time,\n",
    "            cmaes_base_models_training_time,\n",
    "            qmc_base_models_training_time\n",
    "        ],\n",
    "        'Meta Model Training Time (seconds)': [\n",
    "            tpe_meta_model_training_time,\n",
    "            gp_meta_model_training_time,\n",
    "            cmaes_meta_model_training_time,\n",
    "            qmc_meta_model_training_time\n",
    "        ],\n",
    "        'Total Training Time (seconds)': [\n",
    "            tpe_base_models_training_time + tpe_meta_model_training_time,\n",
    "            gp_base_models_training_time + gp_meta_model_training_time,\n",
    "            cmaes_base_models_training_time + cmaes_meta_model_training_time,\n",
    "            qmc_base_models_training_time + qmc_meta_model_training_time\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    train_times_df = pd.DataFrame(train_times)\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs('../artifacts/ds1/models', exist_ok=True)\n",
    "    \n",
    "    train_times_df.to_csv('../artifacts/ds1/models/training_times.csv', index=False)\n",
    "    display(train_times_df)\n",
    "else:\n",
    "    print(\"Skipping training times saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TPE SEL-NNML training history to ../artifacts/ds1/models/tpe/sel-nnml_training_history.csv\n",
      "Saved GP SEL-NNML training history to ../artifacts/ds1/models/gp/sel-nnml_training_history.csv\n",
      "Saved CMA-ES SEL-NNML training history to ../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv\n",
      "Saved QMC SEL-NNML training history to ../artifacts/ds1/models/qmc/sel-nnml_training_history.csv\n",
      "\n",
      "Sample of TPE SEL-NNML Training History (first 10 iterations):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration     score\n",
       "0          1  0.893333\n",
       "1          2  0.913333\n",
       "2          3  0.913333\n",
       "3          4  0.913333\n",
       "4          5  0.900000\n",
       "5          6  0.913333\n",
       "6          7  0.900000\n",
       "7          8  0.893333\n",
       "8          9  0.000000\n",
       "9         10  0.900000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # SAVE SEL-NNML TRAINING HISTORY (CONVERGENCE DATA) FOR EACH SAMPLER\n",
    "    # These will be used to create convergence plots showing how the model performance\n",
    "    # improved over the 100 optimization iterations\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    # Ensure directories exist for each sampler\n",
    "    samplers = ['tpe', 'gp', 'cmaes', 'qmc']\n",
    "    for sampler in samplers:\n",
    "        os.makedirs(f'../artifacts/ds1/models/{sampler}', exist_ok=True)\n",
    "    \n",
    "    # Save TPE SEL-NNML training history\n",
    "    tpe_meta_history.to_csv('../artifacts/ds1/models/tpe/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved TPE SEL-NNML training history to ../artifacts/ds1/models/tpe/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save GP SEL-NNML training history\n",
    "    gp_meta_history.to_csv('../artifacts/ds1/models/gp/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved GP SEL-NNML training history to ../artifacts/ds1/models/gp/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save CMA-ES SEL-NNML training history\n",
    "    cmaes_meta_history.to_csv('../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved CMA-ES SEL-NNML training history to ../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save QMC SEL-NNML training history\n",
    "    qmc_meta_history.to_csv('../artifacts/ds1/models/qmc/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved QMC SEL-NNML training history to ../artifacts/ds1/models/qmc/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Display a sample of one history to verify the data\n",
    "    print(\"\\nSample of TPE SEL-NNML Training History (first 10 iterations):\")\n",
    "    display(tpe_meta_history.head(10))\n",
    "else:\n",
    "    print(\"Skipping SEL-NNML training history saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP_TRAINING is False. Models should be trained in steps 4 and 5.\n"
     ]
    }
   ],
   "source": [
    "# Skip step 4 and load every best model for each tuning method if SKIP_TRAINING is True\n",
    "if SKIP_TRAINING:\n",
    "    print(\"Loading pre-existing models...\")\n",
    "    all_models = {sampler: {\n",
    "            'Logistic Regression': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/logistic_regression_best_model.pkl'),\n",
    "            'Decision Tree': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/decision_tree_best_model.pkl'),\n",
    "            'Random Forest': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/random_forest_best_model.pkl'),\n",
    "            'K-Nearest Neighbors': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/k-nearest_neighbors_best_model.pkl'),\n",
    "            'Support Vector Machine': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/support_vector_machine_best_model.pkl'),\n",
    "            'AdaBoost': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/adaboost_best_model.pkl'),\n",
    "            'Gradient Boosting': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/gradient_boosting_best_model.pkl'),\n",
    "            'SEL-NNML': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/sel-nnml_best_model.pkl')\n",
    "        } for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']}\n",
    "    print(\"All models loaded successfully!\")\n",
    "    \n",
    "    # Load training times\n",
    "    print(\"Loading training times...\")\n",
    "    train_times_df = pd.read_csv('../artifacts/ds1/models/training_times.csv')\n",
    "    \n",
    "    # Extract individual training times for each sampler\n",
    "    for idx, row in train_times_df.iterrows():\n",
    "        sampler = row['Sampler']\n",
    "        if sampler == 'TPE':\n",
    "            tpe_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            tpe_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'GP':\n",
    "            gp_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            gp_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'CMA-ES':\n",
    "            cmaes_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            cmaes_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'QMC':\n",
    "            qmc_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            qmc_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "    \n",
    "    print(\"Training times loaded successfully!\")\n",
    "    display(train_times_df)\n",
    "    \n",
    "    # Load SEL-NNML training histories for convergence plots\n",
    "    print(\"\\nLoading SEL-NNML training histories...\")\n",
    "    tpe_meta_history = pd.read_csv('../artifacts/ds1/models/tpe/sel-nnml_training_history.csv')\n",
    "    gp_meta_history = pd.read_csv('../artifacts/ds1/models/gp/sel-nnml_training_history.csv')\n",
    "    cmaes_meta_history = pd.read_csv('../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv')\n",
    "    qmc_meta_history = pd.read_csv('../artifacts/ds1/models/qmc/sel-nnml_training_history.csv')\n",
    "    print(\"SEL-NNML training histories loaded successfully!\")\n",
    "else:\n",
    "    print(\"SKIP_TRAINING is False. Models should be trained in steps 4 and 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Save Baseline Models**\n",
    "\n",
    "Save default base models and stacking models for later evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Logistic Regression default model to ../artifacts/ds1/models/baseline/logistic_regression_default_model.pkl\n",
      "Saved Decision Tree default model to ../artifacts/ds1/models/baseline/decision_tree_default_model.pkl\n",
      "Saved Random Forest default model to ../artifacts/ds1/models/baseline/random_forest_default_model.pkl\n",
      "Saved K-Nearest Neighbors default model to ../artifacts/ds1/models/baseline/k-nearest_neighbors_default_model.pkl\n",
      "Saved Support Vector Machine default model to ../artifacts/ds1/models/baseline/support_vector_machine_default_model.pkl\n",
      "Saved AdaBoost default model to ../artifacts/ds1/models/baseline/adaboost_default_model.pkl\n",
      "Saved Gradient Boosting default model to ../artifacts/ds1/models/baseline/gradient_boosting_default_model.pkl\n",
      "Saved Stacking + Linear Regression model to ../artifacts/ds1/models/baseline/stacking_lr_model.pkl\n",
      "Saved Stacking + Default MLP model to ../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl\n",
      "Saved baseline training times to ../artifacts/ds1/models/baseline/baseline_training_times.csv\n",
      "Saved Stacking + Linear Regression model to ../artifacts/ds1/models/baseline/stacking_lr_model.pkl\n",
      "Saved Stacking + Default MLP model to ../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl\n",
      "Saved baseline training times to ../artifacts/ds1/models/baseline/baseline_training_times.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Base Models</td>\n",
       "      <td>0.522654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stacking + Linear Regression</td>\n",
       "      <td>2.838612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking + Default MLP</td>\n",
       "      <td>1.148985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Type  Training Time (seconds)\n",
       "0           Default Base Models                 0.522654\n",
       "1  Stacking + Linear Regression                 2.838612\n",
       "2        Stacking + Default MLP                 1.148985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # Save default base models\n",
    "    os.makedirs('../artifacts/ds1/models/baseline', exist_ok=True)\n",
    "    \n",
    "    for model_name, model in default_base_models.items():\n",
    "        filename = f'../artifacts/ds1/models/baseline/{model_name.replace(\" \", \"_\").lower()}_default_model.pkl'\n",
    "        joblib.dump(model, filename)\n",
    "        print(f'Saved {model_name} default model to {filename}')\n",
    "    \n",
    "    # Save stacking models\n",
    "    joblib.dump(stacking_lr, '../artifacts/ds1/models/baseline/stacking_lr_model.pkl')\n",
    "    print(f'Saved Stacking + Linear Regression model to ../artifacts/ds1/models/baseline/stacking_lr_model.pkl')\n",
    "    \n",
    "    joblib.dump(stacking_mlp, '../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    print(f'Saved Stacking + Default MLP model to ../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    \n",
    "    # Save baseline training times\n",
    "    baseline_times = pd.DataFrame({\n",
    "        'Model Type': ['Default Base Models', 'Stacking + Linear Regression', 'Stacking + Default MLP'],\n",
    "        'Training Time (seconds)': [default_models_training_time, stack_lr_training_time, stack_mlp_training_time]\n",
    "    })\n",
    "    baseline_times.to_csv('../artifacts/ds1/models/baseline/baseline_training_times.csv', index=False)\n",
    "    print(f'Saved baseline training times to ../artifacts/ds1/models/baseline/baseline_training_times.csv')\n",
    "    \n",
    "    display(baseline_times)\n",
    "else:\n",
    "    print(\"Skipping baseline model saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP_TRAINING is False. Models should be trained in sections 3.1-3.3.\n"
     ]
    }
   ],
   "source": [
    "if SKIP_TRAINING:\n",
    "    print(\"Loading baseline models...\")\n",
    "    \n",
    "    # Load default base models\n",
    "    default_base_models = {\n",
    "        'Logistic Regression': joblib.load('../artifacts/ds1/models/baseline/logistic_regression_default_model.pkl'),\n",
    "        'Decision Tree': joblib.load('../artifacts/ds1/models/baseline/decision_tree_default_model.pkl'),\n",
    "        'Random Forest': joblib.load('../artifacts/ds1/models/baseline/random_forest_default_model.pkl'),\n",
    "        'K-Nearest Neighbors': joblib.load('../artifacts/ds1/models/baseline/k-nearest_neighbors_default_model.pkl'),\n",
    "        'Support Vector Machine': joblib.load('../artifacts/ds1/models/baseline/support_vector_machine_default_model.pkl'),\n",
    "        'AdaBoost': joblib.load('../artifacts/ds1/models/baseline/adaboost_default_model.pkl'),\n",
    "        'Gradient Boosting': joblib.load('../artifacts/ds1/models/baseline/gradient_boosting_default_model.pkl')\n",
    "    }\n",
    "    \n",
    "    # Load stacking models\n",
    "    stacking_lr = joblib.load('../artifacts/ds1/models/baseline/stacking_lr_model.pkl')\n",
    "    stacking_mlp = joblib.load('../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    \n",
    "    # Load baseline training times\n",
    "    baseline_times = pd.read_csv('../artifacts/ds1/models/baseline/baseline_training_times.csv')\n",
    "    \n",
    "    # Extract training times\n",
    "    default_models_training_time = baseline_times[baseline_times['Model Type'] == 'Default Base Models']['Training Time (seconds)'].values[0]\n",
    "    stack_lr_training_time = baseline_times[baseline_times['Model Type'] == 'Stacking + Linear Regression']['Training Time (seconds)'].values[0]\n",
    "    stack_mlp_training_time = baseline_times[baseline_times['Model Type'] == 'Stacking + Default MLP']['Training Time (seconds)'].values[0]\n",
    "    \n",
    "    print(\"✓ All baseline models loaded successfully!\")\n",
    "    display(baseline_times)\n",
    "else:\n",
    "    print(\"SKIP_TRAINING is False. Models should be trained in sections 3.1-3.3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage contains model evaluation on the test set, with details as follows:\n",
    "- `plot_evaluation_metrics()`: Shows the confusion matrix graph & scores for accuracy, precision, recall, and F1-Score\n",
    "- `Model Performance Comparison Plot`: Displays accuracy, precision, recall, F1-Score, and ROC AUC scores\n",
    "- `overfitting_index_plot()`: Shows the percentage of the difference between model scores on test data versus training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Model Evaluation Dashboard\n",
    "def evaluation_metrics_plot(y_true, y_pred):\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "    }\n",
    "    metric_order = ['F1-Score', 'Recall', 'Precision', 'Accuracy']\n",
    "    values = [metrics[name] for name in metric_order]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    cm_pos = [0.08, 0.15, 0.53, 0.7]\n",
    "    metrics_pos = [0.75, 0.15, 0.21, 0.7]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    ax_cm = fig.add_axes(cm_pos)\n",
    "    im = ax_cm.imshow(cm, cmap='Blues', interpolation='nearest', aspect='equal')\n",
    "    cbar_ax = fig.add_axes([cm_pos[0] + cm_pos[2] + 0.02, cm_pos[1], 0.02, cm_pos[3]])\n",
    "    fig.colorbar(im, cax=cbar_ax).ax.tick_params(labelsize=16)\n",
    "\n",
    "    cm_pct = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count, pct = int(cm[i, j]), cm_pct[i, j]\n",
    "            color = 'white' if count > cm.max() / 2 else 'black'\n",
    "            ax_cm.text(j, i, f'{count}\\n({pct:.1f}%)', ha='center', va='center',\n",
    "                    color=color, fontsize=18, fontweight='bold', linespacing=1.1)\n",
    "\n",
    "    ax_cm.set_xticks([0, 1])\n",
    "    ax_cm.set_yticks([0, 1])\n",
    "    ax_cm.set_xticklabels(['No\\n(0)', 'Disease\\n(1)'], fontsize=16)\n",
    "    ax_cm.set_yticklabels(['No (0)', 'Disease (1)'], fontsize=16, rotation=90, va='center')\n",
    "    ax_cm.set_xlabel('Predicted', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_ylabel('Actual', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_title('Confusion Matrix', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_cm.set_ylim(1.5, -0.5)\n",
    "\n",
    "    # Metrics Bar\n",
    "    ax_metrics = fig.add_axes(metrics_pos)\n",
    "    y_positions = np.arange(len(metric_order)) * 2\n",
    "    bars = ax_metrics.barh(y_positions, values, height=0.8, color='#31688E', alpha=0.8)\n",
    "\n",
    "    for bar, value in zip(bars, values):\n",
    "        color = 'white' if value > 0.5 else 'black'\n",
    "        x_pos = value - 0.02 if value > 0.5 else value + 0.02\n",
    "        ha = 'right' if value > 0.5 else 'left'\n",
    "        ax_metrics.text(x_pos, bar.get_y() + bar.get_height()/2, f'{value:.3f}',\n",
    "                        ha=ha, va='center', fontsize=18, fontweight='bold', color=color)\n",
    "\n",
    "    ax_metrics.set_xlim(-0.05, 1.05)\n",
    "    ax_metrics.set_ylim(-0.8, len(metric_order) * 2 - 0.2)\n",
    "    ax_metrics.set_xticks([0, 0.5, 1.0])\n",
    "    ax_metrics.set_xticklabels(['0.0', '0.5', '1.0'], fontsize=16)\n",
    "    ax_metrics.set_yticks(y_positions)\n",
    "    ax_metrics.set_yticklabels(metric_order, fontsize=16, rotation=90, ha='left', va='center')\n",
    "    ax_metrics.tick_params(axis='y', pad=15)\n",
    "    ax_metrics.tick_params(axis='x', pad=8)\n",
    "    ax_metrics.set_xlabel('Score', fontsize=16, fontweight='bold')\n",
    "    ax_metrics.set_title('Performance Metrics', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_metrics.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    for spine in ['top', 'right', 'left']:\n",
    "        ax_metrics.spines[spine].set_visible(False)\n",
    "    ax_metrics.spines['bottom'].set_alpha(0.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Model Comparison Dashboard (for comparing all models)\n",
    "def model_comparison_plot(models, x_test, y_test):\n",
    "    metrics = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'F1-Score': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "    \n",
    "    # Map full names to short names\n",
    "    short_names = {\n",
    "        'Logistic Regression': 'LR',\n",
    "        'Decision Tree': 'DT',\n",
    "        'Random Forest': 'RF',\n",
    "        'K-Nearest Neighbors': 'KNN',\n",
    "        'Support Vector Machine': 'SVM',\n",
    "        'AdaBoost': 'AdaBoost',\n",
    "        'Gradient Boosting': 'Gradient Boosting',\n",
    "        'SEL-NNML': 'SEL-NNML'\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics for each model\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(x_test)\n",
    "        metrics['Model'].append(short_names[model_name])\n",
    "        metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['F1-Score'].append(f1_score(y_test, y_pred))\n",
    "        metrics['Precision'].append(precision_score(y_test, y_pred))\n",
    "        metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "        \n",
    "        # Calculate AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        metrics['AUC'].append(roc_auc)\n",
    "    \n",
    "    # Convert metrics to DataFrame for sorting\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "    fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold') \n",
    "    \n",
    "    # Helper function to plot sorted bar charts\n",
    "    def plot_sorted_bar_chart(ax, metric_name):\n",
    "        sorted_df = metrics_df.sort_values(by=metric_name, ascending=False)\n",
    "        colors = ['tab:orange' if model == 'SEL-NNML' else 'tab:blue' for model in sorted_df['Model']]\n",
    "        ax.bar(sorted_df['Model'], sorted_df[metric_name], color=colors)\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_xticks(range(len(sorted_df['Model'])))\n",
    "        ax.set_xticklabels(sorted_df['Model'], rotation=30, ha='center')\n",
    "        for i, v in enumerate(sorted_df[metric_name]):\n",
    "            ax.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "    # Plot each metric\n",
    "    plot_sorted_bar_chart(axes[0, 0], 'Accuracy')\n",
    "    plot_sorted_bar_chart(axes[0, 1], 'F1-Score')\n",
    "    plot_sorted_bar_chart(axes[1, 0], 'Precision')\n",
    "    plot_sorted_bar_chart(axes[1, 1], 'Recall')\n",
    "    \n",
    "    # ROC Curve\n",
    "    ax_roc = axes[2, 0]\n",
    "    for model_name, model in models.items():\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax_roc.plot(fpr, tpr, lw=2, label=f'{short_names[model_name]} (AUC = {roc_auc:.3f})')\n",
    "    ax_roc.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_title('Receiver Operating Characteristic')\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Bar chart for AUC\n",
    "    plot_sorted_bar_chart(axes[2, 1], 'AUC')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfitting_index_plot(all_models, x_train, y_train, x_test, y_test):\n",
    "    metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "    overfitting_indices = {metric: [] for metric in metrics}\n",
    "\n",
    "    for _, model in all_models.items():\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "        overfitting_indices['Accuracy'].append(abs(accuracy_score(y_train, y_train_pred) - accuracy_score(y_test, y_test_pred)) / accuracy_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['F1-Score'].append(abs(f1_score(y_train, y_train_pred) - f1_score(y_test, y_test_pred)) / f1_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Precision'].append(abs(precision_score(y_train, y_train_pred) - precision_score(y_test, y_test_pred)) / precision_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Recall'].append(abs(recall_score(y_train, y_train_pred) - recall_score(y_test, y_test_pred)) / recall_score(y_train, y_train_pred) * 100)\n",
    "\n",
    "    overfitting_df = pd.DataFrame(overfitting_indices, index=all_models.keys())\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Overfitting Index for All Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "    def get_bar_colors(models, highlight_model='SEL-NNML', default_color='tab:blue', highlight_color='tab:orange'):\n",
    "        return [highlight_color if model == highlight_model else default_color for model in models]\n",
    "\n",
    "    # Accuracy\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Accuracy', ascending=False)\n",
    "    axes[0, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Accuracy'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 0].set_title('Accuracy Overfitting Index')\n",
    "    axes[0, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 0].set_ylim([0, 100])\n",
    "    axes[0, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Accuracy']):\n",
    "        axes[0, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # F1-Score\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='F1-Score', ascending=False)\n",
    "    axes[0, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['F1-Score'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 1].set_title('F1-Score Overfitting Index')\n",
    "    axes[0, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 1].set_ylim([0, 100])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['F1-Score']):\n",
    "        axes[0, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Precision\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Precision', ascending=False)\n",
    "    axes[1, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Precision'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 0].set_title('Precision Overfitting Index')\n",
    "    axes[1, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 0].set_ylim([0, 100])\n",
    "    axes[1, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Precision']):\n",
    "        axes[1, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Recall\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Recall', ascending=False)\n",
    "    axes[1, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['Recall'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 1].set_title('Recall Overfitting Index')\n",
    "    axes[1, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 1].set_ylim([0, 100])\n",
    "    axes[1, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Recall']):\n",
    "        axes[1, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 SEL-NNML Model Evaluation**\n",
    "\n",
    "This section evaluates the SEL-NNML model from the selected sampler. Change `SELECTED_SAMPLER` in the cell below to evaluate a different sampler's SEL-NNML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sampler: TPE\n",
      "Models available: ['Logistic Regression', 'Decision Tree', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine', 'AdaBoost', 'Gradient Boosting', 'SEL-NNML']\n"
     ]
    }
   ],
   "source": [
    "# Select which sampler's models to evaluate\n",
    "# Options: 'TPE', 'GP', 'CMA-ES', 'QMC'\n",
    "SELECTED_SAMPLER = 'TPE'\n",
    "\n",
    "# Extract models and training times for the selected sampler\n",
    "selected_models = all_models[SELECTED_SAMPLER]\n",
    "sel_nnml = selected_models['SEL-NNML']\n",
    "\n",
    "# Extract training times for the selected sampler\n",
    "if SELECTED_SAMPLER == 'TPE':\n",
    "    base_models_training_time = tpe_base_models_training_time\n",
    "    meta_model_training_time = tpe_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'GP':\n",
    "    base_models_training_time = gp_base_models_training_time\n",
    "    meta_model_training_time = gp_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'CMA-ES':\n",
    "    base_models_training_time = cmaes_base_models_training_time\n",
    "    meta_model_training_time = cmaes_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'QMC':\n",
    "    base_models_training_time = qmc_base_models_training_time\n",
    "    meta_model_training_time = qmc_meta_model_training_time\n",
    "\n",
    "print(f'Selected sampler: {SELECTED_SAMPLER}')\n",
    "print(f'Models available: {list(selected_models.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show SEL-NNML Evaluation Metrics\n",
    "y_pred_stack = sel_nnml.predict(X_test)\n",
    "evaluation_metrics_plot(y_test, y_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: [0.86666667 0.85714286 0.87394958 0.79831933 0.84033613]\n",
      "Mean: 0.8473\n",
      "Standard Deviation: 0.0269\n"
     ]
    }
   ],
   "source": [
    "# Show SEL-NNM: all fold scores with mean and std \n",
    "sel_nnml_cv_scores = cross_val_score(sel_nnml, X_train, y_train, cv=CV_FOLDS, scoring='accuracy', n_jobs=N_JOBS)\n",
    "print(f'SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: {sel_nnml_cv_scores}')\n",
    "print(f'Mean: {sel_nnml_cv_scores.mean():.4f}')\n",
    "print(f'Standard Deviation: {sel_nnml_cv_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Models Tuning & Training Time: 47.76 seconds\n",
      "Meta Model Tuning & Training Time: 102.66 seconds\n",
      "Total SEL-NNML Tuning & Training Time: 150.42 seconds\n"
     ]
    }
   ],
   "source": [
    "# Show SELL-NNML Training Time\n",
    "Total_training_time = base_models_training_time + meta_model_training_time\n",
    "print(f'Base Models Tuning & Training Time: {base_models_training_time:.2f} seconds')\n",
    "print(f'Meta Model Tuning & Training Time: {meta_model_training_time:.2f} seconds')\n",
    "print(f'Total SEL-NNML Tuning & Training Time: {Total_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Multiple Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation below compares all models (base models + SEL-NNML) for the selected sampler. To compare models across different samplers, change the `SELECTED_SAMPLER` variable in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the selected sampler's models for comparison\n",
    "model_comparison_plot(selected_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the selected sampler's models for overfitting index comparison\n",
    "overfitting_index_plot(selected_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating feature importance for TPE...\n",
      "✓ Saved TPE feature importance to: ../artifacts/ds1/models/tpe/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for GP...\n",
      "✓ Saved TPE feature importance to: ../artifacts/ds1/models/tpe/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for GP...\n",
      "✓ Saved GP feature importance to: ../artifacts/ds1/models/gp/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for CMA-ES...\n",
      "✓ Saved GP feature importance to: ../artifacts/ds1/models/gp/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for CMA-ES...\n",
      "✓ Saved CMA-ES feature importance to: ../artifacts/ds1/models/cmaes/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for QMC...\n",
      "✓ Saved CMA-ES feature importance to: ../artifacts/ds1/models/cmaes/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for QMC...\n",
      "✓ Saved QMC feature importance to: ../artifacts/ds1/models/qmc/sel-nnml_feature_importance.csv\n",
      "\n",
      "All feature importance data saved successfully!\n",
      "✓ Saved QMC feature importance to: ../artifacts/ds1/models/qmc/sel-nnml_feature_importance.csv\n",
      "\n",
      "All feature importance data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save feature importance results for all samplers\n",
    "import os\n",
    "\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    # Set the sampler\n",
    "    temp_sampler = sampler\n",
    "    temp_models = all_models[temp_sampler]\n",
    "    temp_sel_nnml = temp_models['SEL-NNML']\n",
    "    \n",
    "    # Calculate permutation importance for this sampler\n",
    "    print(f\"Calculating feature importance for {temp_sampler}...\")\n",
    "    temp_perm_importance = permutation_importance(\n",
    "        temp_sel_nnml, X_test, y_test,\n",
    "        n_repeats=30, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Create dataframe\n",
    "    temp_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns.tolist(),\n",
    "        'Importance Mean': temp_perm_importance.importances_mean,\n",
    "        'Importance Std': temp_perm_importance.importances_std\n",
    "    }).sort_values('Importance Mean', ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    sampler_folder = temp_sampler.lower().replace(\"-\", \"\")\n",
    "    os.makedirs(f'../artifacts/ds1/models/{sampler_folder}', exist_ok=True)\n",
    "    importance_save_path = f'../artifacts/ds1/models/{sampler_folder}/sel-nnml_feature_importance.csv'\n",
    "    temp_importance_df.to_csv(importance_save_path, index=False)\n",
    "    print(f\"✓ Saved {temp_sampler} feature importance to: {importance_save_path}\")\n",
    "\n",
    "print(\"\\nAll feature importance data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3 Save All Models Metrics (All Samplers)**\n",
    "\n",
    "This section calculates and saves performance metrics for all models across all samplers. This data will be used for cross-sampler comparisons in the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for all models across all samplers + baseline models...\n",
      "\n",
      "Processing BASELINE models...\n",
      "  ✓ Logistic Regression (Default): Acc=0.8867, AUC=0.9577\n",
      "  ✓ Decision Tree (Default): Acc=0.8600, AUC=0.8621\n",
      "  ✓ Random Forest (Default): Acc=0.8800, AUC=0.9512\n",
      "  ✓ K-Nearest Neighbors (Default): Acc=0.8733, AUC=0.9311\n",
      "  ✓ Support Vector Machine (Default): Acc=0.9067, AUC=0.9490\n",
      "  ✓ AdaBoost (Default): Acc=0.8800, AUC=0.9583\n",
      "  ✓ Gradient Boosting (Default): Acc=0.8867, AUC=0.9594\n",
      "  ✓ Stacking + Linear Regression: Acc=0.9000, AUC=0.9533\n",
      "  ✓ Stacking + Linear Regression: Acc=0.9000, AUC=0.9533\n",
      "  ✓ Stacking + Default MLP: Acc=0.9000, AUC=0.9529\n",
      "\n",
      "Processing TPE models...\n",
      "  ✓ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9350\n",
      "  ✓ Random Forest: Acc=0.8933, AUC=0.9554\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9508\n",
      "  ✓ Support Vector Machine: Acc=0.8533, AUC=0.9606\n",
      "  ✓ AdaBoost: Acc=0.8933, AUC=0.9661\n",
      "  ✓ Gradient Boosting: Acc=0.9067, AUC=0.9624\n",
      "  ✓ Stacking + Default MLP: Acc=0.9000, AUC=0.9529\n",
      "\n",
      "Processing TPE models...\n",
      "  ✓ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9350\n",
      "  ✓ Random Forest: Acc=0.8933, AUC=0.9554\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9508\n",
      "  ✓ Support Vector Machine: Acc=0.8533, AUC=0.9606\n",
      "  ✓ AdaBoost: Acc=0.8933, AUC=0.9661\n",
      "  ✓ Gradient Boosting: Acc=0.9067, AUC=0.9624\n",
      "  ✓ SEL-NNML: Acc=0.9267, AUC=0.9586\n",
      "\n",
      "Processing GP models...\n",
      "  ✓ Logistic Regression: Acc=0.8933, AUC=0.9513\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9354\n",
      "  ✓ SEL-NNML: Acc=0.9267, AUC=0.9586\n",
      "\n",
      "Processing GP models...\n",
      "  ✓ Logistic Regression: Acc=0.8933, AUC=0.9513\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9354\n",
      "  ✓ Random Forest: Acc=0.8867, AUC=0.9540\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9495\n",
      "  ✓ Support Vector Machine: Acc=0.8600, AUC=0.9595\n",
      "  ✓ AdaBoost: Acc=0.8800, AUC=0.9647\n",
      "  ✓ Gradient Boosting: Acc=0.9067, AUC=0.9688\n",
      "  ✓ SEL-NNML: Acc=0.9200, AUC=0.9613\n",
      "\n",
      "Processing CMA-ES models...\n",
      "  ✓ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9350\n",
      "  ✓ Random Forest: Acc=0.8867, AUC=0.9540\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9495\n",
      "  ✓ Support Vector Machine: Acc=0.8600, AUC=0.9595\n",
      "  ✓ AdaBoost: Acc=0.8800, AUC=0.9647\n",
      "  ✓ Gradient Boosting: Acc=0.9067, AUC=0.9688\n",
      "  ✓ SEL-NNML: Acc=0.9200, AUC=0.9613\n",
      "\n",
      "Processing CMA-ES models...\n",
      "  ✓ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9350\n",
      "  ✓ Random Forest: Acc=0.8867, AUC=0.9554\n",
      "  ✓ Random Forest: Acc=0.8867, AUC=0.9554\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9506\n",
      "  ✓ Support Vector Machine: Acc=0.8400, AUC=0.9519\n",
      "  ✓ AdaBoost: Acc=0.8933, AUC=0.9645\n",
      "  ✓ Gradient Boosting: Acc=0.9067, AUC=0.9636\n",
      "  ✓ SEL-NNML: Acc=0.9267, AUC=0.9611\n",
      "\n",
      "Processing QMC models...\n",
      "  ✓ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9243\n",
      "  ✓ Random Forest: Acc=0.8800, AUC=0.9494\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9495\n",
      "  ✓ Support Vector Machine: Acc=0.8600, AUC=0.9602\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9506\n",
      "  ✓ Support Vector Machine: Acc=0.8400, AUC=0.9519\n",
      "  ✓ AdaBoost: Acc=0.8933, AUC=0.9645\n",
      "  ✓ Gradient Boosting: Acc=0.9067, AUC=0.9636\n",
      "  ✓ SEL-NNML: Acc=0.9267, AUC=0.9611\n",
      "\n",
      "Processing QMC models...\n",
      "  ✓ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  ✓ Decision Tree: Acc=0.8933, AUC=0.9243\n",
      "  ✓ Random Forest: Acc=0.8800, AUC=0.9494\n",
      "  ✓ K-Nearest Neighbors: Acc=0.9133, AUC=0.9495\n",
      "  ✓ Support Vector Machine: Acc=0.8600, AUC=0.9602\n",
      "  ✓ AdaBoost: Acc=0.8933, AUC=0.9479\n",
      "  ✓ Gradient Boosting: Acc=0.8933, AUC=0.9624\n",
      "  ✓ SEL-NNML: Acc=0.9200, AUC=0.9617\n",
      "\n",
      "✅ Saved metrics for 41 model configurations\n",
      "   - Metrics: ../artifacts/ds1/models/all_models_metrics.csv\n",
      "   - ROC Data: ../artifacts/ds1/models/all_models_roc_data.csv\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: Top 5 Models by Accuracy\n",
      "================================================================================\n",
      "  ✓ AdaBoost: Acc=0.8933, AUC=0.9479\n",
      "  ✓ Gradient Boosting: Acc=0.8933, AUC=0.9624\n",
      "  ✓ SEL-NNML: Acc=0.9200, AUC=0.9617\n",
      "\n",
      "✅ Saved metrics for 41 model configurations\n",
      "   - Metrics: ../artifacts/ds1/models/all_models_metrics.csv\n",
      "   - ROC Data: ../artifacts/ds1/models/all_models_roc_data.csv\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: Top 5 Models by Accuracy\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TPE</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>0.958638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.929936</td>\n",
       "      <td>0.961134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GP</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.961312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>QMC</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.961669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TPE</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.950793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampler                Model  Accuracy  F1-Score       AUC\n",
       "16     TPE             SEL-NNML  0.926667  0.929032  0.958638\n",
       "32  CMA-ES             SEL-NNML  0.926667  0.929936  0.961134\n",
       "24      GP             SEL-NNML  0.920000  0.923077  0.961312\n",
       "40     QMC             SEL-NNML  0.920000  0.927711  0.961669\n",
       "12     TPE  K-Nearest Neighbors  0.913333  0.917197  0.950793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and save metrics for ALL models from ALL samplers + BASELINE models\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "print(\"Calculating metrics for all models across all samplers + baseline models...\")\n",
    "\n",
    "all_metrics_data = []\n",
    "all_roc_data = []\n",
    "\n",
    "# Process baseline models first\n",
    "print(\"\\nProcessing BASELINE models...\")\n",
    "baseline_models_dict = {\n",
    "    **{f\"{name} (Default)\": model for name, model in default_base_models.items()},\n",
    "    'Stacking + Linear Regression': stacking_lr,\n",
    "    'Stacking + Default MLP': stacking_mlp\n",
    "}\n",
    "\n",
    "for model_name, model in baseline_models_dict.items():\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get probability predictions for AUC and ROC\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_metrics_data.append({\n",
    "        'Sampler': 'Baseline',\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    # Store ROC curve data\n",
    "    for f, t in zip(fpr, tpr):\n",
    "        all_roc_data.append({\n",
    "            'Sampler': 'Baseline',\n",
    "            'Model': model_name,\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "    \n",
    "    print(f\"  ✓ {model_name}: Acc={accuracy_score(y_test, y_pred):.4f}, AUC={roc_auc:.4f}\")\n",
    "\n",
    "# Process optimized models\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    print(f\"\\nProcessing {sampler} models...\")\n",
    "    models = all_models[sampler]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Get probability predictions for AUC and ROC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(X_test)\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Store metrics\n",
    "        all_metrics_data.append({\n",
    "            'Sampler': sampler,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-Score': f1_score(y_test, y_pred),\n",
    "            'AUC': roc_auc\n",
    "        })\n",
    "        \n",
    "        # Store ROC curve data\n",
    "        for f, t in zip(fpr, tpr):\n",
    "            all_roc_data.append({\n",
    "                'Sampler': sampler,\n",
    "                'Model': model_name,\n",
    "                'FPR': f,\n",
    "                'TPR': t\n",
    "            })\n",
    "        \n",
    "        print(f\"  ✓ {model_name}: Acc={accuracy_score(y_test, y_pred):.4f}, AUC={roc_auc:.4f}\")\n",
    "\n",
    "# Create DataFrames\n",
    "all_metrics_df = pd.DataFrame(all_metrics_data)\n",
    "all_roc_df = pd.DataFrame(all_roc_data)\n",
    "\n",
    "# Save to CSV files\n",
    "os.makedirs('../artifacts/ds1/models', exist_ok=True)\n",
    "all_metrics_df.to_csv('../artifacts/ds1/models/all_models_metrics.csv', index=False)\n",
    "all_roc_df.to_csv('../artifacts/ds1/models/all_models_roc_data.csv', index=False)\n",
    "\n",
    "print(f\"\\n✅ Saved metrics for {len(all_metrics_data)} model configurations\")\n",
    "print(f\"   - Metrics: ../artifacts/ds1/models/all_models_metrics.csv\")\n",
    "print(f\"   - ROC Data: ../artifacts/ds1/models/all_models_roc_data.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: Top 5 Models by Accuracy\")\n",
    "print(\"=\"*80)\n",
    "display(all_metrics_df.nlargest(5, 'Accuracy')[['Sampler', 'Model', 'Accuracy', 'F1-Score', 'AUC']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
