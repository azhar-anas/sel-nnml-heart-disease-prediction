{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SEL-NNML Tuning - Kaggle Heart Failure Prediction Dataset**\n",
    "\n",
    "This notebook implements several tuning methods on the `Stacking Ensemble Learning with a Neural Network Meta-Learner (SEL-NNML)` model using the `Kaggle Heart Failure Prediction Dataset (KHFPD)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Global Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global configuration loaded successfully!\n",
      "Random State: 42\n",
      "Test Size: 0.2\n",
      "CV Folds: 5\n",
      "Optimization Iterations: 100\n",
      "Optimization Metric: accuracy\n",
      "Optimization Direction: maximize\n",
      "Skip Training: False\n"
     ]
    }
   ],
   "source": [
    "# Random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Data splitting configuration\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Cross-validation configuration\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Hyperparameter tuning configuration\n",
    "OPTIMIZATION_ITERATIONS = 100\n",
    "OPTIMIZATION_METRIC = 'accuracy'\n",
    "OPTIMIZATION_DIRECTION='maximize'\n",
    "\n",
    "# Parallel processing configuration\n",
    "N_JOBS = -1 \n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_PATH = '../datasets/processed/ds1_kaggle_heart_clean.csv'\n",
    "TARGET_COLUMN = 'HeartDisease'\n",
    "\n",
    "# Training configuration\n",
    "SKIP_TRAINING = True  # Set to True to load pre-existing models instead of training\n",
    "\n",
    "print('Global configuration loaded successfully!')\n",
    "print(f'Random State: {RANDOM_STATE}')\n",
    "print(f'Test Size: {TEST_SIZE}')\n",
    "print(f'CV Folds: {CV_FOLDS}')\n",
    "print(f'Optimization Iterations: {OPTIMIZATION_ITERATIONS}')\n",
    "print(f'Optimization Metric: {OPTIMIZATION_METRIC}')\n",
    "print(f'Optimization Direction: {OPTIMIZATION_DIRECTION}')\n",
    "print(f'Skip Training: {SKIP_TRAINING}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src import base_model_tuning, meta_model_tuning\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 746 entries, 0 to 745\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                746 non-null    int64  \n",
      " 1   Sex                746 non-null    bool   \n",
      " 2   RestingBP          746 non-null    int64  \n",
      " 3   Cholesterol        746 non-null    int64  \n",
      " 4   FastingBS          746 non-null    bool   \n",
      " 5   MaxHR              746 non-null    int64  \n",
      " 6   ExerciseAngina     746 non-null    bool   \n",
      " 7   Oldpeak            746 non-null    float64\n",
      " 8   HeartDisease       746 non-null    bool   \n",
      " 9   ChestPainType_ASY  746 non-null    bool   \n",
      " 10  ChestPainType_ATA  746 non-null    bool   \n",
      " 11  ChestPainType_NAP  746 non-null    bool   \n",
      " 12  ChestPainType_TA   746 non-null    bool   \n",
      " 13  RestingECG_LVH     746 non-null    bool   \n",
      " 14  RestingECG_Normal  746 non-null    bool   \n",
      " 15  RestingECG_ST      746 non-null    bool   \n",
      " 16  ST_Slope_Down      746 non-null    bool   \n",
      " 17  ST_Slope_Flat      746 non-null    bool   \n",
      " 18  ST_Slope_Up        746 non-null    bool   \n",
      "dtypes: bool(14), float64(1), int64(4)\n",
      "memory usage: 39.5 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sex",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingBP",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cholesterol",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "FastingBS",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "MaxHR",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ExerciseAngina",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HeartDisease",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_ASY",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_ATA",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_NAP",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_TA",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingECG_LVH",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingECG_Normal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingECG_ST",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Down",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Flat",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Up",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "8b9189b3-b5d0-4363-911c-c048d2081e18",
       "rows": [
        [
         "0",
         "40",
         "True",
         "140",
         "289",
         "False",
         "172",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "1",
         "49",
         "False",
         "160",
         "180",
         "False",
         "156",
         "False",
         "1.0",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "2",
         "37",
         "True",
         "130",
         "283",
         "False",
         "98",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "3",
         "48",
         "False",
         "138",
         "214",
         "False",
         "108",
         "True",
         "1.5",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "4",
         "54",
         "True",
         "150",
         "195",
         "False",
         "122",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "5",
         "39",
         "True",
         "120",
         "339",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "6",
         "45",
         "False",
         "130",
         "237",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "7",
         "54",
         "True",
         "110",
         "208",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "8",
         "37",
         "True",
         "140",
         "207",
         "False",
         "130",
         "True",
         "1.5",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "9",
         "48",
         "False",
         "120",
         "284",
         "False",
         "120",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "10",
         "37",
         "False",
         "130",
         "211",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "11",
         "58",
         "True",
         "136",
         "164",
         "False",
         "99",
         "True",
         "2.0",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "12",
         "39",
         "True",
         "120",
         "204",
         "False",
         "145",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "13",
         "49",
         "True",
         "140",
         "234",
         "False",
         "140",
         "True",
         "1.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "14",
         "42",
         "False",
         "115",
         "211",
         "False",
         "137",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "15",
         "54",
         "False",
         "120",
         "273",
         "False",
         "150",
         "False",
         "1.5",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "16",
         "38",
         "True",
         "110",
         "196",
         "False",
         "166",
         "False",
         "0.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "17",
         "43",
         "False",
         "120",
         "201",
         "False",
         "165",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "18",
         "60",
         "True",
         "100",
         "248",
         "False",
         "125",
         "False",
         "1.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "19",
         "36",
         "True",
         "120",
         "267",
         "False",
         "160",
         "False",
         "3.0",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "20",
         "43",
         "False",
         "100",
         "223",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "21",
         "44",
         "True",
         "120",
         "184",
         "False",
         "142",
         "False",
         "1.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "22",
         "49",
         "False",
         "124",
         "201",
         "False",
         "164",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "23",
         "44",
         "True",
         "150",
         "288",
         "False",
         "150",
         "True",
         "3.0",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "24",
         "40",
         "True",
         "130",
         "215",
         "False",
         "138",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "25",
         "36",
         "True",
         "130",
         "209",
         "False",
         "178",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "26",
         "53",
         "True",
         "124",
         "260",
         "False",
         "112",
         "True",
         "3.0",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "27",
         "52",
         "True",
         "120",
         "284",
         "False",
         "118",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "28",
         "53",
         "False",
         "113",
         "468",
         "False",
         "127",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "29",
         "51",
         "True",
         "125",
         "188",
         "False",
         "145",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "30",
         "53",
         "True",
         "145",
         "518",
         "False",
         "130",
         "False",
         "0.0",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "31",
         "56",
         "True",
         "130",
         "167",
         "False",
         "114",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "32",
         "54",
         "True",
         "125",
         "224",
         "False",
         "122",
         "False",
         "2.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "33",
         "41",
         "True",
         "130",
         "172",
         "False",
         "130",
         "False",
         "2.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "34",
         "43",
         "False",
         "150",
         "186",
         "False",
         "154",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "35",
         "32",
         "True",
         "125",
         "254",
         "False",
         "155",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "36",
         "65",
         "True",
         "140",
         "306",
         "True",
         "87",
         "True",
         "1.5",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "37",
         "41",
         "False",
         "110",
         "250",
         "False",
         "142",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "38",
         "48",
         "False",
         "120",
         "177",
         "True",
         "148",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "39",
         "48",
         "False",
         "150",
         "227",
         "False",
         "130",
         "True",
         "1.0",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "40",
         "54",
         "False",
         "150",
         "230",
         "False",
         "130",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "41",
         "54",
         "False",
         "130",
         "294",
         "False",
         "100",
         "True",
         "0.0",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "42",
         "35",
         "True",
         "150",
         "264",
         "False",
         "168",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "43",
         "52",
         "True",
         "140",
         "259",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "44",
         "43",
         "True",
         "120",
         "175",
         "False",
         "120",
         "True",
         "1.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "45",
         "59",
         "True",
         "130",
         "318",
         "False",
         "120",
         "True",
         "1.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "46",
         "37",
         "True",
         "120",
         "223",
         "False",
         "168",
         "False",
         "0.0",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "47",
         "50",
         "True",
         "140",
         "216",
         "False",
         "170",
         "False",
         "0.0",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "48",
         "36",
         "True",
         "112",
         "340",
         "False",
         "184",
         "False",
         "1.0",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "49",
         "41",
         "True",
         "110",
         "289",
         "False",
         "170",
         "False",
         "0.0",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 746
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ST_Slope_Down</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>False</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>156</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>False</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>True</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>False</td>\n",
       "      <td>122</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>False</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>True</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>3.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>False</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>False</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age    Sex  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  \\\n",
       "0     40   True        140          289      False    172           False   \n",
       "1     49  False        160          180      False    156           False   \n",
       "2     37   True        130          283      False     98           False   \n",
       "3     48  False        138          214      False    108            True   \n",
       "4     54   True        150          195      False    122           False   \n",
       "..   ...    ...        ...          ...        ...    ...             ...   \n",
       "741   45   True        110          264      False    132           False   \n",
       "742   68   True        144          193       True    141           False   \n",
       "743   57   True        130          131      False    115            True   \n",
       "744   57  False        130          236      False    174           False   \n",
       "745   38   True        138          175      False    173           False   \n",
       "\n",
       "     Oldpeak  HeartDisease  ChestPainType_ASY  ChestPainType_ATA  \\\n",
       "0        0.0         False              False               True   \n",
       "1        1.0          True              False              False   \n",
       "2        0.0         False              False               True   \n",
       "3        1.5          True               True              False   \n",
       "4        0.0         False              False              False   \n",
       "..       ...           ...                ...                ...   \n",
       "741      1.2          True              False              False   \n",
       "742      3.4          True               True              False   \n",
       "743      1.2          True               True              False   \n",
       "744      0.0          True              False               True   \n",
       "745      0.0         False              False              False   \n",
       "\n",
       "     ChestPainType_NAP  ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  \\\n",
       "0                False             False           False               True   \n",
       "1                 True             False           False               True   \n",
       "2                False             False           False              False   \n",
       "3                False             False           False               True   \n",
       "4                 True             False           False               True   \n",
       "..                 ...               ...             ...                ...   \n",
       "741              False              True           False               True   \n",
       "742              False             False           False               True   \n",
       "743              False             False           False               True   \n",
       "744              False             False            True              False   \n",
       "745               True             False           False               True   \n",
       "\n",
       "     RestingECG_ST  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
       "0            False          False          False         True  \n",
       "1            False          False           True        False  \n",
       "2             True          False          False         True  \n",
       "3            False          False           True        False  \n",
       "4            False          False          False         True  \n",
       "..             ...            ...            ...          ...  \n",
       "741          False          False           True        False  \n",
       "742          False          False           True        False  \n",
       "743          False          False           True        False  \n",
       "744          False          False           True        False  \n",
       "745          False          False          False         True  \n",
       "\n",
       "[746 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into desired training and testing\n",
    "- After that, Scaling the data using Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Min-Max Scaler function for this dataset to ../artifacts/ds1/models/min_max_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "# Separate numeric and boolean columns\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "bool_cols = X_train.select_dtypes(include=['bool', 'uint8']).columns  # includes one-hot from get_dummies\n",
    "\n",
    "# Initialize scaler and fit_transform only on numeric data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=num_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=num_cols, index=X_test.index)\n",
    "\n",
    "# Concatenate back with boolean features (without modification)\n",
    "X_train = pd.concat([X_train_scaled, X_train[bool_cols]], axis=1)\n",
    "X_test = pd.concat([X_test_scaled, X_test[bool_cols]], axis=1)\n",
    "\n",
    "# Save Min-Max Scaler\n",
    "scaler_filename = '../artifacts/ds1/models/min_max_scaler.pkl'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f'Saved Min-Max Scaler function for this dataset to {scaler_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RestingBP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cholesterol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MaxHR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sex",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "FastingBS",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ExerciseAngina",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_ASY",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_ATA",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_NAP",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ChestPainType_TA",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingECG_LVH",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingECG_Normal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "RestingECG_ST",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Down",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Flat",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ST_Slope_Up",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "22e05bdc-6b42-4987-afab-e907cfab7bb3",
       "rows": [
        [
         "70",
         "0.5833333333333334",
         "0.4444444444444444",
         "0.34749034749034746",
         "0.5714285714285714",
         "0.1929824561403509",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "164",
         "0.47916666666666663",
         "0.4444444444444444",
         "0.2702702702702703",
         "0.5338345864661653",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "710",
         "0.5624999999999999",
         "0.4444444444444444",
         "0.40347490347490345",
         "0.631578947368421",
         "0.24561403508771934",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "265",
         "0.5208333333333334",
         "0.6296296296296295",
         "0.42471042471042475",
         "0.7969924812030074",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "250",
         "0.3125",
         "0.39814814814814814",
         "0.7837837837837838",
         "0.49624060150375926",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "135",
         "0.41666666666666663",
         "0.2129629629629628",
         "0.34749034749034746",
         "0.7969924812030074",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "467",
         "0.5208333333333334",
         "0.37037037037037024",
         "0.3918918918918919",
         "0.6766917293233081",
         "0.01754385964912281",
         "False",
         "True",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "28",
         "0.4999999999999999",
         "0.19444444444444442",
         "0.7393822393822393",
         "0.43609022556390964",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "593",
         "0.25",
         "0.18518518518518512",
         "0.31853281853281856",
         "0.8270676691729322",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "381",
         "0.9374999999999999",
         "0.4907407407407407",
         "0.2528957528957529",
         "0.35338345864661647",
         "0.33333333333333337",
         "True",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "453",
         "0.6249999999999999",
         "0.39814814814814814",
         "0.2876447876447876",
         "0.6917293233082706",
         "0.10526315789473685",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "136",
         "0.29166666666666663",
         "0.2592592592592593",
         "0.25096525096525096",
         "0.7969924812030074",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "204",
         "0.5624999999999999",
         "0.35185185185185186",
         "0.19111969111969113",
         "0.23308270676691722",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "6",
         "0.33333333333333337",
         "0.35185185185185186",
         "0.29343629343629346",
         "0.7593984962406015",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "334",
         "0.7499999999999999",
         "0.4074074074074072",
         "0.31467181467181465",
         "0.5338345864661653",
         "0.7192982456140352",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "73",
         "0.3125",
         "0.2592592592592593",
         "0.25675675675675674",
         "0.3458646616541352",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "244",
         "0.39583333333333337",
         "0.6296296296296295",
         "0.35328185328185324",
         "0.2556390977443608",
         "0.1929824561403509",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "196",
         "0.41666666666666663",
         "0.2592592592592593",
         "0.4092664092664092",
         "0.4736842105263157",
         "0.1929824561403509",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "145",
         "0.20833333333333337",
         "0.16666666666666652",
         "0.362934362934363",
         "0.4736842105263157",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "738",
         "0.25",
         "0.2592592592592593",
         "0.138996138996139",
         "0.8496240601503757",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "668",
         "0.25",
         "0.39814814814814814",
         "0.2277992277992278",
         "0.4736842105263157",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "132",
         "0.5624999999999999",
         "0.7222222222222221",
         "0.584942084942085",
         "0.3984962406015037",
         "0.368421052631579",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "434",
         "0.6874999999999999",
         "0.6296296296296295",
         "0.32625482625482627",
         "0.29323308270676685",
         "0.5438596491228072",
         "True",
         "True",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "377",
         "0.8124999999999999",
         "0.4351851851851851",
         "0.18532818532818535",
         "0.49624060150375926",
         "0.05263157894736843",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "697",
         "0.6249999999999999",
         "0.537037037037037",
         "0.24517374517374518",
         "0.6616541353383458",
         "0.29824561403508776",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "41",
         "0.5208333333333334",
         "0.35185185185185186",
         "0.40347490347490345",
         "0.23308270676691722",
         "0.01754385964912281",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "108",
         "0.4374999999999999",
         "0.4444444444444444",
         "0.08494208494208494",
         "0.49624060150375926",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "292",
         "0.4999999999999999",
         "0.35185185185185186",
         "0.18725868725868727",
         "0.593984962406015",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "56",
         "0.04166666666666663",
         "0.2592592592592593",
         "0.3571428571428571",
         "0.631578947368421",
         "0.28070175438596495",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "220",
         "0.35416666666666663",
         "0.35185185185185186",
         "0.2644787644787645",
         "0.32330827067669166",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "290",
         "0.39583333333333337",
         "0.16666666666666652",
         "0.24324324324324326",
         "0.518796992481203",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "350",
         "0.7291666666666666",
         "0.35185185185185186",
         "0.26640926640926643",
         "0.4436090225563909",
         "0.10526315789473685",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "552",
         "0.33333333333333337",
         "0.18518518518518512",
         "0.14478764478764478",
         "0.518796992481203",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "685",
         "0.4999999999999999",
         "0.35185185185185186",
         "0.34555984555984554",
         "0.5563909774436089",
         "0.08771929824561404",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "24",
         "0.22916666666666663",
         "0.35185185185185186",
         "0.25096525096525096",
         "0.518796992481203",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "199",
         "0.5833333333333334",
         "0.35185185185185186",
         "0.43050193050193053",
         "0.21804511278195482",
         "0.1929824561403509",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "213",
         "0.5624999999999999",
         "0.35185185185185186",
         "0.25868725868725867",
         "0.7142857142857142",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "394",
         "0.25",
         "0.537037037037037",
         "0.16602316602316602",
         "0.4436090225563909",
         "0.28070175438596495",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "327",
         "0.45833333333333337",
         "0.4166666666666665",
         "0.49034749034749037",
         "0.43609022556390964",
         "0.31578947368421056",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "445",
         "0.5833333333333334",
         "0.2962962962962963",
         "0.33976833976833976",
         "0.5413533834586466",
         "0.07017543859649124",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "110",
         "0.6249999999999999",
         "0.35185185185185186",
         "0.19884169884169883",
         "0.4135338345864661",
         "0.1929824561403509",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "82",
         "0.7083333333333334",
         "0.537037037037037",
         "0.26640926640926643",
         "0.3458646616541352",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "51",
         "0.375",
         "0.2592592592592593",
         "0.23166023166023164",
         "0.21804511278195482",
         "0.368421052631579",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "530",
         "0.6249999999999999",
         "0.7962962962962963",
         "0.3571428571428571",
         "0.5714285714285714",
         "0.7543859649122808",
         "True",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "598",
         "0.35416666666666663",
         "0.12037037037037035",
         "0.22972972972972971",
         "0.7744360902255638",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "519",
         "0.33333333333333337",
         "0.11111111111111105",
         "0.23745173745173748",
         "0.593984962406015",
         "0.5438596491228072",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "568",
         "0.5208333333333334",
         "0.6296296296296295",
         "0.22393822393822393",
         "0.7067669172932329",
         "0.01754385964912281",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "405",
         "0.7916666666666666",
         "0.5",
         "0.5482625482625483",
         "0.30827067669172925",
         "0.3508771929824562",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "342",
         "0.6041666666666666",
         "0.16666666666666652",
         "0.21814671814671815",
         "0.30827067669172925",
         "0.01754385964912281",
         "True",
         "False",
         "False",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ],
        [
         "139",
         "0.29166666666666663",
         "0.537037037037037",
         "0.3127413127413127",
         "0.4586466165413533",
         "0.368421052631579",
         "True",
         "False",
         "True",
         "True",
         "False",
         "False",
         "False",
         "False",
         "True",
         "False",
         "False",
         "True",
         "False"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 596
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Sex</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ST_Slope_Down</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.347490</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.533835</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.403475</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.424710</td>\n",
       "      <td>0.796992</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.496241</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>0.496241</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.326255</td>\n",
       "      <td>0.308271</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.533835</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.415058</td>\n",
       "      <td>0.443609</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.592664</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>596 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  RestingBP  Cholesterol     MaxHR   Oldpeak    Sex  FastingBS  \\\n",
       "70   0.583333   0.444444     0.347490  0.571429  0.192982   True      False   \n",
       "164  0.479167   0.444444     0.270270  0.533835  0.017544  False      False   \n",
       "710  0.562500   0.444444     0.403475  0.631579  0.245614  False      False   \n",
       "265  0.520833   0.629630     0.424710  0.796992  0.017544   True      False   \n",
       "250  0.312500   0.398148     0.783784  0.496241  0.017544   True      False   \n",
       "..        ...        ...          ...       ...       ...    ...        ...   \n",
       "71   0.312500   0.351852     0.250965  0.496241  0.017544   True      False   \n",
       "106  0.395833   0.259259     0.326255  0.308271  0.017544  False      False   \n",
       "270  0.333333   0.259259     0.270270  0.533835  0.017544   True      False   \n",
       "435  0.500000   0.481481     0.415058  0.443609  0.280702   True       True   \n",
       "102  0.229167   0.537037     0.592664  0.458647  0.368421  False      False   \n",
       "\n",
       "     ExerciseAngina  ChestPainType_ASY  ChestPainType_ATA  ChestPainType_NAP  \\\n",
       "70             True              False               True              False   \n",
       "164           False              False               True              False   \n",
       "710           False              False               True              False   \n",
       "265           False              False               True              False   \n",
       "250           False               True              False              False   \n",
       "..              ...                ...                ...                ...   \n",
       "71            False              False               True              False   \n",
       "106           False               True              False              False   \n",
       "270           False               True              False              False   \n",
       "435            True               True              False              False   \n",
       "102           False               True              False              False   \n",
       "\n",
       "     ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  RestingECG_ST  \\\n",
       "70              False           False              False           True   \n",
       "164             False           False               True          False   \n",
       "710             False            True              False          False   \n",
       "265             False           False               True          False   \n",
       "250             False           False               True          False   \n",
       "..                ...             ...                ...            ...   \n",
       "71              False           False               True          False   \n",
       "106             False           False              False           True   \n",
       "270             False           False               True          False   \n",
       "435             False           False              False           True   \n",
       "102             False           False               True          False   \n",
       "\n",
       "     ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
       "70           False           True        False  \n",
       "164          False          False         True  \n",
       "710          False           True        False  \n",
       "265          False          False         True  \n",
       "250          False           True        False  \n",
       "..             ...            ...          ...  \n",
       "71           False          False         True  \n",
       "106          False          False         True  \n",
       "270          False          False         True  \n",
       "435          False           True        False  \n",
       "102          False           True        False  \n",
       "\n",
       "[596 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Default Base Models (Baseline)**\n",
    "\n",
    "Create base models with default parameters as a baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training default base models...\n",
      "Default Base Models Training Time: 0.47 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    default_models_training_start = time.time()\n",
    "    \n",
    "    # Initialize base models with default parameters\n",
    "    default_logistic_regression = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    default_decision_tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    default_random_forest = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    default_knn = KNeighborsClassifier(n_jobs=N_JOBS)\n",
    "    default_svc = SVC(random_state=RANDOM_STATE, probability=True)  # probability=True for predict_proba\n",
    "    default_adaboost = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "    default_gradient_boosting = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Fit all default models\n",
    "    print(\"Training default base models...\")\n",
    "    default_logistic_regression.fit(X_train, y_train)\n",
    "    default_decision_tree.fit(X_train, y_train)\n",
    "    default_random_forest.fit(X_train, y_train)\n",
    "    default_knn.fit(X_train, y_train)\n",
    "    default_svc.fit(X_train, y_train)\n",
    "    default_adaboost.fit(X_train, y_train)\n",
    "    default_gradient_boosting.fit(X_train, y_train)\n",
    "    \n",
    "    default_models_training_end = time.time()\n",
    "    default_models_training_time = default_models_training_end - default_models_training_start\n",
    "    \n",
    "    print(f'Default Base Models Training Time: {default_models_training_time:.2f} seconds')\n",
    "    \n",
    "    # Store in dictionary\n",
    "    default_base_models = {\n",
    "        'Logistic Regression': default_logistic_regression,\n",
    "        'Decision Tree': default_decision_tree,\n",
    "        'Random Forest': default_random_forest,\n",
    "        'K-Nearest Neighbors': default_knn,\n",
    "        'Support Vector Machine': default_svc,\n",
    "        'AdaBoost': default_adaboost,\n",
    "        'Gradient Boosting': default_gradient_boosting\n",
    "    }\n",
    "else:\n",
    "    print(\"Skipping default base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Stacking with Default Base Models + Linear Regression**\n",
    "\n",
    "Create a stacking ensemble using default base learners with Linear Regression as the meta-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking model with Linear Regression meta-learner...\n",
      "Stacking + Linear Regression Training Time: 6.36 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    stack_lr_training_start = time.time()\n",
    "    \n",
    "    # Create stacking ensemble with Linear Regression as meta-learner\n",
    "    base_estimators = [\n",
    "        ('Logistic Regression', default_logistic_regression),\n",
    "        ('Decision Tree', default_decision_tree),\n",
    "        ('Random Forest', default_random_forest),\n",
    "        ('K-Nearest Neighbors', default_knn),\n",
    "        ('Support Vector Machine', default_svc),\n",
    "        ('AdaBoost', default_adaboost),\n",
    "        ('Gradient Boosting', default_gradient_boosting)\n",
    "    ]\n",
    "    \n",
    "    # Linear Regression meta-learner (using LogisticRegression for classification)\n",
    "    meta_lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    \n",
    "    stacking_lr = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_lr,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    print(\"Training Stacking model with Linear Regression meta-learner...\")\n",
    "    stacking_lr.fit(X_train, y_train)\n",
    "    \n",
    "    stack_lr_training_end = time.time()\n",
    "    stack_lr_training_time = stack_lr_training_end - stack_lr_training_start\n",
    "    \n",
    "    print(f'Stacking + Linear Regression Training Time: {stack_lr_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping Stacking + LR training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Stacking with Default Base Models + Default MLP**\n",
    "\n",
    "Create a stacking ensemble using default base learners with a default MLP (Multi-Layer Perceptron) as the meta-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking model with default MLP meta-learner...\n",
      "Stacking + Default MLP Training Time: 2.72 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    stack_mlp_training_start = time.time()\n",
    "    \n",
    "    # Create stacking ensemble with default MLP as meta-learner\n",
    "    # Using default MLP with just random_state for reproducibility\n",
    "    meta_mlp = MLPClassifier(random_state=RANDOM_STATE, max_iter=300)\n",
    "    \n",
    "    stacking_mlp = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=meta_mlp,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    print(\"Training Stacking model with default MLP meta-learner...\")\n",
    "    stacking_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    stack_mlp_training_end = time.time()\n",
    "    stack_mlp_training_time = stack_mlp_training_end - stack_mlp_training_start\n",
    "    \n",
    "    print(f'Stacking + Default MLP Training Time: {stack_mlp_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping Stacking + MLP training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Base Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Set `SKIP_TRAINING = True` in the global configuration to skip steps 4 and 5 and load pre-existing models instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:47,170] A new study created in memory with name: Logistic Regression Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51d7a575cc2413fafb565cd1f0238a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:47,227] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:19:47,298] Trial 1 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-12-28 19:19:47,353] Trial 2 finished with value: 0.5704481792717087 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-12-28 19:19:47,400] Trial 3 finished with value: 0.8288375350140056 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-12-28 19:19:47,437] Trial 4 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:19:47,476] Trial 5 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:19:47,522] Trial 6 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:19:47,559] Trial 7 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:19:47,597] Trial 8 finished with value: 0.8087254901960785 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:19:47,633] Trial 9 finished with value: 0.5888795518207283 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:19:47,672] Trial 10 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.23114272501983435}. Best is trial 10 with value: 0.8439495798319328.\n",
      "[I 2025-12-28 19:19:47,712] Trial 11 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.1581215145862693}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:19:47,750] Trial 12 finished with value: 0.8422689075630252 and parameters: {'solver': 'lbfgs', 'C': 0.2826411346239428}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:19:47,788] Trial 13 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.22334872496479957}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:19:47,828] Trial 14 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 2.7909857969226555}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:19:47,868] Trial 15 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.08051559097588631}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:19:47,908] Trial 16 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06973505218372578}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:19:47,950] Trial 17 finished with value: 0.83890756302521 and parameters: {'solver': 'sag', 'C': 1.3579090291127172}. Best is trial 11 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:19:47,998] Trial 18 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05119794498962474}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,048] Trial 19 finished with value: 0.8405602240896359 and parameters: {'solver': 'newton-cholesky', 'C': 0.00866904026900546}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,099] Trial 20 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.8998683788955588}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,138] Trial 21 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.04872063049862065}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,177] Trial 22 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.08004964515949381}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,217] Trial 23 finished with value: 0.8304901960784313 and parameters: {'solver': 'lbfgs', 'C': 0.007375728907568315}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,254] Trial 24 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.11217459449652216}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,293] Trial 25 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.03242812751236521}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,334] Trial 26 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.6910214262026081}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,371] Trial 27 finished with value: 0.8439495798319328 and parameters: {'solver': 'sag', 'C': 0.11333540081021488}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,411] Trial 28 finished with value: 0.8304901960784313 and parameters: {'solver': 'lbfgs', 'C': 0.006548996783712976}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,451] Trial 29 finished with value: 0.84390756302521 and parameters: {'solver': 'newton-cg', 'C': 0.021566274494266163}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,488] Trial 30 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 0.5728845685542989}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,527] Trial 31 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.0617120881760318}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,568] Trial 32 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1262642748705287}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,605] Trial 33 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.03510986273247759}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,643] Trial 34 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.38350453073093715}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,683] Trial 35 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 1.7618478700595492}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,721] Trial 36 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.16285844385179696}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,759] Trial 37 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.013729639897869718}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,799] Trial 38 finished with value: 0.8305182072829131 and parameters: {'solver': 'lbfgs', 'C': 0.0030410067875272263}. Best is trial 18 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:19:48,838] Trial 39 finished with value: 0.8489495798319329 and parameters: {'solver': 'newton-cg', 'C': 0.058569663055341156}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:48,879] Trial 40 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.028451658104795507}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:48,919] Trial 41 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.04768319394347642}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:48,958] Trial 42 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.10096174908404341}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:48,996] Trial 43 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06921802568515424}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,037] Trial 44 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 0.3970896440591384}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,076] Trial 45 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.17039811624517065}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,115] Trial 46 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.0002161881801369018}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,155] Trial 47 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 0.014579010740313227}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,192] Trial 48 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.21828528522579926}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,234] Trial 49 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.04657721498227119}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,273] Trial 50 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.022902951698565554}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,311] Trial 51 finished with value: 0.8439355742296918 and parameters: {'solver': 'newton-cholesky', 'C': 0.09731474393794932}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,350] Trial 52 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.07214026929869138}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,389] Trial 53 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cholesky', 'C': 0.31808075912658285}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,425] Trial 54 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 0.011622799886819647}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,465] Trial 55 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.07312656232811204}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,505] Trial 56 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03815512214428066}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,544] Trial 57 finished with value: 0.8321848739495797 and parameters: {'solver': 'lbfgs', 'C': 0.003923855267960691}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,584] Trial 58 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 8.064276941408508}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,623] Trial 59 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03791621774817248}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,660] Trial 60 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.03383766483232432}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,700] Trial 61 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.04837022121925013}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,740] Trial 62 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.14990407553147947}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,779] Trial 63 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.020280185040408252}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,818] Trial 64 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.15729553484021602}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,859] Trial 65 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.164976620818719}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,896] Trial 66 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 0.5774556008496671}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,935] Trial 67 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.24902758728746863}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:49,981] Trial 68 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.16469854292220812}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,019] Trial 69 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 1.0908336922463593}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,058] Trial 70 finished with value: 0.8405602240896359 and parameters: {'solver': 'lbfgs', 'C': 0.00975666515903636}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,099] Trial 71 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.27355433957008496}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,137] Trial 72 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.14151394200714704}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,177] Trial 73 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 0.4174203778888286}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,218] Trial 74 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03733329128405273}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,258] Trial 75 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03869645307868559}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,296] Trial 76 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026707373513957734}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,337] Trial 77 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.025293525506976892}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,374] Trial 78 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026728604297654238}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,414] Trial 79 finished with value: 0.8321708683473389 and parameters: {'solver': 'sag', 'C': 0.005678286963186668}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,454] Trial 80 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.01628463082294873}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,492] Trial 81 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.027002765082027372}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,531] Trial 82 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.03920263854915855}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,572] Trial 83 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.025816750619589275}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,611] Trial 84 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.058005808362322574}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,652] Trial 85 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.03720486825290074}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,692] Trial 86 finished with value: 0.84390756302521 and parameters: {'solver': 'sag', 'C': 0.020681162708917507}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,730] Trial 87 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.011952087204337748}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,768] Trial 88 finished with value: 0.7835994397759103 and parameters: {'solver': 'sag', 'C': 0.001648795363081182}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,812] Trial 89 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.017459817973215715}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,850] Trial 90 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.09225357958481326}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,889] Trial 91 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.02644954206319839}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,932] Trial 92 finished with value: 0.8472689075630253 and parameters: {'solver': 'sag', 'C': 0.028716978099140436}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:50,969] Trial 93 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05269692097958243}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:51,008] Trial 94 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.04100851208918775}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:51,053] Trial 95 finished with value: 0.8472549019607843 and parameters: {'solver': 'sag', 'C': 0.030887535969435755}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:51,090] Trial 96 finished with value: 0.8405462184873949 and parameters: {'solver': 'sag', 'C': 0.01192382113477605}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:51,131] Trial 97 finished with value: 0.8405602240896359 and parameters: {'solver': 'newton-cg', 'C': 0.008521018011915764}. Best is trial 39 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:51,214] A new study created in memory with name: Decision Tree Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:51,172] Trial 98 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05941864093493942}. Best is trial 39 with value: 0.8489495798319329.\n",
      "[I 2025-12-28 19:19:51,211] Trial 99 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05954942719938483}. Best is trial 39 with value: 0.8489495798319329.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using TPESampler: {'solver': 'newton-cg', 'C': 0.058569663055341156}\n",
      "Best accuracy: 0.8489, at trial: 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5294b8ac33d04cabb7717b227efd3b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:51,250] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[I 2025-12-28 19:19:51,288] Trial 1 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,315] Trial 2 finished with value: 0.807044817927171 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,344] Trial 3 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,374] Trial 4 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,402] Trial 5 finished with value: 0.8070448179271708 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,430] Trial 6 finished with value: 0.8272128851540617 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,448] Trial 7 finished with value: 0.8036974789915966 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,463] Trial 8 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,490] Trial 9 finished with value: 0.8002941176470589 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,513] Trial 10 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,535] Trial 11 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,559] Trial 12 finished with value: 0.8204901960784314 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:19:51,580] Trial 13 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:19:51,612] Trial 14 finished with value: 0.8221708683473388 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:19:51,635] Trial 15 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:19:51,658] Trial 16 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:19:51,694] Trial 17 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:19:51,726] Trial 18 finished with value: 0.8154481792717088 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:19:51,748] Trial 19 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,772] Trial 20 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,795] Trial 21 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,816] Trial 22 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,847] Trial 23 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,870] Trial 24 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,891] Trial 25 finished with value: 0.8321848739495799 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,925] Trial 26 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,946] Trial 27 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,967] Trial 28 finished with value: 0.8070028011204482 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:51,988] Trial 29 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,010] Trial 30 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,032] Trial 31 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,052] Trial 32 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,084] Trial 33 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,108] Trial 34 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,129] Trial 35 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,152] Trial 36 finished with value: 0.8137675070028012 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,173] Trial 37 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,204] Trial 38 finished with value: 0.8322408963585433 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,226] Trial 39 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,247] Trial 40 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,268] Trial 41 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,288] Trial 42 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,310] Trial 43 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,331] Trial 44 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,352] Trial 45 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,375] Trial 46 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,396] Trial 47 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,417] Trial 48 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,438] Trial 49 finished with value: 0.8221708683473388 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,458] Trial 50 finished with value: 0.8171148459383752 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,481] Trial 51 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,501] Trial 52 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,523] Trial 53 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,545] Trial 54 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,567] Trial 55 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,589] Trial 56 finished with value: 0.8305182072829131 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,610] Trial 57 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,631] Trial 58 finished with value: 0.8238655462184873 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,652] Trial 59 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,674] Trial 60 finished with value: 0.813781512605042 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,698] Trial 61 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,718] Trial 62 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,741] Trial 63 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,775] Trial 64 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,797] Trial 65 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,819] Trial 66 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,840] Trial 67 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,862] Trial 68 finished with value: 0.8288515406162464 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,883] Trial 69 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,904] Trial 70 finished with value: 0.8087394957983193 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,926] Trial 71 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,948] Trial 72 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,970] Trial 73 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:52,992] Trial 74 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,014] Trial 75 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,036] Trial 76 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,057] Trial 77 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,078] Trial 78 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,100] Trial 79 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,122] Trial 80 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,145] Trial 81 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,167] Trial 82 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,189] Trial 83 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,211] Trial 84 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,233] Trial 85 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,256] Trial 86 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,277] Trial 87 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,299] Trial 88 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,321] Trial 89 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,342] Trial 90 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,365] Trial 91 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,387] Trial 92 finished with value: 0.8389215686274509 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,419] Trial 93 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:53,557] A new study created in memory with name: Random Forest Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:53,443] Trial 94 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,466] Trial 95 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,490] Trial 96 finished with value: 0.797016806722689 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,510] Trial 97 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,533] Trial 98 finished with value: 0.8171148459383752 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:19:53,555] Trial 99 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.850700280112045.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using TPESampler: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}\n",
      "Best accuracy: 0.8507, at trial: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866792f95717409fb4eafca7290e642b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:19:53,673] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[I 2025-12-28 19:19:53,803] Trial 1 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8489915966386554.\n",
      "[I 2025-12-28 19:19:53,893] Trial 2 finished with value: 0.8288655462184874 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8489915966386554.\n",
      "[I 2025-12-28 19:19:54,003] Trial 3 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:19:54,103] Trial 4 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:19:54,181] Trial 5 finished with value: 0.842282913165266 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:19:54,271] Trial 6 finished with value: 0.8355882352941176 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:19:54,430] Trial 7 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:19:54,592] Trial 8 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:19:54,724] Trial 9 finished with value: 0.8489775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:19:54,913] Trial 10 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 98, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:19:55,105] Trial 11 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 96, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:19:55,317] Trial 12 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:19:55,518] Trial 13 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:19:55,698] Trial 14 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:19:55,858] Trial 15 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:19:56,037] Trial 16 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:56,188] Trial 17 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:56,336] Trial 18 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:56,513] Trial 19 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:56,640] Trial 20 finished with value: 0.8557563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:56,757] Trial 21 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:56,884] Trial 22 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:57,032] Trial 23 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:57,180] Trial 24 finished with value: 0.8456582633053221 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:57,338] Trial 25 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:57,497] Trial 26 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:57,675] Trial 27 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:57,791] Trial 28 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:57,981] Trial 29 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:58,140] Trial 30 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:58,298] Trial 31 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:58,433] Trial 32 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 64, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:58,602] Trial 33 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:58,709] Trial 34 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:58,805] Trial 35 finished with value: 0.8490196078431372 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 30, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:58,940] Trial 36 finished with value: 0.8506862745098038 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:59,100] Trial 37 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 73, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:59,280] Trial 38 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:59,447] Trial 39 finished with value: 0.8406302521008403 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 80, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:59,596] Trial 40 finished with value: 0.8523389355742296 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:59,754] Trial 41 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:59,891] Trial 42 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:19:59,967] Trial 43 finished with value: 0.8456302521008402 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 12, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:00,094] Trial 44 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:00,263] Trial 45 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:00,412] Trial 46 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:00,611] Trial 47 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:00,794] Trial 48 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:00,902] Trial 49 finished with value: 0.8439775910364148 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 35, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:01,039] Trial 50 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:01,199] Trial 51 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:01,358] Trial 52 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:01,528] Trial 53 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:01,657] Trial 54 finished with value: 0.8557563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 53, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:01,784] Trial 55 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 53, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:01,902] Trial 56 finished with value: 0.8557563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,018] Trial 57 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 47, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,135] Trial 58 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,243] Trial 59 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 39, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,359] Trial 60 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,487] Trial 61 finished with value: 0.8523949579831932 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 56, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,616] Trial 62 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,795] Trial 63 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:02,945] Trial 64 finished with value: 0.8523949579831932 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:03,072] Trial 65 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:03,220] Trial 66 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:03,357] Trial 67 finished with value: 0.8423109243697479 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:03,507] Trial 68 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:03,615] Trial 69 finished with value: 0.8472969187675069 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 35, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:03,732] Trial 70 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:03,880] Trial 71 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 70, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:04,049] Trial 72 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:04,211] Trial 73 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:04,380] Trial 74 finished with value: 0.8523809523809526 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:04,548] Trial 75 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:04,675] Trial 76 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 56, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:04,834] Trial 77 finished with value: 0.8540476190476189 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 74, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:04,922] Trial 78 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 21, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:05,058] Trial 79 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:05,199] Trial 80 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:05,357] Trial 81 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:05,528] Trial 82 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:05,697] Trial 83 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:05,869] Trial 84 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:06,050] Trial 85 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 93, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:06,209] Trial 86 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 82, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:06,390] Trial 87 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 98, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:06,570] Trial 88 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 84, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:20:06,762] Trial 89 finished with value: 0.8607563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:06,932] Trial 90 finished with value: 0.8607563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:07,113] Trial 91 finished with value: 0.8607563025210083 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:07,282] Trial 92 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:07,452] Trial 93 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:07,621] Trial 94 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:07,812] Trial 95 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 93, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:07,971] Trial 96 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:08,141] Trial 97 finished with value: 0.845658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 89 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:08,331] Trial 98 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 97, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:08,524] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:08,522] Trial 99 finished with value: 0.8456582633053221 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 92, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 89 with value: 0.8607563025210083.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using TPESampler: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}\n",
      "Best accuracy: 0.8608, at trial: 89\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd0e94c30d54e3e8c1f351a78c18b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:08,579] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[I 2025-12-28 19:20:08,709] Trial 1 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:20:08,758] Trial 2 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:20:08,891] Trial 3 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:20:08,939] Trial 4 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:20:08,985] Trial 5 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:20:09,033] Trial 6 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:20:09,082] Trial 7 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:20:09,128] Trial 8 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:20:09,176] Trial 9 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:20:09,227] Trial 10 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:20:09,266] Trial 11 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:20:09,317] Trial 12 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,370] Trial 13 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,421] Trial 14 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,525] Trial 15 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,575] Trial 16 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,627] Trial 17 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,656] Trial 18 finished with value: 0.8288515406162464 and parameters: {'algorithm': 'brute', 'n_neighbors': 4, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,706] Trial 19 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,757] Trial 20 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,806] Trial 21 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,860] Trial 22 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,911] Trial 23 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:09,963] Trial 24 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,013] Trial 25 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,067] Trial 26 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,117] Trial 27 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,170] Trial 28 finished with value: 0.850658263305322 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,200] Trial 29 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,250] Trial 30 finished with value: 0.850686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,302] Trial 31 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,350] Trial 32 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,402] Trial 33 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,453] Trial 34 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,482] Trial 35 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,532] Trial 36 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,584] Trial 37 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 23, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,633] Trial 38 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,684] Trial 39 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,737] Trial 40 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 36, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,786] Trial 41 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,827] Trial 42 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,879] Trial 43 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,930] Trial 44 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:10,970] Trial 45 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,054] Trial 46 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,103] Trial 47 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 16, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,153] Trial 48 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,205] Trial 49 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,254] Trial 50 finished with value: 0.8254901960784313 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,306] Trial 51 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,356] Trial 52 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,408] Trial 53 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,458] Trial 54 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,510] Trial 55 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,560] Trial 56 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,592] Trial 57 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 49, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,642] Trial 58 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,683] Trial 59 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,725] Trial 60 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,764] Trial 61 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,815] Trial 62 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,868] Trial 63 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,918] Trial 64 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:11,959] Trial 65 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,011] Trial 66 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,093] Trial 67 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,143] Trial 68 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,184] Trial 69 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 36, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,234] Trial 70 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,284] Trial 71 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,336] Trial 72 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,375] Trial 73 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,415] Trial 74 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,466] Trial 75 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,515] Trial 76 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,567] Trial 77 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,618] Trial 78 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,668] Trial 79 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,719] Trial 80 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,772] Trial 81 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,811] Trial 82 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,861] Trial 83 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,893] Trial 84 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,943] Trial 85 finished with value: 0.842282913165266 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:12,994] Trial 86 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,046] Trial 87 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,096] Trial 88 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,147] Trial 89 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,200] Trial 90 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,250] Trial 91 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,301] Trial 92 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,341] Trial 93 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,392] Trial 94 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,442] Trial 95 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:13,620] A new study created in memory with name: Support Vector Machine Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:13,496] Trial 96 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,526] Trial 97 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,566] Trial 98 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 12 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:20:13,618] Trial 99 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 1}. Best is trial 12 with value: 0.8523669467787116.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using TPESampler: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1be594b996425893bb75227ff58f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:13,664] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,701] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,739] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,788] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,815] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,851] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,879] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,904] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,931] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,958] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:13,991] Trial 10 finished with value: 0.7718347338935574 and parameters: {'kernel': 'poly', 'C': 0.0021291805287692966, 'degree': 5}. Best is trial 10 with value: 0.7718347338935574.\n",
      "[I 2025-12-28 19:20:14,021] Trial 11 finished with value: 0.7718347338935574 and parameters: {'kernel': 'poly', 'C': 0.0021085512855092427, 'degree': 5}. Best is trial 10 with value: 0.7718347338935574.\n",
      "[I 2025-12-28 19:20:14,051] Trial 12 finished with value: 0.7902941176470588 and parameters: {'kernel': 'poly', 'C': 0.0030343529095853763, 'degree': 5}. Best is trial 12 with value: 0.7902941176470588.\n",
      "[I 2025-12-28 19:20:14,083] Trial 13 finished with value: 0.7902941176470588 and parameters: {'kernel': 'poly', 'C': 0.0030833342416828526, 'degree': 5}. Best is trial 12 with value: 0.7902941176470588.\n",
      "[I 2025-12-28 19:20:14,115] Trial 14 finished with value: 0.8154341736694677 and parameters: {'kernel': 'poly', 'C': 0.004499680933767333, 'degree': 5}. Best is trial 14 with value: 0.8154341736694677.\n",
      "[I 2025-12-28 19:20:14,144] Trial 15 finished with value: 0.8171148459383752 and parameters: {'kernel': 'poly', 'C': 0.004080251178358777, 'degree': 4}. Best is trial 15 with value: 0.8171148459383752.\n",
      "[I 2025-12-28 19:20:14,175] Trial 16 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.007999452977705724, 'degree': 3}. Best is trial 16 with value: 0.8355462184873949.\n",
      "[I 2025-12-28 19:20:14,203] Trial 17 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009851506433650771, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,236] Trial 18 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009769128821659161, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,264] Trial 19 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.009563854514148548, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,294] Trial 20 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00011585594234321439, 'degree': 2}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,325] Trial 21 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.006732534117889717, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,356] Trial 22 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009628531956521132, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,386] Trial 23 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009954618519931012, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,417] Trial 24 finished with value: 0.8288375350140054 and parameters: {'kernel': 'poly', 'C': 0.0059581346138133625, 'degree': 4}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,455] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0037433095612438615}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,486] Trial 26 finished with value: 0.835532212885154 and parameters: {'kernel': 'poly', 'C': 0.006171605058256973, 'degree': 2}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,515] Trial 27 finished with value: 0.5956302521008403 and parameters: {'kernel': 'poly', 'C': 0.0008478772686135207, 'degree': 4}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,544] Trial 28 finished with value: 0.8070728291316526 and parameters: {'kernel': 'poly', 'C': 0.0025815325463280888, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,583] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0015388727422125698}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,616] Trial 30 finished with value: 0.8338655462184873 and parameters: {'kernel': 'poly', 'C': 0.004837775947425762, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,645] Trial 31 finished with value: 0.8338655462184873 and parameters: {'kernel': 'poly', 'C': 0.009130640392183169, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,675] Trial 32 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.0069017858913567485, 'degree': 3}. Best is trial 17 with value: 0.8372268907563024.\n",
      "[I 2025-12-28 19:20:14,704] Trial 33 finished with value: 0.8405882352941175 and parameters: {'kernel': 'poly', 'C': 0.009922745041727202, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,736] Trial 34 finished with value: 0.8238235294117645 and parameters: {'kernel': 'poly', 'C': 0.0055110877060886975, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,763] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.007738986953345059}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,791] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005131855034712696}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,821] Trial 37 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009810323221255416, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,851] Trial 38 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.007203642503010532}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,880] Trial 39 finished with value: 0.8070588235294117 and parameters: {'kernel': 'poly', 'C': 0.0033399318860387593, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,918] Trial 40 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0014582841621375497}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,948] Trial 41 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.00993824372973719, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:14,979] Trial 42 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007623399953065998, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,008] Trial 43 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.005719587919802941, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,038] Trial 44 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.008282062240761345, 'degree': 2}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,067] Trial 45 finished with value: 0.8321848739495797 and parameters: {'kernel': 'poly', 'C': 0.00407772545215666, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,096] Trial 46 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007243510897530972}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,124] Trial 47 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.006517584165480652, 'degree': 2}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,153] Trial 48 finished with value: 0.822142857142857 and parameters: {'kernel': 'poly', 'C': 0.005037187241321775, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,182] Trial 49 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009810624915759214, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,222] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003821441278540708}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,251] Trial 51 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.008724882959588344, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,281] Trial 52 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.009937772238136338, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,316] Trial 53 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.00795065710253696, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,347] Trial 54 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.006782145040738353, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,377] Trial 55 finished with value: 0.8321848739495797 and parameters: {'kernel': 'poly', 'C': 0.004507308749010253, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,406] Trial 56 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.008282894366622563, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,434] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005809302849933278}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,465] Trial 58 finished with value: 0.7785434173669469 and parameters: {'kernel': 'poly', 'C': 0.0025811624051328354, 'degree': 5}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,495] Trial 59 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007083582159710286, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,526] Trial 60 finished with value: 0.8137535014005601 and parameters: {'kernel': 'poly', 'C': 0.0036970590182907968, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,556] Trial 61 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009661877472005826, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,588] Trial 62 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009654821759383751, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,617] Trial 63 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.008291989076486162, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,647] Trial 64 finished with value: 0.8355462184873949 and parameters: {'kernel': 'poly', 'C': 0.006252542862414033, 'degree': 3}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,676] Trial 65 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.008439221310852455, 'degree': 4}. Best is trial 33 with value: 0.8405882352941175.\n",
      "[I 2025-12-28 19:20:15,706] Trial 66 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009904811255677668, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,736] Trial 67 finished with value: 0.8388935574229691 and parameters: {'kernel': 'poly', 'C': 0.006993998290387851, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,775] Trial 68 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.007410494227143837}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,805] Trial 69 finished with value: 0.8238375350140055 and parameters: {'kernel': 'poly', 'C': 0.005113084745483224, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,836] Trial 70 finished with value: 0.8338655462184873 and parameters: {'kernel': 'poly', 'C': 0.006511320466375181, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,865] Trial 71 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008797469250730376, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,895] Trial 72 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008768141001012255, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,924] Trial 73 finished with value: 0.8456162464985993 and parameters: {'kernel': 'poly', 'C': 0.008394833471914423, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,956] Trial 74 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.007710750971501395, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:15,984] Trial 75 finished with value: 0.8271708683473389 and parameters: {'kernel': 'poly', 'C': 0.0059589031520669725, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,014] Trial 76 finished with value: 0.8439355742296918 and parameters: {'kernel': 'poly', 'C': 0.0075160143672365785, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,043] Trial 77 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004358011571595808}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,074] Trial 78 finished with value: 0.8456162464985993 and parameters: {'kernel': 'poly', 'C': 0.008291924730300536, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,103] Trial 79 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0001151803562605867, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,132] Trial 80 finished with value: 0.7449719887955182 and parameters: {'kernel': 'poly', 'C': 0.0012780154691508891, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,163] Trial 81 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008727075927936742, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,195] Trial 82 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.007675983338878304, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,225] Trial 83 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.007838900558841873, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,255] Trial 84 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008591207091563231, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,285] Trial 85 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.00883656629461005, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,320] Trial 86 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008734054542152252, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,349] Trial 87 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.00890200793634219, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,389] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005456476532749609}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,419] Trial 89 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.00891655818503809, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,450] Trial 90 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.00876434515432339, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,479] Trial 91 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008838264244515916, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,510] Trial 92 finished with value: 0.8305182072829131 and parameters: {'kernel': 'poly', 'C': 0.0063385875678568905, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,541] Trial 93 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00014894772739047142, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,571] Trial 94 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008894700312726387, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,599] Trial 95 finished with value: 0.8372268907563025 and parameters: {'kernel': 'poly', 'C': 0.006848566252048697, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,627] Trial 96 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004849898776063868}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,657] Trial 97 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.008685060154587863, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,687] Trial 98 finished with value: 0.8255042016806721 and parameters: {'kernel': 'poly', 'C': 0.005548022518187406, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:16,716] Trial 99 finished with value: 0.8154341736694677 and parameters: {'kernel': 'poly', 'C': 0.004662015620663967, 'degree': 5}. Best is trial 66 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:16,719] A new study created in memory with name: AdaBoost Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Support Vector Machine Using TPESampler: {'kernel': 'poly', 'C': 0.009904811255677668, 'degree': 5}\n",
      "Best accuracy: 0.8456, at trial: 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0efb3281f5c438da50c8418da10c67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:16,824] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:20:16,959] Trial 1 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,016] Trial 2 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,052] Trial 3 finished with value: 0.8490196078431372 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,163] Trial 4 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,211] Trial 5 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,361] Trial 6 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,431] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,497] Trial 8 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,595] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,760] Trial 10 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 98, 'learning_rate': 0.026301587628514228}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:17,885] Trial 11 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 68, 'learning_rate': 0.1265897737239208}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,026] Trial 12 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 78, 'learning_rate': 0.19188668274684334}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,139] Trial 13 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 60, 'learning_rate': 0.026033163308986553}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,272] Trial 14 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 81, 'learning_rate': 0.372686569112744}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,312] Trial 15 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 11, 'learning_rate': 0.05853307315216102}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,463] Trial 16 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 91, 'learning_rate': 0.01187451013407021}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,599] Trial 17 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 74, 'learning_rate': 0.2851114291790847}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,701] Trial 18 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 55, 'learning_rate': 0.059573197085131493}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,774] Trial 19 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 34, 'learning_rate': 0.4397177199618146}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,835] Trial 20 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 20, 'learning_rate': 0.0011997872798046381}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:18,948] Trial 21 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 65, 'learning_rate': 0.2558114094477826}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:19,071] Trial 22 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 73, 'learning_rate': 0.09409697218623145}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:19,196] Trial 23 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 75, 'learning_rate': 0.3127097040298134}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:19,348] Trial 24 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 89, 'learning_rate': 0.6043826849048642}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:20:19,513] Trial 25 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 100, 'learning_rate': 0.18421410660731244}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:19,668] Trial 26 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 96, 'learning_rate': 0.07444634246579308}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:19,835] Trial 27 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 100, 'learning_rate': 0.01407511416724749}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:19,991] Trial 28 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 90, 'learning_rate': 0.16615521320951043}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,084] Trial 29 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 48, 'learning_rate': 0.9766289712820946}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,164] Trial 30 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 40, 'learning_rate': 0.5266440971115494}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,277] Trial 31 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 70, 'learning_rate': 0.23436732632306176}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,390] Trial 32 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 56, 'learning_rate': 0.09486058845824517}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,522] Trial 33 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 81, 'learning_rate': 0.037662549048883213}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,583] Trial 34 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 29, 'learning_rate': 0.14377891834776593}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,718] Trial 35 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 85, 'learning_rate': 0.3152506662360831}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:20,892] Trial 36 finished with value: 0.8456162464985993 and parameters: {'n_estimators': 93, 'learning_rate': 0.6968302533622738}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,005] Trial 37 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 61, 'learning_rate': 0.11903360375250044}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,056] Trial 38 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 18, 'learning_rate': 0.0490020255679608}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,209] Trial 39 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 86, 'learning_rate': 0.20618412150950824}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,316] Trial 40 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 52, 'learning_rate': 0.4913142814210831}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,409] Trial 41 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 44, 'learning_rate': 0.44645333501243967}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,502] Trial 42 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 51, 'learning_rate': 0.6337578455103275}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,617] Trial 43 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 68, 'learning_rate': 0.288439498148867}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,764] Trial 44 finished with value: 0.8422549019607842 and parameters: {'n_estimators': 77, 'learning_rate': 0.8108112766164263}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,838] Trial 45 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 34, 'learning_rate': 0.18256199140502957}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:21,940] Trial 46 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 61, 'learning_rate': 0.10078069494363223}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,023] Trial 47 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 44, 'learning_rate': 0.41472703103701014}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,187] Trial 48 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 95, 'learning_rate': 0.3448860600467003}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,229] Trial 49 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 15, 'learning_rate': 0.15630315267646563}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,290] Trial 50 finished with value: 0.8389215686274509 and parameters: {'n_estimators': 27, 'learning_rate': 0.9542838266642856}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,382] Trial 51 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 49, 'learning_rate': 0.5320940051528489}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,482] Trial 52 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 56, 'learning_rate': 0.9623534905424915}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,586] Trial 53 finished with value: 0.8506722689075629 and parameters: {'n_estimators': 52, 'learning_rate': 0.7037928229863228}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,688] Trial 54 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 65, 'learning_rate': 0.2169271620068775}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,811] Trial 55 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 72, 'learning_rate': 0.44590408397820486}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:22,946] Trial 56 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 82, 'learning_rate': 0.021124874240428245}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,029] Trial 57 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 40, 'learning_rate': 0.25547326783369034}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,121] Trial 58 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 52, 'learning_rate': 0.001717788084031656}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,226] Trial 59 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 59, 'learning_rate': 0.005582572235596191}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,307] Trial 60 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 45, 'learning_rate': 0.5457402436779762}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,390] Trial 61 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 48, 'learning_rate': 0.7194442555271549}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,482] Trial 62 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 53, 'learning_rate': 0.3678677026403923}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,587] Trial 63 finished with value: 0.8355462184873949 and parameters: {'n_estimators': 58, 'learning_rate': 0.8216561889837727}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,689] Trial 64 finished with value: 0.8473389355742296 and parameters: {'n_estimators': 64, 'learning_rate': 0.07256075014300983}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,750] Trial 65 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 32, 'learning_rate': 0.5219374092891805}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,821] Trial 66 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 38, 'learning_rate': 0.27626020294896647}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,904] Trial 67 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 47, 'learning_rate': 0.9826740452177564}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:23,953] Trial 68 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 22, 'learning_rate': 0.6831829749846364}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,120] Trial 69 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 99, 'learning_rate': 0.11868519219350666}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,233] Trial 70 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 67, 'learning_rate': 0.3896959952815792}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,326] Trial 71 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 52, 'learning_rate': 0.6453106984727631}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,419] Trial 72 finished with value: 0.8473109243697478 and parameters: {'n_estimators': 51, 'learning_rate': 0.5723679184641048}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,492] Trial 73 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 41, 'learning_rate': 0.7519039290912717}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,531] Trial 74 finished with value: 0.8422969187675069 and parameters: {'n_estimators': 11, 'learning_rate': 0.47583533640722514}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,625] Trial 75 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 55, 'learning_rate': 0.314899810112969}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,735] Trial 76 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 63, 'learning_rate': 0.6302695549785787}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,870] Trial 77 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 87, 'learning_rate': 0.18906145387329693}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:24,994] Trial 78 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 75, 'learning_rate': 0.03948431235108333}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,128] Trial 79 finished with value: 0.8490056022408963 and parameters: {'n_estimators': 82, 'learning_rate': 0.3692234121471063}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,220] Trial 80 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 50, 'learning_rate': 0.832554296926904}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,344] Trial 81 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 78, 'learning_rate': 0.2457794222510603}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,464] Trial 82 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 69, 'learning_rate': 0.2988636613882853}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,589] Trial 83 finished with value: 0.842282913165266 and parameters: {'n_estimators': 73, 'learning_rate': 0.4507245504963696}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,703] Trial 84 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 67, 'learning_rate': 0.15752287012008218}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,796] Trial 85 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 55, 'learning_rate': 0.33909052806425577}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:25,878] Trial 86 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 46, 'learning_rate': 0.020003988826927752}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,003] Trial 87 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 78, 'learning_rate': 0.21736361081937178}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,086] Trial 88 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 42, 'learning_rate': 0.5810255092323889}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,188] Trial 89 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 62, 'learning_rate': 0.12761036649893326}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,304] Trial 90 finished with value: 0.8506442577030813 and parameters: {'n_estimators': 70, 'learning_rate': 0.8637317176629973}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,429] Trial 91 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 71, 'learning_rate': 0.8685979375239825}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,554] Trial 92 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.49307045770663255}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,679] Trial 93 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 75, 'learning_rate': 0.7052464934343605}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,781] Trial 94 finished with value: 0.850686274509804 and parameters: {'n_estimators': 58, 'learning_rate': 0.46592652438999344}. Best is trial 25 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:20:26,917] Trial 95 finished with value: 0.8540336134453781 and parameters: {'n_estimators': 79, 'learning_rate': 0.49104198519099207}. Best is trial 95 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:20:27,053] Trial 96 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 83, 'learning_rate': 0.4681574176863684}. Best is trial 95 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:20:27,178] Trial 97 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 79, 'learning_rate': 0.423546492720966}. Best is trial 95 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:27,450] A new study created in memory with name: Gradient Boosting Model Fine Tuning with TPESampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:27,323] Trial 98 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 88, 'learning_rate': 0.520685143355798}. Best is trial 95 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:20:27,447] Trial 99 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 74, 'learning_rate': 0.402517241857049}. Best is trial 95 with value: 0.8540336134453781.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using TPESampler: {'n_estimators': 79, 'learning_rate': 0.49104198519099207}\n",
      "Best accuracy: 0.8540, at trial: 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5079567d92426596b083c8dc97f8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:27,563] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n",
      "[I 2025-12-28 19:20:27,706] Trial 1 finished with value: 0.8372408963585434 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:20:27,766] Trial 2 finished with value: 0.6844257703081233 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:20:27,856] Trial 3 finished with value: 0.8019887955182072 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:20:27,956] Trial 4 finished with value: 0.6978151260504202 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:20:28,085] Trial 5 finished with value: 0.8103361344537815 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:20:28,146] Trial 6 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:20:28,192] Trial 7 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 7 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:20:28,271] Trial 8 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 8 with value: 0.8557142857142856.\n",
      "[I 2025-12-28 19:20:28,349] Trial 9 finished with value: 0.8204341736694678 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 8 with value: 0.8557142857142856.\n",
      "[I 2025-12-28 19:20:28,727] Trial 10 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.08691089486124963, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.9861142660861426}. Best is trial 10 with value: 0.8590616246498598.\n",
      "[I 2025-12-28 19:20:29,124] Trial 11 finished with value: 0.8523249299719888 and parameters: {'max_features': 'log2', 'n_estimators': 97, 'learning_rate': 0.09888513616343735, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.995813023603747}. Best is trial 10 with value: 0.8590616246498598.\n",
      "[I 2025-12-28 19:20:29,428] Trial 12 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.02397622727424071, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.8555615028924779}. Best is trial 10 with value: 0.8590616246498598.\n",
      "[I 2025-12-28 19:20:29,683] Trial 13 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.018478118803565778, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.836932074470251}. Best is trial 10 with value: 0.8590616246498598.\n",
      "[I 2025-12-28 19:20:29,998] Trial 14 finished with value: 0.8473389355742297 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.0997068227503642, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.8493007914343119}. Best is trial 10 with value: 0.8590616246498598.\n",
      "[I 2025-12-28 19:20:30,200] Trial 15 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.010500938486143583, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.5181188440599487}. Best is trial 10 with value: 0.8590616246498598.\n",
      "[I 2025-12-28 19:20:30,518] Trial 16 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 73, 'learning_rate': 0.043746620268146935, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.9845865044437605}. Best is trial 10 with value: 0.8590616246498598.\n",
      "[I 2025-12-28 19:20:30,626] Trial 17 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 47, 'learning_rate': 0.01862621967971954, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.7085073674615998}. Best is trial 17 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:30,736] Trial 18 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.009029245888295038, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.6861160154920254}. Best is trial 17 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:30,782] Trial 19 finished with value: 0.8490196078431375 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.06870855431251481, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.6921907103362633}. Best is trial 17 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:30,869] Trial 20 finished with value: 0.8490056022408965 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.013787870379812274, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.5199377120069424}. Best is trial 17 with value: 0.8607563025210083.\n",
      "[I 2025-12-28 19:20:31,095] Trial 21 finished with value: 0.8624229691876751 and parameters: {'max_features': 'log2', 'n_estimators': 90, 'learning_rate': 0.027291166265763087, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.8456554954995721}. Best is trial 21 with value: 0.8624229691876751.\n",
      "[I 2025-12-28 19:20:31,298] Trial 22 finished with value: 0.8473109243697479 and parameters: {'max_features': 'log2', 'n_estimators': 90, 'learning_rate': 0.025592388829684943, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7813137876167394}. Best is trial 21 with value: 0.8624229691876751.\n",
      "[I 2025-12-28 19:20:31,448] Trial 23 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 68, 'learning_rate': 0.061194056908349136, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.6960034356849912}. Best is trial 21 with value: 0.8624229691876751.\n",
      "[I 2025-12-28 19:20:31,587] Trial 24 finished with value: 0.8556862745098041 and parameters: {'max_features': 'log2', 'n_estimators': 32, 'learning_rate': 0.006801964547180289, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.8898317735329486}. Best is trial 21 with value: 0.8624229691876751.\n",
      "[I 2025-12-28 19:20:31,706] Trial 25 finished with value: 0.8574089635854343 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.015873254057493482, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.817994968109712}. Best is trial 21 with value: 0.8624229691876751.\n",
      "[I 2025-12-28 19:20:31,969] Trial 26 finished with value: 0.8674649859943978 and parameters: {'max_features': 'log2', 'n_estimators': 94, 'learning_rate': 0.06053781067930206, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7306935702749274}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:32,079] Trial 27 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.025228926073624966, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7338552650548413}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:32,239] Trial 28 finished with value: 0.8489775910364145 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.05022554149030947, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.6644092238956741}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:32,566] Trial 29 finished with value: 0.8338655462184873 and parameters: {'max_features': None, 'n_estimators': 94, 'learning_rate': 0.030402687904812598, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7966519772857097}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:32,696] Trial 30 finished with value: 0.8456162464985993 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.060589926860725195, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7243946416713933}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:33,041] Trial 31 finished with value: 0.8473249299719889 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.07523956119874407, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.87574476507543}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:33,317] Trial 32 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 87, 'learning_rate': 0.01950095381601666, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.7646145904620643}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:33,580] Trial 33 finished with value: 0.8540616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 99, 'learning_rate': 0.046652947823806024, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.6324552561714333}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:33,817] Trial 34 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 80, 'learning_rate': 0.012057658244175904, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.9596121740470057}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,011] Trial 35 finished with value: 0.850672268907563 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.03335649191687067, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8153449092638796}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,192] Trial 36 finished with value: 0.850658263305322 and parameters: {'max_features': 'log2', 'n_estimators': 85, 'learning_rate': 0.007970193143777607, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7625103322835702}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,355] Trial 37 finished with value: 0.8557002801120449 and parameters: {'max_features': None, 'n_estimators': 95, 'learning_rate': 0.07486848442031632, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.7163620833129682}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,507] Trial 38 finished with value: 0.8674649859943978 and parameters: {'max_features': 'log2', 'n_estimators': 53, 'learning_rate': 0.054202630894678895, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.5615793845473197}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,604] Trial 39 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 53, 'learning_rate': 0.05190772477391452, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.5777853244552633}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,743] Trial 40 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 44, 'learning_rate': 0.021007328541071183, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.5493764265205424}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,834] Trial 41 finished with value: 0.8489915966386553 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.0546266197075751, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.5774768421223694}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:34,922] Trial 42 finished with value: 0.8607282913165266 and parameters: {'max_features': 'log2', 'n_estimators': 54, 'learning_rate': 0.03779598167636519, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6393098736910559}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,001] Trial 43 finished with value: 0.8523249299719888 and parameters: {'max_features': 'log2', 'n_estimators': 36, 'learning_rate': 0.03486341089239528, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.6388764672574719}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,110] Trial 44 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 47, 'learning_rate': 0.02715161155665044, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6526195189518047}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,294] Trial 45 finished with value: 0.8473109243697479 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.03915361157101104, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.603962275081501}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,396] Trial 46 finished with value: 0.8389215686274509 and parameters: {'max_features': None, 'n_estimators': 57, 'learning_rate': 0.01594492465058246, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.6109513288699826}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,496] Trial 47 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.03991012296899608, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.669379150383474}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,586] Trial 48 finished with value: 0.862450980392157 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.031103757016867444, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.5520083839394913}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,654] Trial 49 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 29, 'learning_rate': 0.0011305785446349397, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.5277283801053201}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,763] Trial 50 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 37, 'learning_rate': 0.02928417408893918, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.5705840025767959}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,862] Trial 51 finished with value: 0.8405742296918767 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.04159752680887006, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.5034327778141325}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:35,972] Trial 52 finished with value: 0.5788095238095239 and parameters: {'max_features': 'log2', 'n_estimators': 48, 'learning_rate': 0.0016113483324820073, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.5495892623509615}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,104] Trial 53 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 55, 'learning_rate': 0.01929306534812935, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7037778360960761}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,194] Trial 54 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 43, 'learning_rate': 0.034244468493201646, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.7420491915083925}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,292] Trial 55 finished with value: 0.7717507002801121 and parameters: {'max_features': 'sqrt', 'n_estimators': 34, 'learning_rate': 0.003441583572616611, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.6175350200305362}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,340] Trial 56 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.022915878452624328, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.5524439951484083}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,407] Trial 57 finished with value: 0.8355742296918767 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.01645646478469922, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.6670320862114345}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,498] Trial 58 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.08536372028401966, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.5923532812024959}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,606] Trial 59 finished with value: 0.8641176470588237 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.06295813403884058, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.6787063735419252}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,716] Trial 60 finished with value: 0.8506722689075629 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.06076619222221698, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.7850036238207687}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,814] Trial 61 finished with value: 0.85906162464986 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.04413846450601451, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9, 'subsample': 0.7124626402091153}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:36,937] Trial 62 finished with value: 0.8590756302521008 and parameters: {'max_features': None, 'n_estimators': 60, 'learning_rate': 0.0687680275486313, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.6471897879303189}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,067] Trial 63 finished with value: 0.8406162464985993 and parameters: {'max_features': None, 'n_estimators': 53, 'learning_rate': 0.0557994148272074, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.6878352853884927}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,148] Trial 64 finished with value: 0.8607703081232494 and parameters: {'max_features': 'log2', 'n_estimators': 45, 'learning_rate': 0.0879862938600457, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8, 'subsample': 0.6731034490203602}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,247] Trial 65 finished with value: 0.8540336134453781 and parameters: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.089498916214999, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.7286483889771334}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,336] Trial 66 finished with value: 0.867450980392157 and parameters: {'max_features': 'sqrt', 'n_estimators': 44, 'learning_rate': 0.07832928381693209, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.7609363198730732}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,423] Trial 67 finished with value: 0.8557422969187677 and parameters: {'max_features': 'sqrt', 'n_estimators': 31, 'learning_rate': 0.09966284669890399, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.745889478310471}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,512] Trial 68 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 40, 'learning_rate': 0.07931106322796729, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 9, 'subsample': 0.8334133757939284}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,590] Trial 69 finished with value: 0.8641176470588234 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.06852701545035472, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.7693076357829964}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,668] Trial 70 finished with value: 0.862450980392157 and parameters: {'max_features': 'sqrt', 'n_estimators': 37, 'learning_rate': 0.06889664939393113, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.7759248884121498}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,736] Trial 71 finished with value: 0.8607843137254904 and parameters: {'max_features': 'sqrt', 'n_estimators': 34, 'learning_rate': 0.06724167571061253, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.7772407975455434}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,827] Trial 72 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 37, 'learning_rate': 0.04858222745375089, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.8131025462284748}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:37,914] Trial 73 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.06382485465334077, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.7981126734545818}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,056] Trial 74 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.07545756739799472, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 9, 'subsample': 0.8660278172812691}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,143] Trial 75 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.056241520384301774, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.759544084396814}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,232] Trial 76 finished with value: 0.8641036414565827 and parameters: {'max_features': 'sqrt', 'n_estimators': 50, 'learning_rate': 0.045675145305675784, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.8974808539398685}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,319] Trial 77 finished with value: 0.8590896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.07126221130222526, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9, 'subsample': 0.9056365550280088}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,410] Trial 78 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.04654012550658423, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.9458838984860725}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,497] Trial 79 finished with value: 0.86578431372549 and parameters: {'max_features': 'sqrt', 'n_estimators': 49, 'learning_rate': 0.052978859626254246, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.772403867874626}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,610] Trial 80 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.05389588033742622, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10, 'subsample': 0.8313442201063798}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,699] Trial 81 finished with value: 0.8607703081232494 and parameters: {'max_features': 'sqrt', 'n_estimators': 50, 'learning_rate': 0.08429746285934014, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.7803917232317866}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,777] Trial 82 finished with value: 0.8557282913165265 and parameters: {'max_features': 'sqrt', 'n_estimators': 43, 'learning_rate': 0.0607382789730936, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.7679567193090124}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,854] Trial 83 finished with value: 0.8540476190476189 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.04918261842287887, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.759004817704106}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:38,966] Trial 84 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 58, 'learning_rate': 0.06805597297601944, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9, 'subsample': 0.7478243405421269}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,042] Trial 85 finished with value: 0.8355462184873949 and parameters: {'max_features': 'sqrt', 'n_estimators': 35, 'learning_rate': 0.005804305753767861, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.8077977040884426}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,143] Trial 86 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 45, 'learning_rate': 0.04281134452493292, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.5337643384847426}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,220] Trial 87 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 31, 'learning_rate': 0.031584713501723816, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.7917482779553192}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,320] Trial 88 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.03714731207021633, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.7255818147980817}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,398] Trial 89 finished with value: 0.8641596638655461 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.05874394566727191, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.8879311959014751}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,490] Trial 90 finished with value: 0.8607703081232494 and parameters: {'max_features': 'sqrt', 'n_estimators': 42, 'learning_rate': 0.05741276877291261, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.9200849909816016}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,568] Trial 91 finished with value: 0.8641176470588234 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.07772327025665235, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.8582370643571877}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,669] Trial 92 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 47, 'learning_rate': 0.07992707290956906, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.8892081869697092}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,758] Trial 93 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.09322286369022567, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.8864908942261552}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,870] Trial 94 finished with value: 0.8590476190476192 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.05014971967155207, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.8628314742102864}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:39,938] Trial 95 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 33, 'learning_rate': 0.0631692687498397, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.9214432436154862}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:40,080] Trial 96 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 45, 'learning_rate': 0.07618361805243858, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.8764881964902943}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:40,177] Trial 97 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 49, 'learning_rate': 0.052576266904785965, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.9695635012005741}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:40,246] Trial 98 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 25, 'learning_rate': 0.044737081067270354, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.9036076079094092}. Best is trial 26 with value: 0.8674649859943978.\n",
      "[I 2025-12-28 19:20:40,378] Trial 99 finished with value: 0.8590896358543418 and parameters: {'max_features': None, 'n_estimators': 39, 'learning_rate': 0.060160199107374274, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.8436015131182003}. Best is trial 26 with value: 0.8674649859943978.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using TPESampler: {'max_features': 'log2', 'n_estimators': 94, 'learning_rate': 0.06053781067930206, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7306935702749274}\n",
      "Best accuracy: 0.8675, at trial: 26\n",
      "TPE Base Models Training Time: 53.73 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_base_models_training_start = time.time()\n",
    "\n",
    "    # TPE Hyperparameter Tuning with Cross Validation\n",
    "    tpe_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='TPESampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    tpe_logistic_regression.fit(X_train, y_train)\n",
    "    tpe_decision_tree.fit(X_train, y_train)\n",
    "    tpe_random_forest.fit(X_train, y_train)\n",
    "    tpe_knn.fit(X_train, y_train)\n",
    "    tpe_svc.fit(X_train, y_train)\n",
    "    tpe_adaboost.fit(X_train, y_train)\n",
    "    tpe_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    tpe_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE base models training\n",
    "    tpe_base_models_training_time = tpe_base_models_training_end - tpe_base_models_training_start\n",
    "    print(f'TPE Base Models Training Time: {tpe_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping TPE base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:20:40,928] A new study created in memory with name: Logistic Regression Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fdb7ee6863471cbbdaa03500f76786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:20:40,970] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:20:41,007] Trial 1 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cholesky', 'C': 0.3470266988650412}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-12-28 19:20:41,044] Trial 2 finished with value: 0.5704481792717087 and parameters: {'solver': 'newton-cg', 'C': 0.0008111941985431928}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-12-28 19:20:41,082] Trial 3 finished with value: 0.8288375350140056 and parameters: {'solver': 'newton-cholesky', 'C': 0.0028585493941961923}. Best is trial 1 with value: 0.8405882352941176.\n",
      "[I 2025-12-28 19:20:41,117] Trial 4 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.019069966103000432}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:41,154] Trial 5 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00017070728830306665}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:41,203] Trial 6 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.732248920775331}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:41,238] Trial 7 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.015876781526923997}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:41,275] Trial 8 finished with value: 0.8087254901960785 and parameters: {'solver': 'sag', 'C': 0.0019674328025306126}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:41,312] Trial 9 finished with value: 0.5888795518207283 and parameters: {'solver': 'lbfgs', 'C': 0.0008399864445957502}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:45,490] Trial 10 finished with value: 0.8422268907563024 and parameters: {'solver': 'sag', 'C': 0.018417084349353685}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:47,689] Trial 11 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cholesky', 'C': 0.015696165881356743}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:49,865] Trial 12 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 1.0743268516838402}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:51,788] Trial 13 finished with value: 0.8304901960784313 and parameters: {'solver': 'sag', 'C': 0.006083280540299305}. Best is trial 4 with value: 0.84390756302521.\n",
      "[I 2025-12-28 19:20:51,931] Trial 14 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.09010567835309394}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-12-28 19:20:52,096] Trial 15 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 0.6008632954817963}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-12-28 19:20:52,221] Trial 16 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 0.46070611208561313}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-12-28 19:20:52,344] Trial 17 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 9.999999999999993}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-12-28 19:20:52,461] Trial 18 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 9.999999999999993}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-12-28 19:20:52,642] Trial 19 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.0501912139123069}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-12-28 19:20:52,790] Trial 20 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 2.7691730677144086}. Best is trial 14 with value: 0.8456162464985993.\n",
      "[I 2025-12-28 19:20:52,976] Trial 21 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.1473353251488926}. Best is trial 21 with value: 0.8456302521008403.\n",
      "[I 2025-12-28 19:20:53,117] Trial 22 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.0373825752731418}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:53,235] Trial 23 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.07158707771050021}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:53,386] Trial 24 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.22944175148619947}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:53,529] Trial 25 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 4.978284149263648}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:53,685] Trial 26 finished with value: 0.835546218487395 and parameters: {'solver': 'sag', 'C': 0.003351695811846066}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:53,838] Trial 27 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.03847872213484664}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:53,967] Trial 28 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cholesky', 'C': 0.14054584256513222}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:54,110] Trial 29 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 1.8759391704887434}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:54,239] Trial 30 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06782823404686641}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:54,400] Trial 31 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.03386910074909205}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:54,534] Trial 32 finished with value: 0.8456302521008403 and parameters: {'solver': 'sag', 'C': 0.1601700929188212}. Best is trial 22 with value: 0.8472689075630251.\n",
      "[I 2025-12-28 19:20:54,670] Trial 33 finished with value: 0.8472689075630253 and parameters: {'solver': 'newton-cholesky', 'C': 0.02891295352813455}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:54,827] Trial 34 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.025145170885534463}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:54,996] Trial 35 finished with value: 0.8472689075630253 and parameters: {'solver': 'lbfgs', 'C': 0.029343585895874377}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:55,133] Trial 36 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.24375323524244277}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:55,297] Trial 37 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 9.973531625144435}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:55,448] Trial 38 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.10704679472060179}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:55,617] Trial 39 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 1.1407558313420432}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:55,772] Trial 40 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.20546122950742557}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:55,957] Trial 41 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.08586399131617344}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:56,107] Trial 42 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05577847570802732}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:56,266] Trial 43 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.046745729925322596}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:56,403] Trial 44 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.03277210291590676}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:56,565] Trial 45 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.03466313306744065}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:56,712] Trial 46 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.024622674546276882}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:56,897] Trial 47 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.045021646685933295}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:57,036] Trial 48 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.03261333549131648}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:57,180] Trial 49 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 2.147236687733701}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:57,319] Trial 50 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.061998271022651666}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:57,476] Trial 51 finished with value: 0.8456302521008403 and parameters: {'solver': 'lbfgs', 'C': 0.13974881865753794}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:57,626] Trial 52 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.045571821227987044}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:57,765] Trial 53 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 3.9691900518476846}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:57,892] Trial 54 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.04999729265320161}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:58,044] Trial 55 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.10407646421897666}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:58,190] Trial 56 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026206560849573783}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:58,332] Trial 57 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026369440213095268}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:58,479] Trial 58 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026424863580874987}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:58,636] Trial 59 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026437373592434445}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:58,797] Trial 60 finished with value: 0.8456302521008403 and parameters: {'solver': 'sag', 'C': 0.24319809201510376}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:58,940] Trial 61 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026438709621283474}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:59,082] Trial 62 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02641324711339976}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:59,227] Trial 63 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02638015186914568}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:59,411] Trial 64 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02634389152982402}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:59,584] Trial 65 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026306530751649848}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:59,808] Trial 66 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02627144105006194}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:20:59,982] Trial 67 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026387459902713073}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:00,133] Trial 68 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.02651846921631244}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:00,313] Trial 69 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026543790921290878}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:00,461] Trial 70 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026554495946053004}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:00,612] Trial 71 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026560354090641124}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:00,805] Trial 72 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026566225588761164}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:00,950] Trial 73 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cg', 'C': 0.31751147803764446}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:01,114] Trial 74 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1953318691826493}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:01,317] Trial 75 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026783879201260744}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:01,515] Trial 76 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02619614107806779}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:01,696] Trial 77 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.026861360178697186}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:01,923] Trial 78 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026533466884080568}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:02,105] Trial 79 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 6.9305597826064425}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:02,286] Trial 80 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026632674651196755}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:02,487] Trial 81 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.027071257654551314}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:02,719] Trial 82 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026845491168669133}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:03,006] Trial 83 finished with value: 0.83890756302521 and parameters: {'solver': 'sag', 'C': 0.8477348336748014}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:03,248] Trial 84 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.027170928391214082}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:03,427] Trial 85 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025468463027872583}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:03,648] Trial 86 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025569392366260508}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:03,910] Trial 87 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025662440890438537}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:04,049] Trial 88 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025749506345743516}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:04,301] Trial 89 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02583703580968716}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:04,488] Trial 90 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.025928435866366832}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:04,698] Trial 91 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.02601789708980147}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:04,915] Trial 92 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026116813554755255}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:05,111] Trial 93 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.0261922451406888}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:05,358] Trial 94 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.026255092433546626}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:05,634] Trial 95 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.0263057794118137}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:05,846] Trial 96 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.11365720200602504}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:06,065] Trial 97 finished with value: 0.8455882352941175 and parameters: {'solver': 'sag', 'C': 0.024905981266234074}. Best is trial 33 with value: 0.8472689075630253.\n",
      "[I 2025-12-28 19:21:06,228] Trial 98 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.027077620543819226}. Best is trial 33 with value: 0.8472689075630253.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:21:06,420] A new study created in memory with name: Decision Tree Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:21:06,419] Trial 99 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.027047395887894374}. Best is trial 33 with value: 0.8472689075630253.\n",
      "\n",
      "Best Hyperparameters for Logistic Regression Using GPSampler: {'solver': 'newton-cholesky', 'C': 0.02891295352813455}\n",
      "Best accuracy: 0.8473, at trial: 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfc2c58178a427ea857b27913b4e079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:21:06,446] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[I 2025-12-28 19:21:06,462] Trial 1 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,489] Trial 2 finished with value: 0.807044817927171 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,506] Trial 3 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,532] Trial 4 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,562] Trial 5 finished with value: 0.8070448179271708 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,589] Trial 6 finished with value: 0.8272128851540617 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,606] Trial 7 finished with value: 0.8036974789915966 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,623] Trial 8 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,640] Trial 9 finished with value: 0.8002941176470589 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,733] Trial 10 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,811] Trial 11 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:06,918] Trial 12 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:07,024] Trial 13 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:07,107] Trial 14 finished with value: 0.8204901960784312 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:07,199] Trial 15 finished with value: 0.8373109243697477 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:07,282] Trial 16 finished with value: 0.8255322128851541 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.8423109243697479.\n",
      "[I 2025-12-28 19:21:07,374] Trial 17 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 17 with value: 0.8439775910364145.\n",
      "[I 2025-12-28 19:21:07,466] Trial 18 finished with value: 0.8473109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 18 with value: 0.8473109243697479.\n",
      "[I 2025-12-28 19:21:07,560] Trial 19 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.8473109243697479.\n",
      "[I 2025-12-28 19:21:07,642] Trial 20 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 18 with value: 0.8473109243697479.\n",
      "[I 2025-12-28 19:21:07,731] Trial 21 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 18 with value: 0.8473109243697479.\n",
      "[I 2025-12-28 19:21:07,828] Trial 22 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 18 with value: 0.8473109243697479.\n",
      "[I 2025-12-28 19:21:07,907] Trial 23 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:07,986] Trial 24 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,075] Trial 25 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,143] Trial 26 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,217] Trial 27 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,315] Trial 28 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,427] Trial 29 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,516] Trial 30 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,613] Trial 31 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,708] Trial 32 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,800] Trial 33 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,880] Trial 34 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:08,985] Trial 35 finished with value: 0.7969467787114846 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,093] Trial 36 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,178] Trial 37 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,253] Trial 38 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,356] Trial 39 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,451] Trial 40 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,538] Trial 41 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,628] Trial 42 finished with value: 0.8104621848739495 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,711] Trial 43 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,802] Trial 44 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:09,902] Trial 45 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,011] Trial 46 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,125] Trial 47 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,275] Trial 48 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,382] Trial 49 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,494] Trial 50 finished with value: 0.8389215686274509 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,609] Trial 51 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,741] Trial 52 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,859] Trial 53 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:10,984] Trial 54 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:11,115] Trial 55 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:11,240] Trial 56 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:11,380] Trial 57 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:11,498] Trial 58 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:11,640] Trial 59 finished with value: 0.7987254901960783 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:11,767] Trial 60 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:11,902] Trial 61 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:12,047] Trial 62 finished with value: 0.8222128851540618 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:12,188] Trial 63 finished with value: 0.8138375350140056 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:12,325] Trial 64 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:12,467] Trial 65 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:12,613] Trial 66 finished with value: 0.8422969187675069 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:12,754] Trial 67 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:12,909] Trial 68 finished with value: 0.8188235294117646 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:13,046] Trial 69 finished with value: 0.8255322128851541 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:13,193] Trial 70 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:13,342] Trial 71 finished with value: 0.8020028011204481 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:13,480] Trial 72 finished with value: 0.7936274509803921 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:13,618] Trial 73 finished with value: 0.8372829131652659 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:13,739] Trial 74 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:13,883] Trial 75 finished with value: 0.8372829131652659 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:14,007] Trial 76 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:14,142] Trial 77 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:14,282] Trial 78 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:14,444] Trial 79 finished with value: 0.8422969187675069 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:14,590] Trial 80 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:14,737] Trial 81 finished with value: 0.8020308123249299 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:14,882] Trial 82 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,021] Trial 83 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,143] Trial 84 finished with value: 0.8171148459383752 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,286] Trial 85 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,421] Trial 86 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,547] Trial 87 finished with value: 0.8322408963585433 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,695] Trial 88 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,824] Trial 89 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:15,974] Trial 90 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:16,107] Trial 91 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:16,241] Trial 92 finished with value: 0.8389495798319327 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:16,372] Trial 93 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:16,507] Trial 94 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:16,649] Trial 95 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:16,790] Trial 96 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:16,939] Trial 97 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n",
      "[I 2025-12-28 19:21:17,061] Trial 98 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 23 with value: 0.850700280112045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:21:17,204] A new study created in memory with name: Random Forest Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:21:17,201] Trial 99 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 23 with value: 0.850700280112045.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using GPSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}\n",
      "Best accuracy: 0.8507, at trial: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d448a05d784519ac596360c48db9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:21:17,303] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[I 2025-12-28 19:21:17,425] Trial 1 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8489915966386554.\n",
      "[I 2025-12-28 19:21:17,537] Trial 2 finished with value: 0.8288655462184874 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8489915966386554.\n",
      "[I 2025-12-28 19:21:17,648] Trial 3 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:17,770] Trial 4 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:17,860] Trial 5 finished with value: 0.842282913165266 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:17,957] Trial 6 finished with value: 0.8355882352941176 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 22, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:18,141] Trial 7 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:18,325] Trial 8 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:18,466] Trial 9 finished with value: 0.8489775910364145 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:18,823] Trial 10 finished with value: 0.8456582633053223 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:19,112] Trial 11 finished with value: 0.8439635854341738 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 26, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:19,427] Trial 12 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:19,756] Trial 13 finished with value: 0.842296918767507 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 14, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:20,137] Trial 14 finished with value: 0.8490056022408965 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:20,485] Trial 15 finished with value: 0.8473529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:20,883] Trial 16 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:21,252] Trial 17 finished with value: 0.8490056022408965 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:21,601] Trial 18 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:21:21,956] Trial 19 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:22,374] Trial 20 finished with value: 0.8490196078431375 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:22,838] Trial 21 finished with value: 0.8573669467787115 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:23,225] Trial 22 finished with value: 0.8540476190476189 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 79, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:23,564] Trial 23 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:23,962] Trial 24 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:24,353] Trial 25 finished with value: 0.8473109243697478 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:24,833] Trial 26 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:25,176] Trial 27 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:25,580] Trial 28 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:25,908] Trial 29 finished with value: 0.850658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:26,354] Trial 30 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 21 with value: 0.8573669467787115.\n",
      "[I 2025-12-28 19:21:26,701] Trial 31 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:27,017] Trial 32 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:27,399] Trial 33 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 76, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:27,784] Trial 34 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:28,191] Trial 35 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:28,423] Trial 36 finished with value: 0.8422829131652663 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:28,795] Trial 37 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:29,212] Trial 38 finished with value: 0.8557282913165267 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:29,603] Trial 39 finished with value: 0.8523389355742296 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:29,981] Trial 40 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:30,306] Trial 41 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8573949579831932.\n",
      "[I 2025-12-28 19:21:30,681] Trial 42 finished with value: 0.8590756302521008 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:31,059] Trial 43 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:31,434] Trial 44 finished with value: 0.8557142857142856 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:31,811] Trial 45 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:32,138] Trial 46 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:32,524] Trial 47 finished with value: 0.8573949579831932 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:32,893] Trial 48 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:33,339] Trial 49 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:33,711] Trial 50 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:34,104] Trial 51 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:34,461] Trial 52 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:34,864] Trial 53 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:35,310] Trial 54 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:35,764] Trial 55 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:36,163] Trial 56 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:36,571] Trial 57 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 42 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:21:36,919] Trial 58 finished with value: 0.8607843137254904 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 58 with value: 0.8607843137254904.\n",
      "[I 2025-12-28 19:21:37,240] Trial 59 finished with value: 0.8591036414565826 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 58 with value: 0.8607843137254904.\n",
      "[I 2025-12-28 19:21:37,607] Trial 60 finished with value: 0.862450980392157 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:37,994] Trial 61 finished with value: 0.8590896358543418 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:38,408] Trial 62 finished with value: 0.8456442577030814 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:38,868] Trial 63 finished with value: 0.8473389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:39,247] Trial 64 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:39,630] Trial 65 finished with value: 0.862450980392157 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:40,037] Trial 66 finished with value: 0.8591036414565828 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:40,472] Trial 67 finished with value: 0.8590756302521008 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 69, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:40,940] Trial 68 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:41,334] Trial 69 finished with value: 0.8339495798319326 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 74, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:41,777] Trial 70 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:42,222] Trial 71 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:42,570] Trial 72 finished with value: 0.8574089635854343 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 44, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:43,066] Trial 73 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:43,380] Trial 74 finished with value: 0.8574089635854343 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:44,202] Trial 75 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:44,765] Trial 76 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 28, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:45,343] Trial 77 finished with value: 0.8590896358543418 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:45,870] Trial 78 finished with value: 0.8439635854341738 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:46,169] Trial 79 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:46,494] Trial 80 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:46,798] Trial 81 finished with value: 0.8406022408963585 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:47,202] Trial 82 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 45, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:47,619] Trial 83 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:48,041] Trial 84 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:48,398] Trial 85 finished with value: 0.8439775910364145 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:48,866] Trial 86 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:49,259] Trial 87 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:49,641] Trial 88 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:50,116] Trial 89 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:50,653] Trial 90 finished with value: 0.8339075630252101 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:51,155] Trial 91 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:51,559] Trial 92 finished with value: 0.8456582633053221 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 60, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:52,035] Trial 93 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:52,508] Trial 94 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:52,988] Trial 95 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:53,412] Trial 96 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:53,718] Trial 97 finished with value: 0.8473249299719889 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 60 with value: 0.862450980392157.\n",
      "[I 2025-12-28 19:21:54,231] Trial 98 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:21:54,707] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:21:54,706] Trial 99 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 60 with value: 0.862450980392157.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using GPSampler: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "Best accuracy: 0.8625, at trial: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a189e057f23f40798b462aeed4a58313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:21:54,762] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[I 2025-12-28 19:21:54,788] Trial 1 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:21:54,836] Trial 2 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:21:54,958] Trial 3 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:21:55,004] Trial 4 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 20, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:21:55,051] Trial 5 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 1 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:21:55,099] Trial 6 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:21:55,136] Trial 7 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:21:55,184] Trial 8 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:21:55,232] Trial 9 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 6 with value: 0.8507002801120447.\n",
      "[I 2025-12-28 19:21:55,368] Trial 10 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:55,474] Trial 11 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:55,600] Trial 12 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:55,727] Trial 13 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:55,835] Trial 14 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:55,961] Trial 15 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:56,117] Trial 16 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:56,228] Trial 17 finished with value: 0.8271008403361346 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:56,378] Trial 18 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:56,478] Trial 19 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:56,636] Trial 20 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:56,780] Trial 21 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:56,942] Trial 22 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 22, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:57,076] Trial 23 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:57,254] Trial 24 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:57,382] Trial 25 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:57,524] Trial 26 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:57,662] Trial 27 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:57,772] Trial 28 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:57,884] Trial 29 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,034] Trial 30 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,204] Trial 31 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,336] Trial 32 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,446] Trial 33 finished with value: 0.850686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,576] Trial 34 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,712] Trial 35 finished with value: 0.845658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,853] Trial 36 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:58,972] Trial 37 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:59,145] Trial 38 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:59,322] Trial 39 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:59,476] Trial 40 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:59,627] Trial 41 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 11, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:59,769] Trial 42 finished with value: 0.8506862745098038 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 13, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:21:59,907] Trial 43 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:00,074] Trial 44 finished with value: 0.8473249299719889 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 11, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:00,220] Trial 45 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 9, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:00,346] Trial 46 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 12, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:00,504] Trial 47 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:00,651] Trial 48 finished with value: 0.8472969187675069 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 18, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:00,786] Trial 49 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:00,934] Trial 50 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:01,076] Trial 51 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:01,211] Trial 52 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:01,381] Trial 53 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:01,499] Trial 54 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:01,635] Trial 55 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:01,762] Trial 56 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:01,902] Trial 57 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:02,038] Trial 58 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:02,201] Trial 59 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:02,342] Trial 60 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:02,527] Trial 61 finished with value: 0.850658263305322 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:02,677] Trial 62 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:02,821] Trial 63 finished with value: 0.8489775910364145 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 24, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:02,956] Trial 64 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:03,120] Trial 65 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:03,250] Trial 66 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:03,403] Trial 67 finished with value: 0.850658263305322 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:03,587] Trial 68 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 25, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:03,729] Trial 69 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:03,877] Trial 70 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 48, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:04,022] Trial 71 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:04,171] Trial 72 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:04,309] Trial 73 finished with value: 0.850672268907563 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:04,474] Trial 74 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 16, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:04,626] Trial 75 finished with value: 0.8372549019607842 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 7, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:04,758] Trial 76 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:04,902] Trial 77 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:05,042] Trial 78 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 33, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:05,207] Trial 79 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:05,420] Trial 80 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 17, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:05,529] Trial 81 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:05,691] Trial 82 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:05,854] Trial 83 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:06,029] Trial 84 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:06,174] Trial 85 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:06,342] Trial 86 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:06,511] Trial 87 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:06,685] Trial 88 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:06,844] Trial 89 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:07,012] Trial 90 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:07,173] Trial 91 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:07,328] Trial 92 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:07,459] Trial 93 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:07,618] Trial 94 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:07,815] Trial 95 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 36, 'p': 1}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:07,991] Trial 96 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:08,162] Trial 97 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:22:08,497] A new study created in memory with name: Support Vector Machine Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:22:08,343] Trial 98 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "[I 2025-12-28 19:22:08,494] Trial 99 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 10 with value: 0.8523669467787116.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using GPSampler: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b84aa48a26840818a78fc9cd7d99710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:22:08,543] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,588] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.005399484409787433}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,627] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.008706020878304856}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,666] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023270677083837802}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,691] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0003823475224675188}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,717] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005404103854647331}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,754] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010677482709481358}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,782] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00021930485556643703, 'degree': 2}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,807] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0004066563313514797}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[I 2025-12-28 19:22:08,845] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017541893487450815}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:22:08,928] The parameter `degree` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:08,955] Trial 10 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 10 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:22:09,060] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,086] Trial 11 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 10 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:22:09,155] The parameter `degree` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,181] Trial 12 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,259] The parameter `degree` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,286] Trial 13 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,374] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,400] Trial 14 finished with value: 0.8288375350140054 and parameters: {'kernel': 'poly', 'C': 0.005973863143360628, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,448] The parameter `degree` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,474] Trial 15 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,544] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,571] Trial 16 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,621] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,647] Trial 17 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,757] The parameter `degree` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,784] Trial 18 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.00683594677028223, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,862] The parameter `degree` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,888] Trial 19 finished with value: 0.781890756302521 and parameters: {'kernel': 'poly', 'C': 0.0028509774972042554, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:09,938] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:09,963] Trial 20 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,008] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,034] Trial 21 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,079] The parameter `degree` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,105] Trial 22 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,141] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,167] Trial 23 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,207] The parameter `degree` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,233] Trial 24 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,272] The parameter `degree` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,298] Trial 25 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,347] The parameter `degree` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,372] Trial 26 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,465] The parameter `degree` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,492] Trial 27 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,558] The parameter `degree` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,585] Trial 28 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,694] The parameter `degree` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,721] Trial 29 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:10,811] The parameter `degree` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:10,836] Trial 30 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007627556065784929, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,019] The parameter `degree` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,046] Trial 31 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.0076268703144456865, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,196] The parameter `degree` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,225] Trial 32 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007618916921383272, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,338] The parameter `degree` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,363] Trial 33 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007625835600610076, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,452] The parameter `degree` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,478] Trial 34 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,575] The parameter `degree` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,602] Trial 35 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007613447949452226, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,708] The parameter `degree` in Trial#36 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,736] Trial 36 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,783] The parameter `degree` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,809] Trial 37 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,871] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,898] Trial 38 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:11,959] The parameter `degree` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:11,984] Trial 39 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:12,058] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:12,085] Trial 40 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:12,273] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:12,309] Trial 41 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:12,552] The parameter `degree` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:12,578] Trial 42 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.007548525545035469, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:12,754] The parameter `degree` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:12,780] Trial 43 finished with value: 0.8305042016806722 and parameters: {'kernel': 'poly', 'C': 0.0075531289823978385, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:12,845] The parameter `degree` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:12,871] Trial 44 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:12,959] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:12,989] Trial 45 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,147] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,176] Trial 46 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,276] The parameter `degree` in Trial#47 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,304] Trial 47 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,411] The parameter `degree` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,437] Trial 48 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007498060768275007, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,493] The parameter `degree` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,520] Trial 49 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,620] The parameter `degree` in Trial#50 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,647] Trial 50 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,701] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,727] Trial 51 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,792] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,818] Trial 52 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:13,945] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:13,970] Trial 53 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007464031841422213, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:14,218] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:14,243] Trial 54 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007471021056756715, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:14,388] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:14,413] Trial 55 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:14,499] The parameter `degree` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:14,525] Trial 56 finished with value: 0.8288235294117646 and parameters: {'kernel': 'poly', 'C': 0.007473343756476445, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:14,594] The parameter `degree` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:14,621] Trial 57 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:14,674] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:14,702] Trial 58 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:14,807] The parameter `degree` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:14,832] Trial 59 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:14,906] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:14,932] Trial 60 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:15,055] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:15,081] Trial 61 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:15,184] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:15,210] Trial 62 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:15,278] The parameter `degree` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:15,304] Trial 63 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:15,461] The parameter `degree` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:15,488] Trial 64 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:15,603] The parameter `degree` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:15,630] Trial 65 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:15,721] The parameter `degree` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:15,747] Trial 66 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007478567723759324, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:15,843] The parameter `degree` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:15,870] Trial 67 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:16,116] The parameter `degree` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:16,143] Trial 68 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007441435012312642, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:16,209] The parameter `degree` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:16,234] Trial 69 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:16,339] The parameter `degree` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:16,366] Trial 70 finished with value: 0.8288235294117646 and parameters: {'kernel': 'poly', 'C': 0.007399314587183618, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:16,431] The parameter `degree` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:16,457] Trial 71 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:16,621] The parameter `degree` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:16,647] Trial 72 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:16,709] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:16,735] Trial 73 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:16,934] The parameter `degree` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:16,960] Trial 74 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:17,041] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:17,067] Trial 75 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:17,189] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:17,214] Trial 76 finished with value: 0.8439215686274512 and parameters: {'kernel': 'poly', 'C': 0.007354680282251355, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:17,458] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:17,484] Trial 77 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007357101874813873, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:17,633] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:17,660] Trial 78 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:17,923] The parameter `degree` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:17,951] Trial 79 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007314110984875222, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:18,202] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:18,228] Trial 80 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007319974291662235, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:18,325] The parameter `degree` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:18,353] Trial 81 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:18,491] The parameter `degree` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:18,517] Trial 82 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:18,629] The parameter `degree` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:18,658] Trial 83 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:18,767] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:18,794] Trial 84 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:18,893] The parameter `degree` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:18,925] Trial 85 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:19,182] The parameter `degree` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:19,207] Trial 86 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:19,357] The parameter `degree` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:19,383] Trial 87 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:19,465] The parameter `degree` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:19,490] Trial 88 finished with value: 0.83890756302521 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:19,641] The parameter `degree` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:19,667] Trial 89 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:19,850] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:19,876] Trial 90 finished with value: 0.8456302521008403 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:20,122] The parameter `degree` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:20,147] Trial 91 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:20,230] The parameter `degree` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:20,255] Trial 92 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:20,430] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:20,455] Trial 93 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.01, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:20,635] The parameter `degree` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:20,662] Trial 94 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.0074691589515167535, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:20,810] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:20,835] Trial 95 finished with value: 0.8456022408963587 and parameters: {'kernel': 'poly', 'C': 0.007479120575826659, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:21,260] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:21,285] Trial 96 finished with value: 0.8439355742296918 and parameters: {'kernel': 'poly', 'C': 0.007488967003117248, 'degree': 5}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:21,582] The parameter `degree` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:21,609] Trial 97 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.0075006323069699635, 'degree': 2}. Best is trial 12 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:22:21,815] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:21,841] Trial 98 finished with value: 0.8288235294117646 and parameters: {'kernel': 'poly', 'C': 0.007498718530702834, 'degree': 4}. Best is trial 12 with value: 0.8456302521008403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:22:22,077] A new study created in memory with name: AdaBoost Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:22:22,050] The parameter `degree` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:22:22,075] Trial 99 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.009999999999999995, 'degree': 3}. Best is trial 12 with value: 0.8456302521008403.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using GPSampler: {'kernel': 'poly', 'C': 0.01, 'degree': 5}\n",
      "Best accuracy: 0.8456, at trial: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3ff168012f4a2c84178b1c2872e0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:22:22,194] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:22:22,361] Trial 1 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.06251373574521749}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:22,418] Trial 2 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029375384576328283}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:22,464] Trial 3 finished with value: 0.8490196078431372 and parameters: {'n_estimators': 15, 'learning_rate': 0.39676050770529875}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:22,584] Trial 4 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 64, 'learning_rate': 0.13311216080736885}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:22,630] Trial 5 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 11, 'learning_rate': 0.8123245085588685}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:22,771] Trial 6 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 85, 'learning_rate': 0.004335281794951566}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:22,828] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.0035498788321965025}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:22,922] Trial 8 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 37, 'learning_rate': 0.03752055855124281}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:23,019] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 49, 'learning_rate': 0.007476312062252299}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:23,422] Trial 10 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 96, 'learning_rate': 0.10760350038062885}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:23,725] Trial 11 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 79, 'learning_rate': 0.9741263394918727}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:24,162] Trial 12 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 82, 'learning_rate': 0.08311971700768249}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:24,482] Trial 13 finished with value: 0.8406022408963585 and parameters: {'n_estimators': 39, 'learning_rate': 0.37560924108053667}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:24,795] Trial 14 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 58, 'learning_rate': 1.0}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:25,162] Trial 15 finished with value: 0.8473109243697478 and parameters: {'n_estimators': 100, 'learning_rate': 0.5181579440305357}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:25,466] Trial 16 finished with value: 0.850686274509804 and parameters: {'n_estimators': 81, 'learning_rate': 0.22170188252676323}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:25,817] Trial 17 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 81, 'learning_rate': 0.17542634718225258}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:26,177] Trial 18 finished with value: 0.843921568627451 and parameters: {'n_estimators': 100, 'learning_rate': 0.9999999999999991}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:26,564] Trial 19 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 100, 'learning_rate': 0.04732611944746444}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:26,951] Trial 20 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 100, 'learning_rate': 0.07569433652213897}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:27,288] Trial 21 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 89, 'learning_rate': 0.05528172899755283}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:27,641] Trial 22 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.3878883295066191}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:28,021] Trial 23 finished with value: 0.850686274509804 and parameters: {'n_estimators': 82, 'learning_rate': 0.39692740736334214}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:28,317] Trial 24 finished with value: 0.8372408963585434 and parameters: {'n_estimators': 34, 'learning_rate': 1.0}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:28,688] Trial 25 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 73, 'learning_rate': 0.4161663754426048}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:29,206] Trial 26 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 100, 'learning_rate': 0.26538507375722475}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:29,585] Trial 27 finished with value: 0.850686274509804 and parameters: {'n_estimators': 84, 'learning_rate': 0.3924407785546906}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:29,842] Trial 28 finished with value: 0.8406162464985993 and parameters: {'n_estimators': 10, 'learning_rate': 0.2925619073282869}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:30,225] Trial 29 finished with value: 0.8439495798319328 and parameters: {'n_estimators': 100, 'learning_rate': 0.04009629766229801}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:30,567] Trial 30 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 83, 'learning_rate': 0.3717519038722742}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:30,980] Trial 31 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 88, 'learning_rate': 0.08335750841181368}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:31,379] Trial 32 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 69, 'learning_rate': 0.3770841406683117}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:31,767] Trial 33 finished with value: 0.842282913165266 and parameters: {'n_estimators': 89, 'learning_rate': 0.3186119223061488}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:32,227] Trial 34 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 100, 'learning_rate': 0.09069703429942529}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:32,642] Trial 35 finished with value: 0.845658263305322 and parameters: {'n_estimators': 86, 'learning_rate': 0.0823769727327044}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:33,041] Trial 36 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.1437582077606638}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:33,445] Trial 37 finished with value: 0.850658263305322 and parameters: {'n_estimators': 79, 'learning_rate': 0.5684475244592923}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:33,873] Trial 38 finished with value: 0.850658263305322 and parameters: {'n_estimators': 79, 'learning_rate': 0.5685092232485758}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:34,243] Trial 39 finished with value: 0.850672268907563 and parameters: {'n_estimators': 80, 'learning_rate': 0.5704396482241558}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:34,602] Trial 40 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 80, 'learning_rate': 0.5708696498552465}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:34,943] Trial 41 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 72, 'learning_rate': 0.5503287218703604}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:35,359] Trial 42 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 87, 'learning_rate': 0.563042188330526}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:35,740] Trial 43 finished with value: 0.850672268907563 and parameters: {'n_estimators': 86, 'learning_rate': 0.05115127474774165}. Best is trial 1 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:22:36,085] Trial 44 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 84, 'learning_rate': 0.04859911714531245}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:36,408] Trial 45 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 81, 'learning_rate': 0.03784729801348407}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:36,755] Trial 46 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 100, 'learning_rate': 0.0010000000000000002}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:36,962] Trial 47 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010000000000000002}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:37,372] Trial 48 finished with value: 0.8321848739495799 and parameters: {'n_estimators': 100, 'learning_rate': 0.023132225174489155}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:37,801] Trial 49 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 86, 'learning_rate': 0.05871070566217502}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:38,184] Trial 50 finished with value: 0.850686274509804 and parameters: {'n_estimators': 77, 'learning_rate': 0.06226970717062177}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:38,557] Trial 51 finished with value: 0.850686274509804 and parameters: {'n_estimators': 76, 'learning_rate': 0.061439098497334345}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:38,919] Trial 52 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 75, 'learning_rate': 0.05979446324649275}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:39,304] Trial 53 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 86, 'learning_rate': 0.05641140123596048}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:39,604] Trial 54 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 55, 'learning_rate': 0.0010000000000000002}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:39,960] Trial 55 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 59, 'learning_rate': 0.5454671896311344}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:40,310] Trial 56 finished with value: 0.850686274509804 and parameters: {'n_estimators': 73, 'learning_rate': 0.0800058233738505}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:40,810] Trial 57 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 73, 'learning_rate': 0.056512843945180136}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:41,169] Trial 58 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 72, 'learning_rate': 0.0542823065602427}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:41,540] Trial 59 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 68, 'learning_rate': 0.05014256485748367}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:41,860] Trial 60 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 50, 'learning_rate': 0.5077441047552305}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:42,288] Trial 61 finished with value: 0.8439775910364145 and parameters: {'n_estimators': 22, 'learning_rate': 0.36558044655344635}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:42,675] Trial 62 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 71, 'learning_rate': 0.0730406912514638}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:43,082] Trial 63 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 78, 'learning_rate': 0.05217893488468077}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:43,493] Trial 64 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 69, 'learning_rate': 0.22701427196001614}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:43,843] Trial 65 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 73, 'learning_rate': 0.09459936383076085}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:44,245] Trial 66 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 100, 'learning_rate': 0.06480113679859041}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:44,531] Trial 67 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 10, 'learning_rate': 0.4954339139318402}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:44,932] Trial 68 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 89, 'learning_rate': 0.6546546875777355}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:45,316] Trial 69 finished with value: 0.850658263305322 and parameters: {'n_estimators': 100, 'learning_rate': 0.49169393712507414}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:45,744] Trial 70 finished with value: 0.8523389355742296 and parameters: {'n_estimators': 100, 'learning_rate': 0.5137520227763795}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:46,174] Trial 71 finished with value: 0.8472969187675069 and parameters: {'n_estimators': 100, 'learning_rate': 0.5373366534209835}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:46,574] Trial 72 finished with value: 0.8506862745098038 and parameters: {'n_estimators': 100, 'learning_rate': 0.37958246991352246}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:46,959] Trial 73 finished with value: 0.8506862745098038 and parameters: {'n_estimators': 100, 'learning_rate': 0.38069775297340686}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:47,392] Trial 74 finished with value: 0.8490056022408963 and parameters: {'n_estimators': 100, 'learning_rate': 0.3827885299514773}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:47,845] Trial 75 finished with value: 0.8439495798319326 and parameters: {'n_estimators': 91, 'learning_rate': 0.5164766587871807}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:48,255] Trial 76 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 75, 'learning_rate': 0.04230106349534497}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:48,605] Trial 77 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 63, 'learning_rate': 0.23596090226969024}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:48,955] Trial 78 finished with value: 0.850686274509804 and parameters: {'n_estimators': 72, 'learning_rate': 0.2482958870106895}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:49,354] Trial 79 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 72, 'learning_rate': 0.19372674997003117}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:49,732] Trial 80 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 73, 'learning_rate': 0.2809076605957465}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:50,056] Trial 81 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 53, 'learning_rate': 0.17303280052507664}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:50,469] Trial 82 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 100, 'learning_rate': 0.26643009509647514}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:50,898] Trial 83 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 83, 'learning_rate': 0.06013508475771167}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:51,340] Trial 84 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 100, 'learning_rate': 0.06317158911973957}. Best is trial 44 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:22:51,714] Trial 85 finished with value: 0.8540196078431371 and parameters: {'n_estimators': 100, 'learning_rate': 0.6460014059928207}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:52,052] Trial 86 finished with value: 0.843921568627451 and parameters: {'n_estimators': 100, 'learning_rate': 1.0}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:52,295] Trial 87 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 10, 'learning_rate': 0.13430650663247284}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:52,645] Trial 88 finished with value: 0.8523389355742296 and parameters: {'n_estimators': 100, 'learning_rate': 0.6339260690184583}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:53,004] Trial 89 finished with value: 0.850658263305322 and parameters: {'n_estimators': 100, 'learning_rate': 0.6358961625749688}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:53,227] Trial 90 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.009714480024153876}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:53,497] Trial 91 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 25, 'learning_rate': 0.5558488268597798}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:53,847] Trial 92 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 61, 'learning_rate': 0.08686444717358976}. Best is trial 85 with value: 0.8540196078431371.\n",
      "[I 2025-12-28 19:22:54,249] Trial 93 finished with value: 0.8557002801120447 and parameters: {'n_estimators': 100, 'learning_rate': 0.6457519830686531}. Best is trial 93 with value: 0.8557002801120447.\n",
      "[I 2025-12-28 19:22:54,605] Trial 94 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 53, 'learning_rate': 0.10340087639054046}. Best is trial 93 with value: 0.8557002801120447.\n",
      "[I 2025-12-28 19:22:54,966] Trial 95 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 61, 'learning_rate': 0.07250087769020497}. Best is trial 93 with value: 0.8557002801120447.\n",
      "[I 2025-12-28 19:22:55,569] Trial 96 finished with value: 0.8439775910364145 and parameters: {'n_estimators': 60, 'learning_rate': 0.0719324811271894}. Best is trial 93 with value: 0.8557002801120447.\n",
      "[I 2025-12-28 19:22:55,863] Trial 97 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 42, 'learning_rate': 0.19118594509847603}. Best is trial 93 with value: 0.8557002801120447.\n",
      "[I 2025-12-28 19:22:56,172] Trial 98 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 52, 'learning_rate': 0.24858594288351665}. Best is trial 93 with value: 0.8557002801120447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:22:56,487] A new study created in memory with name: Gradient Boosting Model Fine Tuning with GPSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:22:56,485] Trial 99 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 48, 'learning_rate': 0.1274954432277213}. Best is trial 93 with value: 0.8557002801120447.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using GPSampler: {'n_estimators': 100, 'learning_rate': 0.6457519830686531}\n",
      "Best accuracy: 0.8557, at trial: 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5533f731924cd0a0aa88db4a626af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:22:56,613] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n",
      "[I 2025-12-28 19:22:56,775] Trial 1 finished with value: 0.8372408963585434 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.0026587543983272706, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.762378215816119}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:22:56,835] Trial 2 finished with value: 0.6844257703081233 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.00383962929980417, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.5998368910791798}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:22:56,914] Trial 3 finished with value: 0.8019887955182072 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.002193048555664369, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.9041986740582306}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:22:57,016] Trial 4 finished with value: 0.6978151260504202 and parameters: {'max_features': None, 'n_estimators': 50, 'learning_rate': 0.0017541893487450805, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.6293899908000085}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:22:57,168] Trial 5 finished with value: 0.8103361344537815 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.0023426581058204046, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10, 'subsample': 0.9474136752138245}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:22:57,238] Trial 6 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.0012315571723666018, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.9143687545759647}. Best is trial 1 with value: 0.8372408963585434.\n",
      "[I 2025-12-28 19:22:57,286] Trial 7 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 22, 'learning_rate': 0.040215545266902894, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.5993578407670862}. Best is trial 7 with value: 0.8439495798319326.\n",
      "[I 2025-12-28 19:22:57,378] Trial 8 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.034877126245459314, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9315517129377968}. Best is trial 8 with value: 0.8557142857142856.\n",
      "[I 2025-12-28 19:22:57,457] Trial 9 finished with value: 0.8204341736694678 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.004470608546778492, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7361074625809747}. Best is trial 8 with value: 0.8557142857142856.\n",
      "[I 2025-12-28 19:22:57,960] Trial 10 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.019803074190325624, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 9, 'subsample': 0.7121615336796729}. Best is trial 10 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:22:58,411] Trial 11 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 99, 'learning_rate': 0.0075885951522447, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8, 'subsample': 0.8053336675283711}. Best is trial 10 with value: 0.8590756302521008.\n",
      "[I 2025-12-28 19:22:58,781] Trial 12 finished with value: 0.8590896358543418 and parameters: {'max_features': 'sqrt', 'n_estimators': 33, 'learning_rate': 0.05316671430621068, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.7010067256022179}. Best is trial 12 with value: 0.8590896358543418.\n",
      "[I 2025-12-28 19:22:59,172] Trial 13 finished with value: 0.8657983193277312 and parameters: {'max_features': None, 'n_estimators': 61, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.6874340922389481}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:22:59,658] Trial 14 finished with value: 0.8540476190476192 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.02869107673028196, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.6553103669362197}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:22:59,961] Trial 15 finished with value: 0.8523529411764705 and parameters: {'max_features': 'log2', 'n_estimators': 53, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:00,425] Trial 16 finished with value: 0.8523669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 48, 'learning_rate': 0.013463683710615366, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:00,841] Trial 17 finished with value: 0.8573669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 53, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:01,437] Trial 18 finished with value: 0.8489635854341738 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.00633583274606929, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:02,120] Trial 19 finished with value: 0.8473109243697479 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:02,412] Trial 20 finished with value: 0.8624369747899159 and parameters: {'max_features': 'sqrt', 'n_estimators': 42, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:02,729] Trial 21 finished with value: 0.843921568627451 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0036178251651471397, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:03,100] Trial 22 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 97, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:03,454] Trial 23 finished with value: 0.8339215686274508 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.09999999999999998, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:03,880] Trial 24 finished with value: 0.8389075630252101 and parameters: {'max_features': 'sqrt', 'n_estimators': 68, 'learning_rate': 0.007114599285953966, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:04,408] Trial 25 finished with value: 0.823781512605042 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.001581456838021966, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.9926197895503504}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:04,762] Trial 26 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 91, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:05,098] Trial 27 finished with value: 0.8607422969187676 and parameters: {'max_features': None, 'n_estimators': 37, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:05,439] Trial 28 finished with value: 0.8540336134453781 and parameters: {'max_features': None, 'n_estimators': 85, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:05,696] Trial 29 finished with value: 0.8372268907563024 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:05,959] Trial 30 finished with value: 0.8439495798319326 and parameters: {'max_features': 'sqrt', 'n_estimators': 46, 'learning_rate': 0.0324332629228457, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:06,349] Trial 31 finished with value: 0.8523809523809526 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.09999999999999998, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:06,678] Trial 32 finished with value: 0.8641316526610645 and parameters: {'max_features': None, 'n_estimators': 36, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:07,021] Trial 33 finished with value: 0.850686274509804 and parameters: {'max_features': None, 'n_estimators': 17, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:07,420] Trial 34 finished with value: 0.8490056022408965 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.013344780910549579, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:07,820] Trial 35 finished with value: 0.8473249299719887 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:08,251] Trial 36 finished with value: 0.8540476190476192 and parameters: {'max_features': None, 'n_estimators': 74, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:08,645] Trial 37 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:09,872] Trial 38 finished with value: 0.8556862745098041 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:10,480] Trial 39 finished with value: 0.8523669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.022378325316534848, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:10,838] Trial 40 finished with value: 0.8557282913165267 and parameters: {'max_features': None, 'n_estimators': 51, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:11,176] Trial 41 finished with value: 0.8573809523809525 and parameters: {'max_features': None, 'n_estimators': 18, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:11,546] Trial 42 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 36, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:11,963] Trial 43 finished with value: 0.8490056022408963 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.008515930695551937, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:12,414] Trial 44 finished with value: 0.8540196078431371 and parameters: {'max_features': None, 'n_estimators': 51, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:12,817] Trial 45 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 83, 'learning_rate': 0.03286265879485104, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:13,175] Trial 46 finished with value: 0.8590336134453782 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:13,481] Trial 47 finished with value: 0.8557282913165267 and parameters: {'max_features': None, 'n_estimators': 25, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:14,081] Trial 48 finished with value: 0.8489915966386554 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.09999999999999998, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:14,739] Trial 49 finished with value: 0.8523669467787114 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.020432168963192023, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:15,130] Trial 50 finished with value: 0.8540476190476192 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:15,909] Trial 51 finished with value: 0.8573389355742297 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:16,385] Trial 52 finished with value: 0.8523669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 74, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:17,121] Trial 53 finished with value: 0.7952941176470587 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.00700089975964519, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:18,192] Trial 54 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.033277187250556645, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:19,184] Trial 55 finished with value: 0.8473389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.04718365346764227, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:19,771] Trial 56 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.01752595225644145, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:20,272] Trial 57 finished with value: 0.8372268907563025 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.0034167941637324407, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:20,732] Trial 58 finished with value: 0.8439355742296918 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.00698316604823148, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:21,224] Trial 59 finished with value: 0.8523669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.023524999336533417, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:21,829] Trial 60 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.02136544853032927, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:22,468] Trial 61 finished with value: 0.845658263305322 and parameters: {'max_features': 'log2', 'n_estimators': 57, 'learning_rate': 0.028059480606630688, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:22,951] Trial 62 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.05061204075566082, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:23,373] Trial 63 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 64, 'learning_rate': 0.09999999999999998, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:23,939] Trial 64 finished with value: 0.8406302521008403 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:24,374] Trial 65 finished with value: 0.8439635854341736 and parameters: {'max_features': None, 'n_estimators': 28, 'learning_rate': 0.06905669485315896, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:24,819] Trial 66 finished with value: 0.8355462184873949 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.0243672992803082, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:25,390] Trial 67 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.021597680965101975, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:26,220] Trial 68 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.01608088743504734, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:26,725] Trial 69 finished with value: 0.6861624649859944 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:27,337] Trial 70 finished with value: 0.8439355742296918 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.003112951464631573, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:27,855] Trial 71 finished with value: 0.8607703081232494 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:28,404] Trial 72 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.05270627353421569, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:28,870] Trial 73 finished with value: 0.8473389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.010954955289950037, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:29,510] Trial 74 finished with value: 0.8590616246498598 and parameters: {'max_features': None, 'n_estimators': 34, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.7680054449085554}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:30,623] Trial 75 finished with value: 0.8321708683473389 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.003707971159031482, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:31,264] Trial 76 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.05618048236109469, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:31,666] Trial 77 finished with value: 0.862450980392157 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:32,244] Trial 78 finished with value: 0.850658263305322 and parameters: {'max_features': 'sqrt', 'n_estimators': 62, 'learning_rate': 0.020128412541856017, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:32,739] Trial 79 finished with value: 0.8456162464985993 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.022770866719515507, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:33,655] Trial 80 finished with value: 0.8439495798319328 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.005476337320821443, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 10, 'subsample': 0.7643682329554753}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:34,178] Trial 81 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 77, 'learning_rate': 0.05939170851597857, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:34,779] Trial 82 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.010979496619369108, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:35,437] Trial 83 finished with value: 0.8523669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.04020124070990999, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:35,970] Trial 84 finished with value: 0.8405882352941175 and parameters: {'max_features': 'sqrt', 'n_estimators': 26, 'learning_rate': 0.0348889235988537, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:36,513] Trial 85 finished with value: 0.8574089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.06099294847336349, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:37,136] Trial 86 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 83, 'learning_rate': 0.0332397108388069, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.796031767492539}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:37,585] Trial 87 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 74, 'learning_rate': 0.02245830578667639, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:38,127] Trial 88 finished with value: 0.8254621848739495 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.002925326217388122, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:38,513] Trial 89 finished with value: 0.8439495798319328 and parameters: {'max_features': 'sqrt', 'n_estimators': 40, 'learning_rate': 0.014419317911076316, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:38,932] Trial 90 finished with value: 0.8574089635854343 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.04643303176834607, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:39,399] Trial 91 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.05453104224930476, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:39,947] Trial 92 finished with value: 0.8456442577030812 and parameters: {'max_features': None, 'n_estimators': 100, 'learning_rate': 0.01019443663954966, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:40,404] Trial 93 finished with value: 0.8456582633053221 and parameters: {'max_features': 'sqrt', 'n_estimators': 95, 'learning_rate': 0.09046424758450042, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:40,711] Trial 94 finished with value: 0.8422829131652663 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:41,210] Trial 95 finished with value: 0.8490336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:41,825] Trial 96 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.0445927953722621, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:42,188] Trial 97 finished with value: 0.8321988795518207 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.024082941152862344, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:42,653] Trial 98 finished with value: 0.850686274509804 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 1.0}. Best is trial 13 with value: 0.8657983193277312.\n",
      "[I 2025-12-28 19:23:43,021] Trial 99 finished with value: 0.8422689075630251 and parameters: {'max_features': 'sqrt', 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 13 with value: 0.8657983193277312.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using GPSampler: {'max_features': None, 'n_estimators': 61, 'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.6874340922389481}\n",
      "Best accuracy: 0.8658, at trial: 13\n",
      "GP Base Models Training Time: 182.45 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_base_models_training_start = time.time()\n",
    "\n",
    "    # GP Hyperparameter Tuning with Cross Validation\n",
    "    gp_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='GPSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    gp_logistic_regression.fit(X_train, y_train)\n",
    "    gp_decision_tree.fit(X_train, y_train)\n",
    "    gp_random_forest.fit(X_train, y_train)\n",
    "    gp_knn.fit(X_train, y_train)\n",
    "    gp_svc.fit(X_train, y_train)\n",
    "    gp_adaboost.fit(X_train, y_train)\n",
    "    gp_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    gp_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP base models training\n",
    "    gp_base_models_training_time = gp_base_models_training_end - gp_base_models_training_start\n",
    "    print(f'GP Base Models Training Time: {gp_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping GP base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:23:43,397] A new study created in memory with name: Logistic Regression Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed593e2dd6e48e3b0565f2dade1d154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:23:43,446] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:23:43,459] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,496] Trial 1 finished with value: 0.84390756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.02205741280502818}. Best is trial 1 with value: 0.84390756302521.\n",
      "[W 2025-12-28 19:23:43,500] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,536] Trial 2 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.02802913837564577}. Best is trial 2 with value: 0.8455882352941175.\n",
      "[W 2025-12-28 19:23:43,536] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,575] Trial 3 finished with value: 0.8405882352941176 and parameters: {'solver': 'sag', 'C': 0.36204298853974154}. Best is trial 2 with value: 0.8455882352941175.\n",
      "[W 2025-12-28 19:23:43,577] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,613] Trial 4 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.00011850115518950796}. Best is trial 2 with value: 0.8455882352941175.\n",
      "[W 2025-12-28 19:23:43,618] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,653] Trial 5 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.07655750872937357}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-12-28 19:23:43,656] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,693] Trial 6 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.03395851947833526}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-12-28 19:23:43,694] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,729] Trial 7 finished with value: 0.8305182072829131 and parameters: {'solver': 'newton-cg', 'C': 0.002988698359265086}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-12-28 19:23:43,732] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,767] Trial 8 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.12666361299777856}. Best is trial 5 with value: 0.8456162464985993.\n",
      "[W 2025-12-28 19:23:43,769] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,805] Trial 9 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.160329040179619}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:43,807] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,843] Trial 10 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.2125150037725021}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:43,846] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,882] Trial 11 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.020759772615306444}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:43,883] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,920] Trial 12 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.1050060268493344}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:43,923] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,959] Trial 13 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.9738305134854172}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:43,959] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:43,997] Trial 14 finished with value: 0.8439495798319328 and parameters: {'solver': 'sag', 'C': 0.22468358511032036}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:43,999] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,036] Trial 15 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1279230260153545}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:44,036] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,074] Trial 16 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 0.4821800303373954}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:44,077] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,205] Trial 17 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.07746664121935645}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:44,206] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,243] Trial 18 finished with value: 0.8405882352941176 and parameters: {'solver': 'lbfgs', 'C': 0.33363800555855094}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:44,243] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,280] Trial 19 finished with value: 0.8405882352941176 and parameters: {'solver': 'sag', 'C': 0.30257851486990706}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:44,280] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,410] Trial 20 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.07854266350187925}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:44,413] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,449] Trial 21 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 0.5168408542929493}. Best is trial 9 with value: 0.8456302521008403.\n",
      "[W 2025-12-28 19:23:44,449] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,569] Trial 22 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.06076718966935912}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:23:44,569] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,607] Trial 23 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cg', 'C': 0.1772466311693593}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:23:44,607] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,644] Trial 24 finished with value: 0.8405462184873949 and parameters: {'solver': 'lbfgs', 'C': 0.015897051082828156}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:23:44,644] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,683] Trial 25 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.03851774266987595}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:23:44,684] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,720] Trial 26 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.04838292296476062}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:23:44,721] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,758] Trial 27 finished with value: 0.84390756302521 and parameters: {'solver': 'sag', 'C': 0.019268687553882072}. Best is trial 22 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:23:44,758] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,796] Trial 28 finished with value: 0.8472969187675069 and parameters: {'solver': 'newton-cholesky', 'C': 0.08248633845203973}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-12-28 19:23:44,799] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,834] Trial 29 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06267356648505741}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-12-28 19:23:44,836] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,955] Trial 30 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.11774032747566768}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-12-28 19:23:44,957] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:44,993] Trial 31 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.04748647170395856}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-12-28 19:23:44,996] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,032] Trial 32 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.07344552654374271}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-12-28 19:23:45,032] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,070] Trial 33 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.03780757000240508}. Best is trial 28 with value: 0.8472969187675069.\n",
      "[W 2025-12-28 19:23:45,072] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,190] Trial 34 finished with value: 0.8489495798319329 and parameters: {'solver': 'newton-cholesky', 'C': 0.05851500684973518}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,190] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,227] Trial 35 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.10614080148388617}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,229] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,266] Trial 36 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.04223167409928886}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,267] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,303] Trial 37 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.04654048430698835}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,303] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,341] Trial 38 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.03195952845707616}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,342] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,379] Trial 39 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.051364396056088106}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,379] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,418] Trial 40 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.03997924012395359}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,421] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,457] Trial 41 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.04573213023521467}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,459] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,494] Trial 42 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05137907460083155}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,494] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,532] Trial 43 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.04407162639792366}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,534] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,569] Trial 44 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.060165740040896726}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,572] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,608] Trial 45 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cg', 'C': 0.04945517657402623}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,610] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,647] Trial 46 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06753724588567601}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,649] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,684] Trial 47 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.056299241104257394}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,686] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,722] Trial 48 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.07673301964056288}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,724] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,760] Trial 49 finished with value: 0.8455882352941175 and parameters: {'solver': 'lbfgs', 'C': 0.048117186206091137}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,762] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,800] Trial 50 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.059797234749209456}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,802] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,838] Trial 51 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.054167656458341505}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,841] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,879] Trial 52 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05974075314901565}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,881] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,917] Trial 53 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06349875945154873}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,918] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,954] Trial 54 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.053745731416729094}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,956] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:45,992] Trial 55 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05539587839612086}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:45,994] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,030] Trial 56 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.06001991804146136}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,032] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,067] Trial 57 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.05913531392888549}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,069] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,105] Trial 58 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05505764597902148}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,107] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,144] Trial 59 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.06280341165901325}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,146] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,183] Trial 60 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05533985807757942}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,186] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,221] Trial 61 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05414968013063547}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,223] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,342] Trial 62 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.056834098381984895}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,343] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,380] Trial 63 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.06221763939657786}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,381] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,418] Trial 64 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05772079167845554}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,421] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,457] Trial 65 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.060644659352029895}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,458] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,494] Trial 66 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05879445728173621}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,495] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,531] Trial 67 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.0544345917956727}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,533] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,569] Trial 68 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05585631475689836}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,572] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,608] Trial 69 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05661024089258117}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,610] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,645] Trial 70 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.058293096879936224}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,647] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,682] Trial 71 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05477785575189903}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,683] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,718] Trial 72 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05367862621189727}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,721] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,757] Trial 73 finished with value: 0.8489495798319329 and parameters: {'solver': 'sag', 'C': 0.058898725658782874}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,759] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,795] Trial 74 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05639606205205592}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,797] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,833] Trial 75 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05210165422854395}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,834] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,870] Trial 76 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05579554518606102}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,873] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,908] Trial 77 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05658729754857017}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,909] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,945] Trial 78 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05720671130689813}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,947] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:46,985] Trial 79 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.05956530398980263}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:46,988] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,023] Trial 80 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05812126818398885}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,025] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,061] Trial 81 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.060921300324001594}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,063] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,099] Trial 82 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.057687388878169175}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,101] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,138] Trial 83 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.05763161365481599}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,140] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,175] Trial 84 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.05883940351214112}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,177] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,214] Trial 85 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.059985887058757584}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,217] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,252] Trial 86 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.057985048425705156}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,253] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,290] Trial 87 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05947164228752938}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,292] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,329] Trial 88 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.06236889344961857}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,332] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,368] Trial 89 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.05827137589941847}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,370] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,405] Trial 90 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.05931052073982045}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,407] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,444] Trial 91 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06192109817460199}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,446] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,481] Trial 92 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.06013810896867534}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,483] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,519] Trial 93 finished with value: 0.8472829131652662 and parameters: {'solver': 'sag', 'C': 0.060197400854050745}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,519] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,650] Trial 94 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.059735485704890456}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,652] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,688] Trial 95 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.0600600794019344}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,689] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,726] Trial 96 finished with value: 0.8472829131652662 and parameters: {'solver': 'lbfgs', 'C': 0.06077630427911266}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,726] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,764] Trial 97 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cg', 'C': 0.06068500472738205}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,767] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,803] Trial 98 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.06176450579647705}. Best is trial 34 with value: 0.8489495798319329.\n",
      "[W 2025-12-28 19:23:47,804] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,841] Trial 99 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.061084058496037215}. Best is trial 34 with value: 0.8489495798319329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:23:47,841] A new study created in memory with name: Decision Tree Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Logistic Regression Using CmaEsSampler: {'solver': 'newton-cholesky', 'C': 0.05851500684973518}\n",
      "Best accuracy: 0.8489, at trial: 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88c039e65bf4aa49c26bf3df12a499d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:23:47,878] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:47,900] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:47,902] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,931] Trial 1 finished with value: 0.813781512605042 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:47,934] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:47,935] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,961] Trial 2 finished with value: 0.8037254901960784 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:47,964] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:47,965] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,980] Trial 3 finished with value: 0.8238795518207285 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:47,982] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:47,983] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:47,997] Trial 4 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:47,999] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,000] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,026] Trial 5 finished with value: 0.8087394957983193 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:48,028] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,028] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,044] Trial 6 finished with value: 0.805392156862745 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:48,046] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,046] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,073] Trial 7 finished with value: 0.7935994397759103 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:48,079] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,080] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,094] Trial 8 finished with value: 0.8087254901960783 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:48,095] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,098] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,122] Trial 9 finished with value: 0.8171148459383752 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:23:48,124] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,125] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,141] Trial 10 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,144] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,145] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,160] Trial 11 finished with value: 0.8238235294117647 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,162] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,162] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,188] Trial 12 finished with value: 0.8171008403361345 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,190] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,192] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,206] Trial 13 finished with value: 0.7919467787114846 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,208] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,209] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,224] Trial 14 finished with value: 0.8019887955182072 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,227] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,228] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,253] Trial 15 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,255] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,257] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,281] Trial 16 finished with value: 0.8019887955182072 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,283] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,285] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,299] Trial 17 finished with value: 0.8171008403361345 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,302] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,303] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,318] Trial 18 finished with value: 0.793641456582633 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,320] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,320] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,336] Trial 19 finished with value: 0.8204901960784312 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,338] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,338] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,364] Trial 20 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,365] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,365] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,382] Trial 21 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,383] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,386] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,401] Trial 22 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,404] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,405] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,430] Trial 23 finished with value: 0.7969607843137255 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,430] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,430] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,448] Trial 24 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,452] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,453] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,480] Trial 25 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,484] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,484] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,500] Trial 26 finished with value: 0.8422969187675069 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,502] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,503] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,518] Trial 27 finished with value: 0.8003221288515407 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,520] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,520] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,546] Trial 28 finished with value: 0.8087114845938375 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,547] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,550] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,564] Trial 29 finished with value: 0.8103781512605043 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,565] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,566] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,581] Trial 30 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,583] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,584] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,598] Trial 31 finished with value: 0.8087394957983193 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:23:48,599] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,601] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,616] Trial 32 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 32 with value: 0.8439495798319326.\n",
      "[W 2025-12-28 19:23:48,617] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,619] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,635] Trial 33 finished with value: 0.8087394957983193 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 32 with value: 0.8439495798319326.\n",
      "[W 2025-12-28 19:23:48,638] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,638] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,653] Trial 34 finished with value: 0.8288515406162464 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 32 with value: 0.8439495798319326.\n",
      "[W 2025-12-28 19:23:48,656] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,656] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,671] Trial 35 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8439495798319326.\n",
      "[W 2025-12-28 19:23:48,674] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,674] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,690] Trial 36 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,690] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,693] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,708] Trial 37 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,708] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,708] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,726] Trial 38 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,727] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,727] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,743] Trial 39 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,745] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,747] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,761] Trial 40 finished with value: 0.8373109243697477 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,763] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,763] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,778] Trial 41 finished with value: 0.8120308123249298 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,780] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,781] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,796] Trial 42 finished with value: 0.8154481792717088 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,798] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,799] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,813] Trial 43 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,816] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,817] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,833] Trial 44 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,835] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,836] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,850] Trial 45 finished with value: 0.8288515406162464 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,852] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,854] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,869] Trial 46 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,870] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,872] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,887] Trial 47 finished with value: 0.8255322128851541 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,889] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,890] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,903] Trial 48 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,905] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,906] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,920] Trial 49 finished with value: 0.8087114845938375 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,923] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,924] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,939] Trial 50 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,941] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,942] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,957] Trial 51 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,959] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,960] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,975] Trial 52 finished with value: 0.7969467787114846 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,977] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,978] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:48,992] Trial 53 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:48,994] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:48,995] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,021] Trial 54 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,024] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,025] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,050] Trial 55 finished with value: 0.8321848739495799 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,050] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,050] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,078] Trial 56 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,081] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,082] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,097] Trial 57 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,097] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,097] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,114] Trial 58 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,115] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,117] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,131] Trial 59 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,133] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,133] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,159] Trial 60 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,160] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,160] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,176] Trial 61 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,178] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,179] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,195] Trial 62 finished with value: 0.8255322128851541 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,197] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,198] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,212] Trial 63 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,215] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,216] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,231] Trial 64 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,233] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,234] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,249] Trial 65 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,251] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,252] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,278] Trial 66 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,281] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,281] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,297] Trial 67 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,299] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,299] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,314] Trial 68 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,315] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,317] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,332] Trial 69 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,333] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,333] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,350] Trial 70 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,352] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,352] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,368] Trial 71 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,370] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,370] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,386] Trial 72 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,388] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,388] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,404] Trial 73 finished with value: 0.8188095238095239 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,406] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,406] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,422] Trial 74 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,424] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,424] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,439] Trial 75 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,442] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,443] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,467] Trial 76 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,468] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,468] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,485] Trial 77 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,487] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,488] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,504] Trial 78 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,506] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,507] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,522] Trial 79 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,524] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,525] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,540] Trial 80 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,541] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,543] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,567] Trial 81 finished with value: 0.810392156862745 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,571] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,571] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,586] Trial 82 finished with value: 0.8204901960784314 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,588] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,588] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,604] Trial 83 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,606] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,607] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,622] Trial 84 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,624] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,625] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,650] Trial 85 finished with value: 0.7969467787114846 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,651] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,651] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,679] Trial 86 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,681] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,681] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,697] Trial 87 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,699] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,701] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,716] Trial 88 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,718] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,718] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,734] Trial 89 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,736] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,736] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,752] Trial 90 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,754] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,754] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,770] Trial 91 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,773] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,775] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,789] Trial 92 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:23:49,920] A new study created in memory with name: Random Forest Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:23:49,792] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,794] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,809] Trial 93 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,809] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,809] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,826] Trial 94 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,829] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,832] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,846] Trial 95 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,849] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,850] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,865] Trial 96 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,867] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,867] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,883] Trial 97 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,883] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,886] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,900] Trial 98 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:23:49,902] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:49,904] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:49,918] Trial 99 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 36 with value: 0.8473389355742297.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using CmaEsSampler: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}\n",
      "Best accuracy: 0.8473, at trial: 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dccfa557289445fbf48157776401139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:23:50,007] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[W 2025-12-28 19:23:50,010] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:50,012] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:50,235] Trial 1 finished with value: 0.8540336134453781 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8540336134453781.\n",
      "[W 2025-12-28 19:23:50,238] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:50,239] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:50,480] Trial 2 finished with value: 0.8523669467787114 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8540336134453781.\n",
      "[W 2025-12-28 19:23:50,482] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:50,483] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:50,728] Trial 3 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:50,731] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:50,732] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:50,850] Trial 4 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:50,853] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:50,853] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,012] Trial 5 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 79, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,015] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,015] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,102] Trial 6 finished with value: 0.8490056022408965 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 29, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,103] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,103] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,212] Trial 7 finished with value: 0.8507002801120447 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,215] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,215] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,354] Trial 8 finished with value: 0.8523809523809526 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,359] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,359] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,487] Trial 9 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,490] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,492] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,641] Trial 10 finished with value: 0.8490196078431372 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 65, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,644] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,645] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,802] Trial 11 finished with value: 0.8490196078431371 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,805] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,806] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:51,954] Trial 12 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 73, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:51,958] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:51,958] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:52,087] Trial 13 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:52,091] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:52,092] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:52,208] Trial 14 finished with value: 0.8473529411764705 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:52,211] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:52,212] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:52,351] Trial 15 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:52,354] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:52,354] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:52,433] Trial 16 finished with value: 0.8439495798319328 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 23, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:52,436] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:52,437] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:52,595] Trial 17 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:52,597] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:52,598] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:52,726] Trial 18 finished with value: 0.8523809523809526 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:23:52,729] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:52,730] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:52,859] Trial 19 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:52,862] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:52,863] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:53,105] Trial 20 finished with value: 0.850658263305322 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 74, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:53,108] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:53,109] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:53,322] Trial 21 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:53,324] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:53,325] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:53,474] Trial 22 finished with value: 0.8557282913165267 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:53,477] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:53,477] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:53,607] Trial 23 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:53,610] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:53,610] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:53,790] Trial 24 finished with value: 0.8473389355742297 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 90, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:53,790] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:53,794] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:54,016] Trial 25 finished with value: 0.8473389355742299 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:54,018] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:54,019] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:54,147] Trial 26 finished with value: 0.8423109243697479 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:54,148] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:54,148] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:54,268] Trial 27 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 50, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:54,270] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:54,270] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:54,501] Trial 28 finished with value: 0.8540476190476189 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8557282913165267.\n",
      "[W 2025-12-28 19:23:54,501] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:54,501] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:54,642] Trial 29 finished with value: 0.8573949579831932 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:54,645] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:54,645] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:54,764] Trial 30 finished with value: 0.8473249299719887 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 53, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:54,766] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:54,768] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:54,906] Trial 31 finished with value: 0.8540616246498601 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:54,906] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:54,906] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:55,027] Trial 32 finished with value: 0.8557002801120447 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:55,030] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:55,031] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:55,161] Trial 33 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:55,161] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:55,161] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:55,312] Trial 34 finished with value: 0.8540476190476189 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:55,312] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:55,316] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:55,454] Trial 35 finished with value: 0.845658263305322 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 63, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:55,454] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:55,458] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:55,596] Trial 36 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:55,599] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:55,600] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:55,739] Trial 37 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 69, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:55,742] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:55,742] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:55,861] Trial 38 finished with value: 0.8557282913165267 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:55,863] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:55,864] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:56,023] Trial 39 finished with value: 0.8506862745098038 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:56,026] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:56,027] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:56,155] Trial 40 finished with value: 0.8540196078431371 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 55, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:56,159] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:56,160] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:56,309] Trial 41 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 67, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:56,312] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:56,313] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:56,544] Trial 42 finished with value: 0.8439775910364146 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 63, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:56,547] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:56,547] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:56,664] Trial 43 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 54, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:56,668] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:56,669] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:56,786] Trial 44 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:56,789] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:56,789] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:56,930] Trial 45 finished with value: 0.8473529411764705 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 64, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:56,933] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:56,933] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,050] Trial 46 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,053] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,054] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,183] Trial 47 finished with value: 0.8573809523809522 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,185] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,186] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,314] Trial 48 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 63, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,317] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,318] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,436] Trial 49 finished with value: 0.8406022408963585 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 53, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,439] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,440] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,557] Trial 50 finished with value: 0.8556862745098041 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,560] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,562] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,690] Trial 51 finished with value: 0.8573949579831932 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 57, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,693] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,693] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,833] Trial 52 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 60, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,835] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,836] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:57,953] Trial 53 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:57,957] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:57,957] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:58,085] Trial 54 finished with value: 0.8523389355742296 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:58,088] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:58,089] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:58,228] Trial 55 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 67, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:58,231] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:58,231] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:58,359] Trial 56 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 58, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:58,362] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:58,363] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:58,470] Trial 57 finished with value: 0.8372408963585434 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 42, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:58,473] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:58,474] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:58,612] Trial 58 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:58,615] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:58,615] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:58,722] Trial 59 finished with value: 0.8557422969187677 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:58,725] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:58,725] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:58,925] Trial 60 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 29 with value: 0.8573949579831932.\n",
      "[W 2025-12-28 19:23:58,928] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:58,929] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,036] Trial 61 finished with value: 0.8591036414565828 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,039] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,040] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,178] Trial 62 finished with value: 0.8439775910364146 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,181] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,182] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,300] Trial 63 finished with value: 0.850658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 52, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,303] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,304] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,430] Trial 64 finished with value: 0.8523809523809524 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 53, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,433] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,434] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,562] Trial 65 finished with value: 0.8523809523809524 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 54, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,565] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,566] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,674] Trial 66 finished with value: 0.8339215686274508 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 37, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,677] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,677] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,805] Trial 67 finished with value: 0.8473529411764705 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,808] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,808] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:23:59,926] Trial 68 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:23:59,930] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:23:59,931] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,040] Trial 69 finished with value: 0.8540056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 44, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,043] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,044] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,142] Trial 70 finished with value: 0.8573669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,145] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,146] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,273] Trial 71 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,275] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,276] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,395] Trial 72 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,398] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,399] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,507] Trial 73 finished with value: 0.8523809523809526 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,510] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,511] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,639] Trial 74 finished with value: 0.845658263305322 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 58, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,642] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,643] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,739] Trial 75 finished with value: 0.8540336134453783 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 38, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,743] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,743] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,839] Trial 76 finished with value: 0.8523529411764705 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 41, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,841] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,842] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:00,960] Trial 77 finished with value: 0.8439915966386554 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 48, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:00,963] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:00,964] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,062] Trial 78 finished with value: 0.8573669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,064] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,065] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,173] Trial 79 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,175] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,176] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,284] Trial 80 finished with value: 0.8506862745098038 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 42, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,288] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,289] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,386] Trial 81 finished with value: 0.8523529411764705 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 37, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,389] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,390] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,486] Trial 82 finished with value: 0.8556862745098041 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,489] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,490] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,578] Trial 83 finished with value: 0.8456442577030812 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 24, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,580] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,581] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,667] Trial 84 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 30, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,670] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,671] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,779] Trial 85 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,781] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,782] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:01,879] Trial 86 finished with value: 0.8590476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 42, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:01,882] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:01,883] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,012] Trial 87 finished with value: 0.8406302521008403 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,016] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,017] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,135] Trial 88 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 52, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,138] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,139] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,236] Trial 89 finished with value: 0.8439915966386554 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 35, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,240] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,240] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,327] Trial 90 finished with value: 0.8489775910364145 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,329] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,331] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,427] Trial 91 finished with value: 0.850672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 40, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,429] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,430] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,527] Trial 92 finished with value: 0.8573669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,529] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,530] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,628] Trial 93 finished with value: 0.8490196078431372 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,631] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,632] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,749] Trial 94 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 40, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,751] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,753] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,861] Trial 95 finished with value: 0.8523389355742296 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,863] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,864] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:02,972] Trial 96 finished with value: 0.8523389355742296 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 47, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:02,976] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:02,977] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,095] Trial 97 finished with value: 0.8439915966386554 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 49, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "[W 2025-12-28 19:24:03,098] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:03,099] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,185] Trial 98 finished with value: 0.8540056022408964 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 28, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:03,308] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:24:03,188] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:03,189] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,306] Trial 99 finished with value: 0.8523529411764705 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 49, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 61 with value: 0.8591036414565828.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using CmaEsSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}\n",
      "Best accuracy: 0.8591, at trial: 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01187368fbf745f886f829c5d8f3af09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:03,361] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-12-28 19:24:03,363] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,390] Trial 1 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-12-28 19:24:03,394] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,441] Trial 2 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-12-28 19:24:03,444] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,491] Trial 3 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-12-28 19:24:03,492] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,518] Trial 4 finished with value: 0.8271008403361346 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-12-28 19:24:03,520] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,566] Trial 5 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 1}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-12-28 19:24:03,567] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,616] Trial 6 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 1}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-12-28 19:24:03,617] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,644] Trial 7 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 2}. Best is trial 3 with value: 0.8490056022408965.\n",
      "[W 2025-12-28 19:24:03,646] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,671] Trial 8 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,671] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,719] Trial 9 finished with value: 0.850672268907563 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,720] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,746] Trial 10 finished with value: 0.850658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 26, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,746] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,794] Trial 11 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,794] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,842] Trial 12 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,844] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,869] Trial 13 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,871] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,908] Trial 14 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 37, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,908] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,956] Trial 15 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 1}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,956] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:03,994] Trial 16 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 46, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:03,994] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,020] Trial 17 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:04,022] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,068] Trial 18 finished with value: 0.850672268907563 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 8 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:04,071] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,116] Trial 19 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,116] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,164] Trial 20 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,166] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,191] Trial 21 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 48, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,192] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,239] Trial 22 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,241] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,267] Trial 23 finished with value: 0.850686274509804 and parameters: {'algorithm': 'brute', 'n_neighbors': 44, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,269] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,294] Trial 24 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,297] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,333] Trial 25 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,335] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,381] Trial 26 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,384] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,410] Trial 27 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,411] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,437] Trial 28 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,439] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,464] Trial 29 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,466] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,492] Trial 30 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,495] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,540] Trial 31 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,540] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,588] Trial 32 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,589] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,636] Trial 33 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,636] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,685] Trial 34 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,687] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,734] Trial 35 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,735] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,761] Trial 36 finished with value: 0.850672268907563 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,763] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,789] Trial 37 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,789] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,817] Trial 38 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,818] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,844] Trial 39 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,844] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,891] Trial 40 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,893] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,919] Trial 41 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,920] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,967] Trial 42 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,969] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:04,995] Trial 43 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:04,995] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,043] Trial 44 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,043] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,072] Trial 45 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'brute', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,074] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,120] Trial 46 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,121] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,168] Trial 47 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,170] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,217] Trial 48 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,220] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,266] Trial 49 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,268] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,294] Trial 50 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'brute', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,295] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,321] Trial 51 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,324] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,369] Trial 52 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,371] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,417] Trial 53 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,418] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,466] Trial 54 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,468] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,495] Trial 55 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,497] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,543] Trial 56 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,544] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,591] Trial 57 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,593] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,617] Trial 58 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,620] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,665] Trial 59 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,667] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,714] Trial 60 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,718] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,763] Trial 61 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,765] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,811] Trial 62 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,813] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,860] Trial 63 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,862] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,889] Trial 64 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,891] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,927] Trial 65 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,929] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:05,965] Trial 66 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:05,967] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,012] Trial 67 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,015] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,062] Trial 68 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,065] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,090] Trial 69 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,091] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,117] Trial 70 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,119] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,143] Trial 71 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,146] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,191] Trial 72 finished with value: 0.850686274509804 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,193] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,240] Trial 73 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,242] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,268] Trial 74 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,270] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,315] Trial 75 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,317] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,363] Trial 76 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,366] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,390] Trial 77 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,392] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,417] Trial 78 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,420] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,445] Trial 79 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,447] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,493] Trial 80 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,495] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,520] Trial 81 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,522] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,568] Trial 82 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,570] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,616] Trial 83 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,619] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,644] Trial 84 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,646] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,692] Trial 85 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,695] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,741] Trial 86 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,744] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,790] Trial 87 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,792] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,839] Trial 88 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,842] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,867] Trial 89 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,870] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,905] Trial 90 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,908] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,955] Trial 91 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,957] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:06,982] Trial 92 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:06,984] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,029] Trial 93 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:07,032] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,078] Trial 94 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:07,080] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,105] Trial 95 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:07,107] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,132] Trial 96 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:07,134] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,160] Trial 97 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:07,162] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,198] Trial 98 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:07,200] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,225] Trial 99 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 2}. Best is trial 19 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:07,228] A new study created in memory with name: Support Vector Machine Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using CmaEsSampler: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059c48749ac748a5874152ca0d28570d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:07,260] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,262] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,300] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000865808466690932}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,303] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,340] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0009528924787594206}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,343] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,369] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002651575859618515}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,370] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,396] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010702593573937491}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,398] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,424] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0013648551870204498}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,426] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,462] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009741063383591005}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,464] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,465] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,491] Trial 7 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00035536968608811256, 'degree': 5}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,493] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,494] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,519] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0016819495611083031, 'degree': 2}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,521] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,557] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0018375880092626332}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,557] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,583] Trial 10 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0020594834365669262}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,585] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,586] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,610] Trial 11 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0008036660590116804, 'degree': 3}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,612] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,637] Trial 12 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015484212122073447}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,640] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,676] Trial 13 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.004325242884695832}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:07,676] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,676] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,705] Trial 14 finished with value: 0.5385994397759104 and parameters: {'kernel': 'poly', 'C': 0.0022625707493004244, 'degree': 2}. Best is trial 14 with value: 0.5385994397759104.\n",
      "[W 2025-12-28 19:24:07,707] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,743] Trial 15 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0017640869367327792}. Best is trial 14 with value: 0.5385994397759104.\n",
      "[W 2025-12-28 19:24:07,744] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,746] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,771] Trial 16 finished with value: 0.7181512605042017 and parameters: {'kernel': 'poly', 'C': 0.0031705200615514424, 'degree': 2}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-12-28 19:24:07,774] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,774] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,800] Trial 17 finished with value: 0.64093837535014 and parameters: {'kernel': 'poly', 'C': 0.0015316647334182077, 'degree': 3}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-12-28 19:24:07,801] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,827] Trial 18 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004213260002115004}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-12-28 19:24:07,828] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,854] Trial 19 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.003937407690960455}. Best is trial 16 with value: 0.7181512605042017.\n",
      "[W 2025-12-28 19:24:07,854] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,854] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,883] Trial 20 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.0015463764498834167, 'degree': 5}. Best is trial 20 with value: 0.7516946778711484.\n",
      "[W 2025-12-28 19:24:07,885] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,887] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,912] Trial 21 finished with value: 0.8204761904761904 and parameters: {'kernel': 'poly', 'C': 0.004656263801984052, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:07,914] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,940] Trial 22 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0013377781050154692}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:07,940] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:07,943] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:07,969] Trial 23 finished with value: 0.7903081232492998 and parameters: {'kernel': 'poly', 'C': 0.0024960236634973096, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:07,969] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,006] Trial 24 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006124837057596769}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,007] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,033] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0012247352779240898}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,035] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,071] Trial 26 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0018560190113149195}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,071] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,099] Trial 27 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.000346456896762847}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,101] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,137] Trial 28 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.004908712635519084}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,139] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,166] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.001048690439351866}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,166] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,192] Trial 30 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0034407015907837756}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,192] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,221] Trial 31 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006216718417477049}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,222] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,247] Trial 32 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0014139694325885444}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,250] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,275] Trial 33 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005485682290781661}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,277] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,302] Trial 34 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0011235958186075266}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,305] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,341] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0029863087716820937}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,341] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,378] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006578423719111171}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,380] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,407] Trial 37 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00040296678905901115}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,409] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,409] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,434] Trial 38 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00012428354273999416, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,437] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,462] Trial 39 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005486766842278351}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,462] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,465] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,490] Trial 40 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00025045128145323345, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,492] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,494] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,519] Trial 41 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00022297422161775268, 'degree': 3}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,520] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,557] Trial 42 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00041758508645365846}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,557] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,595] Trial 43 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00018268201190564057}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,595] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,622] Trial 44 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009777458483130987}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,623] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,623] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,650] Trial 45 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0011801408167297345, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,650] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,654] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,688] Trial 46 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.000733538169603612, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,691] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,717] Trial 47 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00019462947879375988}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,717] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,744] Trial 48 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.001860275451439725}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,746] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,785] Trial 49 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0001457770549866019}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,786] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,823] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013881861015164923}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,824] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,824] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,851] Trial 51 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.000497892800949208, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,851] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,853] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,880] Trial 52 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0013746484283862841, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,882] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,883] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,907] Trial 53 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0006456709072415852, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,909] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,909] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,935] Trial 54 finished with value: 0.5419607843137255 and parameters: {'kernel': 'poly', 'C': 0.00040064924663028585, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,935] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:08,935] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:08,963] Trial 55 finished with value: 0.701358543417367 and parameters: {'kernel': 'poly', 'C': 0.0011711266636840357, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:08,965] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,004] Trial 56 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00024255693132920858}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,006] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,031] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0011143711571493776}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,031] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,031] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,059] Trial 58 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00020531775210182816, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,060] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,087] Trial 59 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.004632284392310736}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,089] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,090] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,116] Trial 60 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00023173598536067882, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,116] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,116] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,145] Trial 61 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00014638499390128178, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,147] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,149] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,174] Trial 62 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00044388438395863785, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,176] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,212] Trial 63 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0035352281090840426}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,213] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,250] Trial 64 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006330195558208896}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,250] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,279] Trial 65 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.001693534172703395}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,281] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,306] Trial 66 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0008701158499912172}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,309] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,333] Trial 67 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00016610497459206152}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,335] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,361] Trial 68 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002891007001888565}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,363] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,388] Trial 69 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00036227943241436204}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,390] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,427] Trial 70 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007000923800626298}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,427] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,455] Trial 71 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00017285110890268991}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,457] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,482] Trial 72 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00010956821422522905}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,482] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,485] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,511] Trial 73 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0008707416477194328, 'degree': 3}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,512] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,539] Trial 74 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00033401688760111703}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,541] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,542] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,567] Trial 75 finished with value: 0.6778431372549021 and parameters: {'kernel': 'poly', 'C': 0.0016314830283049898, 'degree': 3}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,568] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,571] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,595] Trial 76 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0002637382508023652, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,598] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,600] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,626] Trial 77 finished with value: 0.6023389355742297 and parameters: {'kernel': 'poly', 'C': 0.000507727755535651, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,627] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,629] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,656] Trial 78 finished with value: 0.5453221288515406 and parameters: {'kernel': 'poly', 'C': 0.0007281552170449111, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,658] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,684] Trial 79 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002775638829018526}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,687] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,688] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,713] Trial 80 finished with value: 0.7399299719887955 and parameters: {'kernel': 'poly', 'C': 0.0012312860578828691, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,715] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,752] Trial 81 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.002674328236858719}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,754] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,790] Trial 82 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0005452178621539986}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,792] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,817] Trial 83 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005300560241009992}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,818] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:09,820] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,845] Trial 84 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0009703753383087068, 'degree': 2}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,847] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,873] Trial 85 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0017239562570707805}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,875] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,911] Trial 86 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000698339733628747}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,914] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,949] Trial 87 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013706374941729019}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,951] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:09,987] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004866464437218511}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:09,989] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,014] Trial 89 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007387576536983534}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,016] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:10,018] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,043] Trial 90 finished with value: 0.7047058823529412 and parameters: {'kernel': 'poly', 'C': 0.0011400833821732094, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,045] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,081] Trial 91 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.003281982837485302}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,082] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,118] Trial 92 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.001601996509714991}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,121] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:10,122] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,147] Trial 93 finished with value: 0.7516946778711484 and parameters: {'kernel': 'poly', 'C': 0.001541261031064547, 'degree': 5}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,149] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,176] Trial 94 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.001205813676188691}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,178] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:10,179] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,204] Trial 95 finished with value: 0.7399439775910365 and parameters: {'kernel': 'poly', 'C': 0.00143308600095653, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,205] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:10,206] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,231] Trial 96 finished with value: 0.7735294117647058 and parameters: {'kernel': 'poly', 'C': 0.0020908385326327984, 'degree': 4}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,233] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,260] Trial 97 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0030902614794854092}. Best is trial 21 with value: 0.8204761904761904.\n",
      "[W 2025-12-28 19:24:10,261] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:10,263] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:10,288] Trial 98 finished with value: 0.8338515406162464 and parameters: {'kernel': 'poly', 'C': 0.007082326034013129, 'degree': 2}. Best is trial 98 with value: 0.8338515406162464.\n",
      "[W 2025-12-28 19:24:10,291] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:10,330] A new study created in memory with name: AdaBoost Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:10,327] Trial 99 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.004206127735212326}. Best is trial 98 with value: 0.8338515406162464.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using CmaEsSampler: {'kernel': 'poly', 'C': 0.007082326034013129, 'degree': 2}\n",
      "Best accuracy: 0.8339, at trial: 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add961dd0c484387a3e619c8aa9ec8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:10,457] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:24:10,537] Trial 1 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 43, 'learning_rate': 0.025476088134515826}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:24:10,624] Trial 2 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 41, 'learning_rate': 0.029414796527869724}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:24:10,737] Trial 3 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 60, 'learning_rate': 0.13653880096488336}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:24:10,835] Trial 4 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 57, 'learning_rate': 0.0011072190527544395}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:24:10,915] Trial 5 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 36, 'learning_rate': 0.08721915368491258}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:24:10,994] Trial 6 finished with value: 0.8490196078431371 and parameters: {'n_estimators': 39, 'learning_rate': 0.11322743764742889}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,033] Trial 7 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 13, 'learning_rate': 0.2334394218151809}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,120] Trial 8 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 43, 'learning_rate': 0.07399096721519229}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,210] Trial 9 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 46, 'learning_rate': 0.1484765386958742}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,319] Trial 10 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 63, 'learning_rate': 0.13319245398373342}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,431] Trial 11 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 55, 'learning_rate': 0.05581453477296136}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,511] Trial 12 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 44, 'learning_rate': 0.14935226414613875}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,604] Trial 13 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 49, 'learning_rate': 0.13842401731481163}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,704] Trial 14 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 53, 'learning_rate': 0.13195147366696638}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,795] Trial 15 finished with value: 0.8422689075630252 and parameters: {'n_estimators': 45, 'learning_rate': 0.8075854510810863}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,904] Trial 16 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 64, 'learning_rate': 0.04942512603468035}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:11,996] Trial 17 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 52, 'learning_rate': 0.6336609183426142}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,094] Trial 18 finished with value: 0.845658263305322 and parameters: {'n_estimators': 47, 'learning_rate': 0.10288801595611617}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,207] Trial 19 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 62, 'learning_rate': 0.43221559482885463}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,305] Trial 20 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 52, 'learning_rate': 0.7282689287680214}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,396] Trial 21 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 46, 'learning_rate': 0.10918100906664782}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,496] Trial 22 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 50, 'learning_rate': 0.06067154702689071}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,556] Trial 23 finished with value: 0.8422969187675069 and parameters: {'n_estimators': 29, 'learning_rate': 0.3170927675415055}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,644] Trial 24 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 48, 'learning_rate': 0.07602769676274197}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,715] Trial 25 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 34, 'learning_rate': 0.07278225797241931}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,772] Trial 26 finished with value: 0.8171428571428571 and parameters: {'n_estimators': 29, 'learning_rate': 0.06516576033789105}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:12,874] Trial 27 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 61, 'learning_rate': 0.30611471590890166}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,005] Trial 28 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 72, 'learning_rate': 0.8577176564263388}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,127] Trial 29 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 68, 'learning_rate': 0.13342575965110032}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,213] Trial 30 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 48, 'learning_rate': 0.31831534584679094}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,344] Trial 31 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 72, 'learning_rate': 0.5770983224907398}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,442] Trial 32 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 53, 'learning_rate': 0.20833137086749096}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,565] Trial 33 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 70, 'learning_rate': 0.3112044025276946}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,673] Trial 34 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 63, 'learning_rate': 0.09290634866187134}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,784] Trial 35 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 54, 'learning_rate': 0.28673317197139236}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:13,903] Trial 36 finished with value: 0.8338655462184874 and parameters: {'n_estimators': 72, 'learning_rate': 0.031143252490389687}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,003] Trial 37 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 59, 'learning_rate': 0.2314713795356876}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,113] Trial 38 finished with value: 0.8439495798319326 and parameters: {'n_estimators': 59, 'learning_rate': 0.3272954464732462}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,222] Trial 39 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 62, 'learning_rate': 0.3020274012286614}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,311] Trial 40 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 50, 'learning_rate': 0.25914640700655733}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,429] Trial 41 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 68, 'learning_rate': 0.3673818935425286}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,560] Trial 42 finished with value: 0.8405882352941175 and parameters: {'n_estimators': 65, 'learning_rate': 0.8382368194270798}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,659] Trial 43 finished with value: 0.8489775910364145 and parameters: {'n_estimators': 57, 'learning_rate': 0.723009850506859}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,766] Trial 44 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 63, 'learning_rate': 0.2265048895530471}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,877] Trial 45 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 55, 'learning_rate': 0.13722410621042982}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:14,996] Trial 46 finished with value: 0.8439915966386554 and parameters: {'n_estimators': 64, 'learning_rate': 0.1318415087841612}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:15,116] Trial 47 finished with value: 0.8456302521008402 and parameters: {'n_estimators': 66, 'learning_rate': 0.2676831117999838}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:15,224] Trial 48 finished with value: 0.842282913165266 and parameters: {'n_estimators': 58, 'learning_rate': 0.522463905626539}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[I 2025-12-28 19:24:15,345] Trial 49 finished with value: 0.850686274509804 and parameters: {'n_estimators': 61, 'learning_rate': 0.46684762630779697}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:15,453] Trial 50 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 53, 'learning_rate': 0.6928423423430802}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:15,573] Trial 51 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 63, 'learning_rate': 0.32969172842538436}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:15,665] Trial 52 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 54, 'learning_rate': 0.6678262122957844}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:15,753] Trial 53 finished with value: 0.8372408963585434 and parameters: {'n_estimators': 52, 'learning_rate': 0.8307476099841089}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:15,854] Trial 54 finished with value: 0.842282913165266 and parameters: {'n_estimators': 53, 'learning_rate': 0.6591045772773164}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:15,978] Trial 55 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 61, 'learning_rate': 0.9971948754002546}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,078] Trial 56 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 58, 'learning_rate': 0.4430766714194921}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,169] Trial 57 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 53, 'learning_rate': 0.34517772412828807}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,266] Trial 58 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 57, 'learning_rate': 0.2615695769939464}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,388] Trial 59 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 61, 'learning_rate': 0.280822261432388}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,521] Trial 60 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 57, 'learning_rate': 0.23003895798447352}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,633] Trial 61 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 64, 'learning_rate': 0.11723273364843298}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,754] Trial 62 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 64, 'learning_rate': 0.09415611217211962}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,864] Trial 63 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 57, 'learning_rate': 0.09177618111522291}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:16,976] Trial 64 finished with value: 0.850672268907563 and parameters: {'n_estimators': 62, 'learning_rate': 0.27023426061294153}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,077] Trial 65 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 59, 'learning_rate': 0.36813638473923505}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,187] Trial 66 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 57, 'learning_rate': 0.42258730227581615}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,290] Trial 67 finished with value: 0.8439635854341736 and parameters: {'n_estimators': 56, 'learning_rate': 0.3625835356262582}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,401] Trial 68 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 63, 'learning_rate': 0.3019914100302694}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,513] Trial 69 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 59, 'learning_rate': 0.17025592365121792}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,633] Trial 70 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 66, 'learning_rate': 0.5756562844391273}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,740] Trial 71 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 62, 'learning_rate': 0.0727605228317948}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,859] Trial 72 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 68, 'learning_rate': 0.04487326581316689}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:17,970] Trial 73 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 60, 'learning_rate': 0.22884454027300194}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,079] Trial 74 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 59, 'learning_rate': 0.516131352478289}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,190] Trial 75 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 62, 'learning_rate': 0.5263862561025988}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,290] Trial 76 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 59, 'learning_rate': 0.5525903137332405}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,399] Trial 77 finished with value: 0.842282913165266 and parameters: {'n_estimators': 58, 'learning_rate': 0.37948667713866246}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,508] Trial 78 finished with value: 0.8439495798319328 and parameters: {'n_estimators': 62, 'learning_rate': 0.2004902553082628}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,619] Trial 79 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 63, 'learning_rate': 0.5314819153756561}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,738] Trial 80 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 66, 'learning_rate': 0.26031507026129513}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,857] Trial 81 finished with value: 0.850672268907563 and parameters: {'n_estimators': 65, 'learning_rate': 0.21272336315252188}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:18,977] Trial 82 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 64, 'learning_rate': 0.31126184620901615}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,097] Trial 83 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 69, 'learning_rate': 0.20859184674524234}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,207] Trial 84 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 64, 'learning_rate': 0.2952963738056541}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,337] Trial 85 finished with value: 0.8473109243697479 and parameters: {'n_estimators': 68, 'learning_rate': 0.18339661914119132}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,458] Trial 86 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 70, 'learning_rate': 0.12555761817179592}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,579] Trial 87 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 72, 'learning_rate': 0.10556224003616961}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,690] Trial 88 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 64, 'learning_rate': 0.45383816370626695}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,810] Trial 89 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 72, 'learning_rate': 0.10061770070204293}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:19,930] Trial 90 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 70, 'learning_rate': 0.14034472329177175}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,073] Trial 91 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 72, 'learning_rate': 0.13904332187699184}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,203] Trial 92 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 74, 'learning_rate': 0.11532393108616165}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,334] Trial 93 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 68, 'learning_rate': 0.03369669865716281}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,445] Trial 94 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 64, 'learning_rate': 0.12334087779500408}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,588] Trial 95 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 74, 'learning_rate': 0.0763094919412178}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,697] Trial 96 finished with value: 0.8439495798319326 and parameters: {'n_estimators': 67, 'learning_rate': 0.49360103339127526}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,798] Trial 97 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 56, 'learning_rate': 0.07971074640810344}. Best is trial 49 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:24:20,908] Trial 98 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 67, 'learning_rate': 0.14787479529644731}. Best is trial 49 with value: 0.850686274509804.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:21,054] A new study created in memory with name: Gradient Boosting Model Fine Tuning with CmaEsSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:21,051] Trial 99 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 78, 'learning_rate': 0.07306051011082514}. Best is trial 49 with value: 0.850686274509804.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using CmaEsSampler: {'n_estimators': 61, 'learning_rate': 0.46684762630779697}\n",
      "Best accuracy: 0.8507, at trial: 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ab01b59d6b4e42832bb0308c3b85be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:21,192] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n",
      "[W 2025-12-28 19:24:21,196] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:21,345] Trial 1 finished with value: 0.8372829131652659 and parameters: {'max_features': None, 'n_estimators': 57, 'learning_rate': 0.008658084666909323, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8397600270730616}. Best is trial 1 with value: 0.8372829131652659.\n",
      "[W 2025-12-28 19:24:21,348] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:21,466] Trial 2 finished with value: 0.850672268907563 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.009528924787594208, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.8029297907760695}. Best is trial 2 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:21,470] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:21,568] Trial 3 finished with value: 0.8473389355742296 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.026515758596185147, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7269530336476903}. Best is trial 2 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:21,571] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:21,668] Trial 4 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 24, 'learning_rate': 0.0010702593573937475, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7677248753915946}. Best is trial 2 with value: 0.850672268907563.\n",
      "[W 2025-12-28 19:24:21,670] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:21,799] Trial 5 finished with value: 0.8523669467787116 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.019667141639294356, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'subsample': 0.7115398922202714}. Best is trial 5 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:21,803] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:21,890] Trial 6 finished with value: 0.8607422969187676 and parameters: {'max_features': 'log2', 'n_estimators': 47, 'learning_rate': 0.02340459441539314, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.7681058459555117}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:21,894] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:21,982] Trial 7 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.01959654330798669, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7131820938134579}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:21,982] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:22,092] Trial 8 finished with value: 0.8557422969187677 and parameters: {'max_features': 'sqrt', 'n_estimators': 29, 'learning_rate': 0.028171880519557702, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8047109221769}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:22,095] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:22,246] Trial 9 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 67, 'learning_rate': 0.011695860437734951, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.757470058328777}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:22,246] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:22,471] Trial 10 finished with value: 0.830546218487395 and parameters: {'max_features': None, 'n_estimators': 67, 'learning_rate': 0.019186756359786283, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.8857092259093142}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:22,471] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:22,601] Trial 11 finished with value: 0.8540336134453781 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.024506038342554746, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.8363351662316645}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:22,603] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:22,691] Trial 12 finished with value: 0.8473109243697479 and parameters: {'max_features': 'log2', 'n_estimators': 29, 'learning_rate': 0.008532778074743636, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.6567406855812525}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:22,694] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:22,885] Trial 13 finished with value: 0.8489915966386554 and parameters: {'max_features': 'sqrt', 'n_estimators': 63, 'learning_rate': 0.005429830479211185, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.8089707074139939}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:22,885] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:22,965] Trial 14 finished with value: 0.8439495798319328 and parameters: {'max_features': None, 'n_estimators': 27, 'learning_rate': 0.03390687284538989, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8, 'subsample': 0.7188888558546109}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:22,967] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,034] Trial 15 finished with value: 0.8490056022408965 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.010810383824017106, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.630278005117144}. Best is trial 6 with value: 0.8607422969187676.\n",
      "[W 2025-12-28 19:24:23,034] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,125] Trial 16 finished with value: 0.8641316526610645 and parameters: {'max_features': 'log2', 'n_estimators': 48, 'learning_rate': 0.054855506254906185, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7778466297599895}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,127] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,215] Trial 17 finished with value: 0.8473669467787113 and parameters: {'max_features': None, 'n_estimators': 35, 'learning_rate': 0.03206273475587771, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7704649943483719}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,216] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,285] Trial 18 finished with value: 0.8221428571428572 and parameters: {'max_features': None, 'n_estimators': 26, 'learning_rate': 0.007468323083543948, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7949752562148357}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,285] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,407] Trial 19 finished with value: 0.8439775910364145 and parameters: {'max_features': None, 'n_estimators': 62, 'learning_rate': 0.01573633683297625, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.8381217973523055}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,407] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,547] Trial 20 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 85, 'learning_rate': 0.02433352805030569, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7434367340213306}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,548] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,615] Trial 21 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 32, 'learning_rate': 0.03215910181189461, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.8589932910252933}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,617] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,664] Trial 22 finished with value: 0.8472969187675069 and parameters: {'max_features': 'log2', 'n_estimators': 36, 'learning_rate': 0.03100216091988688, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6892929197516324}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,665] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,743] Trial 23 finished with value: 0.850658263305322 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.008891631256945186, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.8620374981452141}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,743] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,865] Trial 24 finished with value: 0.8406162464985993 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.03329831400459078, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7605139906379603}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,866] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:23,955] Trial 25 finished with value: 0.8540196078431374 and parameters: {'max_features': 'sqrt', 'n_estimators': 59, 'learning_rate': 0.03489012793048932, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.8583585127891135}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:23,955] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,076] Trial 26 finished with value: 0.8406162464985993 and parameters: {'max_features': None, 'n_estimators': 55, 'learning_rate': 0.020678287237377465, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7315978880861083}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,079] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,157] Trial 27 finished with value: 0.8624649859943979 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.08096745729417958, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.7377879050073111}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,157] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,247] Trial 28 finished with value: 0.8288515406162464 and parameters: {'max_features': None, 'n_estimators': 30, 'learning_rate': 0.030403872015861873, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7966304857376554}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,248] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,327] Trial 29 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.08947616532979838, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.829716710671637}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,327] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,416] Trial 30 finished with value: 0.8624229691876749 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.05004701270566438, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.819223297662963}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,420] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,507] Trial 31 finished with value: 0.8607422969187676 and parameters: {'max_features': None, 'n_estimators': 53, 'learning_rate': 0.09014011672004806, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6795760488980354}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,509] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,689] Trial 32 finished with value: 0.8188095238095239 and parameters: {'max_features': None, 'n_estimators': 47, 'learning_rate': 0.006989813346538339, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.9092367273575508}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,691] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,831] Trial 33 finished with value: 0.8338795518207283 and parameters: {'max_features': None, 'n_estimators': 35, 'learning_rate': 0.0605431801791921, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.8169910517466005}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,831] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:24,900] Trial 34 finished with value: 0.8271988795518206 and parameters: {'max_features': None, 'n_estimators': 18, 'learning_rate': 0.07700995467993466, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.7509308587849869}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:24,902] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,031] Trial 35 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 59, 'learning_rate': 0.03548782780514841, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.765491890810946}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:25,033] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,133] Trial 36 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 36, 'learning_rate': 0.024362062934210945, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7685183441038836}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:25,138] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,244] Trial 37 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 36, 'learning_rate': 0.07358115733166673, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7264336563830502}. Best is trial 16 with value: 0.8641316526610645.\n",
      "[W 2025-12-28 19:24:25,247] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,438] Trial 38 finished with value: 0.8657703081232494 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.020406225830080383, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7797022489294623}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:25,438] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,580] Trial 39 finished with value: 0.8489915966386554 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.02750447417784692, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7834089115198415}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:25,583] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,680] Trial 40 finished with value: 0.8473249299719887 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.06286435966104069, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.8263555149571392}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:25,683] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,750] Trial 41 finished with value: 0.8540616246498599 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.07679684346685603, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.8345575879196525}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:25,753] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,873] Trial 42 finished with value: 0.8473249299719889 and parameters: {'max_features': None, 'n_estimators': 70, 'learning_rate': 0.019813791050297454, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.8345821455150564}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:25,876] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:25,965] Trial 43 finished with value: 0.8657703081232494 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.08862920446677826, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.7425146966808283}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:25,967] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:26,098] Trial 44 finished with value: 0.8607422969187676 and parameters: {'max_features': 'log2', 'n_estimators': 71, 'learning_rate': 0.059750060242190595, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7368827080031677}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:26,101] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:26,178] Trial 45 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 55, 'learning_rate': 0.03376632931726743, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7865603753966572}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:26,181] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:26,300] Trial 46 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.05937839640766812, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7364248448856223}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:26,303] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:26,472] Trial 47 finished with value: 0.8641036414565827 and parameters: {'max_features': 'sqrt', 'n_estimators': 76, 'learning_rate': 0.02851664319123799, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7432797583105208}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:26,475] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:26,564] Trial 48 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.04982051538494294, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8035895691271451}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:26,566] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:26,666] Trial 49 finished with value: 0.8489915966386554 and parameters: {'max_features': 'log2', 'n_estimators': 99, 'learning_rate': 0.018512107531534653, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7752659730003304}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:26,668] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:26,869] Trial 50 finished with value: 0.8507002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 88, 'learning_rate': 0.01744995825094081, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.8399211293965829}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:26,873] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:27,052] Trial 51 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.00663021434923254, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.6334350339828383}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:27,055] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:27,184] Trial 52 finished with value: 0.8557282913165267 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.05867452042891346, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7274087758887515}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:27,187] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:27,318] Trial 53 finished with value: 0.8641036414565825 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.023950760939612178, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.7585413796502605}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:27,320] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:27,513] Trial 54 finished with value: 0.8456442577030814 and parameters: {'max_features': None, 'n_estimators': 98, 'learning_rate': 0.04137705629645841, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.803470612239756}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:27,517] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:27,626] Trial 55 finished with value: 0.8607422969187676 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.02683090983806732, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7903379819382181}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:27,629] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:27,830] Trial 56 finished with value: 0.8439635854341738 and parameters: {'max_features': None, 'n_estimators': 81, 'learning_rate': 0.00991667063487067, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.6385623893236221}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:27,832] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:27,931] Trial 57 finished with value: 0.8574089635854343 and parameters: {'max_features': 'log2', 'n_estimators': 50, 'learning_rate': 0.04107169553300588, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.7589681568393039}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:27,934] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:28,085] Trial 58 finished with value: 0.850686274509804 and parameters: {'max_features': None, 'n_estimators': 76, 'learning_rate': 0.018544779331734044, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.7202292346566332}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:28,088] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:28,188] Trial 59 finished with value: 0.8523529411764705 and parameters: {'max_features': 'sqrt', 'n_estimators': 76, 'learning_rate': 0.015850961603156886, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7142740394800418}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:28,191] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:28,351] Trial 60 finished with value: 0.8590476190476192 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.05179080847801134, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.7177674013939884}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:28,354] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:28,483] Trial 61 finished with value: 0.850686274509804 and parameters: {'max_features': None, 'n_estimators': 47, 'learning_rate': 0.02096337849481903, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7161670760735948}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:28,486] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:28,701] Trial 62 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.005514032322833439, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.822633249992058}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:28,704] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:28,854] Trial 63 finished with value: 0.8406162464985993 and parameters: {'max_features': None, 'n_estimators': 74, 'learning_rate': 0.012155768063708355, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.675933970448064}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:28,858] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:28,997] Trial 64 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 67, 'learning_rate': 0.021952614003054646, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.6808162005668534}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:29,000] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:29,246] Trial 65 finished with value: 0.8456442577030814 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.02091820316412087, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7520314220152857}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:29,249] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:29,409] Trial 66 finished with value: 0.8540476190476192 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.06003570206373041, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7548754528670794}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:29,411] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:29,584] Trial 67 finished with value: 0.8574089635854343 and parameters: {'max_features': 'sqrt', 'n_estimators': 82, 'learning_rate': 0.018132933205581434, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7025234754874583}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:29,587] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:29,665] Trial 68 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.04564327361923159, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7841205767998596}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:29,667] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:29,797] Trial 69 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 58, 'learning_rate': 0.0252640112008135, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7898729900044148}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:29,800] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:29,979] Trial 70 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 65, 'learning_rate': 0.013686831266693796, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.8503754995010688}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:29,982] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:30,216] Trial 71 finished with value: 0.8540196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.02749751830979743, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7932336441749268}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:30,219] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:30,360] Trial 72 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 71, 'learning_rate': 0.059670664029502614, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.7039722890874505}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:30,363] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:30,546] Trial 73 finished with value: 0.8523669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 80, 'learning_rate': 0.007705727516065034, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.8060889217672739}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:30,549] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:30,721] Trial 74 finished with value: 0.8489775910364145 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.020482326470337573, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7514825678954113}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:30,723] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:30,917] Trial 75 finished with value: 0.8523389355742296 and parameters: {'max_features': 'log2', 'n_estimators': 87, 'learning_rate': 0.013970592211066394, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7710335513358371}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:30,920] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:31,051] Trial 76 finished with value: 0.8573809523809525 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.02687379082816112, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7672795140908188}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:31,055] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:31,249] Trial 77 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 80, 'learning_rate': 0.025248108685417138, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7127094013070812}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:31,252] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:31,443] Trial 78 finished with value: 0.8573669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 77, 'learning_rate': 0.009358998116697739, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.6877112383836598}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:31,446] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:31,789] Trial 79 finished with value: 0.8322408963585433 and parameters: {'max_features': None, 'n_estimators': 80, 'learning_rate': 0.01071001176937703, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7969101460149056}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:31,791] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:32,004] Trial 80 finished with value: 0.8489775910364145 and parameters: {'max_features': 'log2', 'n_estimators': 78, 'learning_rate': 0.01580923550035369, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.66168091253303}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:32,007] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:32,249] Trial 81 finished with value: 0.8573669467787116 and parameters: {'max_features': 'sqrt', 'n_estimators': 72, 'learning_rate': 0.010078871223422712, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.7917408932032248}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:32,253] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:32,423] Trial 82 finished with value: 0.8607563025210083 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.029402891329630913, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7822427774963345}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:32,426] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:32,606] Trial 83 finished with value: 0.8523529411764704 and parameters: {'max_features': 'log2', 'n_estimators': 71, 'learning_rate': 0.028171140258139948, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7181452101814902}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:32,609] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:32,851] Trial 84 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 95, 'learning_rate': 0.02389724804864494, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.7419959870981614}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:32,853] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:33,116] Trial 85 finished with value: 0.8557002801120447 and parameters: {'max_features': 'sqrt', 'n_estimators': 93, 'learning_rate': 0.02823791121946593, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.690980675416789}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:33,118] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:33,300] Trial 86 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 86, 'learning_rate': 0.022225855493707595, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7890958311120879}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:33,301] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:33,482] Trial 87 finished with value: 0.8523389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 84, 'learning_rate': 0.010458903598770445, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.6790220054110452}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:33,485] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:33,624] Trial 88 finished with value: 0.8557142857142856 and parameters: {'max_features': None, 'n_estimators': 60, 'learning_rate': 0.02786358714278842, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.6443723445742091}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:33,625] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:33,787] Trial 89 finished with value: 0.8590616246498598 and parameters: {'max_features': 'sqrt', 'n_estimators': 78, 'learning_rate': 0.03029344067632303, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.6707735721419779}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:33,790] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:34,022] Trial 90 finished with value: 0.8540336134453781 and parameters: {'max_features': 'sqrt', 'n_estimators': 89, 'learning_rate': 0.002961066277267689, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6826879226841978}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:34,026] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:34,124] Trial 91 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 76, 'learning_rate': 0.022661621184006858, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7821812302944562}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:34,127] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:34,308] Trial 92 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.04354991720234186, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.696040973718282}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:34,311] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:34,440] Trial 93 finished with value: 0.8523529411764705 and parameters: {'max_features': None, 'n_estimators': 82, 'learning_rate': 0.06733760438645663, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.6786564952310994}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:34,440] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:34,623] Trial 94 finished with value: 0.8641176470588234 and parameters: {'max_features': 'log2', 'n_estimators': 81, 'learning_rate': 0.03199932530606376, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7484363299435675}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:34,626] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:34,745] Trial 95 finished with value: 0.8573809523809522 and parameters: {'max_features': 'log2', 'n_estimators': 72, 'learning_rate': 0.007573918345007175, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7354320405183865}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:34,747] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:34,969] Trial 96 finished with value: 0.8406022408963585 and parameters: {'max_features': None, 'n_estimators': 82, 'learning_rate': 0.025661473605780635, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.8335075122451062}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:34,972] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:35,122] Trial 97 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 74, 'learning_rate': 0.09677167616027735, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.6815195593331664}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:35,125] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:35,305] Trial 98 finished with value: 0.8456302521008403 and parameters: {'max_features': None, 'n_estimators': 96, 'learning_rate': 0.08613925409594979, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7535700353454825}. Best is trial 38 with value: 0.8657703081232494.\n",
      "[W 2025-12-28 19:24:35,309] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:35,467] Trial 99 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.07972103306451035, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.6173702077940904}. Best is trial 38 with value: 0.8657703081232494.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using CmaEsSampler: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.020406225830080383, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7797022489294623}\n",
      "Best accuracy: 0.8658, at trial: 38\n",
      "CMA-ES Base Models Training Time: 52.42 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_base_models_training_start = time.time()\n",
    "\n",
    "    # CMA-ES Hyperparameter Tuning with Cross Validation\n",
    "    cmaes_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    cmaes_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='CmaEsSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    cmaes_logistic_regression.fit(X_train, y_train)\n",
    "    cmaes_decision_tree.fit(X_train, y_train)\n",
    "    cmaes_random_forest.fit(X_train, y_train)\n",
    "    cmaes_knn.fit(X_train, y_train)\n",
    "    cmaes_svc.fit(X_train, y_train)\n",
    "    cmaes_adaboost.fit(X_train, y_train)\n",
    "    cmaes_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES base models training\n",
    "    cmaes_base_models_training_time = cmaes_base_models_training_end - cmaes_base_models_training_start\n",
    "    print(f'CMA-ES Base Models Training Time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping CMA-ES base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:24:35,837] A new study created in memory with name: Logistic Regression Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f7e45b08834a4289402fbb66c05248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:35,883] Trial 0 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0006026889128682511}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:35,885] The parameter `solver` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:35,921] Trial 1 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cholesky', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:35,923] The parameter `solver` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:35,958] Trial 2 finished with value: 0.8472549019607843 and parameters: {'solver': 'newton-cholesky', 'C': 0.0316227766016838}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:35,960] The parameter `solver` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:35,996] Trial 3 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 0.5623413251903494}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:35,998] The parameter `solver` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,033] Trial 4 finished with value: 0.7986974789915966 and parameters: {'solver': 'sag', 'C': 0.0017782794100389236}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,034] The parameter `solver` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,070] Trial 5 finished with value: 0.8304901960784313 and parameters: {'solver': 'sag', 'C': 0.007498942093324564}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,073] The parameter `solver` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,108] Trial 6 finished with value: 0.8355462184873949 and parameters: {'solver': 'lbfgs', 'C': 2.371373705661655}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,109] The parameter `solver` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,146] Trial 7 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cg', 'C': 0.13335214321633232}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,148] The parameter `solver` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,183] Trial 8 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00042169650342858235}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,185] The parameter `solver` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,220] Trial 9 finished with value: 0.5989635854341737 and parameters: {'solver': 'newton-cg', 'C': 0.000865964323360066}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,221] The parameter `solver` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,256] Trial 10 finished with value: 0.8422689075630252 and parameters: {'solver': 'newton-cholesky', 'C': 0.27384196342643613}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,257] The parameter `solver` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,293] Trial 11 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 4.8696752516586255}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,294] The parameter `solver` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,330] Trial 12 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.015399265260594926}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,331] The parameter `solver` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,367] Trial 13 finished with value: 0.8338655462184874 and parameters: {'solver': 'newton-cholesky', 'C': 0.0036517412725483775}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,368] The parameter `solver` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,404] Trial 14 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 1.1547819846894576}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,406] The parameter `solver` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,442] Trial 15 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cg', 'C': 0.06493816315762112}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,443] The parameter `solver` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,478] Trial 16 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cholesky', 'C': 0.0002053525026457149}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,480] The parameter `solver` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,516] Trial 17 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.0002942727176209287}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,518] The parameter `solver` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,553] Trial 18 finished with value: 0.8456162464985993 and parameters: {'solver': 'lbfgs', 'C': 0.0930572040929699}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,554] The parameter `solver` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,590] Trial 19 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 1.6548170999431808}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,592] The parameter `solver` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,629] Trial 20 finished with value: 0.8321708683473389 and parameters: {'solver': 'lbfgs', 'C': 0.005232991146814949}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,630] The parameter `solver` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,666] Trial 21 finished with value: 0.84390756302521 and parameters: {'solver': 'sag', 'C': 0.022067340690845896}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,667] The parameter `solver` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,713] Trial 22 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.978305848598657}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,714] The parameter `solver` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,750] Trial 23 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.3924189758484537}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,752] The parameter `solver` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,787] Trial 24 finished with value: 0.7399719887955183 and parameters: {'solver': 'lbfgs', 'C': 0.0012409377607517208}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,788] The parameter `solver` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,825] Trial 25 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.0006042963902381332}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,826] The parameter `solver` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,862] Trial 26 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.19109529749704401}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,864] The parameter `solver` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,899] Trial 27 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 3.39820832894256}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,900] The parameter `solver` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,935] Trial 28 finished with value: 0.84390756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.010746078283213176}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,936] The parameter `solver` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:36,972] Trial 29 finished with value: 0.8321988795518207 and parameters: {'solver': 'newton-cg', 'C': 0.0025482967479793462}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:36,974] The parameter `solver` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,009] Trial 30 finished with value: 0.83890756302521 and parameters: {'solver': 'lbfgs', 'C': 0.8058421877614811}. Best is trial 2 with value: 0.8472549019607843.\n",
      "[W 2025-12-28 19:24:37,010] The parameter `solver` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,046] Trial 31 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.045315836376008195}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,048] The parameter `solver` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,083] Trial 32 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00014330125702369644}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,085] The parameter `solver` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,120] Trial 33 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00017154378963428796}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,122] The parameter `solver` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,157] Trial 34 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cholesky', 'C': 0.05424690937011324}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,158] The parameter `solver` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,195] Trial 35 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 0.9646616199111994}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,197] The parameter `solver` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,232] Trial 36 finished with value: 0.8305182072829131 and parameters: {'solver': 'newton-cg', 'C': 0.0030505278902670284}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,233] The parameter `solver` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,269] Trial 37 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.01286396944936975}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,270] The parameter `solver` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,306] Trial 38 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 4.067944321083045}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,307] The parameter `solver` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,343] Trial 39 finished with value: 0.8439495798319328 and parameters: {'solver': 'lbfgs', 'C': 0.22875732003183954}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,344] The parameter `solver` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,380] Trial 40 finished with value: 0.5385994397759104 and parameters: {'solver': 'newton-cg', 'C': 0.0007233941627366753}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,381] The parameter `solver` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,416] Trial 41 finished with value: 0.7701820728291316 and parameters: {'solver': 'lbfgs', 'C': 0.0014855080171727755}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,417] The parameter `solver` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,453] Trial 42 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.469758881670649}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,454] The parameter `solver` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,499] Trial 43 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 8.353625469578262}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,500] The parameter `solver` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,536] Trial 44 finished with value: 0.8472689075630251 and parameters: {'solver': 'newton-cg', 'C': 0.026416483203860926}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,537] The parameter `solver` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,573] Trial 45 finished with value: 0.8288095238095238 and parameters: {'solver': 'newton-cg', 'C': 0.00626433536656886}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,574] The parameter `solver` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,609] Trial 46 finished with value: 0.8355462184873949 and parameters: {'solver': 'newton-cg', 'C': 1.9809567785503366}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,611] The parameter `solver` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,647] Trial 47 finished with value: 0.8439495798319328 and parameters: {'solver': 'sag', 'C': 0.11139738599948026}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,649] The parameter `solver` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,683] Trial 48 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.0003522694651473105}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,684] The parameter `solver` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,721] Trial 49 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.0002458244068920199}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,722] The parameter `solver` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,758] Trial 50 finished with value: 0.8456162464985993 and parameters: {'solver': 'newton-cholesky', 'C': 0.07773650302387758}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,760] The parameter `solver` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,795] Trial 51 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 1.3823722273579002}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,796] The parameter `solver` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,834] Trial 52 finished with value: 0.8305042016806722 and parameters: {'solver': 'newton-cholesky', 'C': 0.004371444812611091}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,835] The parameter `solver` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,871] Trial 53 finished with value: 0.8422268907563024 and parameters: {'solver': 'newton-cg', 'C': 0.018434229924091116}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,873] The parameter `solver` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,908] Trial 54 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 5.829415347136073}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,909] The parameter `solver` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,945] Trial 55 finished with value: 0.8405882352941176 and parameters: {'solver': 'lbfgs', 'C': 0.32781211513934566}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,947] The parameter `solver` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:37,983] Trial 56 finished with value: 0.7114285714285714 and parameters: {'solver': 'newton-cg', 'C': 0.001036632928437698}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:37,985] The parameter `solver` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,021] Trial 57 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.0005048065716667473}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,022] The parameter `solver` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,058] Trial 58 finished with value: 0.8456302521008403 and parameters: {'solver': 'newton-cholesky', 'C': 0.15963385442879416}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,059] The parameter `solver` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,096] Trial 59 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 2.8387359647587527}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,098] The parameter `solver` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,134] Trial 60 finished with value: 0.8405602240896359 and parameters: {'solver': 'lbfgs', 'C': 0.008976871324473142}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,136] The parameter `solver` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,171] Trial 61 finished with value: 0.8204621848739496 and parameters: {'solver': 'newton-cholesky', 'C': 0.002128751661796374}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,172] The parameter `solver` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,209] Trial 62 finished with value: 0.83890756302521 and parameters: {'solver': 'lbfgs', 'C': 0.6731703824144981}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,209] The parameter `solver` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,246] Trial 63 finished with value: 0.8472689075630251 and parameters: {'solver': 'sag', 'C': 0.03785515249258631}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,247] The parameter `solver` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,284] Trial 64 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00011970850304957301}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,285] The parameter `solver` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,322] Trial 65 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00013097472643005907}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,323] The parameter `solver` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,359] Trial 66 finished with value: 0.8472689075630251 and parameters: {'solver': 'lbfgs', 'C': 0.04141784514364404}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,361] The parameter `solver` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,396] Trial 67 finished with value: 0.83890756302521 and parameters: {'solver': 'sag', 'C': 0.7365250122712284}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,398] The parameter `solver` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,434] Trial 68 finished with value: 0.8254901960784313 and parameters: {'solver': 'lbfgs', 'C': 0.0023290965924605465}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,436] The parameter `solver` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,472] Trial 69 finished with value: 0.8405602240896359 and parameters: {'solver': 'sag', 'C': 0.009821718891880384}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,473] The parameter `solver` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,509] Trial 70 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 3.105900223624704}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,510] The parameter `solver` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,545] Trial 71 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.17465760476621184}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,547] The parameter `solver` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,583] Trial 72 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.0005523158417307104}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,584] The parameter `solver` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,620] Trial 73 finished with value: 0.7198319327731093 and parameters: {'solver': 'sag', 'C': 0.0011341944035027575}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,621] The parameter `solver` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,656] Trial 74 finished with value: 0.8405882352941176 and parameters: {'solver': 'newton-cg', 'C': 0.3586637624484768}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,658] The parameter `solver` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,692] Trial 75 finished with value: 0.8372268907563024 and parameters: {'solver': 'sag', 'C': 6.378043838892169}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,694] The parameter `solver` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,730] Trial 76 finished with value: 0.84390756302521 and parameters: {'solver': 'lbfgs', 'C': 0.02016914554730331}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,731] The parameter `solver` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,766] Trial 77 finished with value: 0.8304901960784313 and parameters: {'solver': 'newton-cg', 'C': 0.004782858141653791}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,768] The parameter `solver` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,803] Trial 78 finished with value: 0.8372268907563024 and parameters: {'solver': 'lbfgs', 'C': 1.512472545310622}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,805] The parameter `solver` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,841] Trial 79 finished with value: 0.8456162464985993 and parameters: {'solver': 'sag', 'C': 0.08505258154439958}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,843] The parameter `solver` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,878] Trial 80 finished with value: 0.5352380952380952 and parameters: {'solver': 'sag', 'C': 0.00026895987855750467}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,880] The parameter `solver` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,915] Trial 81 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00038542288686231087}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,917] The parameter `solver` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,955] Trial 82 finished with value: 0.8439495798319328 and parameters: {'solver': 'newton-cholesky', 'C': 0.12188141848422895}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,956] The parameter `solver` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:38,993] Trial 83 finished with value: 0.8355462184873949 and parameters: {'solver': 'sag', 'C': 2.167392169568416}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:38,995] The parameter `solver` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,031] Trial 84 finished with value: 0.8288095238095238 and parameters: {'solver': 'lbfgs', 'C': 0.006853895838650084}. Best is trial 31 with value: 0.8472689075630251.\n",
      "[W 2025-12-28 19:24:39,032] The parameter `solver` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,068] Trial 85 finished with value: 0.8472689075630253 and parameters: {'solver': 'lbfgs', 'C': 0.028902639100224517}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,070] The parameter `solver` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,106] Trial 86 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 9.139816994654893}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,108] The parameter `solver` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,144] Trial 87 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cholesky', 'C': 0.5139696800771514}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,145] The parameter `solver` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,181] Trial 88 finished with value: 0.7835994397759103 and parameters: {'solver': 'newton-cholesky', 'C': 0.001625314837311866}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,182] The parameter `solver` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,218] Trial 89 finished with value: 0.5553641456582633 and parameters: {'solver': 'newton-cg', 'C': 0.0007914755439411164}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,220] The parameter `solver` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,255] Trial 90 finished with value: 0.8456302521008403 and parameters: {'solver': 'sag', 'C': 0.2502865431174607}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,256] The parameter `solver` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,292] Trial 91 finished with value: 0.8372268907563024 and parameters: {'solver': 'newton-cg', 'C': 4.450794062355996}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,293] The parameter `solver` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,329] Trial 92 finished with value: 0.8405462184873949 and parameters: {'solver': 'newton-cg', 'C': 0.014074646633398432}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,330] The parameter `solver` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,366] Trial 93 finished with value: 0.835546218487395 and parameters: {'solver': 'sag', 'C': 0.0033376246942920405}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,368] The parameter `solver` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,403] Trial 94 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cg', 'C': 1.0554496008786018}. Best is trial 85 with value: 0.8472689075630253.\n",
      "[W 2025-12-28 19:24:39,404] The parameter `solver` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,440] Trial 95 finished with value: 0.8472829131652662 and parameters: {'solver': 'newton-cholesky', 'C': 0.05935229272296987}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:24:39,441] The parameter `solver` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,478] Trial 96 finished with value: 0.5352380952380952 and parameters: {'solver': 'lbfgs', 'C': 0.00018768842935762206}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:24:39,479] The parameter `solver` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,515] Trial 97 finished with value: 0.5352380952380952 and parameters: {'solver': 'newton-cg', 'C': 0.00015678788438269704}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:24:39,515] The parameter `solver` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,552] Trial 98 finished with value: 0.8455882352941175 and parameters: {'solver': 'newton-cholesky', 'C': 0.04958068241684656}. Best is trial 95 with value: 0.8472829131652662.\n",
      "[W 2025-12-28 19:24:39,552] The parameter `solver` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,589] Trial 99 finished with value: 0.83890756302521 and parameters: {'solver': 'newton-cholesky', 'C': 0.8816830667755706}. Best is trial 95 with value: 0.8472829131652662.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:24:39,592] A new study created in memory with name: Decision Tree Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Logistic Regression Using QMCSampler: {'solver': 'newton-cholesky', 'C': 0.05935229272296987}\n",
      "Best accuracy: 0.8473, at trial: 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656eea219fbb420da034ec09b088ad9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:39,614] Trial 0 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:24:39,615] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,617] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,631] Trial 1 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:24:39,633] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,635] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,649] Trial 2 finished with value: 0.815420168067227 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:24:39,649] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,652] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,667] Trial 3 finished with value: 0.8238655462184873 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8271848739495798.\n",
      "[W 2025-12-28 19:24:39,668] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,670] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,696] Trial 4 finished with value: 0.8272268907563024 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,697] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,697] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,715] Trial 5 finished with value: 0.8154481792717088 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,715] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,718] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,732] Trial 6 finished with value: 0.7768347338935574 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,732] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,732] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,749] Trial 7 finished with value: 0.8120868347338934 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,750] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,750] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,767] Trial 8 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,767] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,770] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,784] Trial 9 finished with value: 0.8087114845938375 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,784] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,784] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,802] Trial 10 finished with value: 0.8171288515406163 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,802] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,802] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,820] Trial 11 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,820] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,820] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,837] Trial 12 finished with value: 0.8003361344537815 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,837] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,839] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,855] Trial 13 finished with value: 0.8086834733893558 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8272268907563024.\n",
      "[W 2025-12-28 19:24:39,855] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,858] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,872] Trial 14 finished with value: 0.8288935574229692 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:39,872] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,874] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,889] Trial 15 finished with value: 0.8171848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:39,890] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,892] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,906] Trial 16 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:39,906] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,906] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,924] Trial 17 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:39,924] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,924] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,941] Trial 18 finished with value: 0.8104621848739495 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:39,943] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,944] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,958] Trial 19 finished with value: 0.8238655462184873 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:39,958] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,958] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:39,975] Trial 20 finished with value: 0.8272268907563024 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:39,976] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:39,976] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,003] Trial 21 finished with value: 0.8137675070028012 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:40,003] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,006] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,020] Trial 22 finished with value: 0.8054201680672269 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:40,020] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,023] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,047] Trial 23 finished with value: 0.8238375350140055 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8288935574229692.\n",
      "[W 2025-12-28 19:24:40,048] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,050] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,065] Trial 24 finished with value: 0.8389215686274509 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 24 with value: 0.8389215686274509.\n",
      "[W 2025-12-28 19:24:40,065] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,067] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,082] Trial 25 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,082] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,082] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,099] Trial 26 finished with value: 0.8120448179271709 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,099] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,101] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,116] Trial 27 finished with value: 0.8187955182072828 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,116] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,118] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,133] Trial 28 finished with value: 0.8171428571428571 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,134] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,136] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,151] Trial 29 finished with value: 0.813781512605042 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,151] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,151] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,168] Trial 30 finished with value: 0.8070308123249299 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,169] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,169] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,185] Trial 31 finished with value: 0.8221988795518207 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,187] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,187] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,203] Trial 32 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,203] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,203] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,219] Trial 33 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,219] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,219] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,247] Trial 34 finished with value: 0.8221568627450979 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,249] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,249] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,264] Trial 35 finished with value: 0.812156862745098 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,265] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,267] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,294] Trial 36 finished with value: 0.8137254901960784 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,294] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,297] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,313] Trial 37 finished with value: 0.7919607843137254 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,315] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,315] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,330] Trial 38 finished with value: 0.8205322128851542 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,330] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,333] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,347] Trial 39 finished with value: 0.805392156862745 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.8423109243697479.\n",
      "[W 2025-12-28 19:24:40,347] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,350] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,364] Trial 40 finished with value: 0.8473109243697479 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,364] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,367] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,383] Trial 41 finished with value: 0.8439775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,383] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,385] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,399] Trial 42 finished with value: 0.8322408963585433 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,399] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,401] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,416] Trial 43 finished with value: 0.7885854341736694 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,418] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,419] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,434] Trial 44 finished with value: 0.8137535014005601 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,435] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,436] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,451] Trial 45 finished with value: 0.8204901960784312 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,451] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,453] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,469] Trial 46 finished with value: 0.8087254901960785 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,471] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,472] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,486] Trial 47 finished with value: 0.8221708683473388 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,486] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,488] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,503] Trial 48 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,503] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,503] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,520] Trial 49 finished with value: 0.8053361344537814 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,521] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,521] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,537] Trial 50 finished with value: 0.8154761904761905 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,537] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,539] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,554] Trial 51 finished with value: 0.8205042016806722 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,554] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,554] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,571] Trial 52 finished with value: 0.8087254901960785 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,571] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,574] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,589] Trial 53 finished with value: 0.8389215686274512 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,589] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,589] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,606] Trial 54 finished with value: 0.8154621848739495 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,607] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,607] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,624] Trial 55 finished with value: 0.8288795518207284 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,626] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,627] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,641] Trial 56 finished with value: 0.8439495798319326 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,643] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,643] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,658] Trial 57 finished with value: 0.8389495798319327 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,659] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,659] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,676] Trial 58 finished with value: 0.8322268907563025 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,676] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,676] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,693] Trial 59 finished with value: 0.8271848739495798 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,693] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,693] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,710] Trial 60 finished with value: 0.8222128851540618 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,712] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,713] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,727] Trial 61 finished with value: 0.8255322128851541 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,728] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,728] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,744] Trial 62 finished with value: 0.8070308123249299 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,744] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,747] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,762] Trial 63 finished with value: 0.8087394957983193 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,763] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,763] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,778] Trial 64 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,779] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,781] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,796] Trial 65 finished with value: 0.8271848739495798 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,798] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,798] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,824] Trial 66 finished with value: 0.8154201680672267 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,826] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,826] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,842] Trial 67 finished with value: 0.8254901960784313 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,842] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,842] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,859] Trial 68 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,859] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,859] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,876] Trial 69 finished with value: 0.8356162464985996 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,876] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,876] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,893] Trial 70 finished with value: 0.8138375350140056 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,893] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,895] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,910] Trial 71 finished with value: 0.8221988795518207 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,910] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,913] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,928] Trial 72 finished with value: 0.8439495798319326 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,929] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,930] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,946] Trial 73 finished with value: 0.7935854341736694 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,947] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,948] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,963] Trial 74 finished with value: 0.810392156862745 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,964] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,965] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,979] Trial 75 finished with value: 0.8188795518207282 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,979] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,982] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:40,996] Trial 76 finished with value: 0.8272128851540617 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:40,996] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:40,999] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,013] Trial 77 finished with value: 0.8255322128851541 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,014] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,015] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,030] Trial 78 finished with value: 0.795266106442577 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,030] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,033] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,048] Trial 79 finished with value: 0.8087254901960783 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,049] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,050] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,065] Trial 80 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,065] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,065] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,082] Trial 81 finished with value: 0.8036554621848738 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,082] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,082] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,100] Trial 82 finished with value: 0.8154761904761905 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,100] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,100] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,117] Trial 83 finished with value: 0.8322408963585433 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,117] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,117] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,144] Trial 84 finished with value: 0.8171008403361345 and parameters: {'criterion': 'entropy', 'max_features': None, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,144] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,148] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,162] Trial 85 finished with value: 0.7919187675070029 and parameters: {'criterion': 'gini', 'max_features': None, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,162] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,162] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,178] Trial 86 finished with value: 0.8205322128851542 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,178] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,178] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,196] Trial 87 finished with value: 0.8321848739495797 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 40 with value: 0.8473109243697479.\n",
      "[W 2025-12-28 19:24:41,196] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,198] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,213] Trial 88 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,215] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,216] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,230] Trial 89 finished with value: 0.8423109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,231] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,231] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,247] Trial 90 finished with value: 0.815420168067227 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,247] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,249] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,263] Trial 91 finished with value: 0.7868627450980392 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,263] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,263] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,281] Trial 92 finished with value: 0.818795518207283 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,281] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,283] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,297] Trial 93 finished with value: 0.8255462184873948 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,298] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,298] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,314] Trial 94 finished with value: 0.8238515406162465 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,314] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,317] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,331] Trial 95 finished with value: 0.8087254901960783 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,333] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,333] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,348] Trial 96 finished with value: 0.8053361344537814 and parameters: {'criterion': 'log_loss', 'max_features': None, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,348] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,351] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,366] Trial 97 finished with value: 0.830532212885154 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 88 with value: 0.8473389355742297.\n",
      "[W 2025-12-28 19:24:41,368] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,368] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,384] Trial 98 finished with value: 0.8221428571428572 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 88 with value: 0.8473389355742297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:24:41,404] A new study created in memory with name: Random Forest Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:24:41,385] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,386] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,402] Trial 99 finished with value: 0.8255182072829133 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 88 with value: 0.8473389355742297.\n",
      "\n",
      "Best Hyperparameters for Decision Tree Using QMCSampler: {'criterion': 'gini', 'max_features': 'log2', 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 8}\n",
      "Best accuracy: 0.8473, at trial: 88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382b1d73497d45b79c160dea50b23046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:41,493] Trial 0 finished with value: 0.8456582633053221 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 15, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[W 2025-12-28 19:24:41,495] The parameter `criterion` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,496] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,563] Trial 1 finished with value: 0.8288515406162464 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8456582633053221.\n",
      "[W 2025-12-28 19:24:41,566] The parameter `criterion` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,567] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,695] Trial 2 finished with value: 0.850658263305322 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.850658263305322.\n",
      "[W 2025-12-28 19:24:41,696] The parameter `criterion` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,698] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,857] Trial 3 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 78, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.850658263305322.\n",
      "[W 2025-12-28 19:24:41,859] The parameter `criterion` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,860] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:41,959] Trial 4 finished with value: 0.8439635854341738 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 32, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.850658263305322.\n",
      "[W 2025-12-28 19:24:41,961] The parameter `criterion` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:41,961] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:42,078] Trial 5 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.850700280112045.\n",
      "[W 2025-12-28 19:24:42,081] The parameter `criterion` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:42,082] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:42,261] Trial 6 finished with value: 0.8523809523809526 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:42,264] The parameter `criterion` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:42,264] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:42,423] Trial 7 finished with value: 0.842296918767507 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 66, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:42,426] The parameter `criterion` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:42,427] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:42,514] Trial 8 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 21, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:42,516] The parameter `criterion` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:42,517] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:42,603] Trial 9 finished with value: 0.8456302521008403 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 27, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:42,605] The parameter `criterion` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:42,605] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:42,764] Trial 10 finished with value: 0.8406442577030813 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:42,766] The parameter `criterion` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:42,767] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:42,957] Trial 11 finished with value: 0.8439635854341736 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 95, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:42,959] The parameter `criterion` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:42,960] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:43,088] Trial 12 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:43,090] The parameter `criterion` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:43,091] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:43,199] Trial 13 finished with value: 0.8473109243697479 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 38, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.8523809523809526.\n",
      "[W 2025-12-28 19:24:43,201] The parameter `criterion` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:43,202] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:43,392] Trial 14 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.8540336134453781.\n",
      "[W 2025-12-28 19:24:43,394] The parameter `criterion` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:43,395] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:43,533] Trial 15 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:24:43,537] The parameter `criterion` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:43,537] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:43,604] Trial 16 finished with value: 0.8489915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 15, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:24:43,604] The parameter `criterion` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:43,606] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:43,693] Trial 17 finished with value: 0.8507002801120448 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 18, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:24:43,693] The parameter `criterion` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:43,693] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:43,833] Trial 18 finished with value: 0.8489775910364145 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 64, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:24:43,835] The parameter `criterion` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:43,835] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,005] Trial 19 finished with value: 0.8523669467787116 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 15 with value: 0.8540476190476192.\n",
      "[W 2025-12-28 19:24:44,007] The parameter `criterion` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,008] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,127] Trial 20 finished with value: 0.8557142857142856 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 41, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-12-28 19:24:44,129] The parameter `criterion` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,129] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,259] Trial 21 finished with value: 0.850672268907563 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 52, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-12-28 19:24:44,259] The parameter `criterion` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,261] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,461] Trial 22 finished with value: 0.8540476190476192 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 98, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-12-28 19:24:44,461] The parameter `criterion` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,465] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,624] Trial 23 finished with value: 0.8473389355742297 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-12-28 19:24:44,624] The parameter `criterion` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,627] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,725] Trial 24 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 29, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-12-28 19:24:44,727] The parameter `criterion` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,727] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,815] Trial 25 finished with value: 0.8405882352941175 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 24, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-12-28 19:24:44,817] The parameter `criterion` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,817] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:44,976] Trial 26 finished with value: 0.8490336134453781 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 20 with value: 0.8557142857142856.\n",
      "[W 2025-12-28 19:24:44,977] The parameter `criterion` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:44,977] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,170] Trial 27 finished with value: 0.8590896358543418 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 92, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,170] The parameter `criterion` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,173] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,291] Trial 28 finished with value: 0.8540476190476192 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 46, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,292] The parameter `criterion` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,294] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,391] Trial 29 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 35, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,391] The parameter `criterion` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,395] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,563] Trial 30 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,566] The parameter `criterion` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,567] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,693] Trial 31 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,695] The parameter `criterion` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,695] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,763] Trial 32 finished with value: 0.8473109243697479 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 12, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,765] The parameter `criterion` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,766] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,832] Trial 33 finished with value: 0.845672268907563 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 14, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,835] The parameter `criterion` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,835] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:45,973] Trial 34 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:45,975] The parameter `criterion` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:45,976] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:46,156] Trial 35 finished with value: 0.8473249299719887 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 82, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:46,158] The parameter `criterion` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:46,159] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:46,267] Trial 36 finished with value: 0.8540336134453781 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:46,269] The parameter `criterion` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:46,270] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:46,388] Trial 37 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 48, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:46,391] The parameter `criterion` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:46,392] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:46,581] Trial 38 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:46,584] The parameter `criterion` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:46,585] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:46,743] Trial 39 finished with value: 0.8523389355742296 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:46,745] The parameter `criterion` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:46,746] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:46,833] Trial 40 finished with value: 0.8406302521008403 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 25, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:46,835] The parameter `criterion` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:46,836] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:46,934] Trial 41 finished with value: 0.8473109243697478 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 31, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:46,936] The parameter `criterion` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:46,938] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:47,096] Trial 42 finished with value: 0.8406162464985993 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:47,098] The parameter `criterion` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:47,099] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:47,288] Trial 43 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:47,290] The parameter `criterion` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:47,291] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:47,419] Trial 44 finished with value: 0.845672268907563 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 54, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:47,422] The parameter `criterion` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:47,423] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:47,540] Trial 45 finished with value: 0.8288795518207281 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 42, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:47,542] The parameter `criterion` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:47,543] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:47,712] Trial 46 finished with value: 0.850700280112045 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:47,715] The parameter `criterion` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:47,715] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:47,853] Trial 47 finished with value: 0.850686274509804 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:47,855] The parameter `criterion` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:47,856] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:47,934] Trial 48 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 19, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:47,935] The parameter `criterion` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:47,936] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,003] Trial 49 finished with value: 0.8355742296918767 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 17, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,005] The parameter `criterion` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,005] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,144] Trial 50 finished with value: 0.8574089635854343 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 62, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,147] The parameter `criterion` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,148] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,316] Trial 51 finished with value: 0.8540616246498601 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 85, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,318] The parameter `criterion` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,319] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,426] Trial 52 finished with value: 0.8439915966386554 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 39, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,428] The parameter `criterion` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,429] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,559] Trial 53 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 51, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,561] The parameter `criterion` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,562] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,740] Trial 54 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,742] The parameter `criterion` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,743] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,891] Trial 55 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 73, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,894] The parameter `criterion` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,895] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:48,992] Trial 56 finished with value: 0.830546218487395 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:48,994] The parameter `criterion` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:48,995] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,071] Trial 57 finished with value: 0.8372268907563024 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 22, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:49,072] The parameter `criterion` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,073] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,222] Trial 58 finished with value: 0.8490196078431375 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 27 with value: 0.8590896358543418.\n",
      "[W 2025-12-28 19:24:49,224] The parameter `criterion` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,225] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,395] Trial 59 finished with value: 0.8607703081232494 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:49,396] The parameter `criterion` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,398] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,515] Trial 60 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 45, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:49,517] The parameter `criterion` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,517] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,616] Trial 61 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:49,618] The parameter `criterion` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,618] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,778] Trial 62 finished with value: 0.8456442577030812 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 79, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:49,780] The parameter `criterion` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,780] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,909] Trial 63 finished with value: 0.8456442577030814 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:49,909] The parameter `criterion` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,912] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:49,978] Trial 64 finished with value: 0.8389635854341737 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 11, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:49,979] The parameter `criterion` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:49,980] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:50,047] Trial 65 finished with value: 0.8490336134453781 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 12, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:50,049] The parameter `criterion` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:50,049] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:50,188] Trial 66 finished with value: 0.8439915966386554 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:50,189] The parameter `criterion` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:50,191] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:50,360] Trial 67 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 80, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:50,360] The parameter `criterion` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:50,360] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:50,460] Trial 68 finished with value: 0.8489915966386554 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 34, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:50,462] The parameter `criterion` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:50,463] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:50,580] Trial 69 finished with value: 0.850686274509804 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 46, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:50,582] The parameter `criterion` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:50,583] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:50,761] Trial 70 finished with value: 0.8573949579831932 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:50,763] The parameter `criterion` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:50,764] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:50,912] Trial 71 finished with value: 0.8473529411764705 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:50,914] The parameter `criterion` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:50,915] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,002] Trial 72 finished with value: 0.8356022408963586 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 23, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,003] The parameter `criterion` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,005] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,091] Trial 73 finished with value: 0.8540336134453781 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 29, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,093] The parameter `criterion` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,093] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,253] Trial 74 finished with value: 0.8389635854341735 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 74, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,255] The parameter `criterion` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,256] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,447] Trial 75 finished with value: 0.8490056022408965 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 97, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,447] The parameter `criterion` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,447] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,570] Trial 76 finished with value: 0.8422969187675069 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,572] The parameter `criterion` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,573] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,679] Trial 77 finished with value: 0.8423249299719888 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 40, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,681] The parameter `criterion` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,682] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,841] Trial 78 finished with value: 0.8540336134453781 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,843] The parameter `criterion` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,843] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:51,981] Trial 79 finished with value: 0.8506862745098038 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 63, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:51,983] The parameter `criterion` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:51,984] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:52,051] Trial 80 finished with value: 0.8439915966386554 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 17, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:52,052] The parameter `criterion` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:52,053] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:52,130] Trial 81 finished with value: 0.8523249299719888 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 20, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:52,132] The parameter `criterion` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:52,133] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:52,270] Trial 82 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:52,273] The parameter `criterion` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:52,274] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:52,443] Trial 83 finished with value: 0.8557142857142856 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 88, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:52,445] The parameter `criterion` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:52,446] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:52,554] Trial 84 finished with value: 0.850686274509804 and parameters: {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 43, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:52,555] The parameter `criterion` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:52,556] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:52,673] Trial 85 finished with value: 0.8490056022408965 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:52,675] The parameter `criterion` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:52,675] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:52,855] Trial 86 finished with value: 0.850672268907563 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:52,857] The parameter `criterion` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:52,858] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,008] Trial 87 finished with value: 0.8389495798319327 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 77, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,010] The parameter `criterion` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,010] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,097] Trial 88 finished with value: 0.8473249299719889 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 32, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,098] The parameter `criterion` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,099] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,185] Trial 89 finished with value: 0.8372689075630252 and parameters: {'criterion': 'log_loss', 'max_features': None, 'n_estimators': 26, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,187] The parameter `criterion` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,187] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,347] Trial 90 finished with value: 0.845658263305322 and parameters: {'criterion': 'gini', 'max_features': None, 'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,349] The parameter `criterion` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,349] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,509] Trial 91 finished with value: 0.8473249299719889 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 94, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,509] The parameter `criterion` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,509] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,620] Trial 92 finished with value: 0.8523669467787116 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 49, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,622] The parameter `criterion` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,623] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,730] Trial 93 finished with value: 0.8490196078431375 and parameters: {'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 37, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,732] The parameter `criterion` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,734] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:53,881] Trial 94 finished with value: 0.8590756302521008 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:53,881] The parameter `criterion` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:53,881] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,011] Trial 95 finished with value: 0.8523669467787116 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:54,013] The parameter `criterion` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:54,014] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,080] Trial 96 finished with value: 0.845672268907563 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 14, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:54,082] The parameter `criterion` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:54,083] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,150] Trial 97 finished with value: 0.8389635854341735 and parameters: {'criterion': 'entropy', 'max_features': None, 'n_estimators': 13, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 59 with value: 0.8607703081232494.\n",
      "[W 2025-12-28 19:24:54,150] The parameter `criterion` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:54,152] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,270] Trial 98 finished with value: 0.8490196078431371 and parameters: {'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 59 with value: 0.8607703081232494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:24:54,425] A new study created in memory with name: K-Nearest Neighbors Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:24:54,270] The parameter `criterion` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:54,270] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,422] Trial 99 finished with value: 0.8540476190476192 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.8607703081232494.\n",
      "\n",
      "Best Hyperparameters for Random Forest Using QMCSampler: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 91, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}\n",
      "Best accuracy: 0.8608, at trial: 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7197cffe3dd454f8d7812c6309b0011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:54,477] Trial 0 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-12-28 19:24:54,478] The parameter `algorithm` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,503] Trial 1 finished with value: 0.8355042016806724 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-12-28 19:24:54,504] The parameter `algorithm` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,551] Trial 2 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 0 with value: 0.8473249299719887.\n",
      "[W 2025-12-28 19:24:54,553] The parameter `algorithm` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,598] Trial 3 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 1}. Best is trial 3 with value: 0.8473389355742296.\n",
      "[W 2025-12-28 19:24:54,599] The parameter `algorithm` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,624] Trial 4 finished with value: 0.8389215686274509 and parameters: {'algorithm': 'brute', 'n_neighbors': 15, 'p': 2}. Best is trial 3 with value: 0.8473389355742296.\n",
      "[W 2025-12-28 19:24:54,626] The parameter `algorithm` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,670] Trial 5 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 1}. Best is trial 5 with value: 0.8490056022408963.\n",
      "[W 2025-12-28 19:24:54,670] The parameter `algorithm` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,717] Trial 6 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 45, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,718] The parameter `algorithm` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,744] Trial 7 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,745] The parameter `algorithm` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,769] Trial 8 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'brute', 'n_neighbors': 9, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,769] The parameter `algorithm` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,816] Trial 9 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 11, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,818] The parameter `algorithm` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,842] Trial 10 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,843] The parameter `algorithm` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,889] Trial 11 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,889] The parameter `algorithm` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,937] Trial 12 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 23, 'p': 2}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,938] The parameter `algorithm` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:54,963] Trial 13 finished with value: 0.8456302521008403 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 1}. Best is trial 6 with value: 0.8490196078431371.\n",
      "[W 2025-12-28 19:24:54,963] The parameter `algorithm` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,010] Trial 14 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,010] The parameter `algorithm` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,058] Trial 15 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 29, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,058] The parameter `algorithm` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,105] Trial 16 finished with value: 0.8304901960784313 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,105] The parameter `algorithm` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,130] Trial 17 finished with value: 0.8372549019607842 and parameters: {'algorithm': 'brute', 'n_neighbors': 7, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,130] The parameter `algorithm` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,177] Trial 18 finished with value: 0.8489915966386553 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 31, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,180] The parameter `algorithm` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,224] Trial 19 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 43, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,225] The parameter `algorithm` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,272] Trial 20 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 19, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,272] The parameter `algorithm` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,299] Trial 21 finished with value: 0.8456442577030812 and parameters: {'algorithm': 'brute', 'n_neighbors': 25, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,302] The parameter `algorithm` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,337] Trial 22 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,339] The parameter `algorithm` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,363] Trial 23 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,363] The parameter `algorithm` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,390] Trial 24 finished with value: 0.8506862745098038 and parameters: {'algorithm': 'brute', 'n_neighbors': 13, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,391] The parameter `algorithm` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,437] Trial 25 finished with value: 0.8338795518207283 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,439] The parameter `algorithm` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,485] Trial 26 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 34, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,485] The parameter `algorithm` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,511] Trial 27 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,513] The parameter `algorithm` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,538] Trial 28 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,540] The parameter `algorithm` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,565] Trial 29 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'brute', 'n_neighbors': 16, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,566] The parameter `algorithm` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,591] Trial 30 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,592] The parameter `algorithm` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,637] Trial 31 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 28, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,639] The parameter `algorithm` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,684] Trial 32 finished with value: 0.8288515406162464 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 4, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,686] The parameter `algorithm` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,722] Trial 33 finished with value: 0.835532212885154 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,723] The parameter `algorithm` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,768] Trial 34 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 29, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,769] The parameter `algorithm` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,815] Trial 35 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,817] The parameter `algorithm` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,841] Trial 36 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'brute', 'n_neighbors': 17, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,842] The parameter `algorithm` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,868] Trial 37 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,870] The parameter `algorithm` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,895] Trial 38 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'brute', 'n_neighbors': 47, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,897] The parameter `algorithm` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,921] Trial 39 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'brute', 'n_neighbors': 35, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,923] The parameter `algorithm` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,969] Trial 40 finished with value: 0.8473249299719889 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 11, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,970] The parameter `algorithm` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:55,995] Trial 41 finished with value: 0.8422549019607842 and parameters: {'algorithm': 'brute', 'n_neighbors': 14, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:55,995] The parameter `algorithm` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,041] Trial 42 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,043] The parameter `algorithm` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,068] Trial 43 finished with value: 0.845658263305322 and parameters: {'algorithm': 'brute', 'n_neighbors': 50, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,069] The parameter `algorithm` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,115] Trial 44 finished with value: 0.850658263305322 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,116] The parameter `algorithm` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,141] Trial 45 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,142] The parameter `algorithm` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,177] Trial 46 finished with value: 0.850686274509804 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 44, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,179] The parameter `algorithm` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,224] Trial 47 finished with value: 0.842282913165266 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,225] The parameter `algorithm` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,272] Trial 48 finished with value: 0.8405742296918767 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 8, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,274] The parameter `algorithm` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,320] Trial 49 finished with value: 0.8221288515406162 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 6, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,321] The parameter `algorithm` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,346] Trial 50 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 30, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,347] The parameter `algorithm` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,372] Trial 51 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'brute', 'n_neighbors': 42, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,373] The parameter `algorithm` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,409] Trial 52 finished with value: 0.8405742296918767 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 18, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,410] The parameter `algorithm` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,446] Trial 53 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 24, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,448] The parameter `algorithm` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,495] Trial 54 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 48, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,496] The parameter `algorithm` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,521] Trial 55 finished with value: 0.8490056022408963 and parameters: {'algorithm': 'brute', 'n_neighbors': 36, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,522] The parameter `algorithm` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,558] Trial 56 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 12, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,560] The parameter `algorithm` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,606] Trial 57 finished with value: 0.8422549019607842 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 9, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,607] The parameter `algorithm` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,632] Trial 58 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 33, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,633] The parameter `algorithm` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,679] Trial 59 finished with value: 0.8507002801120447 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 45, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,681] The parameter `algorithm` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,716] Trial 60 finished with value: 0.8406162464985995 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 21, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,717] The parameter `algorithm` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,763] Trial 61 finished with value: 0.8439495798319328 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 15, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,764] The parameter `algorithm` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,810] Trial 62 finished with value: 0.8523669467787114 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 39, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,812] The parameter `algorithm` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,858] Trial 63 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 27, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,859] The parameter `algorithm` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,884] Trial 64 finished with value: 0.8271008403361346 and parameters: {'algorithm': 'brute', 'n_neighbors': 3, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,885] The parameter `algorithm` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,931] Trial 65 finished with value: 0.8338655462184874 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 4, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,932] The parameter `algorithm` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:56,978] Trial 66 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:56,979] The parameter `algorithm` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,025] Trial 67 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 40, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,026] The parameter `algorithm` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,072] Trial 68 finished with value: 0.8456162464985993 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 16, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,074] The parameter `algorithm` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,100] Trial 69 finished with value: 0.8489915966386554 and parameters: {'algorithm': 'brute', 'n_neighbors': 22, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,101] The parameter `algorithm` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,127] Trial 70 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'brute', 'n_neighbors': 46, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,128] The parameter `algorithm` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,153] Trial 71 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 34, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,154] The parameter `algorithm` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,201] Trial 72 finished with value: 0.8372549019607842 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 10, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,203] The parameter `algorithm` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,248] Trial 73 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 13, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,249] The parameter `algorithm` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,275] Trial 74 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 37, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,277] The parameter `algorithm` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,313] Trial 75 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 49, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,315] The parameter `algorithm` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,360] Trial 76 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 25, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,362] The parameter `algorithm` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,387] Trial 77 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'brute', 'n_neighbors': 19, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,388] The parameter `algorithm` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,414] Trial 78 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'brute', 'n_neighbors': 43, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,416] The parameter `algorithm` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,441] Trial 79 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'brute', 'n_neighbors': 31, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,442] The parameter `algorithm` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,488] Trial 80 finished with value: 0.8254901960784313 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,489] The parameter `algorithm` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,514] Trial 81 finished with value: 0.8372268907563025 and parameters: {'algorithm': 'brute', 'n_neighbors': 8, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,516] The parameter `algorithm` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,562] Trial 82 finished with value: 0.850672268907563 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 32, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,563] The parameter `algorithm` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,599] Trial 83 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 44, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,600] The parameter `algorithm` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,625] Trial 84 finished with value: 0.842282913165266 and parameters: {'algorithm': 'brute', 'n_neighbors': 20, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,627] The parameter `algorithm` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,672] Trial 85 finished with value: 0.8456302521008402 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 26, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,674] The parameter `algorithm` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,710] Trial 86 finished with value: 0.8473389355742296 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 50, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,711] The parameter `algorithm` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,757] Trial 87 finished with value: 0.8523529411764705 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 38, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,759] The parameter `algorithm` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,804] Trial 88 finished with value: 0.8422689075630252 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 14, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,805] The parameter `algorithm` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,830] Trial 89 finished with value: 0.8405882352941175 and parameters: {'algorithm': 'brute', 'n_neighbors': 11, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,832] The parameter `algorithm` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,878] Trial 90 finished with value: 0.8473249299719887 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 35, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,880] The parameter `algorithm` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,926] Trial 91 finished with value: 0.8490196078431371 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 47, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,927] The parameter `algorithm` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:57,953] Trial 92 finished with value: 0.8439355742296918 and parameters: {'algorithm': 'brute', 'n_neighbors': 23, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:57,955] The parameter `algorithm` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,000] Trial 93 finished with value: 0.8456302521008403 and parameters: {'algorithm': 'kd_tree', 'n_neighbors': 17, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:58,003] The parameter `algorithm` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,049] Trial 94 finished with value: 0.8523669467787116 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 41, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:58,050] The parameter `algorithm` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,076] Trial 95 finished with value: 0.8439495798319326 and parameters: {'algorithm': 'brute', 'n_neighbors': 29, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:24:58,205] A new study created in memory with name: Support Vector Machine Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:24:58,077] The parameter `algorithm` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,102] Trial 96 finished with value: 0.8304901960784313 and parameters: {'algorithm': 'brute', 'n_neighbors': 5, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:58,104] The parameter `algorithm` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,129] Trial 97 finished with value: 0.8338655462184874 and parameters: {'algorithm': 'brute', 'n_neighbors': 4, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:58,130] The parameter `algorithm` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,177] Trial 98 finished with value: 0.8473109243697479 and parameters: {'algorithm': 'ball_tree', 'n_neighbors': 28, 'p': 2}. Best is trial 14 with value: 0.8523669467787116.\n",
      "[W 2025-12-28 19:24:58,178] The parameter `algorithm` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,203] Trial 99 finished with value: 0.8490056022408965 and parameters: {'algorithm': 'brute', 'n_neighbors': 40, 'p': 1}. Best is trial 14 with value: 0.8523669467787116.\n",
      "\n",
      "Best Hyperparameters for K-Nearest Neighbors Using QMCSampler: {'algorithm': 'kd_tree', 'n_neighbors': 41, 'p': 2}\n",
      "Best accuracy: 0.8524, at trial: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f8cba07e6d4bf4a2eca44171be3893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:24:58,237] Trial 0 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015751320499779737}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:58,239] The parameter `kernel` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,276] Trial 1 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00010000000000000009}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:58,278] The parameter `kernel` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,315] Trial 2 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0010000000000000002}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:58,317] The parameter `kernel` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,342] Trial 3 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.003162277660168382}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:58,344] The parameter `kernel` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,380] Trial 4 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003162277660168384}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:58,381] The parameter `kernel` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,407] Trial 5 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0005623413251903495}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:58,408] The parameter `kernel` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,433] Trial 6 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005623413251903492}. Best is trial 0 with value: 0.5352380952380952.\n",
      "[W 2025-12-28 19:24:58,435] The parameter `kernel` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,436] The parameter `degree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,460] Trial 7 finished with value: 0.7667787114845938 and parameters: {'kernel': 'poly', 'C': 0.0017782794100389236, 'degree': 5}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-12-28 19:24:58,461] The parameter `kernel` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,463] The parameter `degree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,488] Trial 8 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00017782794100389232, 'degree': 2}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-12-28 19:24:58,489] The parameter `kernel` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,515] Trial 9 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00023713737056616573}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-12-28 19:24:58,516] The parameter `kernel` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,541] Trial 10 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002371373705661656}. Best is trial 7 with value: 0.7667787114845938.\n",
      "[W 2025-12-28 19:24:58,543] The parameter `kernel` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,543] The parameter `degree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,568] Trial 11 finished with value: 0.8372268907563024 and parameters: {'kernel': 'poly', 'C': 0.007498942093324564, 'degree': 3}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,569] The parameter `kernel` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,594] Trial 12 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0007498942093324562}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,595] The parameter `kernel` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,621] Trial 13 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00042169650342858235}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,622] The parameter `kernel` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,624] The parameter `degree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,648] Trial 14 finished with value: 0.8321988795518207 and parameters: {'kernel': 'poly', 'C': 0.004216965034285825, 'degree': 2}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,650] The parameter `kernel` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,676] Trial 15 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0013335214321633251}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,676] The parameter `kernel` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,679] The parameter `degree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,703] Trial 16 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0001333521432163326, 'degree': 2}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,704] The parameter `kernel` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,706] The parameter `degree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,730] Trial 17 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00015399265260594933, 'degree': 3}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,732] The parameter `kernel` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,757] Trial 18 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0015399265260594922}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,759] The parameter `kernel` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,785] Trial 19 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.004869675251658635}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,786] The parameter `kernel` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,788] The parameter `degree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,813] Trial 20 finished with value: 0.5905882352941176 and parameters: {'kernel': 'poly', 'C': 0.00048696752516586337, 'degree': 5}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,814] The parameter `kernel` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,816] The parameter `degree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,840] Trial 21 finished with value: 0.6023389355742297 and parameters: {'kernel': 'poly', 'C': 0.000865964323360066, 'degree': 4}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,842] The parameter `kernel` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,866] Trial 22 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.008659643233600654}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,868] The parameter `kernel` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:58,869] The parameter `degree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,893] Trial 23 finished with value: 0.8003501400560223 and parameters: {'kernel': 'poly', 'C': 0.0027384196342643626, 'degree': 4}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,894] The parameter `kernel` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,920] Trial 24 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002738419634264362}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,921] The parameter `kernel` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,947] Trial 25 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0002053525026457149}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,948] The parameter `kernel` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:58,984] Trial 26 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0020535250264571477}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:58,986] The parameter `kernel` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,011] Trial 27 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0064938163157621165}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,012] The parameter `kernel` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,038] Trial 28 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006493816315762115}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,040] The parameter `kernel` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,076] Trial 29 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.000365174127254838}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,077] The parameter `kernel` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,103] Trial 30 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0036517412725483775}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,105] The parameter `kernel` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,129] Trial 31 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0011547819846894588}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,131] The parameter `kernel` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,156] Trial 32 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00011547819846894585}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,157] The parameter `kernel` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,182] Trial 33 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00012409377607517218}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,183] The parameter `kernel` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,209] Trial 34 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0012409377607517208}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,211] The parameter `kernel` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,247] Trial 35 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.003924189758484535}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,248] The parameter `kernel` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,285] Trial 36 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003924189758484538}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,286] The parameter `kernel` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,311] Trial 37 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0006978305848598669}. Best is trial 11 with value: 0.8372268907563024.\n",
      "[W 2025-12-28 19:24:59,312] The parameter `kernel` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,313] The parameter `degree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,339] Trial 38 finished with value: 0.8372268907563025 and parameters: {'kernel': 'poly', 'C': 0.006978305848598664, 'degree': 5}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,340] The parameter `kernel` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,366] Trial 39 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.002206734069084591}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,367] The parameter `kernel` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,369] The parameter `degree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,393] Trial 40 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00022067340690845924, 'degree': 5}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,394] The parameter `kernel` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,395] The parameter `degree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,420] Trial 41 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0002942727176209287, 'degree': 3}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,422] The parameter `kernel` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,459] Trial 42 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.002942727176209285}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,461] The parameter `kernel` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,495] Trial 43 finished with value: 0.5973109243697479 and parameters: {'kernel': 'rbf', 'C': 0.009305720409296997}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,496] The parameter `kernel` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,521] Trial 44 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009305720409296995}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,522] The parameter `kernel` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,523] The parameter `degree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,549] Trial 45 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005232991146814953, 'degree': 2}. Best is trial 38 with value: 0.8372268907563025.\n",
      "[W 2025-12-28 19:24:59,549] The parameter `kernel` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,551] The parameter `degree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,577] Trial 46 finished with value: 0.8388935574229691 and parameters: {'kernel': 'poly', 'C': 0.005232991146814949, 'degree': 2}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-12-28 19:24:59,579] The parameter `kernel` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,603] Trial 47 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0016548170999431827}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-12-28 19:24:59,604] The parameter `kernel` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,630] Trial 48 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00016548170999431823}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-12-28 19:24:59,630] The parameter `kernel` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,667] Trial 49 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00014330125702369644}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-12-28 19:24:59,668] The parameter `kernel` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,705] Trial 50 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0014330125702369636}. Best is trial 46 with value: 0.8388935574229691.\n",
      "[W 2025-12-28 19:24:59,706] The parameter `kernel` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,706] The parameter `degree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,732] Trial 51 finished with value: 0.8389215686274509 and parameters: {'kernel': 'poly', 'C': 0.0045315836376008225, 'degree': 2}. Best is trial 51 with value: 0.8389215686274509.\n",
      "[W 2025-12-28 19:24:59,732] The parameter `kernel` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,732] The parameter `degree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,760] Trial 52 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00045315836376008217, 'degree': 2}. Best is trial 51 with value: 0.8389215686274509.\n",
      "[W 2025-12-28 19:24:59,762] The parameter `kernel` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,762] The parameter `degree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,788] Trial 53 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0008058421877614828, 'degree': 2}. Best is trial 51 with value: 0.8389215686274509.\n",
      "[W 2025-12-28 19:24:59,788] The parameter `kernel` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,788] The parameter `degree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,815] Trial 54 finished with value: 0.8422549019607842 and parameters: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:24:59,818] The parameter `kernel` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,819] The parameter `degree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,844] Trial 55 finished with value: 0.7936694677871149 and parameters: {'kernel': 'poly', 'C': 0.0025482967479793484, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:24:59,845] The parameter `kernel` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,881] Trial 56 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002548296747979348}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:24:59,882] The parameter `kernel` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,907] Trial 57 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00019109529749704405}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:24:59,907] The parameter `kernel` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,907] The parameter `degree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,935] Trial 58 finished with value: 0.7701400560224089 and parameters: {'kernel': 'poly', 'C': 0.0019109529749704425, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:24:59,937] The parameter `kernel` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,962] Trial 59 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.006042963902381333}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:24:59,962] The parameter `kernel` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,962] The parameter `degree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:24:59,991] Trial 60 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0006042963902381332, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:24:59,993] The parameter `kernel` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:24:59,994] The parameter `degree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,019] Trial 61 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00033982083289425634, 'degree': 2}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,020] The parameter `kernel` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,022] The parameter `degree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,047] Trial 62 finished with value: 0.8070588235294117 and parameters: {'kernel': 'poly', 'C': 0.003398208328942561, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,047] The parameter `kernel` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,074] Trial 63 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0010746078283213184}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,074] The parameter `kernel` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,101] Trial 64 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00010746078283213182}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,103] The parameter `kernel` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,128] Trial 65 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0001113973859994803}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,128] The parameter `kernel` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,155] Trial 66 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001113973859994803}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,156] The parameter `kernel` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,182] Trial 67 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0035226946514731027}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,182] The parameter `kernel` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,209] Trial 68 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0003522694651473105}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,209] The parameter `kernel` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,236] Trial 69 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0006264335366568858}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,238] The parameter `kernel` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,263] Trial 70 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00626433536656886}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,265] The parameter `kernel` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,290] Trial 71 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.001980956778550341}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,291] The parameter `kernel` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,316] Trial 72 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0001980956778550342}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,317] The parameter `kernel` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,320] The parameter `degree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,344] Trial 73 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00026416483203860934, 'degree': 3}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,345] The parameter `kernel` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,370] Trial 74 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0026416483203860943}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,371] The parameter `kernel` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,373] The parameter `degree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,397] Trial 75 finished with value: 0.8338655462184873 and parameters: {'kernel': 'poly', 'C': 0.008353625469578265, 'degree': 3}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,398] The parameter `kernel` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,399] The parameter `degree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,424] Trial 76 finished with value: 0.5905882352941176 and parameters: {'kernel': 'poly', 'C': 0.000835362546957827, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,425] The parameter `kernel` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,427] The parameter `degree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,452] Trial 77 finished with value: 0.5771988795518208 and parameters: {'kernel': 'poly', 'C': 0.0004697588816706495, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,453] The parameter `kernel` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,455] The parameter `degree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,480] Trial 78 finished with value: 0.8204761904761904 and parameters: {'kernel': 'poly', 'C': 0.004697588816706496, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,482] The parameter `kernel` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,507] Trial 79 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0014855080171727755}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,507] The parameter `kernel` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,508] The parameter `degree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,535] Trial 80 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00014855080171727767, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,535] The parameter `kernel` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,561] Trial 81 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00017154378963428796}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,563] The parameter `kernel` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,599] Trial 82 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0017154378963428801}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,601] The parameter `kernel` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,626] Trial 83 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.005424690937011328}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,627] The parameter `kernel` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,628] The parameter `degree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,652] Trial 84 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0005424690937011332, 'degree': 2}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,653] The parameter `kernel` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,679] Trial 85 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.0009646616199111995}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,680] The parameter `kernel` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,717] Trial 86 finished with value: 0.6157983193277311 and parameters: {'kernel': 'rbf', 'C': 0.009646616199111998}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,719] The parameter `kernel` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,744] Trial 87 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0030505278902670284}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,744] The parameter `kernel` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,770] Trial 88 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00030505278902670253}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,770] The parameter `kernel` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,809] Trial 89 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0002287573200318398}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,809] The parameter `kernel` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,811] The parameter `degree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,836] Trial 90 finished with value: 0.7819187675070027 and parameters: {'kernel': 'poly', 'C': 0.0022875732003183966, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,838] The parameter `kernel` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,873] Trial 91 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.007233941627366754}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,874] The parameter `kernel` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,900] Trial 92 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0007233941627366753}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,901] The parameter `kernel` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,902] The parameter `degree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,928] Trial 93 finished with value: 0.5453221288515406 and parameters: {'kernel': 'poly', 'C': 0.0004067944321083049, 'degree': 5}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,928] The parameter `kernel` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,955] Trial 94 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.0040679443210830495}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,957] The parameter `kernel` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,957] The parameter `degree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:00,982] Trial 95 finished with value: 0.7231512605042016 and parameters: {'kernel': 'poly', 'C': 0.0012863969449369757, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:00,982] The parameter `kernel` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:00,982] The parameter `degree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:01,009] Trial 96 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.00012863969449369766, 'degree': 4}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:01,009] The parameter `kernel` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:01,036] Trial 97 finished with value: 0.5352380952380952 and parameters: {'kernel': 'sigmoid', 'C': 0.00011970850304957301}. Best is trial 54 with value: 0.8422549019607842.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:25:01,102] A new study created in memory with name: AdaBoost Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-28 19:25:01,038] The parameter `kernel` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:25:01,039] The parameter `degree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:01,064] Trial 98 finished with value: 0.5352380952380952 and parameters: {'kernel': 'poly', 'C': 0.0011970850304957315, 'degree': 2}. Best is trial 54 with value: 0.8422549019607842.\n",
      "[W 2025-12-28 19:25:01,064] The parameter `kernel` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:01,100] Trial 99 finished with value: 0.5352380952380952 and parameters: {'kernel': 'rbf', 'C': 0.00378551524925863}. Best is trial 54 with value: 0.8422549019607842.\n",
      "\n",
      "Best Hyperparameters for Support Vector Machine Using QMCSampler: {'kernel': 'poly', 'C': 0.008058421877614822, 'degree': 5}\n",
      "Best accuracy: 0.8423, at trial: 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fa64f813f443e3ac0a426b46cb1f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:25:01,187] Trial 0 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 44, 'learning_rate': 0.711447600934342}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:25:01,224] Trial 1 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 10, 'learning_rate': 0.0010000000000000002}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:25:01,323] Trial 2 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 55, 'learning_rate': 0.0316227766016838}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:25:01,441] Trial 3 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 78, 'learning_rate': 0.005623413251903492}. Best is trial 0 with value: 0.8489915966386553.\n",
      "[I 2025-12-28 19:25:01,498] Trial 4 finished with value: 0.850686274509804 and parameters: {'n_estimators': 32, 'learning_rate': 0.1778279410038923}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:01,576] Trial 5 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 44, 'learning_rate': 0.013335214321633242}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:01,717] Trial 6 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 89, 'learning_rate': 0.4216965034285823}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:01,824] Trial 7 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 66, 'learning_rate': 0.002371373705661656}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:01,872] Trial 8 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 21, 'learning_rate': 0.07498942093324559}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:01,928] Trial 9 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 27, 'learning_rate': 0.008659643233600654}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,060] Trial 10 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 72, 'learning_rate': 0.27384196342643613}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,210] Trial 11 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 95, 'learning_rate': 0.0015399265260594922}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,299] Trial 12 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 49, 'learning_rate': 0.04869675251658632}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,366] Trial 13 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 38, 'learning_rate': 0.0036517412725483775}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,496] Trial 14 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 83, 'learning_rate': 0.11547819846894583}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,594] Trial 15 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 61, 'learning_rate': 0.020535250264571463}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,632] Trial 16 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 15, 'learning_rate': 0.6493816315762113}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,678] Trial 17 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 18, 'learning_rate': 0.025482967479793468}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,778] Trial 18 finished with value: 0.83890756302521 and parameters: {'n_estimators': 64, 'learning_rate': 0.8058421877614819}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,908] Trial 19 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 86, 'learning_rate': 0.004531583637600819}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:02,986] Trial 20 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 41, 'learning_rate': 0.14330125702369628}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,075] Trial 21 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 52, 'learning_rate': 0.001910952974970441}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,225] Trial 22 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 98, 'learning_rate': 0.060429639023813285}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,344] Trial 23 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 75, 'learning_rate': 0.010746078283213176}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,401] Trial 24 finished with value: 0.842282913165266 and parameters: {'n_estimators': 29, 'learning_rate': 0.33982083289425596}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,450] Trial 25 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 24, 'learning_rate': 0.0029427271762092824}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,557] Trial 26 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 69, 'learning_rate': 0.0930572040929699}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,700] Trial 27 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 92, 'learning_rate': 0.016548170999431816}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,776] Trial 28 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 46, 'learning_rate': 0.5232991146814947}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,845] Trial 29 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 35, 'learning_rate': 0.006978305848598664}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:03,974] Trial 30 finished with value: 0.850686274509804 and parameters: {'n_estimators': 81, 'learning_rate': 0.220673406908459}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,074] Trial 31 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 58, 'learning_rate': 0.0012409377607517198}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,109] Trial 32 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 12, 'learning_rate': 0.039241897584845364}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,146] Trial 33 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 14, 'learning_rate': 0.006264335366568854}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,243] Trial 34 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 59, 'learning_rate': 0.1980956778550338}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,374] Trial 35 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 82, 'learning_rate': 0.0011139738599948022}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,441] Trial 36 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 37, 'learning_rate': 0.03522694651473102}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,521] Trial 37 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 48, 'learning_rate': 0.0026416483203860917}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,662] Trial 38 finished with value: 0.8473249299719887 and parameters: {'n_estimators': 93, 'learning_rate': 0.08353625469578259}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,784] Trial 39 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 71, 'learning_rate': 0.014855080171727746}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,830] Trial 40 finished with value: 0.8439635854341738 and parameters: {'n_estimators': 25, 'learning_rate': 0.469758881670649}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:04,900] Trial 41 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 31, 'learning_rate': 0.0017154378963428786}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,030] Trial 42 finished with value: 0.8489915966386554 and parameters: {'n_estimators': 76, 'learning_rate': 0.05424690937011326}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,183] Trial 43 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 99, 'learning_rate': 0.00964661619911199}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,272] Trial 44 finished with value: 0.8490056022408965 and parameters: {'n_estimators': 54, 'learning_rate': 0.3050527890267024}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,351] Trial 45 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 42, 'learning_rate': 0.02287573200318396}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,480] Trial 46 finished with value: 0.850658263305322 and parameters: {'n_estimators': 88, 'learning_rate': 0.7233941627366745}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,589] Trial 47 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 65, 'learning_rate': 0.004067944321083046}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,637] Trial 48 finished with value: 0.835546218487395 and parameters: {'n_estimators': 19, 'learning_rate': 0.12863969449369742}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,674] Trial 49 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 17, 'learning_rate': 0.005048065716667474}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,774] Trial 50 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 62, 'learning_rate': 0.1596338544287943}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,906] Trial 51 finished with value: 0.8389075630252101 and parameters: {'n_estimators': 85, 'learning_rate': 0.02838735964758755}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:05,972] Trial 52 finished with value: 0.8422689075630251 and parameters: {'n_estimators': 39, 'learning_rate': 0.8976871324473146}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:06,061] Trial 53 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 51, 'learning_rate': 0.011970850304957308}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:06,211] Trial 54 finished with value: 0.8506862745098038 and parameters: {'n_estimators': 96, 'learning_rate': 0.3785515249258632}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:06,332] Trial 55 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 73, 'learning_rate': 0.002128751661796374}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:06,388] Trial 56 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 28, 'learning_rate': 0.06731703824144986}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:06,436] Trial 57 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 22, 'learning_rate': 0.018434229924091106}. Best is trial 4 with value: 0.850686274509804.\n",
      "[I 2025-12-28 19:25:06,545] Trial 58 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 68, 'learning_rate': 0.5829415347136077}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:06,687] Trial 59 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 91, 'learning_rate': 0.003278121151393461}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:06,765] Trial 60 finished with value: 0.8490196078431371 and parameters: {'n_estimators': 45, 'learning_rate': 0.10366329284376985}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:06,833] Trial 61 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 34, 'learning_rate': 0.0013823722273579005}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:06,961] Trial 62 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 79, 'learning_rate': 0.0437144481261109}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:07,050] Trial 63 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 56, 'learning_rate': 0.007773650302387762}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:07,085] Trial 64 finished with value: 0.8405882352941176 and parameters: {'n_estimators': 11, 'learning_rate': 0.24582440689201987}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:07,122] Trial 65 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 12, 'learning_rate': 0.01567878843826971}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:07,209] Trial 66 finished with value: 0.8489915966386553 and parameters: {'n_estimators': 57, 'learning_rate': 0.4958068241684657}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:07,330] Trial 67 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 80, 'learning_rate': 0.0027881266654131345}. Best is trial 58 with value: 0.8523529411764705.\n",
      "[I 2025-12-28 19:25:07,397] Trial 68 finished with value: 0.8540336134453781 and parameters: {'n_estimators': 34, 'learning_rate': 0.08816830667755711}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:07,476] Trial 69 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 46, 'learning_rate': 0.0011757432659207114}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:07,636] Trial 70 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 91, 'learning_rate': 0.037180266639144754}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:07,746] Trial 71 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 69, 'learning_rate': 0.006611690262414818}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:07,791] Trial 72 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 23, 'learning_rate': 0.20908000412787187}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:07,849] Trial 73 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 29, 'learning_rate': 0.004293510210083484}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:07,968] Trial 74 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 74, 'learning_rate': 0.13577271421051842}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,118] Trial 75 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 97, 'learning_rate': 0.024144182212566402}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,207] Trial 76 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 51, 'learning_rate': 0.7635060803383348}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,286] Trial 77 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 40, 'learning_rate': 0.010181517217181822}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,425] Trial 78 finished with value: 0.842282913165266 and parameters: {'n_estimators': 86, 'learning_rate': 0.321967844425138}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,525] Trial 79 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 63, 'learning_rate': 0.0018105582430271226}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,571] Trial 80 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 17, 'learning_rate': 0.05725487884358381}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,619] Trial 81 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 20, 'learning_rate': 0.0022467900918126454}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,727] Trial 82 finished with value: 0.8523529411764705 and parameters: {'n_estimators': 66, 'learning_rate': 0.07104974114426789}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,869] Trial 83 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 88, 'learning_rate': 0.01263462917654469}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:08,946] Trial 84 finished with value: 0.8473249299719889 and parameters: {'n_estimators': 43, 'learning_rate': 0.39954205589498876}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,046] Trial 85 finished with value: 0.8121008403361344 and parameters: {'n_estimators': 54, 'learning_rate': 0.029961427410043647}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,205] Trial 86 finished with value: 0.8439355742296918 and parameters: {'n_estimators': 100, 'learning_rate': 0.9474635256553756}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,326] Trial 87 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 77, 'learning_rate': 0.005327978945865643}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,394] Trial 88 finished with value: 0.8456442577030812 and parameters: {'n_estimators': 32, 'learning_rate': 0.16848548794358392}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,451] Trial 89 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 26, 'learning_rate': 0.008204696109024995}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,570] Trial 90 finished with value: 0.850672268907563 and parameters: {'n_estimators': 71, 'learning_rate': 0.2594552721404016}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,719] Trial 91 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 94, 'learning_rate': 0.0014590242156305613}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,808] Trial 92 finished with value: 0.8372268907563025 and parameters: {'n_estimators': 49, 'learning_rate': 0.04613839682733216}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:09,874] Trial 93 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 37, 'learning_rate': 0.003459891660869934}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:10,016] Trial 94 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 83, 'learning_rate': 0.10941138105771861}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:10,113] Trial 95 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 60, 'learning_rate': 0.019456400615886365}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:10,150] Trial 96 finished with value: 0.8456302521008403 and parameters: {'n_estimators': 14, 'learning_rate': 0.6152654101490374}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:10,196] Trial 97 finished with value: 0.8154621848739495 and parameters: {'n_estimators': 13, 'learning_rate': 0.0025028654311746077}. Best is trial 68 with value: 0.8540336134453781.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:108: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:25:10,452] A new study created in memory with name: Gradient Boosting Model Fine Tuning with QMCSampler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:25:10,305] Trial 98 finished with value: 0.8456442577030814 and parameters: {'n_estimators': 59, 'learning_rate': 0.0791475543941116}. Best is trial 68 with value: 0.8540336134453781.\n",
      "[I 2025-12-28 19:25:10,449] Trial 99 finished with value: 0.8104201680672268 and parameters: {'n_estimators': 81, 'learning_rate': 0.014074646633398432}. Best is trial 68 with value: 0.8540336134453781.\n",
      "\n",
      "Best Hyperparameters for AdaBoost Using QMCSampler: {'n_estimators': 34, 'learning_rate': 0.08816830667755711}\n",
      "Best accuracy: 0.8540, at trial: 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794d562298d6469ea22fb4b69efee4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:25:10,556] Trial 0 finished with value: 0.800280112044818 and parameters: {'max_features': 'log2', 'n_estimators': 64, 'learning_rate': 0.0020513382630874496, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8005575058716043}. Best is trial 0 with value: 0.800280112044818.\n",
      "[W 2025-12-28 19:25:10,558] The parameter `max_features` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:10,584] Trial 1 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 10, 'learning_rate': 0.0010000000000000002, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.5}. Best is trial 0 with value: 0.800280112044818.\n",
      "[W 2025-12-28 19:25:10,586] The parameter `max_features` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:10,717] Trial 2 finished with value: 0.8540056022408965 and parameters: {'max_features': 'sqrt', 'n_estimators': 55, 'learning_rate': 0.010000000000000004, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.75}. Best is trial 2 with value: 0.8540056022408965.\n",
      "[W 2025-12-28 19:25:10,720] The parameter `max_features` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:10,890] Trial 3 finished with value: 0.8372689075630252 and parameters: {'max_features': None, 'n_estimators': 78, 'learning_rate': 0.003162277660168382, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.875}. Best is trial 2 with value: 0.8540056022408965.\n",
      "[W 2025-12-28 19:25:10,891] The parameter `max_features` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:11,001] Trial 4 finished with value: 0.8607563025210083 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.03162277660168381, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:11,003] The parameter `max_features` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:11,113] Trial 5 finished with value: 0.8405882352941175 and parameters: {'max_features': None, 'n_estimators': 44, 'learning_rate': 0.005623413251903492, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.5625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:11,114] The parameter `max_features` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:11,203] Trial 6 finished with value: 0.8557002801120447 and parameters: {'max_features': 'log2', 'n_estimators': 89, 'learning_rate': 0.05623413251903493, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.8125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:11,204] The parameter `max_features` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:11,364] Trial 7 finished with value: 0.7935294117647059 and parameters: {'max_features': 'log2', 'n_estimators': 66, 'learning_rate': 0.0017782794100389236, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.9375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:11,366] The parameter `max_features` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:11,423] Trial 8 finished with value: 0.8473389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 21, 'learning_rate': 0.01778279410038924, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.6875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:11,424] The parameter `max_features` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:11,491] Trial 9 finished with value: 0.7717366946778712 and parameters: {'max_features': 'log2', 'n_estimators': 27, 'learning_rate': 0.004216965034285825, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.65625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:11,493] The parameter `max_features` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:11,684] Trial 10 finished with value: 0.8338935574229691 and parameters: {'max_features': None, 'n_estimators': 72, 'learning_rate': 0.04216965034285825, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.90625}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:11,684] The parameter `max_features` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,000] Trial 11 finished with value: 0.7902380952380953 and parameters: {'max_features': None, 'n_estimators': 95, 'learning_rate': 0.0013335214321633238, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.78125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,002] The parameter `max_features` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,069] Trial 12 finished with value: 0.8557282913165267 and parameters: {'max_features': 'log2', 'n_estimators': 49, 'learning_rate': 0.013335214321633242, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.53125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,070] The parameter `max_features` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,138] Trial 13 finished with value: 0.6593277310924369 and parameters: {'max_features': 'sqrt', 'n_estimators': 38, 'learning_rate': 0.002371373705661656, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.71875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,140] The parameter `max_features` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,453] Trial 14 finished with value: 0.8389215686274509 and parameters: {'max_features': None, 'n_estimators': 83, 'learning_rate': 0.023713737056616564, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.96875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,455] The parameter `max_features` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,523] Trial 15 finished with value: 0.8439495798319328 and parameters: {'max_features': 'log2', 'n_estimators': 61, 'learning_rate': 0.007498942093324564, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.84375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,525] The parameter `max_features` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,571] Trial 16 finished with value: 0.8607563025210083 and parameters: {'max_features': 'log2', 'n_estimators': 15, 'learning_rate': 0.07498942093324566, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.59375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,571] The parameter `max_features` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,640] Trial 17 finished with value: 0.7970028011204482 and parameters: {'max_features': None, 'n_estimators': 18, 'learning_rate': 0.008659643233600654, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.984375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,642] The parameter `max_features` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,823] Trial 18 finished with value: 0.8573949579831932 and parameters: {'max_features': None, 'n_estimators': 64, 'learning_rate': 0.08659643233600657, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.734375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,824] The parameter `max_features` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:12,953] Trial 19 finished with value: 0.8372408963585434 and parameters: {'max_features': None, 'n_estimators': 86, 'learning_rate': 0.0027384196342643626, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.609375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:12,953] The parameter `max_features` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:13,116] Trial 20 finished with value: 0.8473109243697479 and parameters: {'max_features': 'log2', 'n_estimators': 41, 'learning_rate': 0.027384196342643632, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.859375}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:13,118] The parameter `max_features` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:13,381] Trial 21 finished with value: 0.6491456582633053 and parameters: {'max_features': 'sqrt', 'n_estimators': 52, 'learning_rate': 0.0015399265260594922, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.921875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:13,382] The parameter `max_features` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:13,523] Trial 22 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 98, 'learning_rate': 0.015399265260594926, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.671875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:13,526] The parameter `max_features` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:13,634] Trial 23 finished with value: 0.8472969187675069 and parameters: {'max_features': 'log2', 'n_estimators': 75, 'learning_rate': 0.004869675251658635, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 10, 'subsample': 0.546875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:13,636] The parameter `max_features` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:13,692] Trial 24 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 29, 'learning_rate': 0.04869675251658634, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.796875}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:13,693] The parameter `max_features` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:13,750] Trial 25 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 24, 'learning_rate': 0.0020535250264571477, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.828125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:13,752] The parameter `max_features` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:13,842] Trial 26 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 69, 'learning_rate': 0.020535250264571474, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.578125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:13,844] The parameter `max_features` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,183] Trial 27 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 92, 'learning_rate': 0.0064938163157621165, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.703125}. Best is trial 4 with value: 0.8607563025210083.\n",
      "[W 2025-12-28 19:25:14,186] The parameter `max_features` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,305] Trial 28 finished with value: 0.8624369747899159 and parameters: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.06493816315762117, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:14,308] The parameter `max_features` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,375] Trial 29 finished with value: 0.7935994397759104 and parameters: {'max_features': 'log2', 'n_estimators': 35, 'learning_rate': 0.0036517412725483775, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:14,377] The parameter `max_features` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,579] Trial 30 finished with value: 0.850686274509804 and parameters: {'max_features': 'sqrt', 'n_estimators': 81, 'learning_rate': 0.03651741272548378, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:14,581] The parameter `max_features` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,722] Trial 31 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 58, 'learning_rate': 0.0011547819846894588, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:14,724] The parameter `max_features` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,782] Trial 32 finished with value: 0.8120868347338934 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.01154781984689459, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:14,783] The parameter `max_features` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,862] Trial 33 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.003398208328942561, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.9609375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:14,864] The parameter `max_features` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:14,974] Trial 34 finished with value: 0.8523249299719888 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.03398208328942562, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 7, 'subsample': 0.7109375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:14,976] The parameter `max_features` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:15,131] Trial 35 finished with value: 0.642563025210084 and parameters: {'max_features': 'log2', 'n_estimators': 82, 'learning_rate': 0.0010746078283213173, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.5859375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:15,132] The parameter `max_features` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:15,231] Trial 36 finished with value: 0.8557142857142856 and parameters: {'max_features': 'log2', 'n_estimators': 37, 'learning_rate': 0.010746078283213186, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.8359375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:15,233] The parameter `max_features` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:15,300] Trial 37 finished with value: 0.6223669467787115 and parameters: {'max_features': 'log2', 'n_estimators': 48, 'learning_rate': 0.001910952974970441, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8984375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:15,301] The parameter `max_features` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:15,461] Trial 38 finished with value: 0.8540336134453781 and parameters: {'max_features': 'log2', 'n_estimators': 93, 'learning_rate': 0.019109529749704413, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.6484375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:15,463] The parameter `max_features` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:15,593] Trial 39 finished with value: 0.8490196078431371 and parameters: {'max_features': None, 'n_estimators': 71, 'learning_rate': 0.006042963902381328, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.5234375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:15,593] The parameter `max_features` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:15,693] Trial 40 finished with value: 0.8422969187675069 and parameters: {'max_features': 'log2', 'n_estimators': 25, 'learning_rate': 0.06042963902381334, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.7734375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:15,694] The parameter `max_features` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:15,772] Trial 41 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 31, 'learning_rate': 0.0014330125702369636, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 8, 'subsample': 0.8671875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:15,774] The parameter `max_features` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:16,048] Trial 42 finished with value: 0.8456162464985993 and parameters: {'max_features': None, 'n_estimators': 76, 'learning_rate': 0.014330125702369625, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.6171875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:16,048] The parameter `max_features` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:16,200] Trial 43 finished with value: 0.8389355742296918 and parameters: {'max_features': None, 'n_estimators': 99, 'learning_rate': 0.004531583637600819, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7421875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:16,202] The parameter `max_features` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:16,340] Trial 44 finished with value: 0.8439775910364145 and parameters: {'max_features': 'log2', 'n_estimators': 54, 'learning_rate': 0.045315836376008195, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.9921875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:16,340] The parameter `max_features` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:16,439] Trial 45 finished with value: 0.8523669467787116 and parameters: {'max_features': 'log2', 'n_estimators': 42, 'learning_rate': 0.008058421877614822, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.8046875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:16,439] The parameter `max_features` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:16,643] Trial 46 finished with value: 0.8456302521008403 and parameters: {'max_features': None, 'n_estimators': 88, 'learning_rate': 0.08058421877614824, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.5546875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:16,643] The parameter `max_features` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:16,898] Trial 47 finished with value: 0.8338375350140055 and parameters: {'max_features': 'sqrt', 'n_estimators': 65, 'learning_rate': 0.0025482967479793462, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.6796875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:16,900] The parameter `max_features` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:16,946] Trial 48 finished with value: 0.8489915966386554 and parameters: {'max_features': 'sqrt', 'n_estimators': 19, 'learning_rate': 0.02548296747979348, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.9296875}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:16,946] The parameter `max_features` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:17,015] Trial 49 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.0029427271762092824, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.5390625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:17,015] The parameter `max_features` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:17,137] Trial 50 finished with value: 0.8590616246498598 and parameters: {'max_features': 'log2', 'n_estimators': 62, 'learning_rate': 0.02942727176209283, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'subsample': 0.7890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:17,139] The parameter `max_features` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:17,329] Trial 51 finished with value: 0.8624229691876751 and parameters: {'max_features': 'sqrt', 'n_estimators': 85, 'learning_rate': 0.009305720409296989, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.9140625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:17,330] The parameter `max_features` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:17,389] Trial 52 finished with value: 0.8523389355742296 and parameters: {'max_features': 'sqrt', 'n_estimators': 39, 'learning_rate': 0.09305720409296998, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.6640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:17,391] The parameter `max_features` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:17,500] Trial 53 finished with value: 0.8540056022408964 and parameters: {'max_features': 'sqrt', 'n_estimators': 51, 'learning_rate': 0.005232991146814949, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.6015625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:17,500] The parameter `max_features` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:17,827] Trial 54 finished with value: 0.8372268907563025 and parameters: {'max_features': None, 'n_estimators': 96, 'learning_rate': 0.052329911468149505, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.8515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:17,829] The parameter `max_features` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:17,937] Trial 55 finished with value: 0.7801680672268908 and parameters: {'max_features': 'log2', 'n_estimators': 73, 'learning_rate': 0.0016548170999431814, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.9765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:17,938] The parameter `max_features` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:18,047] Trial 56 finished with value: 0.8322268907563025 and parameters: {'max_features': None, 'n_estimators': 28, 'learning_rate': 0.01654817099943183, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7265625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:18,049] The parameter `max_features` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:18,095] Trial 57 finished with value: 0.8120308123249298 and parameters: {'max_features': 'log2', 'n_estimators': 22, 'learning_rate': 0.006978305848598664, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10, 'subsample': 0.6328125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:18,097] The parameter `max_features` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:18,342] Trial 58 finished with value: 0.8439495798319328 and parameters: {'max_features': None, 'n_estimators': 68, 'learning_rate': 0.06978305848598666, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.8828125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:18,344] The parameter `max_features` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:18,579] Trial 59 finished with value: 0.8422408963585435 and parameters: {'max_features': 'sqrt', 'n_estimators': 91, 'learning_rate': 0.002206734069084591, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7578125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:18,581] The parameter `max_features` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:18,670] Trial 60 finished with value: 0.8590756302521008 and parameters: {'max_features': 'sqrt', 'n_estimators': 45, 'learning_rate': 0.022067340690845913, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.5078125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:18,672] The parameter `max_features` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:18,770] Trial 61 finished with value: 0.5352380952380952 and parameters: {'max_features': None, 'n_estimators': 34, 'learning_rate': 0.0012409377607517198, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:18,773] The parameter `max_features` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:18,861] Trial 62 finished with value: 0.8456162464985993 and parameters: {'max_features': 'sqrt', 'n_estimators': 79, 'learning_rate': 0.0124093776075172, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9453125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:18,863] The parameter `max_features` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,058] Trial 63 finished with value: 0.8204481792717087 and parameters: {'max_features': None, 'n_estimators': 56, 'learning_rate': 0.003924189758484535, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.8203125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,059] The parameter `max_features` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,095] Trial 64 finished with value: 0.8490196078431371 and parameters: {'max_features': 'sqrt', 'n_estimators': 11, 'learning_rate': 0.03924189758484538, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9, 'subsample': 0.5703125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,096] The parameter `max_features` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,143] Trial 65 finished with value: 0.6156582633053221 and parameters: {'max_features': None, 'n_estimators': 12, 'learning_rate': 0.00626433536656886, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.72265625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,144] The parameter `max_features` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,264] Trial 66 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 57, 'learning_rate': 0.06264335366568861, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.97265625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,266] The parameter `max_features` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,487] Trial 67 finished with value: 0.8288235294117646 and parameters: {'max_features': 'sqrt', 'n_estimators': 80, 'learning_rate': 0.001980956778550339, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.84765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,490] The parameter `max_features` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,537] Trial 68 finished with value: 0.8556722689075631 and parameters: {'max_features': 'log2', 'n_estimators': 34, 'learning_rate': 0.019809567785503402, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 9, 'subsample': 0.59765625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,538] The parameter `max_features` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,617] Trial 69 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 46, 'learning_rate': 0.001113973859994803, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.66015625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,619] The parameter `max_features` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:19,957] Trial 70 finished with value: 0.8556722689075629 and parameters: {'max_features': 'log2', 'n_estimators': 91, 'learning_rate': 0.011139738599948034, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.91015625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:19,958] The parameter `max_features` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,077] Trial 71 finished with value: 0.8388935574229691 and parameters: {'max_features': 'sqrt', 'n_estimators': 69, 'learning_rate': 0.0035226946514731027, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.78515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,079] The parameter `max_features` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,135] Trial 72 finished with value: 0.8540476190476192 and parameters: {'max_features': 'log2', 'n_estimators': 23, 'learning_rate': 0.03522694651473104, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.53515625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,137] The parameter `max_features` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,194] Trial 73 finished with value: 0.5369187675070027 and parameters: {'max_features': 'log2', 'n_estimators': 29, 'learning_rate': 0.0026416483203860943, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.56640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,196] The parameter `max_features` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,398] Trial 74 finished with value: 0.8557142857142856 and parameters: {'max_features': 'sqrt', 'n_estimators': 74, 'learning_rate': 0.026416483203860936, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 8, 'subsample': 0.81640625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,400] The parameter `max_features` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,649] Trial 75 finished with value: 0.8590756302521008 and parameters: {'max_features': 'log2', 'n_estimators': 97, 'learning_rate': 0.008353625469578265, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 10, 'subsample': 0.94140625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,652] The parameter `max_features` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,782] Trial 76 finished with value: 0.8490196078431372 and parameters: {'max_features': 'log2', 'n_estimators': 51, 'learning_rate': 0.08353625469578266, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.69140625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,784] The parameter `max_features` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,884] Trial 77 finished with value: 0.8355182072829133 and parameters: {'max_features': 'log2', 'n_estimators': 40, 'learning_rate': 0.004697588816706496, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.50390625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,885] The parameter `max_features` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:20,975] Trial 78 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 86, 'learning_rate': 0.04697588816706495, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.75390625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:20,976] The parameter `max_features` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:21,210] Trial 79 finished with value: 0.7381652661064425 and parameters: {'max_features': None, 'n_estimators': 63, 'learning_rate': 0.0014855080171727755, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.87890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:21,212] The parameter `max_features` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:21,259] Trial 80 finished with value: 0.850686274509804 and parameters: {'max_features': 'log2', 'n_estimators': 17, 'learning_rate': 0.01485508017172776, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.62890625}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:21,260] The parameter `max_features` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:21,318] Trial 81 finished with value: 0.5352380952380952 and parameters: {'max_features': 'sqrt', 'n_estimators': 20, 'learning_rate': 0.0017154378963428801, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.76953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:21,320] The parameter `max_features` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:21,417] Trial 82 finished with value: 0.850658263305322 and parameters: {'max_features': 'sqrt', 'n_estimators': 66, 'learning_rate': 0.017154378963428803, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.51953125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:21,419] The parameter `max_features` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:21,847] Trial 83 finished with value: 0.8573529411764707 and parameters: {'max_features': 'log2', 'n_estimators': 88, 'learning_rate': 0.005424690937011328, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.64453125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:21,850] The parameter `max_features` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:21,971] Trial 84 finished with value: 0.8355462184873949 and parameters: {'max_features': None, 'n_estimators': 43, 'learning_rate': 0.05424690937011329, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.89453125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:21,972] The parameter `max_features` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:22,039] Trial 85 finished with value: 0.8473109243697479 and parameters: {'max_features': 'sqrt', 'n_estimators': 54, 'learning_rate': 0.009646616199111998, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.83203125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:22,040] The parameter `max_features` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:22,345] Trial 86 finished with value: 0.8573389355742297 and parameters: {'max_features': 'sqrt', 'n_estimators': 100, 'learning_rate': 0.09646616199112, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.58203125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:22,347] The parameter `max_features` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:22,485] Trial 87 finished with value: 0.8422549019607842 and parameters: {'max_features': 'sqrt', 'n_estimators': 77, 'learning_rate': 0.003050527890267026, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.70703125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:22,488] The parameter `max_features` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:22,595] Trial 88 finished with value: 0.8490056022408965 and parameters: {'max_features': None, 'n_estimators': 32, 'learning_rate': 0.030505278902670276, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.95703125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:22,598] The parameter `max_features` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:22,655] Trial 89 finished with value: 0.7650560224089636 and parameters: {'max_features': 'sqrt', 'n_estimators': 26, 'learning_rate': 0.0040679443210830495, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.92578125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:22,656] The parameter `max_features` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:22,775] Trial 90 finished with value: 0.8573949579831932 and parameters: {'max_features': 'sqrt', 'n_estimators': 71, 'learning_rate': 0.04067944321083049, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.67578125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:22,778] The parameter `max_features` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:22,875] Trial 91 finished with value: 0.7650700280112045 and parameters: {'max_features': 'log2', 'n_estimators': 94, 'learning_rate': 0.0012863969449369746, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8, 'subsample': 0.55078125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:22,875] The parameter `max_features` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,058] Trial 92 finished with value: 0.8372829131652659 and parameters: {'max_features': None, 'n_estimators': 49, 'learning_rate': 0.01286396944936975, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.80078125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:23,058] The parameter `max_features` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,218] Trial 93 finished with value: 0.7365126050420168 and parameters: {'max_features': None, 'n_estimators': 37, 'learning_rate': 0.0022875732003183966, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.98828125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:23,220] The parameter `max_features` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,380] Trial 94 finished with value: 0.8573949579831932 and parameters: {'max_features': 'log2', 'n_estimators': 83, 'learning_rate': 0.02287573200318397, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.73828125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:23,380] The parameter `max_features` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,490] Trial 95 finished with value: 0.850672268907563 and parameters: {'max_features': 'log2', 'n_estimators': 60, 'learning_rate': 0.007233941627366754, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.61328125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:23,493] The parameter `max_features` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,539] Trial 96 finished with value: 0.8389075630252101 and parameters: {'max_features': None, 'n_estimators': 14, 'learning_rate': 0.0723394162736675, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.86328125}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:23,540] The parameter `max_features` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,587] Trial 97 finished with value: 0.5352380952380952 and parameters: {'max_features': 'log2', 'n_estimators': 13, 'learning_rate': 0.0018434229924091112, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.80859375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:23,589] The parameter `max_features` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,773] Trial 98 finished with value: 0.8355882352941176 and parameters: {'max_features': None, 'n_estimators': 59, 'learning_rate': 0.018434229924091116, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.55859375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "[W 2025-12-28 19:25:23,774] The parameter `max_features` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:25:23,915] Trial 99 finished with value: 0.8439495798319326 and parameters: {'max_features': None, 'n_estimators': 81, 'learning_rate': 0.005829415347136074, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.68359375}. Best is trial 28 with value: 0.8624369747899159.\n",
      "\n",
      "Best Hyperparameters for Gradient Boosting Using QMCSampler: {'max_features': None, 'n_estimators': 46, 'learning_rate': 0.06493816315762117, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.953125}\n",
      "Best accuracy: 0.8624, at trial: 28\n",
      "QMC Base Models Training Time: 48.40 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_base_models_training_start = time.time()\n",
    "\n",
    "    # QMC Hyperparameter Tuning with Cross Validation\n",
    "    qmc_logistic_regression = base_model_tuning('Logistic Regression', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_decision_tree = base_model_tuning('Decision Tree', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_random_forest = base_model_tuning('Random Forest', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_knn = base_model_tuning('K-Nearest Neighbors', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_svc = base_model_tuning('Support Vector Machine', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_adaboost = base_model_tuning('AdaBoost', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_gradient_boosting = base_model_tuning('Gradient Boosting', X_train, y_train, sampler='QMCSampler', cv_folds=CV_FOLDS, iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Model Fitting with best parameters\n",
    "    qmc_logistic_regression.fit(X_train, y_train)\n",
    "    qmc_decision_tree.fit(X_train, y_train)\n",
    "    qmc_random_forest.fit(X_train, y_train)\n",
    "    qmc_knn.fit(X_train, y_train)\n",
    "    qmc_svc.fit(X_train, y_train)\n",
    "    qmc_adaboost.fit(X_train, y_train)\n",
    "    qmc_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "    qmc_base_models_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC base models training\n",
    "    qmc_base_models_training_time = qmc_base_models_training_end - qmc_base_models_training_start\n",
    "    print(f'QMC Base Models Training Time: {qmc_base_models_training_time:.2f} seconds')\n",
    "else:\n",
    "    print(\"Skipping QMC base models training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5 Save Every Best Model Config for each Tuning Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # Base Models Storage for all sampler types\n",
    "    base_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    print(\"Skipping base models storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Meta Model Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters to be tuned are:\n",
    "- Selection of the number and type of base models used\n",
    "- Number of layers in the neural network: 1 - 5\n",
    "- Number of neurons per layer: 10 - 100\n",
    "- Learning rate behavior: Constant or Adaptive\n",
    "- Learning rate value: 0.0001 - 0.01\n",
    "- L2 Regularization value: 0.0001 - 0.01\n",
    "\n",
    "Unchanged Preset hyperparameters:\n",
    "- Activation function: ReLU\n",
    "- Optimizer (Solver): Adam\n",
    "- Epochs (Max Iter): 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 TPE Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:25:24,268] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (TPESampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21df46039a7947bcaf45d41cb2d57109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:25:26,346] Trial 0 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.92.\n",
      "[I 2025-12-28 19:25:27,784] Trial 1 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 0 with value: 0.92.\n",
      "[I 2025-12-28 19:25:28,780] Trial 2 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 0 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:25:30,991] Trial 3 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 0 with value: 0.92.\n",
      "[I 2025-12-28 19:25:32,966] Trial 4 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 0 with value: 0.92.\n",
      "[I 2025-12-28 19:25:34,489] Trial 5 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 0 with value: 0.92.\n",
      "[I 2025-12-28 19:25:36,402] Trial 6 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:37,003] Trial 7 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:37,004] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:39,535] Trial 9 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:41,959] Trial 10 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 43, 'n_neurons_1': 57, 'n_neurons_2': 99, 'learning_rate': 'constant', 'learning_rate_init': 0.006780722035512432, 'alpha': 0.0001858311497609689}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:44,077] Trial 11 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 31, 'n_neurons_1': 57, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045255479354650767, 'alpha': 0.0007629684982954762}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:46,383] Trial 12 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 39, 'n_neurons_1': 57, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0027096556834079184, 'alpha': 0.001094601656965778}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:48,498] Trial 13 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 61, 'n_neurons_1': 41, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00038409185715266344, 'alpha': 0.0013755565663405665}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:50,575] Trial 14 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 47, 'n_neurons_1': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003408615407291458, 'alpha': 0.00011152977421811848}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:52,683] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 38, 'n_neurons_2': 64, 'learning_rate': 'constant', 'learning_rate_init': 0.0020953597636637284, 'alpha': 0.0006872174309842164}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:54,631] Trial 16 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 97, 'n_neurons_1': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003563227004719962, 'alpha': 0.00030193798809716323}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:56,547] Trial 17 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 76, 'n_neurons_1': 45, 'n_neurons_2': 61, 'n_neurons_3': 14, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003182340433021541, 'alpha': 0.0008702212187289844}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:57,523] Trial 18 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 51, 'learning_rate': 'constant', 'learning_rate_init': 0.009237126438812622, 'alpha': 0.002168541575914635}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:25:59,416] Trial 19 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 31, 'n_neurons_1': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012242044270388815, 'alpha': 0.000220760014995141}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:01,460] Trial 20 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 11, 'n_neurons_1': 69, 'n_neurons_2': 45, 'learning_rate': 'constant', 'learning_rate_init': 0.0006385120315241285, 'alpha': 0.0035200516686345784}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:03,346] Trial 21 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 36, 'n_neurons_1': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002548137725183338, 'alpha': 0.0012211358875278719}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:05,207] Trial 22 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 52, 'n_neurons_1': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00390989408639025, 'alpha': 0.0007712666035787818}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:07,101] Trial 23 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001804377700449567, 'alpha': 0.0013891286406471715}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:09,170] Trial 24 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00024755825659916156, 'alpha': 0.0005455903912706116}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:11,546] Trial 25 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 62, 'n_neurons_2': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004922815927154945, 'alpha': 0.0010282151080139579}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:12,642] Trial 26 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 47, 'n_neurons_1': 79, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005263820110984335, 'alpha': 0.001729110925766877}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:14,641] Trial 27 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'constant', 'learning_rate_init': 0.001305406056873756, 'alpha': 0.0031721924798543736}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:16,636] Trial 28 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 47, 'n_neurons_2': 10, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0026518223654311344, 'alpha': 0.0006310522773639975}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:18,649] Trial 29 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 64, 'learning_rate': 'constant', 'learning_rate_init': 0.0009261260944102935, 'alpha': 0.0009838404793513426}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:20,777] Trial 30 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007211254081426995, 'alpha': 0.0003427849848219964}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:22,929] Trial 31 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 95, 'n_neurons_1': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002326219687285724, 'alpha': 0.0002863759115307617}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:25,042] Trial 32 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 72, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005016575332731216, 'alpha': 0.00014344593563113498}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:27,125] Trial 33 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 97, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00022452483018605606, 'alpha': 0.0004538788011400001}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:28,384] Trial 34 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 95, 'n_neurons_1': 61, 'n_neurons_2': 36, 'n_neurons_3': 39, 'n_neurons_4': 93, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00037040911988771015, 'alpha': 0.00026595184160987196}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:30,372] Trial 35 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005271489337369676, 'alpha': 0.0004152422312509689}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:26:32,442] Trial 36 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 84, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010527514902773188, 'alpha': 0.0006814316709696152}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:32,738] Trial 37 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 16, 'n_neurons_1': 53, 'n_neurons_2': 75, 'learning_rate': 'constant', 'learning_rate_init': 0.0009095703490934905, 'alpha': 0.001539816231202374}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:34,938] Trial 38 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 63, 'n_neurons_1': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017512747391119858, 'alpha': 0.008998192724614723}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:35,132] Trial 39 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0017798928778724541, 'alpha': 0.0010609762043008368}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:37,232] Trial 40 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 31, 'n_neurons_1': 48, 'n_neurons_2': 51, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003065495516536166, 'alpha': 0.0005216294184752089}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:39,238] Trial 41 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 32, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0011830668980501243, 'alpha': 0.00017622907883419554}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:41,225] Trial 42 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 23, 'n_neurons_1': 11, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001221096546135541, 'alpha': 0.00023146308841047133}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:43,260] Trial 43 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 27, 'n_neurons_1': 21, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001601464661983791, 'alpha': 0.00035935550258604776}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:26:45,462] Trial 44 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 25, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0024038131965539787, 'alpha': 0.0002162642081956123}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:47,423] Trial 45 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 88, 'n_neurons_1': 34, 'learning_rate': 'constant', 'learning_rate_init': 0.0032939580044989425, 'alpha': 0.0001530640900580139}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:49,883] Trial 46 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 17, 'n_neurons_1': 41, 'n_neurons_2': 94, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008995419187585711, 'alpha': 0.00010068955804936748}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:51,895] Trial 47 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 49, 'n_neurons_1': 67, 'learning_rate': 'constant', 'learning_rate_init': 0.0006245683541760731, 'alpha': 0.0002988687600222704}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:53,859] Trial 48 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 77, 'n_neurons_2': 29, 'n_neurons_3': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005168873524991025, 'alpha': 0.001832275920337713}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:55,183] Trial 49 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 30, 'n_neurons_1': 12, 'n_neurons_2': 67, 'learning_rate': 'constant', 'learning_rate_init': 0.0020346237314380297, 'alpha': 0.0008988790532724189}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:26:57,190] Trial 50 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00042381200674734555, 'alpha': 0.002892098129697109}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:26:59,617] Trial 51 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 12, 'n_neurons_1': 72, 'n_neurons_2': 50, 'learning_rate': 'constant', 'learning_rate_init': 0.000585131292321295, 'alpha': 0.0054736493442029185}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:27:02,105] Trial 52 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 17, 'n_neurons_1': 59, 'n_neurons_2': 46, 'n_neurons_3': 11, 'learning_rate': 'constant', 'learning_rate_init': 0.00077393390300718, 'alpha': 0.0028433796060298344}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:04,266] Trial 53 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 52, 'n_neurons_1': 66, 'n_neurons_2': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0013851877354389348, 'alpha': 0.004023648709701729}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:06,359] Trial 54 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 10, 'n_neurons_1': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.00031497577544397525, 'alpha': 0.0012341356938282422}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:27:08,604] Trial 55 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 25, 'n_neurons_1': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0010757640302840965, 'alpha': 0.003629102620913748}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:10,658] Trial 56 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045111003726223156, 'alpha': 0.0001295772650253771}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:13,219] Trial 57 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 46, 'n_neurons_1': 49, 'n_neurons_2': 74, 'n_neurons_3': 62, 'n_neurons_4': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.000717862978498932, 'alpha': 0.0025200913837319784}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:15,192] Trial 58 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 41, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0031139061499348164, 'alpha': 0.009693833357269558}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:17,258] Trial 59 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 40, 'n_neurons_1': 23, 'n_neurons_2': 57, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006228883605534865, 'alpha': 0.0007674207897251435}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:27:18,452] Trial 60 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.00026900197763010946, 'alpha': 0.0005996721730142995}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:20,412] Trial 61 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 37, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0016682317571916848, 'alpha': 0.0012413978171736317}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:22,472] Trial 62 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002159690114819852, 'alpha': 0.0014773782617910273}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:24,530] Trial 63 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 63, 'n_neurons_1': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0018675473773770968, 'alpha': 0.0017658670991707258}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:26,840] Trial 64 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 33, 'n_neurons_1': 76, 'n_neurons_2': 45, 'n_neurons_3': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001422864804042423, 'alpha': 0.0007722067493316198}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:28,976] Trial 65 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000830662395827343, 'alpha': 0.002066369749513577}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:31,004] Trial 66 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 56, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004064490236837251, 'alpha': 0.005323642999068196}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:27:33,064] Trial 67 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 23, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00019118493686980415, 'alpha': 0.0004640998214917701}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:34,962] Trial 68 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001109566350194022, 'alpha': 0.0001949417338592267}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:36,889] Trial 69 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 44, 'n_neurons_1': 44, 'n_neurons_2': 14, 'learning_rate': 'constant', 'learning_rate_init': 0.002710320186842134, 'alpha': 0.0010813210548255097}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:38,026] Trial 70 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 49, 'n_neurons_1': 17, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00039588101454211946, 'alpha': 0.0013625591798859626}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:40,254] Trial 71 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 19, 'n_neurons_1': 50, 'n_neurons_2': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002590055262337299, 'alpha': 0.0006359236442338992}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:27:42,565] Trial 72 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 14, 'n_neurons_1': 35, 'n_neurons_2': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0030474373808822668, 'alpha': 0.000897795935517006}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:44,532] Trial 73 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 45, 'n_neurons_2': 21, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0034758034052013737, 'alpha': 0.0007591212669304744}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:27:46,885] Trial 74 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 25, 'n_neurons_1': 63, 'n_neurons_2': 28, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0023221303433647424, 'alpha': 0.0005484860308156801}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:49,057] Trial 75 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 29, 'n_neurons_1': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0019032541560679854, 'alpha': 0.0003238927020681102}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:51,356] Trial 76 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 35, 'n_neurons_1': 39, 'n_neurons_2': 33, 'n_neurons_3': 75, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015137264430366163, 'alpha': 0.00024742222160039094}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:53,336] Trial 77 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 90, 'learning_rate': 'constant', 'learning_rate_init': 0.0010196451635660804, 'alpha': 0.0004494308660383508}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:55,281] Trial 78 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 15, 'n_neurons_1': 27, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005195233202800563, 'alpha': 0.001141600119143657}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:57,449] Trial 79 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 28, 'n_neurons_1': 46, 'n_neurons_2': 20, 'n_neurons_3': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012697191145579132, 'alpha': 0.0008582442968964374}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:27:59,422] Trial 80 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 23, 'n_neurons_1': 57, 'n_neurons_2': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.00034913113177106615, 'alpha': 0.0003976743696375759}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:01,380] Trial 81 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 42, 'n_neurons_1': 64, 'learning_rate': 'constant', 'learning_rate_init': 0.0005804326867890114, 'alpha': 0.0009215404678927626}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:03,356] Trial 82 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 52, 'learning_rate': 'constant', 'learning_rate_init': 0.0008865146320200032, 'alpha': 0.0009913397658392181}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:05,414] Trial 83 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 45, 'n_neurons_1': 72, 'learning_rate': 'constant', 'learning_rate_init': 0.0016661599176954521, 'alpha': 0.0013721849161811518}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:07,373] Trial 84 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 33, 'n_neurons_1': 60, 'learning_rate': 'constant', 'learning_rate_init': 0.00044887837356024474, 'alpha': 0.0006870014905330424}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:09,316] Trial 85 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 53, 'learning_rate': 'constant', 'learning_rate_init': 0.0009711781063959439, 'alpha': 0.008011440711464066}. Best is trial 6 with value: 0.9266666666666666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:28:10,607] Trial 86 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 10, 'n_neurons_1': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002782295702405928, 'alpha': 0.0005940841163671485}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:12,620] Trial 87 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 36, 'n_neurons_1': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.0006814792915454016, 'alpha': 0.0009895956354689921}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:14,795] Trial 88 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 50, 'n_neurons_1': 74, 'n_neurons_2': 41, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002839820502018047, 'alpha': 0.0020227830850349784}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:17,019] Trial 89 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 59, 'n_neurons_1': 57, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002139181873178847, 'alpha': 0.0016069569232631468}. Best is trial 6 with value: 0.9266666666666666.\n",
      "[I 2025-12-28 19:28:18,951] Trial 90 finished with value: 0.9333333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 47, 'n_neurons_1': 35, 'n_neurons_2': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.009279059801210795, 'alpha': 0.00017124486140074707}. Best is trial 90 with value: 0.9333333333333333.\n",
      "[I 2025-12-28 19:28:21,301] Trial 91 finished with value: 0.8666666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 47, 'n_neurons_1': 36, 'n_neurons_2': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.004749071116183843, 'alpha': 0.00016611916743587213}. Best is trial 90 with value: 0.9333333333333333.\n",
      "[I 2025-12-28 19:28:23,299] Trial 92 finished with value: 0.94 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 41, 'n_neurons_1': 20, 'n_neurons_2': 83, 'learning_rate': 'constant', 'learning_rate_init': 0.00625943673761351, 'alpha': 0.0002697361725980137}. Best is trial 92 with value: 0.94.\n",
      "[I 2025-12-28 19:28:25,180] Trial 93 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 17, 'n_neurons_2': 83, 'learning_rate': 'constant', 'learning_rate_init': 0.009119126750871643, 'alpha': 0.00020590368916437437}. Best is trial 92 with value: 0.94.\n",
      "[I 2025-12-28 19:28:27,015] Trial 94 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 32, 'n_neurons_2': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.007050715192906042, 'alpha': 0.0002663492883341917}. Best is trial 92 with value: 0.94.\n",
      "[I 2025-12-28 19:28:29,056] Trial 95 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 39, 'n_neurons_1': 28, 'n_neurons_2': 82, 'learning_rate': 'constant', 'learning_rate_init': 0.007982692472478311, 'alpha': 0.00013177921229308583}. Best is trial 92 with value: 0.94.\n",
      "[I 2025-12-28 19:28:31,114] Trial 96 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 32, 'n_neurons_1': 20, 'n_neurons_2': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.009810930134658608, 'alpha': 0.00030771271847209234}. Best is trial 92 with value: 0.94.\n",
      "[I 2025-12-28 19:28:33,153] Trial 97 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 37, 'n_neurons_1': 13, 'n_neurons_2': 90, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006515646427292629, 'alpha': 0.00016026659689500055}. Best is trial 92 with value: 0.94.\n",
      "[I 2025-12-28 19:28:35,033] Trial 98 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 48, 'n_neurons_1': 23, 'n_neurons_2': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0056023411249014774, 'alpha': 0.00023578449031680615}. Best is trial 92 with value: 0.94.\n",
      "[I 2025-12-28 19:28:36,060] Trial 99 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 86, 'n_neurons_1': 14, 'n_neurons_2': 60, 'n_neurons_3': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.00606124952194836, 'alpha': 0.00036243063121938027}. Best is trial 92 with value: 0.94.\n",
      "\n",
      "Selected Base Models for Stacking using TPESampler:\n",
      "- Logistic Regression\n",
      "- Decision Tree\n",
      "- Random Forest\n",
      "- AdaBoost\n",
      "- Gradient Boosting\n",
      "Best Hyperparameters for Meta Model (MLP) using TPESampler: {'learning_rate': 'constant', 'learning_rate_init': 0.00625943673761351, 'alpha': 0.0002697361725980137, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (41, 20, 83), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9400, at trial: 92\n",
      "TPE base models training time: 53.73 seconds\n",
      "TPE SEl-NNML Training Time: 193.78 seconds\n",
      "Total TPE Training Time (Base + Meta): 247.52 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    tpe_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    tpe_sel_nnml, tpe_meta_study = meta_model_tuning(base_models['TPE'], X_train, y_train, X_test, y_test, sampler='TPESampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    tpe_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    tpe_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for TPE SEl-NNML training\n",
    "    tpe_meta_model_training_time = tpe_meta_model_training_end - tpe_meta_model_training_start\n",
    "    print(f'TPE base models training time: {tpe_base_models_training_time:.2f} seconds')\n",
    "    print(f'TPE SEl-NNML Training Time: {tpe_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total TPE Training Time (Base + Meta): {tpe_base_models_training_time + tpe_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    tpe_meta_history = tpe_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    tpe_meta_history.columns = ['iteration', 'score']\n",
    "    tpe_meta_history['iteration'] = tpe_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping TPE meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 GP & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:178: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:28:38,094] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (GPSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1be29df5354eb89b283e4f5bb8a0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:28:39,051] Trial 0 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9.\n",
      "[I 2025-12-28 19:28:40,797] Trial 1 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 83, 'n_neurons_1': 37, 'n_neurons_2': 18, 'n_neurons_3': 72, 'n_neurons_4': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011715937392307068, 'alpha': 0.006586289317583112}. Best is trial 1 with value: 0.9133333333333333.\n",
      "[I 2025-12-28 19:28:41,655] Trial 2 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995}. Best is trial 2 with value: 0.92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:28:42,578] Trial 3 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 20, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00013400367243354819, 'alpha': 0.0004187594718900631}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:28:43,464] Trial 4 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0010402587615883842, 'alpha': 0.006533305220227739}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:28:45,281] Trial 5 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007148510793512986, 'alpha': 0.00432543242796456}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:28:46,566] Trial 6 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 55, 'n_neurons_1': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.001656260589333597, 'alpha': 0.0010124137770478635}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:28:47,312] Trial 7 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 58, 'n_neurons_1': 18, 'n_neurons_2': 86, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0015197980620034217, 'alpha': 0.0022653156413948872}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:28:47,316] Trial 8 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:28:48,598] Trial 9 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 68, 'n_neurons_1': 17, 'n_neurons_2': 24, 'n_neurons_3': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.00015956700210656633, 'alpha': 0.002123261760236048}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:48,718] The parameter `n_layers` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:48,719] The parameter `n_neurons_0` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:48,720] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:48,721] The parameter `learning_rate_init` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:48,721] The parameter `alpha` in Trial#10 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:28:49,565] Trial 10 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020133650202440474, 'alpha': 0.0002808915139812627}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:49,639] The parameter `n_layers` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:49,640] The parameter `n_neurons_0` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:49,640] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:49,641] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:49,641] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:49,642] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:49,642] The parameter `learning_rate_init` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:49,643] The parameter `alpha` in Trial#11 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:28:51,533] Trial 11 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 39, 'n_neurons_2': 77, 'n_neurons_3': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.0013696739838480055, 'alpha': 0.00015393931002140855}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:51,600] The parameter `n_layers` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:51,600] The parameter `n_neurons_0` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:51,602] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:51,603] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:51,603] The parameter `learning_rate_init` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:51,604] The parameter `alpha` in Trial#12 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:28:52,994] Trial 12 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 34, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.0060826539606401225, 'alpha': 0.0018292676411745708}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:53,065] The parameter `n_layers` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:53,067] The parameter `n_neurons_0` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:53,067] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:53,069] The parameter `n_neurons_2` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:53,069] The parameter `n_neurons_3` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:53,069] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:53,069] The parameter `learning_rate_init` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:53,070] The parameter `alpha` in Trial#13 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:28:54,743] Trial 13 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 55, 'n_neurons_1': 62, 'n_neurons_2': 54, 'n_neurons_3': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0001118489555166451, 'alpha': 0.001954090133022007}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:54,809] The parameter `n_layers` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:54,810] The parameter `n_neurons_0` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:54,811] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:54,811] The parameter `learning_rate_init` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:54,812] The parameter `alpha` in Trial#14 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:28:56,113] Trial 14 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.000549942648034561, 'alpha': 0.00010737748632897979}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:56,179] The parameter `n_layers` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,180] The parameter `n_neurons_0` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,180] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,180] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,181] The parameter `n_neurons_3` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,181] The parameter `n_neurons_4` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,182] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,182] The parameter `learning_rate_init` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:56,182] The parameter `alpha` in Trial#15 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:28:58,316] Trial 15 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 48, 'n_neurons_1': 97, 'n_neurons_2': 97, 'n_neurons_3': 87, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004303720019143252, 'alpha': 0.00021826570038901196}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:58,381] The parameter `n_layers` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:58,382] The parameter `n_neurons_0` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:58,382] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:58,382] The parameter `n_neurons_2` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:58,383] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:58,383] The parameter `learning_rate_init` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:58,383] The parameter `alpha` in Trial#16 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:28:59,193] Trial 16 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 95, 'n_neurons_1': 73, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009552294429449873, 'alpha': 0.00019061980918553997}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:28:59,256] The parameter `n_layers` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:59,256] The parameter `n_neurons_0` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:59,256] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:59,256] The parameter `n_neurons_2` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:59,256] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:59,256] The parameter `learning_rate_init` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:28:59,256] The parameter `alpha` in Trial#17 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:00,482] Trial 17 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 77, 'n_neurons_2': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.0003865304288032154, 'alpha': 0.004156447611486069}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:00,564] The parameter `n_layers` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,565] The parameter `n_neurons_0` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,566] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,566] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,566] The parameter `n_neurons_3` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,568] The parameter `n_neurons_4` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,569] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,569] The parameter `learning_rate_init` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:00,569] The parameter `alpha` in Trial#18 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:02,133] Trial 18 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 93, 'n_neurons_2': 56, 'n_neurons_3': 55, 'n_neurons_4': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0039046790191830895, 'alpha': 0.0060257440920984265}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:02,198] The parameter `n_layers` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:02,200] The parameter `n_neurons_0` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:02,200] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:02,201] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:02,201] The parameter `learning_rate_init` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:02,201] The parameter `alpha` in Trial#19 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:03,212] Trial 19 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 18, 'learning_rate': 'constant', 'learning_rate_init': 0.0008534852819566894, 'alpha': 0.0012169963323841}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:03,278] The parameter `n_layers` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:03,278] The parameter `n_neurons_0` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:03,278] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:03,278] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:03,278] The parameter `learning_rate_init` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:03,278] The parameter `alpha` in Trial#20 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:04,362] Trial 20 finished with value: 0.5266666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 63, 'n_neurons_1': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005252684100000482, 'alpha': 0.00017952338368491265}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:04,448] The parameter `n_layers` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:04,449] The parameter `n_neurons_0` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:04,450] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:04,450] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:04,451] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:04,451] The parameter `learning_rate_init` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:04,452] The parameter `alpha` in Trial#21 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:05,412] Trial 21 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 80, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0011553385460530909, 'alpha': 0.0012057860169848358}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:05,497] The parameter `n_layers` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:05,498] The parameter `n_neurons_0` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:05,499] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:05,499] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:05,500] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:05,501] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:05,502] The parameter `learning_rate_init` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:05,502] The parameter `alpha` in Trial#22 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:07,495] Trial 22 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 76, 'n_neurons_1': 98, 'n_neurons_2': 56, 'n_neurons_3': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.0007549928546183039, 'alpha': 0.00014352011136230925}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:07,576] The parameter `n_layers` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:07,577] The parameter `n_neurons_0` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:07,577] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:07,578] The parameter `learning_rate_init` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:07,579] The parameter `alpha` in Trial#23 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:08,921] Trial 23 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.000657515339012736, 'alpha': 0.000222120498838994}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:08,993] The parameter `n_layers` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:08,994] The parameter `n_neurons_0` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:08,994] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:08,995] The parameter `learning_rate_init` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:08,995] The parameter `alpha` in Trial#24 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:10,234] Trial 24 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0020911960669713066, 'alpha': 0.00036296754488993613}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:10,344] The parameter `n_layers` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,344] The parameter `n_neurons_0` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,344] The parameter `n_neurons_1` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,346] The parameter `n_neurons_2` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,346] The parameter `n_neurons_3` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,346] The parameter `n_neurons_4` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,348] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,348] The parameter `learning_rate_init` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:10,348] The parameter `alpha` in Trial#25 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:12,010] Trial 25 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 77, 'n_neurons_1': 60, 'n_neurons_2': 65, 'n_neurons_3': 48, 'n_neurons_4': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00010685306331940677, 'alpha': 0.00017066532063900338}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:12,102] The parameter `n_layers` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:12,103] The parameter `n_neurons_0` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:12,105] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:12,105] The parameter `learning_rate_init` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:12,106] The parameter `alpha` in Trial#26 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:13,464] Trial 26 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 13, 'learning_rate': 'constant', 'learning_rate_init': 0.0008878664758716851, 'alpha': 0.00015691639471778163}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:13,584] The parameter `n_layers` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:13,585] The parameter `n_neurons_0` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:13,586] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:13,586] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:13,587] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:13,587] The parameter `learning_rate_init` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:13,588] The parameter `alpha` in Trial#27 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:15,279] Trial 27 finished with value: 0.86 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 53, 'n_neurons_1': 25, 'n_neurons_2': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001862890387420621, 'alpha': 0.00012319923739394199}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:15,357] The parameter `n_layers` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:15,358] The parameter `n_neurons_0` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:15,359] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:15,360] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:15,360] The parameter `learning_rate_init` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:15,361] The parameter `alpha` in Trial#28 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:16,806] Trial 28 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 66, 'n_neurons_1': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.0002117721540886054, 'alpha': 0.00013840044764106221}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:16,891] The parameter `n_layers` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:16,892] The parameter `n_neurons_0` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:16,893] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:16,893] The parameter `n_neurons_2` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:16,894] The parameter `n_neurons_3` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:16,894] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:16,895] The parameter `learning_rate_init` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:16,895] The parameter `alpha` in Trial#29 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:18,478] Trial 29 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 12, 'n_neurons_1': 63, 'n_neurons_2': 95, 'n_neurons_3': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008250984684608617, 'alpha': 0.0012337682181468137}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:18,556] The parameter `n_layers` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,557] The parameter `n_neurons_0` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,558] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,558] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,559] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,560] The parameter `n_neurons_4` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,560] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,560] The parameter `learning_rate_init` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:18,561] The parameter `alpha` in Trial#30 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:20,390] Trial 30 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 97, 'n_neurons_2': 92, 'n_neurons_3': 27, 'n_neurons_4': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.00015448485924752335, 'alpha': 0.0023228092500006277}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:20,493] The parameter `n_layers` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:20,494] The parameter `n_neurons_0` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:20,494] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:20,495] The parameter `learning_rate_init` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:20,495] The parameter `alpha` in Trial#31 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:21,660] Trial 31 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'constant', 'learning_rate_init': 0.004255366449682059, 'alpha': 0.00036619258793526205}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:21,788] The parameter `n_layers` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:21,788] The parameter `n_neurons_0` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:21,788] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:21,788] The parameter `learning_rate_init` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:21,788] The parameter `alpha` in Trial#32 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:22,410] Trial 32 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002952174928235019, 'alpha': 0.004045403638787863}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:22,486] The parameter `n_layers` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:22,486] The parameter `n_neurons_0` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:22,486] The parameter `n_neurons_1` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:22,491] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:22,491] The parameter `learning_rate_init` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:22,493] The parameter `alpha` in Trial#33 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:23,168] Trial 33 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 78, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006687062061347505, 'alpha': 0.0005546719086332962}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `n_layers` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `n_neurons_0` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `n_neurons_3` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `learning_rate_init` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:23,239] The parameter `alpha` in Trial#34 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:24,576] Trial 34 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 94, 'n_neurons_2': 88, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001607858173371064, 'alpha': 0.006384190143734895}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:24,655] The parameter `n_layers` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:24,656] The parameter `n_neurons_0` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:24,657] The parameter `n_neurons_1` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:24,657] The parameter `n_neurons_2` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:24,658] The parameter `learning_rate` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:24,659] The parameter `learning_rate_init` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:24,659] The parameter `alpha` in Trial#35 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:26,128] Trial 35 finished with value: 0.86 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 39, 'n_neurons_2': 91, 'learning_rate': 'constant', 'learning_rate_init': 0.006467909772210833, 'alpha': 0.00015225562752457967}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:29:26,213] Trial 36 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:26,305] The parameter `n_layers` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:26,305] The parameter `n_neurons_0` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:26,307] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:26,308] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:26,308] The parameter `learning_rate_init` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:26,309] The parameter `alpha` in Trial#37 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:27,003] Trial 37 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 96, 'n_neurons_1': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007886622327732802, 'alpha': 0.00038585269984779924}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:27,087] The parameter `n_layers` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:27,089] The parameter `n_neurons_0` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:27,089] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:27,089] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:27,089] The parameter `learning_rate_init` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:27,091] The parameter `alpha` in Trial#38 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:28,032] Trial 38 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 78, 'learning_rate': 'constant', 'learning_rate_init': 0.00015219914267510963, 'alpha': 0.0009746318720288899}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:28,105] The parameter `n_layers` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:28,106] The parameter `n_neurons_0` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:28,107] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:28,108] The parameter `learning_rate_init` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:28,108] The parameter `alpha` in Trial#39 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:29,378] Trial 39 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005033035864411288, 'alpha': 0.00017144863541673278}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:29,453] The parameter `n_layers` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:29,454] The parameter `n_neurons_0` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:29,454] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:29,455] The parameter `learning_rate_init` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:29,455] The parameter `alpha` in Trial#40 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:30,228] Trial 40 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.00014730368526805275, 'alpha': 0.002523122072859775}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:30,323] The parameter `n_layers` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:30,324] The parameter `n_neurons_0` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:30,324] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:30,324] The parameter `learning_rate_init` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:30,325] The parameter `alpha` in Trial#41 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:31,304] Trial 41 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.00014780033831850363, 'alpha': 0.00940327542674712}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:31,404] The parameter `n_layers` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,404] The parameter `n_neurons_0` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,405] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,405] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,406] The parameter `learning_rate_init` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,406] The parameter `alpha` in Trial#42 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:31,591] Trial 42 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0032118582525883237, 'alpha': 0.0005656127243812504}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:31,664] The parameter `n_layers` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,664] The parameter `n_neurons_0` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,664] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,669] The parameter `learning_rate_init` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:31,669] The parameter `alpha` in Trial#43 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:32,417] Trial 43 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0064969387159423365, 'alpha': 0.0001668764162919581}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:32,490] The parameter `n_layers` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:32,490] The parameter `n_neurons_0` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:32,490] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:32,490] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:32,490] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:32,496] The parameter `learning_rate_init` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:32,496] The parameter `alpha` in Trial#44 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:33,940] Trial 44 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 11, 'n_neurons_1': 52, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019880193364014637, 'alpha': 0.003105201294430152}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:34,015] The parameter `n_layers` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:34,015] The parameter `n_neurons_0` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:34,016] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:34,016] The parameter `n_neurons_2` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:34,017] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:34,017] The parameter `learning_rate_init` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:34,017] The parameter `alpha` in Trial#45 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:35,216] Trial 45 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 44, 'n_neurons_2': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.008441994772287123, 'alpha': 0.00010575695778888723}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:35,301] The parameter `n_layers` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,302] The parameter `n_neurons_0` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,302] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,303] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,303] The parameter `n_neurons_3` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,304] The parameter `n_neurons_4` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,304] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,304] The parameter `learning_rate_init` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:35,305] The parameter `alpha` in Trial#46 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:36,709] Trial 46 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 13, 'n_neurons_1': 91, 'n_neurons_2': 58, 'n_neurons_3': 100, 'n_neurons_4': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001112232774304946, 'alpha': 0.0018146683984526406}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:29:36,777] Trial 47 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:36,879] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:36,880] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:36,881] The parameter `n_neurons_1` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:36,882] The parameter `n_neurons_2` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:36,882] The parameter `n_neurons_3` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:36,883] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:36,883] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:36,884] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:38,192] Trial 48 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 51, 'n_neurons_1': 67, 'n_neurons_2': 63, 'n_neurons_3': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007958348774085428, 'alpha': 0.006032920019762461}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:38,284] The parameter `n_layers` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:38,285] The parameter `n_neurons_0` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:38,286] The parameter `n_neurons_1` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:38,286] The parameter `n_neurons_2` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:38,287] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:38,287] The parameter `learning_rate_init` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:38,287] The parameter `alpha` in Trial#49 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:29:39,601] Trial 49 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 66, 'n_neurons_1': 35, 'n_neurons_2': 27, 'learning_rate': 'constant', 'learning_rate_init': 0.0014699827002313925, 'alpha': 0.00014304387745680657}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:29:39,697] Trial 50 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:39,809] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,811] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,811] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,812] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,813] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,813] The parameter `n_neurons_4` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,815] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,815] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:39,816] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:40,504] Trial 51 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 99, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.006635205362126859, 'alpha': 0.004416461875953999}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:40,580] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,580] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,582] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,582] The parameter `n_neurons_2` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,582] The parameter `n_neurons_3` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,584] The parameter `n_neurons_4` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,584] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,584] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:40,586] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:42,214] Trial 52 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 76, 'n_neurons_1': 65, 'n_neurons_2': 48, 'n_neurons_3': 94, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0005661437715302432, 'alpha': 0.004179329972699849}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:42,292] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,293] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,294] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,294] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,295] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,296] The parameter `n_neurons_4` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,296] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,296] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:42,297] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:43,120] Trial 53 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 23, 'n_neurons_1': 64, 'n_neurons_2': 44, 'n_neurons_3': 98, 'n_neurons_4': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0006755212335411566, 'alpha': 0.00035222010634042685}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:43,187] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,188] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,189] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,189] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,190] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:43,842] Trial 54 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.009846313836604142, 'alpha': 0.0012908132395505268}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:43,912] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,913] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,913] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,914] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,914] The parameter `n_neurons_3` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,915] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,915] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:43,915] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:45,819] Trial 55 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 95, 'n_neurons_1': 87, 'n_neurons_2': 32, 'n_neurons_3': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0016306068743545592, 'alpha': 0.00028660621978595627}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:45,902] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:45,904] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:45,904] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:45,906] The parameter `n_neurons_2` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:45,907] The parameter `n_neurons_3` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:45,907] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:45,907] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:45,908] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:47,359] Trial 56 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 42, 'n_neurons_2': 20, 'n_neurons_3': 71, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010973041007839744, 'alpha': 0.005062476271565486}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:47,424] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:47,425] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:47,427] The parameter `n_neurons_1` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:47,427] The parameter `n_neurons_2` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:47,427] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:47,428] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:47,428] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:48,768] Trial 57 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 89, 'n_neurons_2': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.003237982605211301, 'alpha': 0.001740279894124974}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:29:48,847] Trial 58 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:48,955] The parameter `n_layers` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:48,957] The parameter `n_neurons_0` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:48,958] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:48,959] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:48,959] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:48,960] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:48,960] The parameter `learning_rate_init` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:48,960] The parameter `alpha` in Trial#59 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:49,658] Trial 59 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 29, 'n_neurons_1': 22, 'n_neurons_2': 11, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0007498076102892463, 'alpha': 0.006431575749069943}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:49,723] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:49,723] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:49,724] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:49,724] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:49,725] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:49,725] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:50,600] Trial 60 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005305513421197475, 'alpha': 0.007925766022280026}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:50,681] The parameter `n_layers` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:50,682] The parameter `n_neurons_0` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:50,682] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:50,683] The parameter `learning_rate_init` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:50,683] The parameter `alpha` in Trial#61 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:52,019] Trial 61 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0008284599389099161, 'alpha': 0.009121476646815571}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:52,099] The parameter `n_layers` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:52,100] The parameter `n_neurons_0` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:52,101] The parameter `n_neurons_1` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:52,102] The parameter `n_neurons_2` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:52,102] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:52,103] The parameter `learning_rate_init` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:52,103] The parameter `alpha` in Trial#62 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:53,605] Trial 62 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 39, 'n_neurons_1': 67, 'n_neurons_2': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018033983912317568, 'alpha': 0.0002012822076129274}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:53,686] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:53,686] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:53,686] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:53,686] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:53,686] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:54,507] Trial 63 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0062169420588097215, 'alpha': 0.000886999307004117}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:54,596] The parameter `n_layers` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:54,596] The parameter `n_neurons_0` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:54,596] The parameter `n_neurons_1` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:54,601] The parameter `n_neurons_2` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:54,601] The parameter `n_neurons_3` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:54,601] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:54,601] The parameter `learning_rate_init` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:54,601] The parameter `alpha` in Trial#64 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:56,104] Trial 64 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 25, 'n_neurons_1': 27, 'n_neurons_2': 13, 'n_neurons_3': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0001504544604259194, 'alpha': 0.000174289707961261}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:56,186] The parameter `n_layers` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:56,187] The parameter `n_neurons_0` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:56,187] The parameter `n_neurons_1` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:56,188] The parameter `n_neurons_2` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:56,188] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:56,189] The parameter `learning_rate_init` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:56,189] The parameter `alpha` in Trial#65 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:57,631] Trial 65 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 43, 'n_neurons_2': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.003970276908151301, 'alpha': 0.0018021908442002565}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:57,708] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:57,708] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:57,708] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:57,708] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:57,708] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:58,032] Trial 66 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00035789472410260544, 'alpha': 0.004096401906445582}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:58,104] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,104] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,104] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,108] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,108] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,109] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,109] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,110] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:58,501] Trial 67 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 26, 'n_neurons_1': 29, 'n_neurons_2': 43, 'n_neurons_3': 54, 'learning_rate': 'constant', 'learning_rate_init': 0.0008415296693542193, 'alpha': 0.003125661016787662}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:58,576] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,576] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,576] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,576] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,576] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:29:58,773] Trial 68 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010552488419684378, 'alpha': 0.0011593831134486484}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:29:58,839] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,839] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,839] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,845] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:29:58,845] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:00,226] Trial 69 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 50, 'learning_rate': 'constant', 'learning_rate_init': 0.0003455305583136833, 'alpha': 0.0005682877914899339}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:00,299] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:00,300] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:00,300] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:00,302] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:00,302] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:01,666] Trial 70 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 39, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017358982432215278, 'alpha': 0.006040245096887873}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:01,741] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:01,741] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:01,742] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:01,743] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:01,743] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:01,743] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:01,744] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:03,058] Trial 71 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 71, 'n_neurons_1': 81, 'n_neurons_2': 55, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014917025634138866, 'alpha': 0.0030965560706362177}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:03,142] The parameter `n_layers` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:03,143] The parameter `n_neurons_0` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:03,144] The parameter `n_neurons_1` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:03,144] The parameter `n_neurons_2` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:03,145] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:03,145] The parameter `learning_rate_init` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:03,146] The parameter `alpha` in Trial#72 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:04,259] Trial 72 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 21, 'n_neurons_1': 35, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.0005154581987502424, 'alpha': 0.009397893033412784}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:04,330] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:04,330] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:04,332] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:04,332] The parameter `n_neurons_2` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:04,332] The parameter `n_neurons_3` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:04,332] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:04,334] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:04,334] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:05,396] Trial 73 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 31, 'n_neurons_1': 19, 'n_neurons_2': 23, 'n_neurons_3': 32, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00037169809679792504, 'alpha': 0.00022220160448344761}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:05,461] The parameter `n_layers` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,467] The parameter `n_neurons_0` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,467] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,468] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,468] The parameter `n_neurons_3` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,469] The parameter `n_neurons_4` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,469] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,470] The parameter `learning_rate_init` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:05,470] The parameter `alpha` in Trial#74 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:06,725] Trial 74 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 17, 'n_neurons_1': 57, 'n_neurons_2': 47, 'n_neurons_3': 99, 'n_neurons_4': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005382874466428148, 'alpha': 0.004306695255529367}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:06,793] The parameter `n_layers` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:06,794] The parameter `n_neurons_0` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:06,795] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:06,795] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:06,796] The parameter `learning_rate_init` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:06,797] The parameter `alpha` in Trial#75 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:07,688] Trial 75 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 25, 'n_neurons_1': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.001390674140149984, 'alpha': 0.0003630431002952846}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:07,767] The parameter `n_layers` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:07,769] The parameter `n_neurons_0` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:07,769] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:07,769] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:07,770] The parameter `n_neurons_3` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:07,770] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:07,770] The parameter `learning_rate_init` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:07,770] The parameter `alpha` in Trial#76 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:09,378] Trial 76 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 27, 'n_neurons_1': 39, 'n_neurons_2': 48, 'n_neurons_3': 56, 'learning_rate': 'constant', 'learning_rate_init': 0.001664332465507855, 'alpha': 0.000377799263089713}. Best is trial 2 with value: 0.92.\n",
      "[I 2025-12-28 19:30:09,467] Trial 77 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:09,588] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:09,589] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:09,590] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:09,591] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:09,591] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:09,592] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:09,593] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:11,125] Trial 78 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 24, 'n_neurons_1': 53, 'n_neurons_2': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001857074616553881, 'alpha': 0.0001338905547392675}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:11,211] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,212] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,213] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,213] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,214] The parameter `n_neurons_3` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,215] The parameter `n_neurons_4` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,215] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,215] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:11,216] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:11,961] Trial 79 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 83, 'n_neurons_2': 33, 'n_neurons_3': 72, 'n_neurons_4': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.000666318433858052, 'alpha': 0.0004985819284806489}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `n_layers` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `n_neurons_0` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `n_neurons_1` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `n_neurons_2` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `n_neurons_3` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `n_neurons_4` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `learning_rate_init` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:12,033] The parameter `alpha` in Trial#80 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:13,695] Trial 80 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 85, 'n_neurons_1': 97, 'n_neurons_2': 21, 'n_neurons_3': 76, 'n_neurons_4': 95, 'learning_rate': 'constant', 'learning_rate_init': 0.0030355773144056086, 'alpha': 0.0014091143133651608}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:13,781] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,781] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,782] The parameter `n_neurons_1` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,783] The parameter `n_neurons_2` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,783] The parameter `n_neurons_3` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,784] The parameter `n_neurons_4` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,784] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,785] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:13,785] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:15,179] Trial 81 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 82, 'n_neurons_2': 28, 'n_neurons_3': 24, 'n_neurons_4': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011120667338401567, 'alpha': 0.0005219885398322653}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:15,264] The parameter `n_layers` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,264] The parameter `n_neurons_0` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,265] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,265] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,266] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,266] The parameter `n_neurons_4` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,267] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,267] The parameter `learning_rate_init` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:15,267] The parameter `alpha` in Trial#82 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:16,708] Trial 82 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 45, 'n_neurons_1': 84, 'n_neurons_2': 49, 'n_neurons_3': 44, 'n_neurons_4': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010126066617091951, 'alpha': 0.0002913569554515852}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:16,781] The parameter `n_layers` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,782] The parameter `n_neurons_0` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,784] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,784] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,784] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,785] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,785] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,786] The parameter `learning_rate_init` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:16,786] The parameter `alpha` in Trial#83 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:18,370] Trial 83 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 44, 'n_neurons_1': 59, 'n_neurons_2': 92, 'n_neurons_3': 66, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.00046753187944355057, 'alpha': 0.00018990838710732203}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:18,455] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:18,456] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:18,457] The parameter `n_neurons_1` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:18,458] The parameter `n_neurons_2` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:18,458] The parameter `n_neurons_3` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:18,458] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:18,459] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:18,459] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:19,578] Trial 84 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 58, 'n_neurons_2': 91, 'n_neurons_3': 81, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00031403516315342447, 'alpha': 0.0030753360921253873}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:19,669] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:19,670] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:19,671] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:19,672] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:19,672] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:21,034] Trial 85 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004832406918522534, 'alpha': 0.0043905063473000955}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:21,114] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,116] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,116] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,118] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,118] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:21,736] Trial 86 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003931793782370637, 'alpha': 0.00019945037385407478}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:21,807] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,807] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,812] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,812] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,813] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:21,814] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:23,040] Trial 87 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 75, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012174437001359676, 'alpha': 0.00031885858743643943}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:23,148] The parameter `n_layers` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:23,150] The parameter `n_neurons_0` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:23,151] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:23,151] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:23,152] The parameter `learning_rate_init` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:23,152] The parameter `alpha` in Trial#88 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:24,122] Trial 88 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.000839482422872308, 'alpha': 0.007844525502343443}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:24,188] The parameter `n_layers` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:24,189] The parameter `n_neurons_0` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:24,190] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:24,190] The parameter `learning_rate_init` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:24,190] The parameter `alpha` in Trial#89 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:25,548] Trial 89 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001086977032427697, 'alpha': 0.005549422847797102}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `n_neurons_4` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,631] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:25,635] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:27,721] Trial 90 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 61, 'n_neurons_1': 73, 'n_neurons_2': 93, 'n_neurons_3': 74, 'n_neurons_4': 23, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007051172552124139, 'alpha': 0.0029709029926915354}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:27,811] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,811] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,812] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,812] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,813] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,813] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,814] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,814] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:27,815] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:28,652] Trial 91 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 94, 'n_neurons_1': 51, 'n_neurons_2': 20, 'n_neurons_3': 99, 'n_neurons_4': 86, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005492786568761941, 'alpha': 0.0010906266715261731}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:28,721] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:28,722] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:28,722] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:28,723] The parameter `n_neurons_2` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:28,723] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:28,724] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:28,724] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:29,988] Trial 92 finished with value: 0.8733333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 14, 'n_neurons_2': 40, 'learning_rate': 'constant', 'learning_rate_init': 0.0004645135033311032, 'alpha': 0.0006256585548186114}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:30,061] The parameter `n_layers` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:30,062] The parameter `n_neurons_0` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:30,062] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:30,062] The parameter `n_neurons_2` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:30,062] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:30,062] The parameter `learning_rate_init` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:30,062] The parameter `alpha` in Trial#93 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:31,097] Trial 93 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 93, 'n_neurons_1': 41, 'n_neurons_2': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.0002813258539870692, 'alpha': 0.0008033023403902318}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:31,161] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,162] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,162] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,163] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,163] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:31,919] Trial 94 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.006756033620862479, 'alpha': 0.0005306251107511992}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:31,994] The parameter `n_layers` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,994] The parameter `n_neurons_0` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,995] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,995] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,996] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,996] The parameter `learning_rate_init` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:31,997] The parameter `alpha` in Trial#95 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:32,782] Trial 95 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 11, 'n_neurons_2': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00019830125168914512, 'alpha': 0.0006749137054804921}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:32,851] The parameter `n_layers` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:32,852] The parameter `n_neurons_0` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:32,852] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:32,853] The parameter `learning_rate_init` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:32,853] The parameter `alpha` in Trial#96 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:34,262] Trial 96 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 100, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013619242560057148, 'alpha': 0.0031617020498319144}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:34,344] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:34,344] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:34,346] The parameter `n_neurons_1` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:34,347] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:34,347] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:34,347] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:35,623] Trial 97 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 91, 'n_neurons_1': 28, 'learning_rate': 'constant', 'learning_rate_init': 0.0008792935556463842, 'alpha': 0.0013479763309946922}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:35,696] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:35,697] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:35,697] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:35,698] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:35,698] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:36,937] Trial 98 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007612468242681232, 'alpha': 0.0006331784446999807}. Best is trial 2 with value: 0.92.\n",
      "[W 2025-12-28 19:30:37,020] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:37,021] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:37,021] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:37,022] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:37,022] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:37,023] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:37,023] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `GPSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space is not supported by GPSampler. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `GPSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:38,019] Trial 99 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 24, 'n_neurons_1': 26, 'n_neurons_2': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0003479279724953084, 'alpha': 0.0019408817950172534}. Best is trial 2 with value: 0.92.\n",
      "\n",
      "Selected Base Models for Stacking using GPSampler:\n",
      "- Random Forest\n",
      "- K-Nearest Neighbors\n",
      "- Support Vector Machine\n",
      "Best Hyperparameters for Meta Model (MLP) using GPSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.004544383960336014, 'alpha': 0.0005170191786366995, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (39,), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9200, at trial: 2\n",
      "GP base models training time: 182.45 seconds\n",
      "GP SEl-NNML Training Time: 120.71 seconds\n",
      "Total GP Training Time (Base + Meta): 303.15 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    gp_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    gp_sel_nnml, gp_meta_study = meta_model_tuning(base_models['GP'], X_train, y_train, X_test, y_test, sampler='GPSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    gp_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    gp_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for GP SEl-NNML training\n",
    "    gp_meta_model_training_time = gp_meta_model_training_end - gp_meta_model_training_start\n",
    "    print(f'GP base models training time: {gp_base_models_training_time:.2f} seconds')\n",
    "    print(f'GP SEl-NNML Training Time: {gp_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total GP Training Time (Base + Meta): {gp_base_models_training_time + gp_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    gp_meta_history = gp_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    gp_meta_history.columns = ['iteration', 'score']\n",
    "    gp_meta_history['iteration'] = gp_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping GP meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 CMA-ES & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:38,831] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (CmaEsSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b407463abb5e483dbc97db95f025d529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:40,390] Trial 0 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9066666666666666.\n",
      "[W 2025-12-28 19:30:40,394] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,394] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,395] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,397] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,397] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,398] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,398] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,399] The parameter `n_neurons_1` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:40,400] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:41,296] Trial 1 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.0005404052553935483, 'alpha': 0.000865808466690932}. Best is trial 0 with value: 0.9066666666666666.\n",
      "[W 2025-12-28 19:30:41,300] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,301] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,301] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,302] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,302] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,303] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,303] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,304] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:41,304] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:42,020] Trial 2 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 72, 'n_neurons_1': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0004843830630951302, 'alpha': 0.0009528924787594206}. Best is trial 2 with value: 0.9133333333333333.\n",
      "[W 2025-12-28 19:30:42,024] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,024] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,027] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,027] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,027] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,027] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,027] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,027] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,030] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,030] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:42,324] Trial 3 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 46, 'n_neurons_1': 16, 'n_neurons_2': 99, 'learning_rate': 'constant', 'learning_rate_init': 0.001284803071084827, 'alpha': 0.002651575859618515}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:42,328] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,330] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,331] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,331] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,332] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,332] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,334] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,334] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,335] The parameter `n_neurons_2` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:42,336] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:30:43,862] Trial 4 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 51, 'n_neurons_1': 76, 'n_neurons_2': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.0010997756098965073, 'alpha': 0.00010702593573937491}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:43,867] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,867] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,868] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,869] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,869] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,870] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,870] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,871] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,871] The parameter `n_neurons_2` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,872] The parameter `n_neurons_3` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:43,873] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:44,731] Trial 5 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 79, 'n_neurons_1': 92, 'n_neurons_2': 32, 'n_neurons_3': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00037679762657228646, 'alpha': 0.001966714163929435}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:44,735] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,735] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,736] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,737] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,737] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,738] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,738] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,739] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,739] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:44,740] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:46,326] Trial 6 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 29, 'n_neurons_1': 20, 'n_neurons_2': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045488589409482236, 'alpha': 0.0023404594415393147}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:46,329] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,331] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,331] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,331] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,331] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,333] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,333] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,333] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:46,335] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:47,859] Trial 7 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 38, 'n_neurons_1': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.00039738988185359975, 'alpha': 0.00195965433079867}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:47,863] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,864] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,865] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,865] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,866] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,866] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,867] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,867] The parameter `n_neurons_1` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:47,868] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:48,697] Trial 8 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 60, 'n_neurons_1': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.0022097738266210138, 'alpha': 0.00281718805195577}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:48,701] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,702] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,703] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,703] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,704] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,704] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,705] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,705] The parameter `n_neurons_1` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,705] The parameter `n_neurons_2` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:48,706] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:49,564] Trial 9 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 41, 'n_neurons_1': 25, 'n_neurons_2': 72, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005745972997148793, 'alpha': 0.0019575774647489796}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:49,567] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,567] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,568] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,569] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,569] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,570] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,570] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,571] The parameter `n_neurons_1` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:49,571] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:50,436] Trial 10 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 24, 'n_neurons_1': 67, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006280678796519294, 'alpha': 0.001781828824105039}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:50,439] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,440] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,441] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,442] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,443] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,443] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,443] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,444] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,445] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,445] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,446] The parameter `n_neurons_4` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:50,446] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:51,474] Trial 11 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 26, 'n_neurons_1': 59, 'n_neurons_2': 72, 'n_neurons_3': 69, 'n_neurons_4': 30, 'learning_rate': 'constant', 'learning_rate_init': 0.000716400900205931, 'alpha': 0.0008586891456600408}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:51,476] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,476] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,478] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,478] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,478] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,480] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,481] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,481] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,482] The parameter `n_neurons_2` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:51,482] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:53,216] Trial 12 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 26, 'n_neurons_1': 82, 'n_neurons_2': 55, 'learning_rate': 'constant', 'learning_rate_init': 0.0018809766017783883, 'alpha': 0.001584017558262431}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:53,219] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,220] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,221] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,221] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,222] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,222] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,223] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,223] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,224] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:53,884] Trial 13 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 97, 'learning_rate': 'constant', 'learning_rate_init': 0.00041681945369010086, 'alpha': 0.004673977652227276}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:53,887] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,888] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,888] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,889] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,890] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,890] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,890] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,891] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,892] The parameter `n_neurons_2` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,892] The parameter `n_neurons_3` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:53,892] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:55,080] Trial 14 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 45, 'n_neurons_1': 77, 'n_neurons_2': 73, 'n_neurons_3': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.0010547235195909094, 'alpha': 0.0013758482508785552}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:55,084] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,085] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,086] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,086] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,087] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,088] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,088] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,089] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,089] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:55,090] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:56,799] Trial 15 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 31, 'n_neurons_1': 62, 'n_neurons_2': 13, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014049484748932346, 'alpha': 0.0018814433730436383}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:56,802] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,803] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,803] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,804] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,805] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,805] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,806] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,806] The parameter `n_neurons_1` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,807] The parameter `n_neurons_2` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:56,807] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:57,722] Trial 16 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 62, 'n_neurons_1': 59, 'n_neurons_2': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00032490032108445664, 'alpha': 0.0037441885856741284}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:57,730] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,730] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,730] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,732] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,733] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,733] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,734] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,734] The parameter `n_neurons_1` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,735] The parameter `n_neurons_2` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,735] The parameter `n_neurons_3` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:57,735] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:30:59,244] Trial 17 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 48, 'n_neurons_1': 59, 'n_neurons_2': 75, 'n_neurons_3': 70, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017114093944764147, 'alpha': 0.0012645199758054967}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:30:59,254] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,254] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,254] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,256] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,256] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,257] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,257] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,258] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,258] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,259] The parameter `n_neurons_3` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:30:59,263] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:31:01,205] Trial 18 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 18, 'n_neurons_1': 18, 'n_neurons_2': 54, 'n_neurons_3': 53, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005558322035341868, 'alpha': 0.00332927011097507}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:01,209] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,209] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,210] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,211] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,211] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,213] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,213] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,214] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,215] The parameter `n_neurons_2` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,215] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:01,527] Trial 19 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 35, 'n_neurons_1': 95, 'n_neurons_2': 62, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004601043140764359, 'alpha': 0.0025546515106749817}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:01,530] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,531] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,531] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,532] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,532] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,533] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,533] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,534] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,535] The parameter `n_neurons_2` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,536] The parameter `n_neurons_3` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:01,536] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:02,734] Trial 20 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 35, 'n_neurons_1': 86, 'n_neurons_2': 12, 'n_neurons_3': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.0011086441376895338, 'alpha': 0.0004189071022052665}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:02,743] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,743] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,744] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,745] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,745] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,745] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,747] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,747] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,747] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:02,749] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:04,780] Trial 21 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 40, 'n_neurons_1': 94, 'n_neurons_2': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0011838955808780147, 'alpha': 0.0016431963941249297}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:04,783] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,784] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,784] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,785] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,785] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,786] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,786] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,786] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,788] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,788] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:04,788] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:05,663] Trial 22 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 30, 'n_neurons_1': 62, 'n_neurons_2': 67, 'n_neurons_3': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009808302023474001, 'alpha': 0.000924755627532275}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:05,666] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,667] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,667] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,668] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,668] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,668] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,669] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,671] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,671] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,672] The parameter `n_neurons_3` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:05,673] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:06,732] Trial 23 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 20, 'n_neurons_1': 66, 'n_neurons_2': 19, 'n_neurons_3': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.0009647967215763746, 'alpha': 0.0016410205882129508}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:06,735] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,736] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,737] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,737] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,738] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,738] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,739] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,739] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,740] The parameter `n_neurons_2` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,740] The parameter `n_neurons_3` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,741] The parameter `n_neurons_4` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:06,741] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:07,650] Trial 24 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 47, 'n_neurons_1': 60, 'n_neurons_2': 48, 'n_neurons_3': 92, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.0015211602281344672, 'alpha': 0.0006235090869126785}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:07,654] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,655] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,655] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,655] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,657] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,658] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,658] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,659] The parameter `n_neurons_1` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,659] The parameter `n_neurons_2` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:07,659] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:09,384] Trial 25 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 35, 'n_neurons_1': 98, 'n_neurons_2': 13, 'learning_rate': 'constant', 'learning_rate_init': 0.00042552414799568557, 'alpha': 0.0015986541434541719}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:09,387] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,388] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,389] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,389] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,390] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,390] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,390] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,392] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,393] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,394] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:09,394] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:10,408] Trial 26 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 24, 'n_neurons_1': 91, 'n_neurons_2': 51, 'n_neurons_3': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0012230359361445424, 'alpha': 0.0005886505334077448}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:10,411] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,412] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,413] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,414] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,414] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,415] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,415] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,416] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,417] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,417] The parameter `n_neurons_3` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:10,419] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:12,595] Trial 27 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 38, 'n_neurons_1': 96, 'n_neurons_2': 76, 'n_neurons_3': 65, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007539711933825463, 'alpha': 0.0009352140464432247}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:12,599] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,600] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,600] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,601] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,601] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,602] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,602] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,604] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,604] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,604] The parameter `n_neurons_3` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:12,604] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:14,282] Trial 28 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 34, 'n_neurons_2': 15, 'n_neurons_3': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00047145274552012114, 'alpha': 0.0006289349740129255}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:14,286] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,286] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,287] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,288] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,288] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,289] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,289] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,290] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,290] The parameter `n_neurons_2` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,291] The parameter `n_neurons_3` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:14,291] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:15,990] Trial 29 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 15, 'n_neurons_1': 20, 'n_neurons_2': 71, 'n_neurons_3': 57, 'learning_rate': 'constant', 'learning_rate_init': 0.00015281848871821435, 'alpha': 0.003515891464953707}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:15,993] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,994] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,994] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,995] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,996] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,996] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,997] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,997] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,998] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,998] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,999] The parameter `n_neurons_4` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:15,999] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:17,111] Trial 30 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 50, 'n_neurons_1': 63, 'n_neurons_2': 45, 'n_neurons_3': 49, 'n_neurons_4': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.001555700585117209, 'alpha': 0.001624187830338479}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:17,115] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,115] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,116] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,117] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,117] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,118] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,118] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,119] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,119] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:17,120] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:18,037] Trial 31 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 41, 'n_neurons_1': 31, 'n_neurons_2': 16, 'learning_rate': 'constant', 'learning_rate_init': 0.0019865614606632944, 'alpha': 0.0008095564206479296}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:18,041] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,042] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,042] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,043] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,044] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,044] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,044] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,045] The parameter `n_neurons_1` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,046] The parameter `n_neurons_2` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,046] The parameter `n_neurons_3` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,047] The parameter `n_neurons_4` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:18,047] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:19,855] Trial 32 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 40, 'n_neurons_1': 18, 'n_neurons_2': 20, 'n_neurons_3': 51, 'n_neurons_4': 28, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008922635535943204, 'alpha': 0.0040210389410807275}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:19,859] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,861] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,861] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,862] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,862] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,863] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,863] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,864] The parameter `n_neurons_1` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,865] The parameter `n_neurons_2` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,865] The parameter `n_neurons_3` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:19,866] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:21,051] Trial 33 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 44, 'n_neurons_1': 54, 'n_neurons_2': 66, 'n_neurons_3': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006201647089703917, 'alpha': 0.0006307545708588312}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:21,054] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,055] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,057] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,058] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,059] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,059] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,060] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:21,060] Trial 34 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:21,061] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,062] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,063] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,064] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,064] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,064] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,065] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,065] The parameter `n_layers` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,066] The parameter `n_neurons_0` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,066] The parameter `n_neurons_1` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,067] The parameter `learning_rate` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,068] The parameter `learning_rate_init` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:21,068] The parameter `alpha` in Trial#35 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:22,480] Trial 35 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.009397893033412784, 'alpha': 0.0016276073362367096}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:22,482] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,483] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,483] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,484] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,485] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,486] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,486] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,487] The parameter `n_layers` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,487] The parameter `n_neurons_0` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,488] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,488] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,489] The parameter `learning_rate_init` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:22,489] The parameter `alpha` in Trial#36 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:24,136] Trial 36 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 98, 'n_neurons_1': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00021967223808979652, 'alpha': 0.002174134661221694}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:24,138] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,139] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,139] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,139] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,140] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,140] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,141] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,142] The parameter `n_layers` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,142] The parameter `n_neurons_0` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,143] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,143] The parameter `learning_rate_init` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,144] The parameter `alpha` in Trial#37 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:24,739] Trial 37 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 53, 'learning_rate': 'constant', 'learning_rate_init': 0.00047120355289221097, 'alpha': 0.0001857074616553881}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:24,742] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,743] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,743] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,744] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,744] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,745] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,745] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,746] The parameter `n_layers` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,746] The parameter `n_neurons_0` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,747] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,748] The parameter `learning_rate_init` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:24,748] The parameter `alpha` in Trial#38 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:31:25,147] Trial 38 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 76, 'learning_rate': 'constant', 'learning_rate_init': 0.0001358290098179413, 'alpha': 0.0030355773144056086}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:25,150] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,151] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,151] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,152] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,152] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,153] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,153] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,154] The parameter `n_layers` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,155] The parameter `n_neurons_0` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,155] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,155] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,156] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,156] The parameter `learning_rate_init` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,157] The parameter `alpha` in Trial#39 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:25,850] Trial 39 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 44, 'n_neurons_1': 52, 'n_neurons_2': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0002913569554515852, 'alpha': 0.006297224066462152}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:25,852] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,853] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,853] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,854] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,854] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,855] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,855] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,856] The parameter `n_layers` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,856] The parameter `n_neurons_0` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,857] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,857] The parameter `learning_rate_init` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:25,858] The parameter `alpha` in Trial#40 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:31:27,381] Trial 40 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011669839134877905, 'alpha': 0.001379683179966857}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:27,384] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,385] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,385] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,386] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,386] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,387] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,387] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,388] The parameter `n_layers` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,388] The parameter `n_neurons_0` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,389] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,389] The parameter `n_neurons_2` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,390] The parameter `n_neurons_3` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,390] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,390] The parameter `learning_rate_init` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:27,390] The parameter `alpha` in Trial#41 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:29,174] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 59, 'n_neurons_1': 32, 'n_neurons_2': 41, 'n_neurons_3': 26, 'learning_rate': 'constant', 'learning_rate_init': 0.0006334361335708596, 'alpha': 0.000839482422872308}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:29,177] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,177] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,178] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,179] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,180] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,180] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,181] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,181] The parameter `n_layers` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,181] The parameter `n_neurons_0` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,181] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,183] The parameter `n_neurons_2` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,183] The parameter `n_neurons_3` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,183] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,184] The parameter `learning_rate_init` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:29,184] The parameter `alpha` in Trial#42 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:30,009] Trial 42 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 48, 'n_neurons_1': 77, 'n_neurons_2': 95, 'n_neurons_3': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.009325720560052549, 'alpha': 0.004762074362660966}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:30,011] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,012] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,012] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,014] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,014] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,015] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,015] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,016] The parameter `n_layers` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,016] The parameter `n_neurons_0` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,017] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,017] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,018] The parameter `learning_rate_init` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,018] The parameter `alpha` in Trial#43 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:30,619] Trial 43 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 41, 'n_neurons_1': 77, 'learning_rate': 'constant', 'learning_rate_init': 0.0008033023403902318, 'alpha': 0.00019129959067239522}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:30,621] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,622] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,622] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,623] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,623] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,624] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,624] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,625] The parameter `n_layers` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,625] The parameter `n_neurons_0` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,626] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,626] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,627] The parameter `n_neurons_3` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,627] The parameter `n_neurons_4` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,628] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,628] The parameter `learning_rate_init` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:30,629] The parameter `alpha` in Trial#44 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:32,284] Trial 44 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 55, 'n_neurons_1': 64, 'n_neurons_2': 16, 'n_neurons_3': 78, 'n_neurons_4': 29, 'learning_rate': 'constant', 'learning_rate_init': 0.0002406442235725018, 'alpha': 0.00011833121824597717}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:32,285] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,286] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,287] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,287] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,288] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,288] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,289] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,289] The parameter `n_layers` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,289] The parameter `n_neurons_0` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,289] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,289] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,292] The parameter `learning_rate_init` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:32,292] The parameter `alpha` in Trial#45 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:33,833] Trial 45 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 68, 'n_neurons_1': 47, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0027036125745955072, 'alpha': 0.0020789683791670155}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:33,836] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,836] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,837] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,837] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,838] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,838] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,839] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,840] The parameter `n_layers` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,840] The parameter `n_neurons_0` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,841] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,841] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,842] The parameter `n_neurons_3` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,842] The parameter `n_neurons_4` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,843] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,843] The parameter `learning_rate_init` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:33,844] The parameter `alpha` in Trial#46 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:34,249] Trial 46 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 46, 'n_neurons_1': 70, 'n_neurons_2': 28, 'n_neurons_3': 36, 'n_neurons_4': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002604788766691677, 'alpha': 0.00011299634807122736}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:34,251] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,251] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,252] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,252] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,254] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,254] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,254] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,255] The parameter `n_layers` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,256] The parameter `n_neurons_0` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,256] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,257] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,257] The parameter `learning_rate_init` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:34,258] The parameter `alpha` in Trial#47 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:35,700] Trial 47 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 96, 'n_neurons_1': 79, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000943761803860813, 'alpha': 0.006153248489920153}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:35,702] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,702] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,704] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,704] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,705] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,705] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,705] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,706] The parameter `n_layers` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,707] The parameter `n_neurons_0` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,707] The parameter `n_neurons_1` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,708] The parameter `n_neurons_2` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,708] The parameter `n_neurons_3` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,709] The parameter `n_neurons_4` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,709] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,709] The parameter `learning_rate_init` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:35,710] The parameter `alpha` in Trial#48 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:37,546] Trial 48 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 20, 'n_neurons_1': 62, 'n_neurons_2': 34, 'n_neurons_3': 60, 'n_neurons_4': 69, 'learning_rate': 'constant', 'learning_rate_init': 0.00010519416661057535, 'alpha': 0.00018783272544168123}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:37,549] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,549] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,550] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,550] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,551] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,552] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,552] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,552] The parameter `n_layers` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,554] The parameter `n_neurons_0` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,554] The parameter `n_neurons_1` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,555] The parameter `n_neurons_2` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,555] The parameter `n_neurons_3` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,555] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,556] The parameter `learning_rate_init` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:37,556] The parameter `alpha` in Trial#49 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:39,280] Trial 49 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 45, 'n_neurons_2': 36, 'n_neurons_3': 42, 'learning_rate': 'constant', 'learning_rate_init': 0.0013577170773699243, 'alpha': 0.0008955726134171263}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:39,283] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,285] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,285] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,286] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,286] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,286] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,288] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,289] The parameter `n_layers` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,290] The parameter `n_neurons_0` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,290] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,290] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,290] The parameter `n_neurons_3` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,292] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,292] The parameter `learning_rate_init` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:39,292] The parameter `alpha` in Trial#50 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:40,709] Trial 50 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 55, 'n_neurons_1': 72, 'n_neurons_2': 49, 'n_neurons_3': 32, 'learning_rate': 'constant', 'learning_rate_init': 0.0024512801122407576, 'alpha': 0.00035017914213813497}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:40,711] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,712] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,713] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,713] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,714] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,715] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,715] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,716] The parameter `n_layers` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,716] The parameter `n_neurons_0` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,717] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,717] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,718] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,719] The parameter `n_neurons_4` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,719] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,720] The parameter `learning_rate_init` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,720] The parameter `alpha` in Trial#51 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:40,946] Trial 51 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 32, 'n_neurons_1': 54, 'n_neurons_2': 30, 'n_neurons_3': 99, 'n_neurons_4': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007087558145736653, 'alpha': 0.00022969454974259052}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:40,948] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,949] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,950] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,950] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,951] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,951] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,952] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,952] The parameter `n_layers` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,953] The parameter `n_neurons_0` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,953] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,954] The parameter `n_neurons_2` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,955] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,955] The parameter `learning_rate_init` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:40,956] The parameter `alpha` in Trial#52 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:42,408] Trial 52 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 30, 'n_neurons_1': 20, 'n_neurons_2': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.002815357452964348, 'alpha': 0.00013511783615174891}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:42,410] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,411] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,412] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,412] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,413] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,414] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,414] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,414] The parameter `n_layers` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,414] The parameter `n_neurons_0` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,414] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,414] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,417] The parameter `n_neurons_3` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,417] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,417] The parameter `learning_rate_init` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,419] The parameter `alpha` in Trial#53 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:42,678] Trial 53 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 100, 'n_neurons_1': 41, 'n_neurons_2': 79, 'n_neurons_3': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005589258917257331, 'alpha': 0.009293235406855402}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:42,680] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,680] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,682] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,682] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,683] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,683] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,684] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,685] The parameter `n_layers` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,685] The parameter `n_neurons_0` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,686] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,686] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,687] The parameter `learning_rate_init` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:42,687] The parameter `alpha` in Trial#54 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:44,367] Trial 54 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 29, 'learning_rate': 'constant', 'learning_rate_init': 0.00015094613753824642, 'alpha': 0.0006841661003247827}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:44,370] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,370] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,371] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,372] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,372] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,373] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,373] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,374] The parameter `n_layers` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,375] The parameter `n_neurons_0` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,375] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,376] The parameter `learning_rate_init` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:44,376] The parameter `alpha` in Trial#55 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:45,122] Trial 55 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.008673717241575788, 'alpha': 0.00585560495923566}. Best is trial 3 with value: 0.92.\n",
      "[W 2025-12-28 19:31:45,125] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,125] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,126] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,126] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,127] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,127] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,128] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,128] The parameter `n_layers` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,129] The parameter `n_neurons_0` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,129] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,130] The parameter `n_neurons_2` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,131] The parameter `n_neurons_3` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,131] The parameter `n_neurons_4` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,132] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,132] The parameter `learning_rate_init` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:45,133] The parameter `alpha` in Trial#56 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:47,222] Trial 56 finished with value: 0.9266666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 34, 'n_neurons_1': 21, 'n_neurons_2': 90, 'n_neurons_3': 96, 'n_neurons_4': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.0012639059001467116, 'alpha': 0.0001492703392407429}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:47,225] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,226] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,226] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,227] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,228] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,228] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,230] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,230] The parameter `n_layers` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,230] The parameter `n_neurons_0` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,232] The parameter `n_neurons_1` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,232] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,233] The parameter `learning_rate_init` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:47,233] The parameter `alpha` in Trial#57 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:48,018] Trial 57 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003934160224360252, 'alpha': 0.0020744533327664858}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:48,020] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,021] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,021] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,022] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,022] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,023] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,024] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,024] The parameter `n_layers` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,024] The parameter `n_neurons_0` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,026] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,027] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,027] The parameter `learning_rate_init` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:48,028] The parameter `alpha` in Trial#58 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:49,430] Trial 58 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 24, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010349883647557926, 'alpha': 0.00010298447122215186}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:49,433] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,433] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,434] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,434] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,434] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,436] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,436] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:49,437] Trial 59 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:49,439] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,440] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,440] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,441] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,441] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,442] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,442] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,443] The parameter `n_layers` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,443] The parameter `n_neurons_0` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,445] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,445] The parameter `n_neurons_2` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,446] The parameter `n_neurons_3` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,446] The parameter `n_neurons_4` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,447] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,447] The parameter `learning_rate_init` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:49,447] The parameter `alpha` in Trial#60 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:50,478] Trial 60 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 78, 'n_neurons_1': 21, 'n_neurons_2': 79, 'n_neurons_3': 12, 'n_neurons_4': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0034738801863753908, 'alpha': 0.002325898471109331}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:50,481] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,482] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,483] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,484] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,484] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,485] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,485] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,486] The parameter `n_layers` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,486] The parameter `n_neurons_0` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,487] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,487] The parameter `learning_rate_init` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:50,487] The parameter `alpha` in Trial#61 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:51,345] Trial 61 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 49, 'learning_rate': 'constant', 'learning_rate_init': 0.0018925697547456676, 'alpha': 0.0006240060436145399}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:51,347] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,348] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,349] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,349] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,351] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,351] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,351] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:51,351] Trial 62 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:51,353] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,354] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,355] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,356] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,357] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,357] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,357] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,357] The parameter `n_layers` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,357] The parameter `n_neurons_0` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,359] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,360] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,360] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,361] The parameter `learning_rate_init` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:51,361] The parameter `alpha` in Trial#63 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:52,242] Trial 63 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 28, 'n_neurons_1': 54, 'n_neurons_2': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.003936572019640482, 'alpha': 0.00041756483518393106}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:52,245] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,246] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,246] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,247] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,247] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,248] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,248] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,249] The parameter `n_layers` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,250] The parameter `n_neurons_0` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,250] The parameter `n_neurons_1` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,250] The parameter `n_neurons_2` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,251] The parameter `n_neurons_3` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,252] The parameter `n_neurons_4` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,252] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,253] The parameter `learning_rate_init` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,253] The parameter `alpha` in Trial#64 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:52,602] Trial 64 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 22, 'n_neurons_1': 55, 'n_neurons_2': 66, 'n_neurons_3': 73, 'n_neurons_4': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010849838825181713, 'alpha': 0.00014987631213878993}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:52,604] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,605] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,606] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,606] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,607] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,607] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,607] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,608] The parameter `n_layers` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,608] The parameter `n_neurons_0` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,609] The parameter `n_neurons_1` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,609] The parameter `n_neurons_2` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,611] The parameter `n_neurons_3` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,611] The parameter `n_neurons_4` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,612] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,612] The parameter `learning_rate_init` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:52,613] The parameter `alpha` in Trial#65 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:53,991] Trial 65 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 59, 'n_neurons_2': 74, 'n_neurons_3': 89, 'n_neurons_4': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.004262360980898247, 'alpha': 0.0001446204447457985}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:53,993] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,995] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,996] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,996] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,997] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,997] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,997] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,998] The parameter `n_layers` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,998] The parameter `n_neurons_0` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:53,998] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,000] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,000] The parameter `learning_rate_init` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,001] The parameter `alpha` in Trial#66 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:54,619] Trial 66 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 81, 'learning_rate': 'constant', 'learning_rate_init': 0.001290408163534379, 'alpha': 0.0027441228904630938}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:54,621] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,621] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,623] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,623] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,624] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,625] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,625] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,626] The parameter `n_layers` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,626] The parameter `n_neurons_0` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,627] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,627] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,627] The parameter `learning_rate_init` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:54,628] The parameter `alpha` in Trial#67 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:56,180] Trial 67 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 43, 'n_neurons_1': 99, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014366494705598603, 'alpha': 0.0007537560974952886}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:56,182] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,183] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,183] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,184] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,184] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,185] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,186] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,186] The parameter `n_layers` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,187] The parameter `n_neurons_0` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,187] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,188] The parameter `n_neurons_2` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,189] The parameter `n_neurons_3` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,189] The parameter `n_neurons_4` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,189] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,190] The parameter `learning_rate_init` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,190] The parameter `alpha` in Trial#68 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:56,793] Trial 68 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 26, 'n_neurons_1': 31, 'n_neurons_2': 98, 'n_neurons_3': 26, 'n_neurons_4': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.005514419516648056, 'alpha': 0.0007773390943180892}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:56,795] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,795] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,796] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,797] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,797] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,797] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,798] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,798] The parameter `n_layers` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,799] The parameter `n_neurons_0` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,800] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,800] The parameter `learning_rate_init` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:56,801] The parameter `alpha` in Trial#69 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:58,164] Trial 69 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.004547437426011357, 'alpha': 0.0007274029320947825}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:58,167] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,168] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,168] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,169] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,169] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,170] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,170] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,170] The parameter `n_layers` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,171] The parameter `n_neurons_0` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,172] The parameter `learning_rate` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,172] The parameter `learning_rate_init` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:58,173] The parameter `alpha` in Trial#70 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:31:59,520] Trial 70 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.007468121665987528, 'alpha': 0.00011986353489802667}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:31:59,522] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,522] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,524] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,524] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,525] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,525] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,526] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,526] The parameter `n_layers` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,526] The parameter `n_neurons_0` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,526] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,529] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,529] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,530] The parameter `learning_rate_init` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:31:59,530] The parameter `alpha` in Trial#71 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:01,198] Trial 71 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 70, 'n_neurons_2': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002566619712518178, 'alpha': 0.0002533418305370726}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:01,200] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,201] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,202] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,202] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,203] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,203] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,203] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:01,204] Trial 72 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:01,205] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,205] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,205] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,205] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,209] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,209] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,210] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,210] The parameter `n_layers` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,211] The parameter `n_neurons_0` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,211] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,211] The parameter `n_neurons_2` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,213] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,213] The parameter `learning_rate_init` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:01,213] The parameter `alpha` in Trial#73 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:02,411] Trial 73 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 89, 'n_neurons_1': 81, 'n_neurons_2': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006431031596032392, 'alpha': 0.00045088555611044626}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:02,413] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,414] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,414] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,415] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,416] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,416] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,417] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:02,417] Trial 74 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:02,419] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,420] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,420] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,421] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,422] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,422] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,423] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,423] The parameter `n_layers` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,424] The parameter `n_neurons_0` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,424] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,425] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,425] The parameter `learning_rate_init` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:02,426] The parameter `alpha` in Trial#75 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:04,153] Trial 75 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 46, 'learning_rate': 'constant', 'learning_rate_init': 0.0016436531848333894, 'alpha': 0.00338662042319669}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:04,156] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,157] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,157] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,158] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,159] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,159] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,159] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,160] The parameter `n_layers` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,161] The parameter `n_neurons_0` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,161] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,162] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,162] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,163] The parameter `learning_rate_init` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:04,163] The parameter `alpha` in Trial#76 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:05,659] Trial 76 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 33, 'n_neurons_1': 35, 'n_neurons_2': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.0004193874191709548, 'alpha': 0.001662139868133609}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:05,661] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,662] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,663] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,663] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,664] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,664] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,665] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,666] The parameter `n_layers` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,666] The parameter `n_neurons_0` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,667] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,667] The parameter `n_neurons_2` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,668] The parameter `n_neurons_3` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,668] The parameter `n_neurons_4` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,669] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,669] The parameter `learning_rate_init` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:05,670] The parameter `alpha` in Trial#77 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:07,957] Trial 77 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 60, 'n_neurons_1': 13, 'n_neurons_2': 67, 'n_neurons_3': 96, 'n_neurons_4': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002858640510403272, 'alpha': 0.00026551537824360454}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:07,960] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,960] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,961] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,961] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,962] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,963] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,963] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,963] The parameter `n_layers` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,964] The parameter `n_neurons_0` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,964] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,964] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,966] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,966] The parameter `learning_rate_init` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:07,966] The parameter `alpha` in Trial#78 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:09,827] Trial 78 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 25, 'n_neurons_1': 77, 'n_neurons_2': 88, 'learning_rate': 'constant', 'learning_rate_init': 0.00011150059170836743, 'alpha': 0.0019228393487042126}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:09,829] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,830] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,831] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,831] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,832] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,833] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,833] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,834] The parameter `n_layers` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,835] The parameter `n_neurons_0` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,835] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,836] The parameter `learning_rate_init` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:09,836] The parameter `alpha` in Trial#79 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:10,596] Trial 79 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.0003534445856055918, 'alpha': 0.0001441579965339067}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:10,598] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,599] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,600] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,600] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,601] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,601] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,602] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:10,602] Trial 80 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:10,604] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,605] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,606] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,607] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,607] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,608] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,608] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,609] The parameter `n_layers` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,609] The parameter `n_neurons_0` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,610] The parameter `n_neurons_1` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,610] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,611] The parameter `learning_rate_init` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:10,612] The parameter `alpha` in Trial#81 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:11,246] Trial 81 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 58, 'n_neurons_1': 18, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004956134097083741, 'alpha': 0.002137093133753237}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:11,248] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,250] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,250] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,251] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,252] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,252] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,253] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,253] The parameter `n_layers` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,254] The parameter `n_neurons_0` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,254] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,255] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,256] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,256] The parameter `n_neurons_4` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,256] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,258] The parameter `learning_rate_init` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:11,258] The parameter `alpha` in Trial#82 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:12,783] Trial 82 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 81, 'n_neurons_1': 74, 'n_neurons_2': 13, 'n_neurons_3': 37, 'n_neurons_4': 33, 'learning_rate': 'constant', 'learning_rate_init': 0.007480241960748882, 'alpha': 0.001281163276357022}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:12,786] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,787] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,788] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,788] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,789] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,789] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,790] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,790] The parameter `n_layers` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,791] The parameter `n_neurons_0` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,791] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,792] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,792] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,793] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,793] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,794] The parameter `learning_rate_init` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:12,794] The parameter `alpha` in Trial#83 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:14,264] Trial 83 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 83, 'n_neurons_2': 81, 'n_neurons_3': 37, 'n_neurons_4': 17, 'learning_rate': 'constant', 'learning_rate_init': 0.0024541560696713445, 'alpha': 0.0004922655605142162}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:14,267] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,268] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,268] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,269] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,270] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,271] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,271] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,271] The parameter `n_layers` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,272] The parameter `n_neurons_0` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,273] The parameter `learning_rate` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,273] The parameter `learning_rate_init` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:14,274] The parameter `alpha` in Trial#84 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:15,109] Trial 84 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 12, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012562008177756832, 'alpha': 0.008543667186048135}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:15,112] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,113] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,113] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,114] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,114] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,115] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,115] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,116] The parameter `n_layers` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,117] The parameter `n_neurons_0` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,117] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,117] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,119] The parameter `n_neurons_3` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,119] The parameter `n_neurons_4` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,120] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,120] The parameter `learning_rate_init` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:15,120] The parameter `alpha` in Trial#85 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:17,107] Trial 85 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 73, 'n_neurons_2': 99, 'n_neurons_3': 31, 'n_neurons_4': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015925446667814006, 'alpha': 0.002422828554185797}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:17,109] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,111] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,111] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,112] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,112] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,113] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,114] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,114] The parameter `n_layers` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,115] The parameter `n_neurons_0` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,115] The parameter `n_neurons_1` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,116] The parameter `n_neurons_2` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,117] The parameter `learning_rate` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,117] The parameter `learning_rate_init` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:17,117] The parameter `alpha` in Trial#86 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:18,685] Trial 86 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 76, 'n_neurons_2': 80, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009176737380720279, 'alpha': 0.00010924071993869074}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:18,688] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,690] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,690] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,691] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,692] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,693] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,693] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,694] The parameter `n_layers` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,695] The parameter `n_neurons_0` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,696] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,697] The parameter `n_neurons_2` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,697] The parameter `n_neurons_3` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,698] The parameter `n_neurons_4` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,699] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,699] The parameter `learning_rate_init` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:18,700] The parameter `alpha` in Trial#87 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:20,346] Trial 87 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 18, 'n_neurons_1': 54, 'n_neurons_2': 23, 'n_neurons_3': 39, 'n_neurons_4': 77, 'learning_rate': 'constant', 'learning_rate_init': 0.0006151096737070389, 'alpha': 0.0008296473623735454}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:20,348] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,350] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,350] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,351] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,351] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,351] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,352] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,353] The parameter `n_layers` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,353] The parameter `n_neurons_0` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,354] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,355] The parameter `n_neurons_2` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,355] The parameter `n_neurons_3` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,356] The parameter `n_neurons_4` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,357] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,357] The parameter `learning_rate_init` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:20,357] The parameter `alpha` in Trial#88 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:21,497] Trial 88 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 67, 'n_neurons_1': 65, 'n_neurons_2': 16, 'n_neurons_3': 57, 'n_neurons_4': 23, 'learning_rate': 'constant', 'learning_rate_init': 0.0022932719467128214, 'alpha': 0.00012115624400696192}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:21,501] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,501] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,503] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,503] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,504] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,505] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,505] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,505] The parameter `n_layers` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,506] The parameter `n_neurons_0` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,506] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,506] The parameter `learning_rate_init` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:21,508] The parameter `alpha` in Trial#89 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:23,145] Trial 89 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.00011012601445612862, 'alpha': 0.0001459967993464517}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:23,148] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,149] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,150] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,151] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,151] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,152] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,152] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,153] The parameter `n_layers` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,153] The parameter `n_neurons_0` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,154] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,154] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,154] The parameter `learning_rate_init` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:23,155] The parameter `alpha` in Trial#90 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:24,794] Trial 90 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004202808250827565, 'alpha': 0.0020556880660352003}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:24,795] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,798] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,798] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,799] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,800] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,800] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,801] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,801] The parameter `n_layers` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,801] The parameter `n_neurons_0` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,803] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,804] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,804] The parameter `learning_rate_init` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:24,805] The parameter `alpha` in Trial#91 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:26,270] Trial 91 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 84, 'n_neurons_1': 88, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003195082233827963, 'alpha': 0.0032365614534194923}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:26,272] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,274] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,275] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,275] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,276] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,276] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,277] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,277] The parameter `n_layers` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,278] The parameter `n_neurons_0` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,279] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,279] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,279] The parameter `learning_rate_init` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:26,280] The parameter `alpha` in Trial#92 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:27,292] Trial 92 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 86, 'learning_rate': 'constant', 'learning_rate_init': 0.0015159866641908737, 'alpha': 0.0010392525381080842}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:27,294] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,294] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,296] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,296] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,297] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,297] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,298] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:27,299] Trial 93 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:27,300] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,301] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,302] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,302] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,303] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,303] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,303] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,304] The parameter `n_layers` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,304] The parameter `n_neurons_0` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,305] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,305] The parameter `n_neurons_2` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,306] The parameter `n_neurons_3` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,306] The parameter `n_neurons_4` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,307] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,307] The parameter `learning_rate_init` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:27,308] The parameter `alpha` in Trial#94 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:29,109] Trial 94 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 39, 'n_neurons_2': 23, 'n_neurons_3': 37, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.0007892621240300501, 'alpha': 0.0027806214997722505}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:29,112] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,113] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,113] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,114] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,114] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,115] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,115] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,116] The parameter `n_layers` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,117] The parameter `n_neurons_0` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,117] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,118] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,118] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,119] The parameter `learning_rate_init` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:29,120] The parameter `alpha` in Trial#95 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:30,803] Trial 95 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 61, 'n_neurons_2': 64, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0003464506976855204, 'alpha': 0.004467852431220893}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:30,807] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,808] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,808] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,809] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,809] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,810] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,810] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,811] The parameter `n_layers` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,811] The parameter `n_neurons_0` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,812] The parameter `n_neurons_1` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,813] The parameter `n_neurons_2` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,813] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,813] The parameter `learning_rate_init` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:30,813] The parameter `alpha` in Trial#96 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:31,540] Trial 96 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 100, 'n_neurons_2': 94, 'learning_rate': 'constant', 'learning_rate_init': 0.0018722107277466084, 'alpha': 0.0037265181101734106}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:31,543] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,543] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,544] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,544] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,545] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,545] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,546] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,547] The parameter `n_layers` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,548] The parameter `n_neurons_0` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,548] The parameter `n_neurons_1` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,549] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,549] The parameter `learning_rate_init` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,550] The parameter `alpha` in Trial#97 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:31,789] Trial 97 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 95, 'n_neurons_1': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00482911039455259, 'alpha': 0.00023561494581810438}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:31,791] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,791] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,792] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,792] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,794] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,794] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,795] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,795] The parameter `n_layers` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,795] The parameter `n_neurons_0` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,796] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,797] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,797] The parameter `n_neurons_3` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,798] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,798] The parameter `learning_rate_init` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:31,799] The parameter `alpha` in Trial#98 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:32,002] Trial 98 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 97, 'n_neurons_1': 16, 'n_neurons_2': 15, 'n_neurons_3': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.006493953298280694, 'alpha': 0.00031556759477955416}. Best is trial 56 with value: 0.9266666666666666.\n",
      "[W 2025-12-28 19:32:32,004] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,005] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,006] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,006] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,007] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,008] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,008] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,009] The parameter `n_layers` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,009] The parameter `n_neurons_0` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,010] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,010] The parameter `learning_rate_init` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:32,011] The parameter `alpha` in Trial#99 is sampled independently using `RandomSampler` instead of `CmaEsSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `CmaEsSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `CmaEsSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:32,756] Trial 99 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.0074755805269149074, 'alpha': 0.00012720839073892073}. Best is trial 56 with value: 0.9266666666666666.\n",
      "\n",
      "Selected Base Models for Stacking using CmaEsSampler:\n",
      "- Random Forest\n",
      "- Support Vector Machine\n",
      "- Gradient Boosting\n",
      "Best Hyperparameters for Meta Model (MLP) using CmaEsSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.0012639059001467116, 'alpha': 0.0001492703392407429, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (34, 21, 90, 96, 88), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9267, at trial: 56\n",
      "CMA-ES base models training time: 52.42 seconds\n",
      "CMA-ES SEl-NNML Training Time: 115.98 seconds\n",
      "Total CMA-ES Training Time (Base + Meta): 168.40 seconds\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    cmaes_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    cmaes_sel_nnml, cmaes_meta_study = meta_model_tuning(base_models['CMA-ES'], X_train, y_train, X_test, y_test, sampler='CmaEsSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE) \n",
    "    cmaes_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    cmaes_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for CMA-ES SEl-NNML training\n",
    "    cmaes_meta_model_training_time = cmaes_meta_model_training_end - cmaes_meta_model_training_start\n",
    "    print(f'CMA-ES base models training time: {cmaes_base_models_training_time:.2f} seconds')\n",
    "    print(f'CMA-ES SEl-NNML Training Time: {cmaes_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total CMA-ES Training Time (Base + Meta): {cmaes_base_models_training_time + cmaes_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    cmaes_meta_history = cmaes_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    cmaes_meta_history.columns = ['iteration', 'score']\n",
    "    cmaes_meta_history['iteration'] = cmaes_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping CMA-ES meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4 QMC & CV Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MPTI-TA\\sel-nnml-heart-disease-prediction-nopal\\notebooks\\src\\model_tuning_algorithm.py:178: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler_instance = supported_samplers[sampler](seed=random_state)\n",
      "[I 2025-12-28 19:32:34,844] A new study created in memory with name: Meta Model Fine Tuning: Stacking with MLP (QMCSampler)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14ae639616346ffbfcd2ee30b4235fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:35,928] Trial 0 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 26, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007309539835912913, 'alpha': 0.0003823475224675188}. Best is trial 0 with value: 0.9066666666666666.\n",
      "[W 2025-12-28 19:32:35,934] The parameter `use_Logistic Regression` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:35,934] The parameter `use_Decision Tree` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:35,936] The parameter `use_Random Forest` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:35,937] The parameter `use_K-Nearest Neighbors` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:35,937] The parameter `use_Support Vector Machine` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:35,937] The parameter `use_AdaBoost` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:35,937] The parameter `use_Gradient Boosting` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:35,939] The parameter `learning_rate` in Trial#1 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:36,564] Trial 1 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 10, 'learning_rate': 'constant', 'learning_rate_init': 0.00010000000000000009, 'alpha': 0.00010000000000000009}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:36,568] The parameter `use_Logistic Regression` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,568] The parameter `use_Decision Tree` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,568] The parameter `use_Random Forest` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,570] The parameter `use_K-Nearest Neighbors` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,570] The parameter `use_Support Vector Machine` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,570] The parameter `use_AdaBoost` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,570] The parameter `use_Gradient Boosting` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,572] The parameter `n_neurons_1` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,572] The parameter `n_neurons_2` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:36,572] The parameter `learning_rate` in Trial#2 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:37,763] Trial 2 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 55, 'n_neurons_1': 98, 'n_neurons_2': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0010000000000000002, 'alpha': 0.0010000000000000002}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:37,768] The parameter `use_Logistic Regression` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,769] The parameter `use_Decision Tree` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,769] The parameter `use_Random Forest` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,770] The parameter `use_K-Nearest Neighbors` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,770] The parameter `use_Support Vector Machine` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,771] The parameter `use_AdaBoost` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,772] The parameter `use_Gradient Boosting` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,772] The parameter `n_neurons_1` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,772] The parameter `n_neurons_2` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,773] The parameter `n_neurons_3` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:37,773] The parameter `learning_rate` in Trial#3 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:38,162] Trial 3 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 16, 'n_neurons_2': 99, 'n_neurons_3': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0003162277660168384, 'alpha': 0.0003162277660168384}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:38,166] The parameter `use_Logistic Regression` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,166] The parameter `use_Decision Tree` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,166] The parameter `use_Random Forest` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,168] The parameter `use_K-Nearest Neighbors` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,168] The parameter `use_Support Vector Machine` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,168] The parameter `use_AdaBoost` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,168] The parameter `use_Gradient Boosting` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,170] The parameter `n_neurons_1` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,170] The parameter `learning_rate` in Trial#4 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:38,383] Trial 4 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 78, 'n_neurons_1': 68, 'learning_rate': 'constant', 'learning_rate_init': 0.003162277660168382, 'alpha': 0.003162277660168382}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:38,385] The parameter `use_Logistic Regression` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,385] The parameter `use_Decision Tree` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,385] The parameter `use_Random Forest` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,387] The parameter `use_K-Nearest Neighbors` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,388] The parameter `use_Support Vector Machine` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,388] The parameter `use_AdaBoost` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,389] The parameter `use_Gradient Boosting` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,389] The parameter `n_neurons_1` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:38,390] The parameter `learning_rate` in Trial#5 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:39,524] Trial 5 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 44, 'n_neurons_1': 92, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0017782794100389236, 'alpha': 0.005623413251903492}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:39,527] The parameter `use_Logistic Regression` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,528] The parameter `use_Decision Tree` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,528] The parameter `use_Random Forest` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,529] The parameter `use_K-Nearest Neighbors` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,529] The parameter `use_Support Vector Machine` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,530] The parameter `use_AdaBoost` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,531] The parameter `use_Gradient Boosting` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,531] The parameter `n_neurons_1` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,532] The parameter `n_neurons_2` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,533] The parameter `n_neurons_3` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,533] The parameter `n_neurons_4` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:39,534] The parameter `learning_rate` in Trial#6 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:40,312] Trial 6 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 89, 'n_neurons_1': 91, 'n_neurons_2': 38, 'n_neurons_3': 20, 'n_neurons_4': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00017782794100389232, 'alpha': 0.0005623413251903495}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:40,315] The parameter `use_Logistic Regression` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,317] The parameter `use_Decision Tree` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,317] The parameter `use_Random Forest` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,318] The parameter `use_K-Nearest Neighbors` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,319] The parameter `use_Support Vector Machine` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,320] The parameter `use_AdaBoost` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,320] The parameter `use_Gradient Boosting` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,321] The parameter `n_neurons_1` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,321] The parameter `n_neurons_2` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,322] The parameter `n_neurons_3` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:40,322] The parameter `learning_rate` in Trial#7 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:41,321] Trial 7 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 21, 'n_neurons_1': 32, 'n_neurons_2': 55, 'n_neurons_3': 37, 'learning_rate': 'constant', 'learning_rate_init': 0.005623413251903492, 'alpha': 0.0017782794100389236}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:41,323] The parameter `use_Logistic Regression` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:41,324] The parameter `use_Decision Tree` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:41,325] The parameter `use_Random Forest` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:41,325] The parameter `use_K-Nearest Neighbors` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:41,327] The parameter `use_Support Vector Machine` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:41,327] The parameter `use_AdaBoost` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:41,328] The parameter `use_Gradient Boosting` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:41,328] The parameter `learning_rate` in Trial#8 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:42,372] Trial 8 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 66, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005623413251903495, 'alpha': 0.00017782794100389232}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:42,376] The parameter `use_Logistic Regression` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:42,377] The parameter `use_Decision Tree` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:42,378] The parameter `use_Random Forest` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:42,378] The parameter `use_K-Nearest Neighbors` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:42,379] The parameter `use_Support Vector Machine` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:42,380] The parameter `use_AdaBoost` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:42,380] The parameter `use_Gradient Boosting` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:42,381] The parameter `learning_rate` in Trial#9 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:43,387] Trial 9 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 38, 'learning_rate': 'constant', 'learning_rate_init': 0.007498942093324564, 'alpha': 0.0007498942093324562}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:43,391] The parameter `use_Logistic Regression` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,392] The parameter `use_Decision Tree` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,393] The parameter `use_Random Forest` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,393] The parameter `use_K-Nearest Neighbors` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,394] The parameter `use_Support Vector Machine` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,394] The parameter `use_AdaBoost` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,394] The parameter `use_Gradient Boosting` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,395] The parameter `n_neurons_1` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,397] The parameter `n_neurons_2` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,397] The parameter `n_neurons_3` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:43,398] The parameter `learning_rate` in Trial#10 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:45,417] Trial 10 finished with value: 0.88 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 91, 'n_neurons_2': 67, 'n_neurons_3': 40, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007498942093324562, 'alpha': 0.007498942093324564}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:45,420] The parameter `use_Logistic Regression` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,421] The parameter `use_Decision Tree` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,422] The parameter `use_Random Forest` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,422] The parameter `use_K-Nearest Neighbors` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,423] The parameter `use_Support Vector Machine` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,424] The parameter `use_AdaBoost` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,424] The parameter `use_Gradient Boosting` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,425] The parameter `n_neurons_1` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,426] The parameter `n_neurons_2` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,426] The parameter `n_neurons_3` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,426] The parameter `n_neurons_4` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:45,427] The parameter `learning_rate` in Trial#11 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:46,253] Trial 11 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 15, 'n_neurons_1': 72, 'n_neurons_2': 69, 'n_neurons_3': 30, 'n_neurons_4': 74, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002371373705661656, 'alpha': 0.00023713737056616573}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:46,256] The parameter `use_Logistic Regression` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,257] The parameter `use_Decision Tree` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,259] The parameter `use_Random Forest` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,259] The parameter `use_K-Nearest Neighbors` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,260] The parameter `use_Support Vector Machine` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,260] The parameter `use_AdaBoost` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,261] The parameter `use_Gradient Boosting` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,261] The parameter `n_neurons_1` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,262] The parameter `n_neurons_2` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:46,262] The parameter `learning_rate` in Trial#12 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:47,448] Trial 12 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 61, 'n_neurons_1': 55, 'n_neurons_2': 62, 'learning_rate': 'constant', 'learning_rate_init': 0.00023713737056616573, 'alpha': 0.002371373705661656}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:47,450] The parameter `use_Logistic Regression` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,451] The parameter `use_Decision Tree` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,452] The parameter `use_Random Forest` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,452] The parameter `use_K-Nearest Neighbors` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,453] The parameter `use_Support Vector Machine` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,454] The parameter `use_AdaBoost` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,454] The parameter `use_Gradient Boosting` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,455] The parameter `n_neurons_1` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:47,455] The parameter `learning_rate` in Trial#13 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:48,276] Trial 13 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 27, 'n_neurons_1': 87, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00042169650342858235, 'alpha': 0.0013335214321633251}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:48,279] The parameter `use_Logistic Regression` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,280] The parameter `use_Decision Tree` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,280] The parameter `use_Random Forest` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,281] The parameter `use_K-Nearest Neighbors` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,281] The parameter `use_Support Vector Machine` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,282] The parameter `use_AdaBoost` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,282] The parameter `use_Gradient Boosting` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,284] The parameter `n_neurons_1` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,285] The parameter `n_neurons_2` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,285] The parameter `n_neurons_3` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,286] The parameter `n_neurons_4` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:48,286] The parameter `learning_rate` in Trial#14 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:49,369] Trial 14 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 72, 'n_neurons_1': 73, 'n_neurons_2': 73, 'n_neurons_3': 42, 'n_neurons_4': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004216965034285825, 'alpha': 0.0001333521432163326}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:49,371] The parameter `use_Logistic Regression` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,372] The parameter `use_Decision Tree` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,373] The parameter `use_Random Forest` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,373] The parameter `use_K-Nearest Neighbors` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,374] The parameter `use_Support Vector Machine` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,374] The parameter `use_AdaBoost` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,375] The parameter `use_Gradient Boosting` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,376] The parameter `n_neurons_1` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,377] The parameter `n_neurons_2` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:49,377] The parameter `learning_rate` in Trial#15 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:50,627] Trial 15 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 52, 'n_neurons_2': 59, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001333521432163326, 'alpha': 0.004216965034285825}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:50,631] The parameter `use_Logistic Regression` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,632] The parameter `use_Decision Tree` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,633] The parameter `use_Random Forest` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,634] The parameter `use_K-Nearest Neighbors` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,635] The parameter `use_Support Vector Machine` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,635] The parameter `use_AdaBoost` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,635] The parameter `use_Gradient Boosting` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,637] The parameter `learning_rate` in Trial#16 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:50,935] Trial 16 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 95, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013335214321633251, 'alpha': 0.00042169650342858235}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:50,939] The parameter `use_Logistic Regression` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,940] The parameter `use_Decision Tree` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,940] The parameter `use_Random Forest` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,941] The parameter `use_K-Nearest Neighbors` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,941] The parameter `use_Support Vector Machine` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,941] The parameter `use_AdaBoost` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,942] The parameter `use_Gradient Boosting` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:50,943] The parameter `learning_rate` in Trial#17 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:51,947] Trial 17 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 52, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000865964323360066, 'alpha': 0.0020535250264571477}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:51,950] The parameter `use_Logistic Regression` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,951] The parameter `use_Decision Tree` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,951] The parameter `use_Random Forest` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,952] The parameter `use_K-Nearest Neighbors` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,952] The parameter `use_Support Vector Machine` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,953] The parameter `use_AdaBoost` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,953] The parameter `use_Gradient Boosting` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,954] The parameter `n_neurons_1` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,954] The parameter `n_neurons_2` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:51,955] The parameter `learning_rate` in Trial#18 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:52,751] Trial 18 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 98, 'n_neurons_1': 87, 'n_neurons_2': 74, 'learning_rate': 'constant', 'learning_rate_init': 0.008659643233600654, 'alpha': 0.0002053525026457149}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:52,753] The parameter `use_Logistic Regression` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,753] The parameter `use_Decision Tree` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,754] The parameter `use_Random Forest` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,755] The parameter `use_K-Nearest Neighbors` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,755] The parameter `use_Support Vector Machine` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,755] The parameter `use_AdaBoost` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,756] The parameter `use_Gradient Boosting` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,756] The parameter `n_neurons_1` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,757] The parameter `n_neurons_2` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,759] The parameter `n_neurons_3` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,759] The parameter `n_neurons_4` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:52,760] The parameter `learning_rate` in Trial#19 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:53,702] Trial 19 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 29, 'n_neurons_1': 16, 'n_neurons_2': 68, 'n_neurons_3': 12, 'n_neurons_4': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.0002738419634264362, 'alpha': 0.0064938163157621165}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:53,704] The parameter `use_Logistic Regression` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,705] The parameter `use_Decision Tree` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,706] The parameter `use_Random Forest` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,706] The parameter `use_K-Nearest Neighbors` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,707] The parameter `use_Support Vector Machine` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,707] The parameter `use_AdaBoost` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,708] The parameter `use_Gradient Boosting` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,709] The parameter `n_neurons_1` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:53,712] The parameter `learning_rate` in Trial#20 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:54,901] Trial 20 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 75, 'n_neurons_1': 16, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0027384196342643626, 'alpha': 0.0006493816315762115}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:54,903] The parameter `use_Logistic Regression` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,905] The parameter `use_Decision Tree` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,906] The parameter `use_Random Forest` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,906] The parameter `use_K-Nearest Neighbors` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,907] The parameter `use_Support Vector Machine` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,907] The parameter `use_AdaBoost` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,908] The parameter `use_Gradient Boosting` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,908] The parameter `n_neurons_1` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,909] The parameter `n_neurons_2` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:54,910] The parameter `learning_rate` in Trial#21 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:56,100] Trial 21 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 18, 'n_neurons_1': 47, 'n_neurons_2': 43, 'learning_rate': 'constant', 'learning_rate_init': 0.004869675251658635, 'alpha': 0.000365174127254838}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:56,102] The parameter `use_Logistic Regression` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,104] The parameter `use_Decision Tree` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,104] The parameter `use_Random Forest` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,105] The parameter `use_K-Nearest Neighbors` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,105] The parameter `use_Support Vector Machine` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,105] The parameter `use_AdaBoost` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,106] The parameter `use_Gradient Boosting` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,106] The parameter `n_neurons_1` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,108] The parameter `n_neurons_2` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,108] The parameter `n_neurons_3` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,109] The parameter `n_neurons_4` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:56,110] The parameter `learning_rate` in Trial#22 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:32:57,946] Trial 22 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 64, 'n_neurons_1': 18, 'n_neurons_2': 39, 'n_neurons_3': 96, 'n_neurons_4': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00048696752516586337, 'alpha': 0.0036517412725483775}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:57,954] The parameter `use_Logistic Regression` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,955] The parameter `use_Decision Tree` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,956] The parameter `use_Random Forest` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,956] The parameter `use_K-Nearest Neighbors` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,957] The parameter `use_Support Vector Machine` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,957] The parameter `use_AdaBoost` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,958] The parameter `use_Gradient Boosting` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,959] The parameter `n_neurons_1` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,959] The parameter `n_neurons_2` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,959] The parameter `n_neurons_3` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:57,961] The parameter `learning_rate` in Trial#23 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:32:58,909] Trial 23 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 41, 'n_neurons_1': 20, 'n_neurons_2': 23, 'n_neurons_3': 79, 'learning_rate': 'constant', 'learning_rate_init': 0.0015399265260594922, 'alpha': 0.00011547819846894585}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:32:58,912] The parameter `use_Logistic Regression` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,912] The parameter `use_Decision Tree` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,912] The parameter `use_Random Forest` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,914] The parameter `use_K-Nearest Neighbors` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,914] The parameter `use_Support Vector Machine` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,914] The parameter `use_AdaBoost` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,916] The parameter `use_Gradient Boosting` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,917] The parameter `n_neurons_1` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:32:58,917] The parameter `learning_rate` in Trial#24 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:00,064] Trial 24 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 86, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00015399265260594933, 'alpha': 0.0011547819846894588}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:00,067] The parameter `use_Logistic Regression` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:00,067] The parameter `use_Decision Tree` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:00,068] The parameter `use_Random Forest` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:00,069] The parameter `use_K-Nearest Neighbors` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:00,069] The parameter `use_Support Vector Machine` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:00,070] The parameter `use_AdaBoost` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:00,071] The parameter `use_Gradient Boosting` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:00,071] The parameter `learning_rate` in Trial#25 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:01,048] Trial 25 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0011547819846894588, 'alpha': 0.004869675251658635}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:01,050] The parameter `use_Logistic Regression` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,051] The parameter `use_Decision Tree` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,051] The parameter `use_Random Forest` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,052] The parameter `use_K-Nearest Neighbors` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,052] The parameter `use_Support Vector Machine` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,053] The parameter `use_AdaBoost` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,053] The parameter `use_Gradient Boosting` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,054] The parameter `n_neurons_1` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,055] The parameter `n_neurons_2` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,055] The parameter `n_neurons_3` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:01,056] The parameter `learning_rate` in Trial#26 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:02,274] Trial 26 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 69, 'n_neurons_1': 73, 'n_neurons_2': 51, 'n_neurons_3': 67, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011547819846894585, 'alpha': 0.00048696752516586337}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:02,277] The parameter `use_Logistic Regression` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,278] The parameter `use_Decision Tree` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,279] The parameter `use_Random Forest` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,279] The parameter `use_K-Nearest Neighbors` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,280] The parameter `use_Support Vector Machine` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,280] The parameter `use_AdaBoost` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,281] The parameter `use_Gradient Boosting` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,282] The parameter `n_neurons_1` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,282] The parameter `n_neurons_2` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,283] The parameter `n_neurons_3` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,283] The parameter `n_neurons_4` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:02,284] The parameter `learning_rate` in Trial#27 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:03,078] Trial 27 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 46, 'n_neurons_1': 73, 'n_neurons_2': 58, 'n_neurons_3': 38, 'n_neurons_4': 84, 'learning_rate': 'constant', 'learning_rate_init': 0.0036517412725483775, 'alpha': 0.0015399265260594922}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:03,081] The parameter `use_Logistic Regression` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,082] The parameter `use_Decision Tree` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,082] The parameter `use_Random Forest` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,083] The parameter `use_K-Nearest Neighbors` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,084] The parameter `use_Support Vector Machine` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,085] The parameter `use_AdaBoost` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,085] The parameter `use_Gradient Boosting` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,086] The parameter `n_neurons_1` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,087] The parameter `n_neurons_2` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:03,087] The parameter `learning_rate` in Trial#28 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:04,638] Trial 28 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 92, 'n_neurons_1': 64, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.000365174127254838, 'alpha': 0.00015399265260594933}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:04,640] The parameter `use_Logistic Regression` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,641] The parameter `use_Decision Tree` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,641] The parameter `use_Random Forest` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,642] The parameter `use_K-Nearest Neighbors` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,642] The parameter `use_Support Vector Machine` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,643] The parameter `use_AdaBoost` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,643] The parameter `use_Gradient Boosting` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,644] The parameter `n_neurons_1` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:04,644] The parameter `learning_rate` in Trial#29 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:05,440] Trial 29 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 35, 'n_neurons_1': 50, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002053525026457149, 'alpha': 0.0002738419634264362}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:05,443] The parameter `use_Logistic Regression` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,444] The parameter `use_Decision Tree` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,444] The parameter `use_Random Forest` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,445] The parameter `use_K-Nearest Neighbors` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,445] The parameter `use_Support Vector Machine` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,445] The parameter `use_AdaBoost` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,446] The parameter `use_Gradient Boosting` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,446] The parameter `n_neurons_1` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,447] The parameter `n_neurons_2` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,448] The parameter `n_neurons_3` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:05,448] The parameter `learning_rate` in Trial#30 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:06,548] Trial 30 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 81, 'n_neurons_1': 46, 'n_neurons_2': 22, 'n_neurons_3': 12, 'learning_rate': 'constant', 'learning_rate_init': 0.0020535250264571477, 'alpha': 0.0027384196342643626}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:06,551] The parameter `use_Logistic Regression` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,552] The parameter `use_Decision Tree` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,553] The parameter `use_Random Forest` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,553] The parameter `use_K-Nearest Neighbors` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,553] The parameter `use_Support Vector Machine` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,554] The parameter `use_AdaBoost` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,555] The parameter `use_Gradient Boosting` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,556] The parameter `n_neurons_1` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,556] The parameter `n_neurons_2` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:06,557] The parameter `learning_rate` in Trial#31 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:07,244] Trial 31 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 12, 'n_neurons_1': 88, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006493816315762115, 'alpha': 0.000865964323360066}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:07,250] The parameter `use_Logistic Regression` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:07,251] The parameter `use_Decision Tree` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:07,251] The parameter `use_Random Forest` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:07,252] The parameter `use_K-Nearest Neighbors` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:07,252] The parameter `use_Support Vector Machine` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:07,254] The parameter `use_AdaBoost` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:07,254] The parameter `use_Gradient Boosting` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:07,254] The parameter `learning_rate` in Trial#32 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:08,191] Trial 32 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 58, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0064938163157621165, 'alpha': 0.008659643233600654}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:08,193] The parameter `use_Logistic Regression` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:08,194] The parameter `use_Decision Tree` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:08,195] The parameter `use_Random Forest` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:08,195] The parameter `use_K-Nearest Neighbors` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:08,195] The parameter `use_Support Vector Machine` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:08,196] The parameter `use_AdaBoost` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:08,197] The parameter `use_Gradient Boosting` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:08,197] The parameter `learning_rate` in Trial#33 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:09,120] Trial 33 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 34, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0025482967479793484, 'alpha': 0.0012409377607517208}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:09,122] The parameter `use_Logistic Regression` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,123] The parameter `use_Decision Tree` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,123] The parameter `use_Random Forest` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,124] The parameter `use_K-Nearest Neighbors` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,124] The parameter `use_Support Vector Machine` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,125] The parameter `use_AdaBoost` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,125] The parameter `use_Gradient Boosting` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,126] The parameter `n_neurons_1` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,126] The parameter `n_neurons_2` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,127] The parameter `learning_rate` in Trial#34 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:09,435] Trial 34 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 79, 'n_neurons_1': 66, 'n_neurons_2': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002548296747979348, 'alpha': 0.00012409377607517218}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:09,437] The parameter `use_Logistic Regression` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,438] The parameter `use_Decision Tree` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,438] The parameter `use_Random Forest` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,439] The parameter `use_K-Nearest Neighbors` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,439] The parameter `use_Support Vector Machine` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,440] The parameter `use_AdaBoost` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,441] The parameter `use_Gradient Boosting` in Trial#35 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:09,441] Trial 35 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:09,442] The parameter `use_Logistic Regression` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,445] The parameter `use_Decision Tree` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,445] The parameter `use_Random Forest` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,446] The parameter `use_K-Nearest Neighbors` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,447] The parameter `use_Support Vector Machine` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,447] The parameter `use_AdaBoost` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,448] The parameter `use_Gradient Boosting` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,449] The parameter `n_neurons_1` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:09,449] The parameter `learning_rate` in Trial#36 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:10,187] Trial 36 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 56, 'n_neurons_1': 35, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008058421877614828, 'alpha': 0.0003924189758484538}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:10,190] The parameter `use_Logistic Regression` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,191] The parameter `use_Decision Tree` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,191] The parameter `use_Random Forest` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,191] The parameter `use_K-Nearest Neighbors` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,193] The parameter `use_Support Vector Machine` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,193] The parameter `use_AdaBoost` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,194] The parameter `use_Gradient Boosting` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,194] The parameter `n_neurons_1` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,195] The parameter `n_neurons_2` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:10,195] The parameter `learning_rate` in Trial#37 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:11,511] Trial 37 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 22, 'n_neurons_1': 57, 'n_neurons_2': 47, 'learning_rate': 'constant', 'learning_rate_init': 0.00014330125702369644, 'alpha': 0.0006978305848598669}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:11,514] The parameter `use_Logistic Regression` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,515] The parameter `use_Decision Tree` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,515] The parameter `use_Random Forest` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,517] The parameter `use_K-Nearest Neighbors` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,517] The parameter `use_Support Vector Machine` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,518] The parameter `use_AdaBoost` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,519] The parameter `use_Gradient Boosting` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,520] The parameter `n_neurons_1` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,521] The parameter `n_neurons_2` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,521] The parameter `n_neurons_3` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,521] The parameter `n_neurons_4` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:11,522] The parameter `learning_rate` in Trial#38 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:12,756] Trial 38 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 68, 'n_neurons_1': 48, 'n_neurons_2': 56, 'n_neurons_3': 32, 'n_neurons_4': 20, 'learning_rate': 'constant', 'learning_rate_init': 0.0014330125702369636, 'alpha': 0.006978305848598664}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:12,759] The parameter `use_Logistic Regression` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,760] The parameter `use_Decision Tree` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,761] The parameter `use_Random Forest` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,761] The parameter `use_K-Nearest Neighbors` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,762] The parameter `use_Support Vector Machine` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,762] The parameter `use_AdaBoost` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,763] The parameter `use_Gradient Boosting` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,764] The parameter `n_neurons_1` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,764] The parameter `n_neurons_2` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,765] The parameter `n_neurons_3` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:12,765] The parameter `learning_rate` in Trial#39 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:13,531] Trial 39 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 45, 'n_neurons_1': 64, 'n_neurons_2': 52, 'n_neurons_3': 47, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00045315836376008217, 'alpha': 0.00022067340690845924}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:13,533] The parameter `use_Logistic Regression` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:13,534] The parameter `use_Decision Tree` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:13,534] The parameter `use_Random Forest` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:13,535] The parameter `use_K-Nearest Neighbors` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:13,535] The parameter `use_Support Vector Machine` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:13,537] The parameter `use_AdaBoost` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:13,537] The parameter `use_Gradient Boosting` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:13,538] The parameter `learning_rate` in Trial#40 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:14,436] Trial 40 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 91, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0045315836376008225, 'alpha': 0.002206734069084591}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:14,438] The parameter `use_Logistic Regression` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,439] The parameter `use_Decision Tree` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,439] The parameter `use_Random Forest` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,441] The parameter `use_K-Nearest Neighbors` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,441] The parameter `use_Support Vector Machine` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,442] The parameter `use_AdaBoost` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,442] The parameter `use_Gradient Boosting` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,443] The parameter `n_neurons_1` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:14,444] The parameter `learning_rate` in Trial#41 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:15,099] Trial 41 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 17, 'n_neurons_1': 44, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00033982083289425634, 'alpha': 0.009305720409296997}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:15,101] The parameter `use_Logistic Regression` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,102] The parameter `use_Decision Tree` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,104] The parameter `use_Random Forest` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,104] The parameter `use_K-Nearest Neighbors` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,104] The parameter `use_Support Vector Machine` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,105] The parameter `use_AdaBoost` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,105] The parameter `use_Gradient Boosting` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,106] The parameter `n_neurons_1` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,107] The parameter `n_neurons_2` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,107] The parameter `n_neurons_3` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:15,108] The parameter `learning_rate` in Trial#42 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:16,174] Trial 42 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 62, 'n_neurons_1': 77, 'n_neurons_2': 13, 'n_neurons_3': 61, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003398208328942561, 'alpha': 0.0009305720409296995}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:16,177] The parameter `use_Logistic Regression` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,178] The parameter `use_Decision Tree` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,178] The parameter `use_Random Forest` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,178] The parameter `use_K-Nearest Neighbors` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,179] The parameter `use_Support Vector Machine` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,180] The parameter `use_AdaBoost` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,180] The parameter `use_Gradient Boosting` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,180] The parameter `n_neurons_1` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,180] The parameter `n_neurons_2` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,180] The parameter `n_neurons_3` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,180] The parameter `n_neurons_4` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:16,184] The parameter `learning_rate` in Trial#43 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:17,336] Trial 43 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 39, 'n_neurons_1': 32, 'n_neurons_2': 41, 'n_neurons_3': 26, 'n_neurons_4': 92, 'learning_rate': 'constant', 'learning_rate_init': 0.00010746078283213182, 'alpha': 0.002942727176209285}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:17,339] The parameter `use_Logistic Regression` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,339] The parameter `use_Decision Tree` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,339] The parameter `use_Random Forest` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,341] The parameter `use_K-Nearest Neighbors` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,341] The parameter `use_Support Vector Machine` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,342] The parameter `use_AdaBoost` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,342] The parameter `use_Gradient Boosting` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,343] The parameter `n_neurons_1` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,344] The parameter `n_neurons_2` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:17,344] The parameter `learning_rate` in Trial#44 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:18,339] Trial 44 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 85, 'n_neurons_1': 62, 'n_neurons_2': 65, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0010746078283213184, 'alpha': 0.0002942727176209287}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:18,342] The parameter `use_Logistic Regression` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,343] The parameter `use_Decision Tree` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,343] The parameter `use_Random Forest` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,345] The parameter `use_K-Nearest Neighbors` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,345] The parameter `use_Support Vector Machine` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,346] The parameter `use_AdaBoost` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,347] The parameter `use_Gradient Boosting` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,347] The parameter `n_neurons_1` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:18,348] The parameter `learning_rate` in Trial#45 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:19,561] Trial 45 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 51, 'n_neurons_1': 83, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006042963902381333, 'alpha': 0.00016548170999431823}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:19,566] The parameter `use_Logistic Regression` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,567] The parameter `use_Decision Tree` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,567] The parameter `use_Random Forest` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,568] The parameter `use_K-Nearest Neighbors` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,568] The parameter `use_Support Vector Machine` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,569] The parameter `use_AdaBoost` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,569] The parameter `use_Gradient Boosting` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,570] The parameter `n_neurons_1` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,570] The parameter `n_neurons_2` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,571] The parameter `n_neurons_3` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,572] The parameter `n_neurons_4` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:19,572] The parameter `learning_rate` in Trial#46 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:20,653] Trial 46 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 96, 'n_neurons_1': 42, 'n_neurons_2': 62, 'n_neurons_3': 67, 'n_neurons_4': 11, 'learning_rate': 'constant', 'learning_rate_init': 0.0006042963902381332, 'alpha': 0.0016548170999431827}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:20,655] The parameter `use_Logistic Regression` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,657] The parameter `use_Decision Tree` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,658] The parameter `use_Random Forest` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,658] The parameter `use_K-Nearest Neighbors` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,659] The parameter `use_Support Vector Machine` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,660] The parameter `use_AdaBoost` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,660] The parameter `use_Gradient Boosting` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,660] The parameter `n_neurons_1` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,661] The parameter `n_neurons_2` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,661] The parameter `n_neurons_3` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:20,661] The parameter `learning_rate` in Trial#47 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:21,992] Trial 47 finished with value: 0.86 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 28, 'n_neurons_1': 52, 'n_neurons_2': 61, 'n_neurons_3': 15, 'learning_rate': 'constant', 'learning_rate_init': 0.0019109529749704425, 'alpha': 0.0005232991146814953}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:21,996] The parameter `use_Logistic Regression` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:21,997] The parameter `use_Decision Tree` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:21,998] The parameter `use_Random Forest` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:21,998] The parameter `use_K-Nearest Neighbors` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:21,999] The parameter `use_Support Vector Machine` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,000] The parameter `use_AdaBoost` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,000] The parameter `use_Gradient Boosting` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,001] The parameter `learning_rate` in Trial#48 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:22,722] Trial 48 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 73, 'learning_rate': 'constant', 'learning_rate_init': 0.00019109529749704405, 'alpha': 0.005232991146814949}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:22,724] The parameter `use_Logistic Regression` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,725] The parameter `use_Decision Tree` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,726] The parameter `use_Random Forest` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,727] The parameter `use_K-Nearest Neighbors` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,727] The parameter `use_Support Vector Machine` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,728] The parameter `use_AdaBoost` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,728] The parameter `use_Gradient Boosting` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,729] The parameter `learning_rate` in Trial#49 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:22,903] Trial 49 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.003924189758484535, 'alpha': 0.00019109529749704405}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:22,905] The parameter `use_Logistic Regression` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,906] The parameter `use_Decision Tree` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,906] The parameter `use_Random Forest` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,907] The parameter `use_K-Nearest Neighbors` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,907] The parameter `use_Support Vector Machine` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,908] The parameter `use_AdaBoost` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,908] The parameter `use_Gradient Boosting` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,910] The parameter `n_neurons_1` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,911] The parameter `n_neurons_2` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:22,911] The parameter `learning_rate` in Trial#50 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:23,728] Trial 50 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 76, 'n_neurons_1': 33, 'n_neurons_2': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.0003924189758484538, 'alpha': 0.0019109529749704425}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:23,729] The parameter `use_Logistic Regression` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,730] The parameter `use_Decision Tree` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,731] The parameter `use_Random Forest` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,732] The parameter `use_K-Nearest Neighbors` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,732] The parameter `use_Support Vector Machine` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,732] The parameter `use_AdaBoost` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,733] The parameter `use_Gradient Boosting` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,733] The parameter `n_neurons_1` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,734] The parameter `n_neurons_2` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,734] The parameter `n_neurons_3` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,735] The parameter `n_neurons_4` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:23,735] The parameter `learning_rate` in Trial#51 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:24,812] Trial 51 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 54, 'n_neurons_1': 34, 'n_neurons_2': 59, 'n_neurons_3': 67, 'n_neurons_4': 33, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0012409377607517208, 'alpha': 0.0006042963902381332}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:24,814] The parameter `use_Logistic Regression` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,815] The parameter `use_Decision Tree` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,815] The parameter `use_Random Forest` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,817] The parameter `use_K-Nearest Neighbors` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,817] The parameter `use_Support Vector Machine` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,818] The parameter `use_AdaBoost` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,818] The parameter `use_Gradient Boosting` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,819] The parameter `n_neurons_1` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:24,819] The parameter `learning_rate` in Trial#52 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:25,810] Trial 52 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 99, 'n_neurons_1': 22, 'learning_rate': 'constant', 'learning_rate_init': 0.00012409377607517218, 'alpha': 0.006042963902381333}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:25,813] The parameter `use_Logistic Regression` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,814] The parameter `use_Decision Tree` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,814] The parameter `use_Random Forest` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,815] The parameter `use_K-Nearest Neighbors` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,815] The parameter `use_Support Vector Machine` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,816] The parameter `use_AdaBoost` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,816] The parameter `use_Gradient Boosting` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,817] The parameter `n_neurons_1` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,818] The parameter `n_neurons_2` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:25,818] The parameter `learning_rate` in Trial#53 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:26,991] Trial 53 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 42, 'n_neurons_1': 45, 'n_neurons_2': 36, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006978305848598669, 'alpha': 0.003398208328942561}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:26,993] The parameter `use_Logistic Regression` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,994] The parameter `use_Decision Tree` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,994] The parameter `use_Random Forest` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,995] The parameter `use_K-Nearest Neighbors` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,995] The parameter `use_Support Vector Machine` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,996] The parameter `use_AdaBoost` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,996] The parameter `use_Gradient Boosting` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,996] The parameter `n_neurons_1` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,998] The parameter `n_neurons_2` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,998] The parameter `n_neurons_3` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,998] The parameter `n_neurons_4` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:26,998] The parameter `learning_rate` in Trial#54 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:27,956] Trial 54 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 88, 'n_neurons_1': 80, 'n_neurons_2': 19, 'n_neurons_3': 16, 'n_neurons_4': 76, 'learning_rate': 'adaptive', 'learning_rate_init': 0.006978305848598664, 'alpha': 0.00033982083289425634}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:27,957] The parameter `use_Logistic Regression` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,958] The parameter `use_Decision Tree` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,958] The parameter `use_Random Forest` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,959] The parameter `use_K-Nearest Neighbors` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,959] The parameter `use_Support Vector Machine` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,959] The parameter `use_AdaBoost` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,961] The parameter `use_Gradient Boosting` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,961] The parameter `n_neurons_1` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,962] The parameter `n_neurons_2` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,962] The parameter `n_neurons_3` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:27,963] The parameter `learning_rate` in Trial#55 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:29,280] Trial 55 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 19, 'n_neurons_1': 59, 'n_neurons_2': 89, 'n_neurons_3': 76, 'learning_rate': 'constant', 'learning_rate_init': 0.00022067340690845924, 'alpha': 0.0010746078283213184}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:29,284] The parameter `use_Logistic Regression` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,285] The parameter `use_Decision Tree` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,286] The parameter `use_Random Forest` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,286] The parameter `use_K-Nearest Neighbors` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,288] The parameter `use_Support Vector Machine` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,289] The parameter `use_AdaBoost` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,289] The parameter `use_Gradient Boosting` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,290] The parameter `n_neurons_1` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:29,291] The parameter `learning_rate` in Trial#56 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:30,160] Trial 56 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 65, 'n_neurons_1': 73, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002206734069084591, 'alpha': 0.00010746078283213182}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:30,162] The parameter `use_Logistic Regression` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:30,163] The parameter `use_Decision Tree` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:30,164] The parameter `use_Random Forest` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:30,164] The parameter `use_K-Nearest Neighbors` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:30,165] The parameter `use_Support Vector Machine` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:30,165] The parameter `use_AdaBoost` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:30,166] The parameter `use_Gradient Boosting` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:30,167] The parameter `learning_rate` in Trial#57 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:31,265] Trial 57 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 48, 'learning_rate': 'constant', 'learning_rate_init': 0.0002942727176209287, 'alpha': 0.00045315836376008217}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:31,267] The parameter `use_Logistic Regression` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,268] The parameter `use_Decision Tree` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,269] The parameter `use_Random Forest` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,269] The parameter `use_K-Nearest Neighbors` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,270] The parameter `use_Support Vector Machine` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,270] The parameter `use_AdaBoost` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,270] The parameter `use_Gradient Boosting` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,271] The parameter `n_neurons_1` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,272] The parameter `n_neurons_2` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,273] The parameter `n_neurons_3` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,273] The parameter `learning_rate` in Trial#58 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:31,603] Trial 58 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 93, 'n_neurons_1': 82, 'n_neurons_2': 100, 'n_neurons_3': 41, 'learning_rate': 'constant', 'learning_rate_init': 0.002942727176209285, 'alpha': 0.0045315836376008225}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:31,606] The parameter `use_Logistic Regression` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,606] The parameter `use_Decision Tree` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,607] The parameter `use_Random Forest` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,607] The parameter `use_K-Nearest Neighbors` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,607] The parameter `use_Support Vector Machine` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,608] The parameter `use_AdaBoost` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,608] The parameter `use_Gradient Boosting` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,608] The parameter `n_neurons_1` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,609] The parameter `n_neurons_2` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,609] The parameter `n_neurons_3` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,610] The parameter `n_neurons_4` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:31,611] The parameter `learning_rate` in Trial#59 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:33,209] Trial 59 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 25, 'n_neurons_1': 13, 'n_neurons_2': 11, 'n_neurons_3': 99, 'n_neurons_4': 48, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0009305720409296995, 'alpha': 0.00014330125702369644}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:33,212] The parameter `use_Logistic Regression` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,213] The parameter `use_Decision Tree` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,213] The parameter `use_Random Forest` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,214] The parameter `use_K-Nearest Neighbors` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,214] The parameter `use_Support Vector Machine` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,215] The parameter `use_AdaBoost` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,215] The parameter `use_Gradient Boosting` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,216] The parameter `n_neurons_1` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,217] The parameter `learning_rate` in Trial#60 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:33,992] Trial 60 finished with value: 0.88 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 71, 'n_neurons_1': 65, 'learning_rate': 'constant', 'learning_rate_init': 0.009305720409296997, 'alpha': 0.0014330125702369636}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:33,995] The parameter `use_Logistic Regression` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,995] The parameter `use_Decision Tree` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,996] The parameter `use_Random Forest` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,997] The parameter `use_K-Nearest Neighbors` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,997] The parameter `use_Support Vector Machine` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,998] The parameter `use_AdaBoost` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,998] The parameter `use_Gradient Boosting` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,999] The parameter `n_neurons_1` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:33,999] The parameter `learning_rate` in Trial#61 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:34,913] Trial 61 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 14, 'n_neurons_1': 24, 'learning_rate': 'constant', 'learning_rate_init': 0.0016548170999431827, 'alpha': 0.0025482967479793484}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:34,914] The parameter `use_Logistic Regression` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,915] The parameter `use_Decision Tree` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,916] The parameter `use_Random Forest` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,916] The parameter `use_K-Nearest Neighbors` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,916] The parameter `use_Support Vector Machine` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,917] The parameter `use_AdaBoost` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,917] The parameter `use_Gradient Boosting` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,919] The parameter `n_neurons_1` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,920] The parameter `n_neurons_2` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,920] The parameter `n_neurons_3` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:34,920] The parameter `learning_rate` in Trial#62 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:35,908] Trial 62 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 59, 'n_neurons_1': 17, 'n_neurons_2': 47, 'n_neurons_3': 43, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00016548170999431823, 'alpha': 0.0002548296747979348}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:35,911] The parameter `use_Logistic Regression` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,912] The parameter `use_Decision Tree` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,912] The parameter `use_Random Forest` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,912] The parameter `use_K-Nearest Neighbors` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,912] The parameter `use_Support Vector Machine` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,914] The parameter `use_AdaBoost` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,914] The parameter `use_Gradient Boosting` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,915] The parameter `n_neurons_1` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,915] The parameter `n_neurons_2` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:35,917] The parameter `learning_rate` in Trial#63 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:36,677] Trial 63 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 37, 'n_neurons_1': 89, 'n_neurons_2': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.005232991146814949, 'alpha': 0.008058421877614822}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:36,677] The parameter `use_Logistic Regression` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:36,677] The parameter `use_Decision Tree` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:36,677] The parameter `use_Random Forest` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:36,681] The parameter `use_K-Nearest Neighbors` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:36,681] The parameter `use_Support Vector Machine` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:36,682] The parameter `use_AdaBoost` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:36,682] The parameter `use_Gradient Boosting` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:36,683] The parameter `learning_rate` in Trial#64 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:37,711] Trial 64 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 82, 'learning_rate': 'constant', 'learning_rate_init': 0.0005232991146814953, 'alpha': 0.0008058421877614828}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:37,714] The parameter `use_Logistic Regression` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,714] The parameter `use_Decision Tree` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,715] The parameter `use_Random Forest` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,715] The parameter `use_K-Nearest Neighbors` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,716] The parameter `use_Support Vector Machine` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,716] The parameter `use_AdaBoost` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,717] The parameter `use_Gradient Boosting` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,718] The parameter `learning_rate` in Trial#65 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:37,868] Trial 65 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 46, 'learning_rate': 'adaptive', 'learning_rate_init': 0.004371444812611091, 'alpha': 0.004697588816706496}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:37,870] The parameter `use_Logistic Regression` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,871] The parameter `use_Decision Tree` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,871] The parameter `use_Random Forest` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,872] The parameter `use_K-Nearest Neighbors` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,872] The parameter `use_Support Vector Machine` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,873] The parameter `use_AdaBoost` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,873] The parameter `use_Gradient Boosting` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,874] The parameter `n_neurons_1` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,875] The parameter `n_neurons_2` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:37,875] The parameter `learning_rate` in Trial#66 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:39,597] Trial 66 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 91, 'n_neurons_1': 89, 'n_neurons_2': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0004371444812611094, 'alpha': 0.0004697588816706495}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:39,603] The parameter `use_Logistic Regression` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,604] The parameter `use_Decision Tree` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,604] The parameter `use_Random Forest` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,605] The parameter `use_K-Nearest Neighbors` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,605] The parameter `use_Support Vector Machine` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,606] The parameter `use_AdaBoost` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,608] The parameter `use_Gradient Boosting` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,608] The parameter `n_neurons_1` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,609] The parameter `n_neurons_2` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,610] The parameter `n_neurons_3` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:39,610] The parameter `learning_rate` in Trial#67 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:40,639] Trial 67 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 23, 'n_neurons_1': 82, 'n_neurons_2': 73, 'n_neurons_3': 30, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0013823722273579005, 'alpha': 0.0014855080171727755}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:40,644] The parameter `use_Logistic Regression` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,645] The parameter `use_Decision Tree` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,646] The parameter `use_Random Forest` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,646] The parameter `use_K-Nearest Neighbors` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,647] The parameter `use_Support Vector Machine` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,647] The parameter `use_AdaBoost` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,648] The parameter `use_Gradient Boosting` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,648] The parameter `n_neurons_1` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:40,648] The parameter `learning_rate` in Trial#68 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:41,601] Trial 68 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 69, 'n_neurons_1': 29, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00013823722273579014, 'alpha': 0.00014855080171727767}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:41,603] The parameter `use_Logistic Regression` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,604] The parameter `use_Decision Tree` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,605] The parameter `use_Random Forest` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,605] The parameter `use_K-Nearest Neighbors` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,606] The parameter `use_Support Vector Machine` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,607] The parameter `use_AdaBoost` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,607] The parameter `use_Gradient Boosting` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,609] The parameter `n_neurons_1` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:41,609] The parameter `learning_rate` in Trial#69 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:42,210] Trial 69 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 12, 'n_neurons_1': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0007773650302387768, 'alpha': 0.00026416483203860934}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:42,213] The parameter `use_Logistic Regression` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,213] The parameter `use_Decision Tree` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,214] The parameter `use_Random Forest` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,214] The parameter `use_K-Nearest Neighbors` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,215] The parameter `use_Support Vector Machine` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,215] The parameter `use_AdaBoost` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,216] The parameter `use_Gradient Boosting` in Trial#70 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:42,216] Trial 70 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:42,218] The parameter `use_Logistic Regression` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,219] The parameter `use_Decision Tree` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,220] The parameter `use_Random Forest` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,220] The parameter `use_K-Nearest Neighbors` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,221] The parameter `use_Support Vector Machine` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,221] The parameter `use_AdaBoost` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,222] The parameter `use_Gradient Boosting` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,223] The parameter `n_neurons_1` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,223] The parameter `n_neurons_2` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,224] The parameter `n_neurons_3` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,224] The parameter `learning_rate` in Trial#71 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:42,647] Trial 71 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 34, 'n_neurons_1': 66, 'n_neurons_2': 73, 'n_neurons_3': 60, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002458244068920199, 'alpha': 0.000835362546957827}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:42,649] The parameter `use_Logistic Regression` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,650] The parameter `use_Decision Tree` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,651] The parameter `use_Random Forest` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,651] The parameter `use_K-Nearest Neighbors` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,652] The parameter `use_Support Vector Machine` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,652] The parameter `use_AdaBoost` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,652] The parameter `use_Gradient Boosting` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:42,653] The parameter `learning_rate` in Trial#72 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:43,140] Trial 72 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 80, 'learning_rate': 'constant', 'learning_rate_init': 0.0024582440689201977, 'alpha': 0.008353625469578265}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:43,143] The parameter `use_Logistic Regression` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,144] The parameter `use_Decision Tree` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,145] The parameter `use_Random Forest` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,145] The parameter `use_K-Nearest Neighbors` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,145] The parameter `use_Support Vector Machine` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,146] The parameter `use_AdaBoost` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,146] The parameter `use_Gradient Boosting` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,148] The parameter `n_neurons_1` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:43,149] The parameter `learning_rate` in Trial#73 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:44,327] Trial 73 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 29, 'n_neurons_1': 68, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00018434229924091107, 'alpha': 0.001980956778550341}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:44,330] The parameter `use_Logistic Regression` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,331] The parameter `use_Decision Tree` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,332] The parameter `use_Random Forest` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,332] The parameter `use_K-Nearest Neighbors` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,333] The parameter `use_Support Vector Machine` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,333] The parameter `use_AdaBoost` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,334] The parameter `use_Gradient Boosting` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,334] The parameter `n_neurons_1` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,335] The parameter `n_neurons_2` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,335] The parameter `n_neurons_3` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:44,336] The parameter `learning_rate` in Trial#74 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:45,609] Trial 74 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 74, 'n_neurons_1': 30, 'n_neurons_2': 100, 'n_neurons_3': 98, 'learning_rate': 'constant', 'learning_rate_init': 0.0018434229924091127, 'alpha': 0.0001980956778550342}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:45,611] The parameter `use_Logistic Regression` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,611] The parameter `use_Decision Tree` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,612] The parameter `use_Random Forest` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,612] The parameter `use_K-Nearest Neighbors` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,613] The parameter `use_Support Vector Machine` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,613] The parameter `use_AdaBoost` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,614] The parameter `use_Gradient Boosting` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,614] The parameter `n_neurons_1` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,615] The parameter `n_neurons_2` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,615] The parameter `n_neurons_3` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,615] The parameter `n_neurons_4` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:45,616] The parameter `learning_rate` in Trial#75 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:46,078] Trial 75 finished with value: 0.92 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 51, 'n_neurons_1': 62, 'n_neurons_2': 49, 'n_neurons_3': 75, 'n_neurons_4': 54, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005829415347136078, 'alpha': 0.00626433536656886}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:46,080] The parameter `use_Logistic Regression` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,081] The parameter `use_Decision Tree` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,081] The parameter `use_Random Forest` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,082] The parameter `use_K-Nearest Neighbors` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,083] The parameter `use_Support Vector Machine` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,083] The parameter `use_AdaBoost` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,084] The parameter `use_Gradient Boosting` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,085] The parameter `n_neurons_1` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,085] The parameter `n_neurons_2` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,085] The parameter `learning_rate` in Trial#76 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:46,557] Trial 76 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 97, 'n_neurons_1': 26, 'n_neurons_2': 87, 'learning_rate': 'constant', 'learning_rate_init': 0.0058294153471360795, 'alpha': 0.0006264335366568858}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:46,559] The parameter `use_Logistic Regression` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,559] The parameter `use_Decision Tree` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,561] The parameter `use_Random Forest` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,561] The parameter `use_K-Nearest Neighbors` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,562] The parameter `use_Support Vector Machine` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,562] The parameter `use_AdaBoost` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,563] The parameter `use_Gradient Boosting` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,563] The parameter `n_neurons_1` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:46,564] The parameter `learning_rate` in Trial#77 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:47,594] Trial 77 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 40, 'n_neurons_1': 51, 'learning_rate': 'constant', 'learning_rate_init': 0.001036632928437698, 'alpha': 0.0003522694651473105}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:47,597] The parameter `use_Logistic Regression` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,598] The parameter `use_Decision Tree` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,598] The parameter `use_Random Forest` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,599] The parameter `use_K-Nearest Neighbors` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,600] The parameter `use_Support Vector Machine` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,600] The parameter `use_AdaBoost` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,601] The parameter `use_Gradient Boosting` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,601] The parameter `n_neurons_1` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,602] The parameter `n_neurons_2` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,603] The parameter `n_neurons_3` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,603] The parameter `n_neurons_4` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:47,604] The parameter `learning_rate` in Trial#78 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:49,115] Trial 78 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 86, 'n_neurons_1': 86, 'n_neurons_2': 83, 'n_neurons_3': 63, 'n_neurons_4': 89, 'learning_rate': 'constant', 'learning_rate_init': 0.00010366329284376988, 'alpha': 0.0035226946514731027}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:49,118] The parameter `use_Logistic Regression` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,118] The parameter `use_Decision Tree` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,119] The parameter `use_Random Forest` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,120] The parameter `use_K-Nearest Neighbors` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,121] The parameter `use_Support Vector Machine` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,121] The parameter `use_AdaBoost` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,122] The parameter `use_Gradient Boosting` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,123] The parameter `n_neurons_1` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,123] The parameter `n_neurons_2` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,125] The parameter `learning_rate` in Trial#79 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:49,929] Trial 79 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 3, 'n_neurons_0': 17, 'n_neurons_1': 10, 'n_neurons_2': 96, 'learning_rate': 'adaptive', 'learning_rate_init': 0.003278121151393461, 'alpha': 0.0001113973859994803}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:49,932] The parameter `use_Logistic Regression` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,933] The parameter `use_Decision Tree` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,934] The parameter `use_Random Forest` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,935] The parameter `use_K-Nearest Neighbors` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,935] The parameter `use_Support Vector Machine` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,936] The parameter `use_AdaBoost` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,937] The parameter `use_Gradient Boosting` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:49,937] The parameter `learning_rate` in Trial#80 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:51,070] Trial 80 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 63, 'learning_rate': 'constant', 'learning_rate_init': 0.00032781211513934627, 'alpha': 0.001113973859994803}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:51,073] The parameter `use_Logistic Regression` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,074] The parameter `use_Decision Tree` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,076] The parameter `use_Random Forest` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,076] The parameter `use_K-Nearest Neighbors` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,076] The parameter `use_Support Vector Machine` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,077] The parameter `use_AdaBoost` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,077] The parameter `use_Gradient Boosting` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,078] The parameter `learning_rate` in Trial#81 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:51,605] Trial 81 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 20, 'learning_rate': 'adaptive', 'learning_rate_init': 0.002128751661796374, 'alpha': 0.0009646616199111995}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:51,608] The parameter `use_Logistic Regression` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,608] The parameter `use_Decision Tree` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,609] The parameter `use_Random Forest` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,610] The parameter `use_K-Nearest Neighbors` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,610] The parameter `use_Support Vector Machine` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,611] The parameter `use_AdaBoost` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,611] The parameter `use_Gradient Boosting` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,612] The parameter `n_neurons_1` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,613] The parameter `n_neurons_2` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,613] The parameter `n_neurons_3` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:51,614] The parameter `learning_rate` in Trial#82 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:33:53,467] Trial 82 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 4, 'n_neurons_0': 66, 'n_neurons_1': 83, 'n_neurons_2': 79, 'n_neurons_3': 82, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00021287516617963755, 'alpha': 0.009646616199111998}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:53,470] The parameter `use_Logistic Regression` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,470] The parameter `use_Decision Tree` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,472] The parameter `use_Random Forest` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,472] The parameter `use_K-Nearest Neighbors` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,473] The parameter `use_Support Vector Machine` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,473] The parameter `use_AdaBoost` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,474] The parameter `use_Gradient Boosting` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,475] The parameter `n_neurons_1` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,475] The parameter `n_neurons_2` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,476] The parameter `n_neurons_3` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,476] The parameter `n_neurons_4` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:53,477] The parameter `learning_rate` in Trial#83 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:54,058] Trial 83 finished with value: 0.92 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 43, 'n_neurons_1': 70, 'n_neurons_2': 66, 'n_neurons_3': 52, 'n_neurons_4': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.006731703824144984, 'alpha': 0.00030505278902670253}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:54,061] The parameter `use_Logistic Regression` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,062] The parameter `use_Decision Tree` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,062] The parameter `use_Random Forest` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,063] The parameter `use_K-Nearest Neighbors` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,063] The parameter `use_Support Vector Machine` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,063] The parameter `use_AdaBoost` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,064] The parameter `use_Gradient Boosting` in Trial#84 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:54,064] Trial 84 finished with value: 0.0 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:54,066] The parameter `use_Logistic Regression` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,067] The parameter `use_Decision Tree` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,068] The parameter `use_Random Forest` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,068] The parameter `use_K-Nearest Neighbors` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,068] The parameter `use_Support Vector Machine` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,069] The parameter `use_AdaBoost` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,069] The parameter `use_Gradient Boosting` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,069] The parameter `n_neurons_1` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,069] The parameter `n_neurons_2` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:54,069] The parameter `learning_rate` in Trial#85 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:55,351] Trial 85 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 54, 'n_neurons_1': 59, 'n_neurons_2': 38, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00011970850304957301, 'alpha': 0.0017154378963428801}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:55,354] The parameter `use_Logistic Regression` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,355] The parameter `use_Decision Tree` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,355] The parameter `use_Random Forest` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,356] The parameter `use_K-Nearest Neighbors` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,356] The parameter `use_Support Vector Machine` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,357] The parameter `use_AdaBoost` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,357] The parameter `use_Gradient Boosting` in Trial#86 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:55,359] Trial 86 finished with value: 0.0 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': False}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:55,360] The parameter `use_Logistic Regression` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,361] The parameter `use_Decision Tree` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,364] The parameter `use_Random Forest` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,365] The parameter `use_K-Nearest Neighbors` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,366] The parameter `use_Support Vector Machine` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,367] The parameter `use_AdaBoost` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,367] The parameter `use_Gradient Boosting` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,369] The parameter `n_neurons_1` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,370] The parameter `n_neurons_2` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,371] The parameter `n_neurons_3` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:55,371] The parameter `learning_rate` in Trial#87 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:56,321] Trial 87 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 32, 'n_neurons_1': 31, 'n_neurons_2': 81, 'n_neurons_3': 35, 'learning_rate': 'constant', 'learning_rate_init': 0.0003785515249258633, 'alpha': 0.005424690937011328}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:56,323] The parameter `use_Logistic Regression` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,324] The parameter `use_Decision Tree` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,325] The parameter `use_Random Forest` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,325] The parameter `use_K-Nearest Neighbors` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,326] The parameter `use_Support Vector Machine` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,326] The parameter `use_AdaBoost` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,327] The parameter `use_Gradient Boosting` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,328] The parameter `n_neurons_1` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:56,328] The parameter `learning_rate` in Trial#88 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:57,350] Trial 88 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 2, 'n_neurons_0': 77, 'n_neurons_1': 31, 'learning_rate': 'adaptive', 'learning_rate_init': 0.00378551524925863, 'alpha': 0.0005424690937011332}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:57,352] The parameter `use_Logistic Regression` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:57,353] The parameter `use_Decision Tree` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:57,353] The parameter `use_Random Forest` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:57,354] The parameter `use_K-Nearest Neighbors` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:57,354] The parameter `use_Support Vector Machine` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:57,355] The parameter `use_AdaBoost` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:57,355] The parameter `use_Gradient Boosting` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:57,356] The parameter `learning_rate` in Trial#89 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:58,079] Trial 89 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 1, 'n_neurons_0': 37, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0005048065716667477, 'alpha': 0.00012863969449369766}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:58,081] The parameter `use_Logistic Regression` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,082] The parameter `use_Decision Tree` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,084] The parameter `use_Random Forest` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,084] The parameter `use_K-Nearest Neighbors` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,085] The parameter `use_Support Vector Machine` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,085] The parameter `use_AdaBoost` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,085] The parameter `use_Gradient Boosting` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,086] The parameter `n_neurons_1` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,087] The parameter `n_neurons_2` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,087] The parameter `n_neurons_3` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:58,088] The parameter `learning_rate` in Trial#90 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:33:59,275] Trial 90 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 83, 'n_neurons_1': 39, 'n_neurons_2': 40, 'n_neurons_3': 70, 'learning_rate': 'constant', 'learning_rate_init': 0.005048065716667474, 'alpha': 0.0012863969449369757}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:33:59,277] The parameter `use_Logistic Regression` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,278] The parameter `use_Decision Tree` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,279] The parameter `use_Random Forest` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,279] The parameter `use_K-Nearest Neighbors` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,280] The parameter `use_Support Vector Machine` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,281] The parameter `use_AdaBoost` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,281] The parameter `use_Gradient Boosting` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,282] The parameter `n_neurons_1` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,282] The parameter `n_neurons_2` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,283] The parameter `n_neurons_3` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,284] The parameter `n_neurons_4` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:33:59,284] The parameter `learning_rate` in Trial#91 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:00,378] Trial 91 finished with value: 0.9 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 5, 'n_neurons_0': 14, 'n_neurons_1': 70, 'n_neurons_2': 82, 'n_neurons_3': 94, 'n_neurons_4': 31, 'learning_rate': 'constant', 'learning_rate_init': 0.00015963385442879435, 'alpha': 0.0004067944321083049}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:00,380] The parameter `use_Logistic Regression` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,381] The parameter `use_Decision Tree` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,381] The parameter `use_Random Forest` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,382] The parameter `use_K-Nearest Neighbors` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,382] The parameter `use_Support Vector Machine` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,384] The parameter `use_AdaBoost` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,385] The parameter `use_Gradient Boosting` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,385] The parameter `n_neurons_1` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,386] The parameter `n_neurons_2` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,386] The parameter `learning_rate` in Trial#92 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:00,943] Trial 92 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': False, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 60, 'n_neurons_1': 33, 'n_neurons_2': 42, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0015963385442879423, 'alpha': 0.0040679443210830495}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:00,945] The parameter `use_Logistic Regression` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,946] The parameter `use_Decision Tree` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,946] The parameter `use_Random Forest` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,947] The parameter `use_K-Nearest Neighbors` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,948] The parameter `use_Support Vector Machine` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,948] The parameter `use_AdaBoost` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,949] The parameter `use_Gradient Boosting` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,950] The parameter `n_neurons_1` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:00,950] The parameter `learning_rate` in Trial#93 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:01,934] Trial 93 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': False, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 2, 'n_neurons_0': 26, 'n_neurons_1': 44, 'learning_rate': 'constant', 'learning_rate_init': 0.00897687132447315, 'alpha': 0.007233941627366754}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:01,936] The parameter `use_Logistic Regression` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,937] The parameter `use_Decision Tree` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,937] The parameter `use_Random Forest` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,938] The parameter `use_K-Nearest Neighbors` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,939] The parameter `use_Support Vector Machine` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,939] The parameter `use_AdaBoost` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,940] The parameter `use_Gradient Boosting` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,940] The parameter `n_neurons_1` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,941] The parameter `n_neurons_2` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,941] The parameter `n_neurons_3` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,942] The parameter `n_neurons_4` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:01,942] The parameter `learning_rate` in Trial#94 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 19:34:03,793] Trial 94 finished with value: 0.8866666666666667 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 5, 'n_neurons_0': 71, 'n_neurons_1': 54, 'n_neurons_2': 65, 'n_neurons_3': 79, 'n_neurons_4': 25, 'learning_rate': 'constant', 'learning_rate_init': 0.0008976871324473148, 'alpha': 0.0007233941627366753}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:03,796] The parameter `use_Logistic Regression` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,796] The parameter `use_Decision Tree` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,797] The parameter `use_Random Forest` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,797] The parameter `use_K-Nearest Neighbors` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,797] The parameter `use_Support Vector Machine` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,798] The parameter `use_AdaBoost` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,799] The parameter `use_Gradient Boosting` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,799] The parameter `n_neurons_1` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,799] The parameter `n_neurons_2` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:03,799] The parameter `learning_rate` in Trial#95 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:04,378] Trial 95 finished with value: 0.9133333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': True, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 49, 'n_neurons_1': 29, 'n_neurons_2': 66, 'learning_rate': 'constant', 'learning_rate_init': 0.0028387359647587583, 'alpha': 0.0022875732003183966}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:04,380] The parameter `use_Logistic Regression` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:04,381] The parameter `use_Decision Tree` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:04,382] The parameter `use_Random Forest` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:04,382] The parameter `use_K-Nearest Neighbors` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:04,382] The parameter `use_Support Vector Machine` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:04,383] The parameter `use_AdaBoost` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:04,385] The parameter `use_Gradient Boosting` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:04,385] The parameter `learning_rate` in Trial#96 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:05,466] Trial 96 finished with value: 0.8933333333333333 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 94, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0002838735964758755, 'alpha': 0.0002287573200318398}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:05,468] The parameter `use_Logistic Regression` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:05,469] The parameter `use_Decision Tree` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:05,469] The parameter `use_Random Forest` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:05,469] The parameter `use_K-Nearest Neighbors` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:05,471] The parameter `use_Support Vector Machine` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:05,471] The parameter `use_AdaBoost` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:05,472] The parameter `use_Gradient Boosting` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:05,472] The parameter `learning_rate` in Trial#97 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:06,509] Trial 97 finished with value: 0.9 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': True, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 1, 'n_neurons_0': 22, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0006264335366568858, 'alpha': 0.0005048065716667477}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:06,512] The parameter `use_Logistic Regression` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,512] The parameter `use_Decision Tree` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,513] The parameter `use_Random Forest` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,513] The parameter `use_K-Nearest Neighbors` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,514] The parameter `use_Support Vector Machine` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,514] The parameter `use_AdaBoost` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,515] The parameter `use_Gradient Boosting` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,515] The parameter `n_neurons_1` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,516] The parameter `n_neurons_2` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,517] The parameter `learning_rate` in Trial#98 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:06,680] Trial 98 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': False, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': False, 'use_Support Vector Machine': True, 'use_AdaBoost': False, 'use_Gradient Boosting': False, 'n_layers': 3, 'n_neurons_0': 67, 'n_neurons_1': 54, 'n_neurons_2': 19, 'learning_rate': 'constant', 'learning_rate_init': 0.00626433536656886, 'alpha': 0.005048065716667474}. Best is trial 1 with value: 0.92.\n",
      "[W 2025-12-28 19:34:06,682] The parameter `use_Logistic Regression` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,683] The parameter `use_Decision Tree` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,683] The parameter `use_Random Forest` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,684] The parameter `use_K-Nearest Neighbors` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,684] The parameter `use_Support Vector Machine` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,685] The parameter `use_AdaBoost` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,685] The parameter `use_Gradient Boosting` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,686] The parameter `n_neurons_1` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,687] The parameter `n_neurons_2` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,687] The parameter `n_neurons_3` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[W 2025-12-28 19:34:06,688] The parameter `learning_rate` in Trial#99 is sampled independently using `RandomSampler` instead of `QMCSampler`, potentially degrading the optimization performance. This fallback happend because dynamic search space and `CategoricalDistribution` are not supported by `QMCSampler`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler` if this independent sampling is intended behavior.\n",
      "[I 2025-12-28 19:34:07,699] Trial 99 finished with value: 0.9066666666666666 and parameters: {'use_Logistic Regression': True, 'use_Decision Tree': True, 'use_Random Forest': False, 'use_K-Nearest Neighbors': True, 'use_Support Vector Machine': False, 'use_AdaBoost': False, 'use_Gradient Boosting': True, 'n_layers': 4, 'n_neurons_0': 44, 'n_neurons_1': 38, 'n_neurons_2': 72, 'n_neurons_3': 49, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001980956778550342, 'alpha': 0.00015963385442879435}. Best is trial 1 with value: 0.92.\n",
      "\n",
      "Selected Base Models for Stacking using QMCSampler:\n",
      "- Logistic Regression\n",
      "- Support Vector Machine\n",
      "- AdaBoost\n",
      "Best Hyperparameters for Meta Model (MLP) using QMCSampler: {'learning_rate': 'constant', 'learning_rate_init': 0.00010000000000000009, 'alpha': 0.00010000000000000009, 'activation': 'relu', 'solver': 'adam', 'hidden_layer_sizes': (10,), 'max_iter': 300, 'random_state': 42}\n",
      "Best accuracy on Test Set: 0.9200, at trial: 1\n",
      "QMC base models training time: 48.40 seconds\n",
      "QMC SEl-NNML Training Time: 93.47 seconds\n",
      "Total QMC Training Time (Base + Meta): 141.86 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\azhar\\miniconda3\\envs\\sel_nnml\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    qmc_meta_model_training_start = time.time()\n",
    "\n",
    "    # Meta Model Tuning and Final Stacking Model Fitting\n",
    "    qmc_sel_nnml, qmc_meta_study = meta_model_tuning(base_models['QMC'], X_train, y_train, X_test, y_test, sampler='QMCSampler', iterations=OPTIMIZATION_ITERATIONS, metric_compare=OPTIMIZATION_METRIC, direction=OPTIMIZATION_DIRECTION, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    qmc_sel_nnml.fit(X_train, y_train)\n",
    "\n",
    "    qmc_meta_model_training_end = time.time()\n",
    "\n",
    "    # Time taken for QMC SEl-NNML training\n",
    "    qmc_meta_model_training_time = qmc_meta_model_training_end - qmc_meta_model_training_start\n",
    "    print(f'QMC base models training time: {qmc_base_models_training_time:.2f} seconds')\n",
    "    print(f'QMC SEl-NNML Training Time: {qmc_meta_model_training_time:.2f} seconds')\n",
    "    print(f'Total QMC Training Time (Base + Meta): {qmc_base_models_training_time + qmc_meta_model_training_time:.2f} seconds')\n",
    "    \n",
    "    # Extract and save training history for convergence plot\n",
    "    qmc_meta_history = qmc_meta_study.trials_dataframe()[['number', 'value']].copy()\n",
    "    qmc_meta_history.columns = ['iteration', 'score']\n",
    "    qmc_meta_history['iteration'] = qmc_meta_history['iteration'] + 1  # Start from 1 instead of 0\n",
    "else:\n",
    "    print(\"Skipping QMC meta model training (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Best Hyperparameters",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "ff99c08d-15d1-4fa1-a59c-892d9fc6fa85",
       "rows": [
        [
         "0",
         "TPE",
         "Logistic Regression",
         "{'C': 0.058569663055341156, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "1",
         "TPE",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 10, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "2",
         "TPE",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 9, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 89, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "3",
         "TPE",
         "K-Nearest Neighbors",
         "{'algorithm': 'ball_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 42, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "4",
         "TPE",
         "Support Vector Machine",
         "{'C': 0.009904811255677668, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "5",
         "TPE",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.49104198519099207, 'n_estimators': 79, 'random_state': 42}"
        ],
        [
         "6",
         "TPE",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.06053781067930206, 'loss': 'log_loss', 'max_depth': 8, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 94, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.7306935702749274, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "7",
         "TPE",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Logistic Regression', LogisticRegression(C=0.058569663055341156, max_iter=1000, n_jobs=-1,\n                   random_state=42, solver='newton-cg')), ('Decision Tree', DecisionTreeClassifier(max_depth=4, max_features='sqrt', min_samples_leaf=10,\n                       min_samples_split=3, random_state=42)), ('Random Forest', RandomForestClassifier(max_depth=8, max_features='log2', min_samples_leaf=5,\n                       min_samples_split=9, n_estimators=89, n_jobs=-1,\n                       random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.49104198519099207, n_estimators=79,\n                   random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(learning_rate=0.06053781067930206, max_depth=8,\n                           max_features='log2', min_samples_leaf=3,\n                           min_samples_split=4, n_estimators=94,\n                           random_state=42, subsample=0.7306935702749274))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.0002697361725980137, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (41, 20, 83), 'final_estimator__learning_rate': 'constant', 'final_estimator__learning_rate_init': 0.00625943673761351, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.0002697361725980137, hidden_layer_sizes=(41, 20, 83),\n              learning_rate_init=0.00625943673761351, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Logistic Regression': LogisticRegression(C=0.058569663055341156, max_iter=1000, n_jobs=-1,\n                   random_state=42, solver='newton-cg'), 'Decision Tree': DecisionTreeClassifier(max_depth=4, max_features='sqrt', min_samples_leaf=10,\n                       min_samples_split=3, random_state=42), 'Random Forest': RandomForestClassifier(max_depth=8, max_features='log2', min_samples_leaf=5,\n                       min_samples_split=9, n_estimators=89, n_jobs=-1,\n                       random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.49104198519099207, n_estimators=79,\n                   random_state=42), 'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.06053781067930206, max_depth=8,\n                           max_features='log2', min_samples_leaf=3,\n                           min_samples_split=4, n_estimators=94,\n                           random_state=42, subsample=0.7306935702749274), 'Logistic Regression__C': 0.058569663055341156, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'deprecated', 'Logistic Regression__n_jobs': -1, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 42, 'Logistic Regression__solver': 'newton-cg', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Decision Tree__ccp_alpha': 0.0, 'Decision Tree__class_weight': None, 'Decision Tree__criterion': 'gini', 'Decision Tree__max_depth': 4, 'Decision Tree__max_features': 'sqrt', 'Decision Tree__max_leaf_nodes': None, 'Decision Tree__min_impurity_decrease': 0.0, 'Decision Tree__min_samples_leaf': 10, 'Decision Tree__min_samples_split': 3, 'Decision Tree__min_weight_fraction_leaf': 0.0, 'Decision Tree__monotonic_cst': None, 'Decision Tree__random_state': 42, 'Decision Tree__splitter': 'best', 'Random Forest__bootstrap': True, 'Random Forest__ccp_alpha': 0.0, 'Random Forest__class_weight': None, 'Random Forest__criterion': 'gini', 'Random Forest__max_depth': 8, 'Random Forest__max_features': 'log2', 'Random Forest__max_leaf_nodes': None, 'Random Forest__max_samples': None, 'Random Forest__min_impurity_decrease': 0.0, 'Random Forest__min_samples_leaf': 5, 'Random Forest__min_samples_split': 9, 'Random Forest__min_weight_fraction_leaf': 0.0, 'Random Forest__monotonic_cst': None, 'Random Forest__n_estimators': 89, 'Random Forest__n_jobs': -1, 'Random Forest__oob_score': False, 'Random Forest__random_state': 42, 'Random Forest__verbose': 0, 'Random Forest__warm_start': False, 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.49104198519099207, 'AdaBoost__n_estimators': 79, 'AdaBoost__random_state': 42, 'Gradient Boosting__ccp_alpha': 0.0, 'Gradient Boosting__criterion': 'friedman_mse', 'Gradient Boosting__init': None, 'Gradient Boosting__learning_rate': 0.06053781067930206, 'Gradient Boosting__loss': 'log_loss', 'Gradient Boosting__max_depth': 8, 'Gradient Boosting__max_features': 'log2', 'Gradient Boosting__max_leaf_nodes': None, 'Gradient Boosting__min_impurity_decrease': 0.0, 'Gradient Boosting__min_samples_leaf': 3, 'Gradient Boosting__min_samples_split': 4, 'Gradient Boosting__min_weight_fraction_leaf': 0.0, 'Gradient Boosting__n_estimators': 94, 'Gradient Boosting__n_iter_no_change': None, 'Gradient Boosting__random_state': 42, 'Gradient Boosting__subsample': 0.7306935702749274, 'Gradient Boosting__tol': 0.0001, 'Gradient Boosting__validation_fraction': 0.1, 'Gradient Boosting__verbose': 0, 'Gradient Boosting__warm_start': False}"
        ],
        [
         "8",
         "GP",
         "Logistic Regression",
         "{'C': 0.02891295352813455, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cholesky', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "9",
         "GP",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 10, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "10",
         "GP",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'log_loss', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 72, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "11",
         "GP",
         "K-Nearest Neighbors",
         "{'algorithm': 'ball_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 41, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "12",
         "GP",
         "Support Vector Machine",
         "{'C': 0.01, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "13",
         "GP",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.6457519830686531, 'n_estimators': 100, 'random_state': 42}"
        ],
        [
         "14",
         "GP",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 61, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.6874340922389481, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "15",
         "GP",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Random Forest', RandomForestClassifier(criterion='log_loss', max_depth=10, n_estimators=72,\n                       n_jobs=-1, random_state=42)), ('K-Nearest Neighbors', KNeighborsClassifier(algorithm='ball_tree', n_jobs=-1, n_neighbors=41)), ('Support Vector Machine', SVC(C=0.01, degree=5, kernel='poly', random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.0005170191786366995, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (39,), 'final_estimator__learning_rate': 'constant', 'final_estimator__learning_rate_init': 0.004544383960336014, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.0005170191786366995, hidden_layer_sizes=(39,),\n              learning_rate_init=0.004544383960336014, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Random Forest': RandomForestClassifier(criterion='log_loss', max_depth=10, n_estimators=72,\n                       n_jobs=-1, random_state=42), 'K-Nearest Neighbors': KNeighborsClassifier(algorithm='ball_tree', n_jobs=-1, n_neighbors=41), 'Support Vector Machine': SVC(C=0.01, degree=5, kernel='poly', random_state=42), 'Random Forest__bootstrap': True, 'Random Forest__ccp_alpha': 0.0, 'Random Forest__class_weight': None, 'Random Forest__criterion': 'log_loss', 'Random Forest__max_depth': 10, 'Random Forest__max_features': 'sqrt', 'Random Forest__max_leaf_nodes': None, 'Random Forest__max_samples': None, 'Random Forest__min_impurity_decrease': 0.0, 'Random Forest__min_samples_leaf': 1, 'Random Forest__min_samples_split': 2, 'Random Forest__min_weight_fraction_leaf': 0.0, 'Random Forest__monotonic_cst': None, 'Random Forest__n_estimators': 72, 'Random Forest__n_jobs': -1, 'Random Forest__oob_score': False, 'Random Forest__random_state': 42, 'Random Forest__verbose': 0, 'Random Forest__warm_start': False, 'K-Nearest Neighbors__algorithm': 'ball_tree', 'K-Nearest Neighbors__leaf_size': 30, 'K-Nearest Neighbors__metric': 'minkowski', 'K-Nearest Neighbors__metric_params': None, 'K-Nearest Neighbors__n_jobs': -1, 'K-Nearest Neighbors__n_neighbors': 41, 'K-Nearest Neighbors__p': 2, 'K-Nearest Neighbors__weights': 'uniform', 'Support Vector Machine__C': 0.01, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 5, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False}"
        ],
        [
         "16",
         "CMA-ES",
         "Logistic Regression",
         "{'C': 0.05851500684973518, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cholesky', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "17",
         "CMA-ES",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 7, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "18",
         "CMA-ES",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 43, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "19",
         "CMA-ES",
         "K-Nearest Neighbors",
         "{'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 43, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "20",
         "CMA-ES",
         "Support Vector Machine",
         "{'C': 0.007082326034013129, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 2, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "21",
         "CMA-ES",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.46684762630779697, 'n_estimators': 61, 'random_state': 42}"
        ],
        [
         "22",
         "CMA-ES",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.020406225830080383, 'loss': 'log_loss', 'max_depth': 6, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 82, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.7797022489294623, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "23",
         "CMA-ES",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Random Forest', RandomForestClassifier(max_depth=9, min_samples_leaf=4, min_samples_split=4,\n                       n_estimators=43, n_jobs=-1, random_state=42)), ('Support Vector Machine', SVC(C=0.007082326034013129, degree=2, kernel='poly', random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(learning_rate=0.020406225830080383, max_depth=6,\n                           max_features='log2', min_samples_leaf=3,\n                           min_samples_split=4, n_estimators=82,\n                           random_state=42, subsample=0.7797022489294623))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.0001492703392407429, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (34, 21, 90, 96, 88), 'final_estimator__learning_rate': 'constant', 'final_estimator__learning_rate_init': 0.0012639059001467116, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.0001492703392407429,\n              hidden_layer_sizes=(34, 21, 90, 96, 88),\n              learning_rate_init=0.0012639059001467116, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Random Forest': RandomForestClassifier(max_depth=9, min_samples_leaf=4, min_samples_split=4,\n                       n_estimators=43, n_jobs=-1, random_state=42), 'Support Vector Machine': SVC(C=0.007082326034013129, degree=2, kernel='poly', random_state=42), 'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.020406225830080383, max_depth=6,\n                           max_features='log2', min_samples_leaf=3,\n                           min_samples_split=4, n_estimators=82,\n                           random_state=42, subsample=0.7797022489294623), 'Random Forest__bootstrap': True, 'Random Forest__ccp_alpha': 0.0, 'Random Forest__class_weight': None, 'Random Forest__criterion': 'gini', 'Random Forest__max_depth': 9, 'Random Forest__max_features': 'sqrt', 'Random Forest__max_leaf_nodes': None, 'Random Forest__max_samples': None, 'Random Forest__min_impurity_decrease': 0.0, 'Random Forest__min_samples_leaf': 4, 'Random Forest__min_samples_split': 4, 'Random Forest__min_weight_fraction_leaf': 0.0, 'Random Forest__monotonic_cst': None, 'Random Forest__n_estimators': 43, 'Random Forest__n_jobs': -1, 'Random Forest__oob_score': False, 'Random Forest__random_state': 42, 'Random Forest__verbose': 0, 'Random Forest__warm_start': False, 'Support Vector Machine__C': 0.007082326034013129, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 2, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False, 'Gradient Boosting__ccp_alpha': 0.0, 'Gradient Boosting__criterion': 'friedman_mse', 'Gradient Boosting__init': None, 'Gradient Boosting__learning_rate': 0.020406225830080383, 'Gradient Boosting__loss': 'log_loss', 'Gradient Boosting__max_depth': 6, 'Gradient Boosting__max_features': 'log2', 'Gradient Boosting__max_leaf_nodes': None, 'Gradient Boosting__min_impurity_decrease': 0.0, 'Gradient Boosting__min_samples_leaf': 3, 'Gradient Boosting__min_samples_split': 4, 'Gradient Boosting__min_weight_fraction_leaf': 0.0, 'Gradient Boosting__n_estimators': 82, 'Gradient Boosting__n_iter_no_change': None, 'Gradient Boosting__random_state': 42, 'Gradient Boosting__subsample': 0.7797022489294623, 'Gradient Boosting__tol': 0.0001, 'Gradient Boosting__validation_fraction': 0.1, 'Gradient Boosting__verbose': 0, 'Gradient Boosting__warm_start': False}"
        ],
        [
         "24",
         "QMC",
         "Logistic Regression",
         "{'C': 0.05935229272296987, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cholesky', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "25",
         "QMC",
         "Decision Tree",
         "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 8, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}"
        ],
        [
         "26",
         "QMC",
         "Random Forest",
         "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 91, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "27",
         "QMC",
         "K-Nearest Neighbors",
         "{'algorithm': 'kd_tree', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 41, 'p': 2, 'weights': 'uniform'}"
        ],
        [
         "28",
         "QMC",
         "Support Vector Machine",
         "{'C': 0.008058421877614822, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}"
        ],
        [
         "29",
         "QMC",
         "AdaBoost",
         "{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.08816830667755711, 'n_estimators': 34, 'random_state': 42}"
        ],
        [
         "30",
         "QMC",
         "Gradient Boosting",
         "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.06493816315762117, 'loss': 'log_loss', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 46, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 0.953125, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}"
        ],
        [
         "31",
         "QMC",
         "SEL-NNML",
         "{'cv': None, 'estimators': [('Logistic Regression', LogisticRegression(C=0.05935229272296987, max_iter=1000, n_jobs=-1,\n                   random_state=42, solver='newton-cholesky')), ('Support Vector Machine', SVC(C=0.008058421877614822, degree=5, kernel='poly', random_state=42)), ('AdaBoost', AdaBoostClassifier(learning_rate=0.08816830667755711, n_estimators=34,\n                   random_state=42))], 'final_estimator__activation': 'relu', 'final_estimator__alpha': 0.00010000000000000009, 'final_estimator__batch_size': 'auto', 'final_estimator__beta_1': 0.9, 'final_estimator__beta_2': 0.999, 'final_estimator__early_stopping': False, 'final_estimator__epsilon': 1e-08, 'final_estimator__hidden_layer_sizes': (10,), 'final_estimator__learning_rate': 'constant', 'final_estimator__learning_rate_init': 0.00010000000000000009, 'final_estimator__max_fun': 15000, 'final_estimator__max_iter': 300, 'final_estimator__momentum': 0.9, 'final_estimator__n_iter_no_change': 10, 'final_estimator__nesterovs_momentum': True, 'final_estimator__power_t': 0.5, 'final_estimator__random_state': 42, 'final_estimator__shuffle': True, 'final_estimator__solver': 'adam', 'final_estimator__tol': 0.0001, 'final_estimator__validation_fraction': 0.1, 'final_estimator__verbose': False, 'final_estimator__warm_start': False, 'final_estimator': MLPClassifier(alpha=0.00010000000000000009, hidden_layer_sizes=(10,),\n              learning_rate_init=0.00010000000000000009, max_iter=300,\n              random_state=42), 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Logistic Regression': LogisticRegression(C=0.05935229272296987, max_iter=1000, n_jobs=-1,\n                   random_state=42, solver='newton-cholesky'), 'Support Vector Machine': SVC(C=0.008058421877614822, degree=5, kernel='poly', random_state=42), 'AdaBoost': AdaBoostClassifier(learning_rate=0.08816830667755711, n_estimators=34,\n                   random_state=42), 'Logistic Regression__C': 0.05935229272296987, 'Logistic Regression__class_weight': None, 'Logistic Regression__dual': False, 'Logistic Regression__fit_intercept': True, 'Logistic Regression__intercept_scaling': 1, 'Logistic Regression__l1_ratio': None, 'Logistic Regression__max_iter': 1000, 'Logistic Regression__multi_class': 'deprecated', 'Logistic Regression__n_jobs': -1, 'Logistic Regression__penalty': 'l2', 'Logistic Regression__random_state': 42, 'Logistic Regression__solver': 'newton-cholesky', 'Logistic Regression__tol': 0.0001, 'Logistic Regression__verbose': 0, 'Logistic Regression__warm_start': False, 'Support Vector Machine__C': 0.008058421877614822, 'Support Vector Machine__break_ties': False, 'Support Vector Machine__cache_size': 200, 'Support Vector Machine__class_weight': None, 'Support Vector Machine__coef0': 0.0, 'Support Vector Machine__decision_function_shape': 'ovr', 'Support Vector Machine__degree': 5, 'Support Vector Machine__gamma': 'scale', 'Support Vector Machine__kernel': 'poly', 'Support Vector Machine__max_iter': -1, 'Support Vector Machine__probability': False, 'Support Vector Machine__random_state': 42, 'Support Vector Machine__shrinking': True, 'Support Vector Machine__tol': 0.001, 'Support Vector Machine__verbose': False, 'AdaBoost__algorithm': 'deprecated', 'AdaBoost__estimator': None, 'AdaBoost__learning_rate': 0.08816830667755711, 'AdaBoost__n_estimators': 34, 'AdaBoost__random_state': 42}"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 32
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Best Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.058569663055341156, 'class_weight': No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPE</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 30, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.009904811255677668, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TPE</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TPE</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TPE</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Logistic Regress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GP</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.02891295352813455, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GP</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GP</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 30, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GP</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.01, 'break_ties': False, 'cache_size':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GP</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GP</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Random Forest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.05851500684973518, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 30, 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.007082326034013129, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Random Forest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.05935229272296987, 'class_weight': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QMC</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 30, 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.008058421877614822, 'break_ties': Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>QMC</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'algorithm': 'deprecated', 'estimator': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>QMC</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>QMC</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>{'cv': None, 'estimators': [('Logistic Regress...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampler              Model Name  \\\n",
       "0      TPE     Logistic Regression   \n",
       "1      TPE           Decision Tree   \n",
       "2      TPE           Random Forest   \n",
       "3      TPE     K-Nearest Neighbors   \n",
       "4      TPE  Support Vector Machine   \n",
       "5      TPE                AdaBoost   \n",
       "6      TPE       Gradient Boosting   \n",
       "7      TPE                SEL-NNML   \n",
       "8       GP     Logistic Regression   \n",
       "9       GP           Decision Tree   \n",
       "10      GP           Random Forest   \n",
       "11      GP     K-Nearest Neighbors   \n",
       "12      GP  Support Vector Machine   \n",
       "13      GP                AdaBoost   \n",
       "14      GP       Gradient Boosting   \n",
       "15      GP                SEL-NNML   \n",
       "16  CMA-ES     Logistic Regression   \n",
       "17  CMA-ES           Decision Tree   \n",
       "18  CMA-ES           Random Forest   \n",
       "19  CMA-ES     K-Nearest Neighbors   \n",
       "20  CMA-ES  Support Vector Machine   \n",
       "21  CMA-ES                AdaBoost   \n",
       "22  CMA-ES       Gradient Boosting   \n",
       "23  CMA-ES                SEL-NNML   \n",
       "24     QMC     Logistic Regression   \n",
       "25     QMC           Decision Tree   \n",
       "26     QMC           Random Forest   \n",
       "27     QMC     K-Nearest Neighbors   \n",
       "28     QMC  Support Vector Machine   \n",
       "29     QMC                AdaBoost   \n",
       "30     QMC       Gradient Boosting   \n",
       "31     QMC                SEL-NNML   \n",
       "\n",
       "                                 Best Hyperparameters  \n",
       "0   {'C': 0.058569663055341156, 'class_weight': No...  \n",
       "1   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "2   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "3   {'algorithm': 'ball_tree', 'leaf_size': 30, 'm...  \n",
       "4   {'C': 0.009904811255677668, 'break_ties': Fals...  \n",
       "5   {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "6   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "7   {'cv': None, 'estimators': [('Logistic Regress...  \n",
       "8   {'C': 0.02891295352813455, 'class_weight': Non...  \n",
       "9   {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "10  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "11  {'algorithm': 'ball_tree', 'leaf_size': 30, 'm...  \n",
       "12  {'C': 0.01, 'break_ties': False, 'cache_size':...  \n",
       "13  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "14  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "15  {'cv': None, 'estimators': [('Random Forest', ...  \n",
       "16  {'C': 0.05851500684973518, 'class_weight': Non...  \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "18  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "19  {'algorithm': 'kd_tree', 'leaf_size': 30, 'met...  \n",
       "20  {'C': 0.007082326034013129, 'break_ties': Fals...  \n",
       "21  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "22  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "23  {'cv': None, 'estimators': [('Random Forest', ...  \n",
       "24  {'C': 0.05935229272296987, 'class_weight': Non...  \n",
       "25  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "26  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "27  {'algorithm': 'kd_tree', 'leaf_size': 30, 'met...  \n",
       "28  {'C': 0.008058421877614822, 'break_ties': Fals...  \n",
       "29  {'algorithm': 'deprecated', 'estimator': None,...  \n",
       "30  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  \n",
       "31  {'cv': None, 'estimators': [('Logistic Regress...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # All Models Storage for all sampler types\n",
    "    all_models = {\n",
    "        'TPE': {\n",
    "            'Logistic Regression': tpe_logistic_regression,\n",
    "            'Decision Tree': tpe_decision_tree,\n",
    "            'Random Forest': tpe_random_forest,\n",
    "            'K-Nearest Neighbors': tpe_knn,\n",
    "            'Support Vector Machine': tpe_svc,\n",
    "            'AdaBoost': tpe_adaboost,\n",
    "            'Gradient Boosting': tpe_gradient_boosting,\n",
    "            'SEL-NNML': tpe_sel_nnml\n",
    "        },\n",
    "        'GP': {\n",
    "            'Logistic Regression': gp_logistic_regression,\n",
    "            'Decision Tree': gp_decision_tree,\n",
    "            'Random Forest': gp_random_forest,\n",
    "            'K-Nearest Neighbors': gp_knn,\n",
    "            'Support Vector Machine': gp_svc,\n",
    "            'AdaBoost': gp_adaboost,\n",
    "            'Gradient Boosting': gp_gradient_boosting,\n",
    "            'SEL-NNML': gp_sel_nnml\n",
    "        },\n",
    "        'CMA-ES': {\n",
    "            'Logistic Regression': cmaes_logistic_regression,\n",
    "            'Decision Tree': cmaes_decision_tree,\n",
    "            'Random Forest': cmaes_random_forest,\n",
    "            'K-Nearest Neighbors': cmaes_knn,\n",
    "            'Support Vector Machine': cmaes_svc,\n",
    "            'AdaBoost': cmaes_adaboost,\n",
    "            'Gradient Boosting': cmaes_gradient_boosting,\n",
    "            'SEL-NNML': cmaes_sel_nnml\n",
    "        },\n",
    "        'QMC': {\n",
    "            'Logistic Regression': qmc_logistic_regression,\n",
    "            'Decision Tree': qmc_decision_tree,\n",
    "            'Random Forest': qmc_random_forest,\n",
    "            'K-Nearest Neighbors': qmc_knn,\n",
    "            'Support Vector Machine': qmc_svc,\n",
    "            'AdaBoost': qmc_adaboost,\n",
    "            'Gradient Boosting': qmc_gradient_boosting,\n",
    "            'SEL-NNML': qmc_sel_nnml\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save Every Best Model Config for each Tuning Method (Base + Meta) as CSV\n",
    "    all_model_hyperparameters = []\n",
    "    for sampler, models in all_models.items():\n",
    "        for model_name, model in models.items():\n",
    "            # Some meta models (e.g., stacking) may not have get_params, handle gracefully\n",
    "            params = model.get_params() if hasattr(model, 'get_params') else None\n",
    "            all_model_hyperparameters.append({\n",
    "                'Sampler': sampler,\n",
    "                'Model Name': model_name,\n",
    "                'Best Hyperparameters': params\n",
    "            })\n",
    "    all_model_hyperparameters_df = pd.DataFrame(all_model_hyperparameters)\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs('../artifacts/ds1/models', exist_ok=True)\n",
    "    \n",
    "    all_model_hyperparameters_df.to_csv('../artifacts/ds1/models/all_model_hyperparameters.csv', index=False)\n",
    "\n",
    "    # Show All Model Hyperparameters for all samplers\n",
    "    display(all_model_hyperparameters_df)\n",
    "else:\n",
    "    print(\"Skipping model storage (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Logistic Regression model tuned with TPE to ../artifacts/ds1/models/tpe/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with TPE to ../artifacts/ds1/models/tpe/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with TPE to ../artifacts/ds1/models/tpe/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with TPE to ../artifacts/ds1/models/tpe/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with TPE to ../artifacts/ds1/models/tpe/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with TPE to ../artifacts/ds1/models/tpe/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with TPE to ../artifacts/ds1/models/tpe/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with TPE to ../artifacts/ds1/models/tpe/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with GP to ../artifacts/ds1/models/gp/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with GP to ../artifacts/ds1/models/gp/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with GP to ../artifacts/ds1/models/gp/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with GP to ../artifacts/ds1/models/gp/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with GP to ../artifacts/ds1/models/gp/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with GP to ../artifacts/ds1/models/gp/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with GP to ../artifacts/ds1/models/gp/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with GP to ../artifacts/ds1/models/gp/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with CMA-ES to ../artifacts/ds1/models/cmaes/sel-nnml_best_model.pkl\n",
      "Saved Logistic Regression model tuned with QMC to ../artifacts/ds1/models/qmc/logistic_regression_best_model.pkl\n",
      "Saved Decision Tree model tuned with QMC to ../artifacts/ds1/models/qmc/decision_tree_best_model.pkl\n",
      "Saved Random Forest model tuned with QMC to ../artifacts/ds1/models/qmc/random_forest_best_model.pkl\n",
      "Saved K-Nearest Neighbors model tuned with QMC to ../artifacts/ds1/models/qmc/k-nearest_neighbors_best_model.pkl\n",
      "Saved Support Vector Machine model tuned with QMC to ../artifacts/ds1/models/qmc/support_vector_machine_best_model.pkl\n",
      "Saved AdaBoost model tuned with QMC to ../artifacts/ds1/models/qmc/adaboost_best_model.pkl\n",
      "Saved Gradient Boosting model tuned with QMC to ../artifacts/ds1/models/qmc/gradient_boosting_best_model.pkl\n",
      "Saved SEL-NNML model tuned with QMC to ../artifacts/ds1/models/qmc/sel-nnml_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # Save Every Best Meta Model for each Tuning Method as .pkl\n",
    "    for sampler, models in all_models.items():\n",
    "        folder = sampler.lower().replace(\"-\", \"\")\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(f'../artifacts/ds1/models/{folder}', exist_ok=True)\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            filename = f'../artifacts/ds1/models/{folder}/{model_name.replace(\" \", \"_\").lower()}_best_model.pkl'\n",
    "            joblib.dump(model, filename)\n",
    "            print(f'Saved {model_name} model tuned with {sampler} to {filename}')\n",
    "else:\n",
    "    print(\"Skipping model saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Base Models Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Meta Model Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e239448f-ae0b-4230-aee5-2ab612afe09e",
       "rows": [
        [
         "0",
         "TPE",
         "53.734062910079956",
         "193.78354024887085",
         "247.5176031589508"
        ],
        [
         "1",
         "GP",
         "182.44605374336243",
         "120.7078058719635",
         "303.1538596153259"
        ],
        [
         "2",
         "CMA-ES",
         "52.41893029212952",
         "115.981924533844",
         "168.4008548259735"
        ],
        [
         "3",
         "QMC",
         "48.39629054069519",
         "93.4653947353363",
         "141.8616852760315"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Base Models Training Time (seconds)</th>\n",
       "      <th>Meta Model Training Time (seconds)</th>\n",
       "      <th>Total Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPE</td>\n",
       "      <td>53.734063</td>\n",
       "      <td>193.783540</td>\n",
       "      <td>247.517603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>182.446054</td>\n",
       "      <td>120.707806</td>\n",
       "      <td>303.153860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>52.418930</td>\n",
       "      <td>115.981925</td>\n",
       "      <td>168.400855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QMC</td>\n",
       "      <td>48.396291</td>\n",
       "      <td>93.465395</td>\n",
       "      <td>141.861685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sampler  Base Models Training Time (seconds)  \\\n",
       "0     TPE                            53.734063   \n",
       "1      GP                           182.446054   \n",
       "2  CMA-ES                            52.418930   \n",
       "3     QMC                            48.396291   \n",
       "\n",
       "   Meta Model Training Time (seconds)  Total Training Time (seconds)  \n",
       "0                          193.783540                     247.517603  \n",
       "1                          120.707806                     303.153860  \n",
       "2                          115.981925                     168.400855  \n",
       "3                           93.465395                     141.861685  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # SAVE TRAIN TIME FOR EACH SAMPLER TYPE (BASE + META) IN A FILE\n",
    "    train_times = {\n",
    "        'Sampler': ['TPE', 'GP', 'CMA-ES', 'QMC'],\n",
    "        'Base Models Training Time (seconds)': [\n",
    "            tpe_base_models_training_time,\n",
    "            gp_base_models_training_time,\n",
    "            cmaes_base_models_training_time,\n",
    "            qmc_base_models_training_time\n",
    "        ],\n",
    "        'Meta Model Training Time (seconds)': [\n",
    "            tpe_meta_model_training_time,\n",
    "            gp_meta_model_training_time,\n",
    "            cmaes_meta_model_training_time,\n",
    "            qmc_meta_model_training_time\n",
    "        ],\n",
    "        'Total Training Time (seconds)': [\n",
    "            tpe_base_models_training_time + tpe_meta_model_training_time,\n",
    "            gp_base_models_training_time + gp_meta_model_training_time,\n",
    "            cmaes_base_models_training_time + cmaes_meta_model_training_time,\n",
    "            qmc_base_models_training_time + qmc_meta_model_training_time\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    train_times_df = pd.DataFrame(train_times)\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs('../artifacts/ds1/models', exist_ok=True)\n",
    "    \n",
    "    train_times_df.to_csv('../artifacts/ds1/models/training_times.csv', index=False)\n",
    "    display(train_times_df)\n",
    "else:\n",
    "    print(\"Skipping training times saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TPE SEL-NNML training history to ../artifacts/ds1/models/tpe/sel-nnml_training_history.csv\n",
      "Saved GP SEL-NNML training history to ../artifacts/ds1/models/gp/sel-nnml_training_history.csv\n",
      "Saved CMA-ES SEL-NNML training history to ../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv\n",
      "Saved QMC SEL-NNML training history to ../artifacts/ds1/models/qmc/sel-nnml_training_history.csv\n",
      "\n",
      "Sample of TPE SEL-NNML Training History (first 10 iterations):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "iteration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ef4fa7c4-35e5-415d-94c3-362a588d3935",
       "rows": [
        [
         "0",
         "1",
         "0.92"
        ],
        [
         "1",
         "2",
         "0.9133333333333333"
        ],
        [
         "2",
         "3",
         "0.9133333333333333"
        ],
        [
         "3",
         "4",
         "0.92"
        ],
        [
         "4",
         "5",
         "0.9133333333333333"
        ],
        [
         "5",
         "6",
         "0.92"
        ],
        [
         "6",
         "7",
         "0.9266666666666666"
        ],
        [
         "7",
         "8",
         "0.8933333333333333"
        ],
        [
         "8",
         "9",
         "0.0"
        ],
        [
         "9",
         "10",
         "0.9133333333333333"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration     score\n",
       "0          1  0.920000\n",
       "1          2  0.913333\n",
       "2          3  0.913333\n",
       "3          4  0.920000\n",
       "4          5  0.913333\n",
       "5          6  0.920000\n",
       "6          7  0.926667\n",
       "7          8  0.893333\n",
       "8          9  0.000000\n",
       "9         10  0.913333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # SAVE SEL-NNML TRAINING HISTORY (CONVERGENCE DATA) FOR EACH SAMPLER\n",
    "    # These will be used to create convergence plots showing how the model performance\n",
    "    # improved over the 100 optimization iterations\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    # Ensure directories exist for each sampler\n",
    "    samplers = ['tpe', 'gp', 'cmaes', 'qmc']\n",
    "    for sampler in samplers:\n",
    "        os.makedirs(f'../artifacts/ds1/models/{sampler}', exist_ok=True)\n",
    "    \n",
    "    # Save TPE SEL-NNML training history\n",
    "    tpe_meta_history.to_csv('../artifacts/ds1/models/tpe/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved TPE SEL-NNML training history to ../artifacts/ds1/models/tpe/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save GP SEL-NNML training history\n",
    "    gp_meta_history.to_csv('../artifacts/ds1/models/gp/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved GP SEL-NNML training history to ../artifacts/ds1/models/gp/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save CMA-ES SEL-NNML training history\n",
    "    cmaes_meta_history.to_csv('../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved CMA-ES SEL-NNML training history to ../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Save QMC SEL-NNML training history\n",
    "    qmc_meta_history.to_csv('../artifacts/ds1/models/qmc/sel-nnml_training_history.csv', index=False)\n",
    "    print(f'Saved QMC SEL-NNML training history to ../artifacts/ds1/models/qmc/sel-nnml_training_history.csv')\n",
    "    \n",
    "    # Display a sample of one history to verify the data\n",
    "    print(\"\\nSample of TPE SEL-NNML Training History (first 10 iterations):\")\n",
    "    display(tpe_meta_history.head(10))\n",
    "else:\n",
    "    print(\"Skipping SEL-NNML training history saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP_TRAINING is False. Models should be trained in steps 4 and 5.\n"
     ]
    }
   ],
   "source": [
    "# Skip step 4 and load every best model for each tuning method if SKIP_TRAINING is True\n",
    "if SKIP_TRAINING:\n",
    "    print(\"Loading pre-existing models...\")\n",
    "    all_models = {sampler: {\n",
    "            'Logistic Regression': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/logistic_regression_best_model.pkl'),\n",
    "            'Decision Tree': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/decision_tree_best_model.pkl'),\n",
    "            'Random Forest': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/random_forest_best_model.pkl'),\n",
    "            'K-Nearest Neighbors': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/k-nearest_neighbors_best_model.pkl'),\n",
    "            'Support Vector Machine': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/support_vector_machine_best_model.pkl'),\n",
    "            'AdaBoost': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/adaboost_best_model.pkl'),\n",
    "            'Gradient Boosting': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/gradient_boosting_best_model.pkl'),\n",
    "            'SEL-NNML': joblib.load(f'../artifacts/ds1/models/{sampler.lower().replace(\"-\", \"\")}/sel-nnml_best_model.pkl')\n",
    "        } for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']}\n",
    "    print(\"All models loaded successfully!\")\n",
    "    \n",
    "    # Load training times\n",
    "    print(\"Loading training times...\")\n",
    "    train_times_df = pd.read_csv('../artifacts/ds1/models/training_times.csv')\n",
    "    \n",
    "    # Extract individual training times for each sampler\n",
    "    for idx, row in train_times_df.iterrows():\n",
    "        sampler = row['Sampler']\n",
    "        if sampler == 'TPE':\n",
    "            tpe_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            tpe_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'GP':\n",
    "            gp_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            gp_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'CMA-ES':\n",
    "            cmaes_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            cmaes_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "        elif sampler == 'QMC':\n",
    "            qmc_base_models_training_time = row['Base Models Training Time (seconds)']\n",
    "            qmc_meta_model_training_time = row['Meta Model Training Time (seconds)']\n",
    "    \n",
    "    print(\"Training times loaded successfully!\")\n",
    "    display(train_times_df)\n",
    "    \n",
    "    # Load SEL-NNML training histories for convergence plots\n",
    "    print(\"\\nLoading SEL-NNML training histories...\")\n",
    "    tpe_meta_history = pd.read_csv('../artifacts/ds1/models/tpe/sel-nnml_training_history.csv')\n",
    "    gp_meta_history = pd.read_csv('../artifacts/ds1/models/gp/sel-nnml_training_history.csv')\n",
    "    cmaes_meta_history = pd.read_csv('../artifacts/ds1/models/cmaes/sel-nnml_training_history.csv')\n",
    "    qmc_meta_history = pd.read_csv('../artifacts/ds1/models/qmc/sel-nnml_training_history.csv')\n",
    "    print(\"SEL-NNML training histories loaded successfully!\")\n",
    "else:\n",
    "    print(\"SKIP_TRAINING is False. Models should be trained in steps 4 and 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Save Baseline Models**\n",
    "\n",
    "Save default base models and stacking models for later evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Logistic Regression default model to ../artifacts/ds1/models/baseline/logistic_regression_default_model.pkl\n",
      "Saved Decision Tree default model to ../artifacts/ds1/models/baseline/decision_tree_default_model.pkl\n",
      "Saved Random Forest default model to ../artifacts/ds1/models/baseline/random_forest_default_model.pkl\n",
      "Saved K-Nearest Neighbors default model to ../artifacts/ds1/models/baseline/k-nearest_neighbors_default_model.pkl\n",
      "Saved Support Vector Machine default model to ../artifacts/ds1/models/baseline/support_vector_machine_default_model.pkl\n",
      "Saved AdaBoost default model to ../artifacts/ds1/models/baseline/adaboost_default_model.pkl\n",
      "Saved Gradient Boosting default model to ../artifacts/ds1/models/baseline/gradient_boosting_default_model.pkl\n",
      "Saved Stacking + Linear Regression model to ../artifacts/ds1/models/baseline/stacking_lr_model.pkl\n",
      "Saved Stacking + Default MLP model to ../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl\n",
      "Saved baseline training times to ../artifacts/ds1/models/baseline/baseline_training_times.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Time (seconds)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3088fd70-2e57-4bdf-bb10-3c1acc578cbd",
       "rows": [
        [
         "0",
         "Default Base Models",
         "0.4739844799041748"
        ],
        [
         "1",
         "Stacking + Linear Regression",
         "6.358065605163574"
        ],
        [
         "2",
         "Stacking + Default MLP",
         "2.718488931655884"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Base Models</td>\n",
       "      <td>0.473984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stacking + Linear Regression</td>\n",
       "      <td>6.358066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking + Default MLP</td>\n",
       "      <td>2.718489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Type  Training Time (seconds)\n",
       "0           Default Base Models                 0.473984\n",
       "1  Stacking + Linear Regression                 6.358066\n",
       "2        Stacking + Default MLP                 2.718489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    import os\n",
    "    \n",
    "    # Save default base models\n",
    "    os.makedirs('../artifacts/ds1/models/baseline', exist_ok=True)\n",
    "    \n",
    "    for model_name, model in default_base_models.items():\n",
    "        filename = f'../artifacts/ds1/models/baseline/{model_name.replace(\" \", \"_\").lower()}_default_model.pkl'\n",
    "        joblib.dump(model, filename)\n",
    "        print(f'Saved {model_name} default model to {filename}')\n",
    "    \n",
    "    # Save stacking models\n",
    "    joblib.dump(stacking_lr, '../artifacts/ds1/models/baseline/stacking_lr_model.pkl')\n",
    "    print(f'Saved Stacking + Linear Regression model to ../artifacts/ds1/models/baseline/stacking_lr_model.pkl')\n",
    "    \n",
    "    joblib.dump(stacking_mlp, '../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    print(f'Saved Stacking + Default MLP model to ../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    \n",
    "    # Save baseline training times\n",
    "    baseline_times = pd.DataFrame({\n",
    "        'Model Type': ['Default Base Models', 'Stacking + Linear Regression', 'Stacking + Default MLP'],\n",
    "        'Training Time (seconds)': [default_models_training_time, stack_lr_training_time, stack_mlp_training_time]\n",
    "    })\n",
    "    baseline_times.to_csv('../artifacts/ds1/models/baseline/baseline_training_times.csv', index=False)\n",
    "    print(f'Saved baseline training times to ../artifacts/ds1/models/baseline/baseline_training_times.csv')\n",
    "    \n",
    "    display(baseline_times)\n",
    "else:\n",
    "    print(\"Skipping baseline model saving (SKIP_TRAINING = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP_TRAINING is False. Models should be trained in sections 3.1-3.3.\n"
     ]
    }
   ],
   "source": [
    "if SKIP_TRAINING:\n",
    "    print(\"Loading baseline models...\")\n",
    "    \n",
    "    # Load default base models\n",
    "    default_base_models = {\n",
    "        'Logistic Regression': joblib.load('../artifacts/ds1/models/baseline/logistic_regression_default_model.pkl'),\n",
    "        'Decision Tree': joblib.load('../artifacts/ds1/models/baseline/decision_tree_default_model.pkl'),\n",
    "        'Random Forest': joblib.load('../artifacts/ds1/models/baseline/random_forest_default_model.pkl'),\n",
    "        'K-Nearest Neighbors': joblib.load('../artifacts/ds1/models/baseline/k-nearest_neighbors_default_model.pkl'),\n",
    "        'Support Vector Machine': joblib.load('../artifacts/ds1/models/baseline/support_vector_machine_default_model.pkl'),\n",
    "        'AdaBoost': joblib.load('../artifacts/ds1/models/baseline/adaboost_default_model.pkl'),\n",
    "        'Gradient Boosting': joblib.load('../artifacts/ds1/models/baseline/gradient_boosting_default_model.pkl')\n",
    "    }\n",
    "    \n",
    "    # Load stacking models\n",
    "    stacking_lr = joblib.load('../artifacts/ds1/models/baseline/stacking_lr_model.pkl')\n",
    "    stacking_mlp = joblib.load('../artifacts/ds1/models/baseline/stacking_mlp_default_model.pkl')\n",
    "    \n",
    "    # Load baseline training times\n",
    "    baseline_times = pd.read_csv('../artifacts/ds1/models/baseline/baseline_training_times.csv')\n",
    "    \n",
    "    # Extract training times\n",
    "    default_models_training_time = baseline_times[baseline_times['Model Type'] == 'Default Base Models']['Training Time (seconds)'].values[0]\n",
    "    stack_lr_training_time = baseline_times[baseline_times['Model Type'] == 'Stacking + Linear Regression']['Training Time (seconds)'].values[0]\n",
    "    stack_mlp_training_time = baseline_times[baseline_times['Model Type'] == 'Stacking + Default MLP']['Training Time (seconds)'].values[0]\n",
    "    \n",
    "    print(\"âœ“ All baseline models loaded successfully!\")\n",
    "    display(baseline_times)\n",
    "else:\n",
    "    print(\"SKIP_TRAINING is False. Models should be trained in sections 3.1-3.3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage contains model evaluation on the test set, with details as follows:\n",
    "- `plot_evaluation_metrics()`: Shows the confusion matrix graph & scores for accuracy, precision, recall, and F1-Score\n",
    "- `Model Performance Comparison Plot`: Displays accuracy, precision, recall, F1-Score, and ROC AUC scores\n",
    "- `overfitting_index_plot()`: Shows the percentage of the difference between model scores on test data versus training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Model Evaluation Dashboard\n",
    "def evaluation_metrics_plot(y_true, y_pred):\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "    }\n",
    "    metric_order = ['F1-Score', 'Recall', 'Precision', 'Accuracy']\n",
    "    values = [metrics[name] for name in metric_order]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    cm_pos = [0.08, 0.15, 0.53, 0.7]\n",
    "    metrics_pos = [0.75, 0.15, 0.21, 0.7]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    ax_cm = fig.add_axes(cm_pos)\n",
    "    im = ax_cm.imshow(cm, cmap='Blues', interpolation='nearest', aspect='equal')\n",
    "    cbar_ax = fig.add_axes([cm_pos[0] + cm_pos[2] + 0.02, cm_pos[1], 0.02, cm_pos[3]])\n",
    "    fig.colorbar(im, cax=cbar_ax).ax.tick_params(labelsize=16)\n",
    "\n",
    "    cm_pct = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count, pct = int(cm[i, j]), cm_pct[i, j]\n",
    "            color = 'white' if count > cm.max() / 2 else 'black'\n",
    "            ax_cm.text(j, i, f'{count}\\n({pct:.1f}%)', ha='center', va='center',\n",
    "                    color=color, fontsize=18, fontweight='bold', linespacing=1.1)\n",
    "\n",
    "    ax_cm.set_xticks([0, 1])\n",
    "    ax_cm.set_yticks([0, 1])\n",
    "    ax_cm.set_xticklabels(['No\\n(0)', 'Disease\\n(1)'], fontsize=16)\n",
    "    ax_cm.set_yticklabels(['No (0)', 'Disease (1)'], fontsize=16, rotation=90, va='center')\n",
    "    ax_cm.set_xlabel('Predicted', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_ylabel('Actual', fontsize=16, fontweight='bold')\n",
    "    ax_cm.set_title('Confusion Matrix', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_cm.set_ylim(1.5, -0.5)\n",
    "\n",
    "    # Metrics Bar\n",
    "    ax_metrics = fig.add_axes(metrics_pos)\n",
    "    y_positions = np.arange(len(metric_order)) * 2\n",
    "    bars = ax_metrics.barh(y_positions, values, height=0.8, color='#31688E', alpha=0.8)\n",
    "\n",
    "    for bar, value in zip(bars, values):\n",
    "        color = 'white' if value > 0.5 else 'black'\n",
    "        x_pos = value - 0.02 if value > 0.5 else value + 0.02\n",
    "        ha = 'right' if value > 0.5 else 'left'\n",
    "        ax_metrics.text(x_pos, bar.get_y() + bar.get_height()/2, f'{value:.3f}',\n",
    "                        ha=ha, va='center', fontsize=18, fontweight='bold', color=color)\n",
    "\n",
    "    ax_metrics.set_xlim(-0.05, 1.05)\n",
    "    ax_metrics.set_ylim(-0.8, len(metric_order) * 2 - 0.2)\n",
    "    ax_metrics.set_xticks([0, 0.5, 1.0])\n",
    "    ax_metrics.set_xticklabels(['0.0', '0.5', '1.0'], fontsize=16)\n",
    "    ax_metrics.set_yticks(y_positions)\n",
    "    ax_metrics.set_yticklabels(metric_order, fontsize=16, rotation=90, ha='left', va='center')\n",
    "    ax_metrics.tick_params(axis='y', pad=15)\n",
    "    ax_metrics.tick_params(axis='x', pad=8)\n",
    "    ax_metrics.set_xlabel('Score', fontsize=16, fontweight='bold')\n",
    "    ax_metrics.set_title('Performance Metrics', fontsize=16, fontweight='bold', pad=10)\n",
    "    ax_metrics.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    for spine in ['top', 'right', 'left']:\n",
    "        ax_metrics.spines[spine].set_visible(False)\n",
    "    ax_metrics.spines['bottom'].set_alpha(0.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Model Comparison Dashboard (for comparing all models)\n",
    "def model_comparison_plot(models, x_test, y_test):\n",
    "    metrics = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'F1-Score': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "    \n",
    "    # Map full names to short names\n",
    "    short_names = {\n",
    "        'Logistic Regression': 'LR',\n",
    "        'Decision Tree': 'DT',\n",
    "        'Random Forest': 'RF',\n",
    "        'K-Nearest Neighbors': 'KNN',\n",
    "        'Support Vector Machine': 'SVM',\n",
    "        'AdaBoost': 'AdaBoost',\n",
    "        'Gradient Boosting': 'Gradient Boosting',\n",
    "        'SEL-NNML': 'SEL-NNML'\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics for each model\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(x_test)\n",
    "        metrics['Model'].append(short_names[model_name])\n",
    "        metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['F1-Score'].append(f1_score(y_test, y_pred))\n",
    "        metrics['Precision'].append(precision_score(y_test, y_pred))\n",
    "        metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "        \n",
    "        # Calculate AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        metrics['AUC'].append(roc_auc)\n",
    "    \n",
    "    # Convert metrics to DataFrame for sorting\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "    fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold') \n",
    "    \n",
    "    # Helper function to plot sorted bar charts\n",
    "    def plot_sorted_bar_chart(ax, metric_name):\n",
    "        sorted_df = metrics_df.sort_values(by=metric_name, ascending=False)\n",
    "        colors = ['tab:orange' if model == 'SEL-NNML' else 'tab:blue' for model in sorted_df['Model']]\n",
    "        ax.bar(sorted_df['Model'], sorted_df[metric_name], color=colors)\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_xticks(range(len(sorted_df['Model'])))\n",
    "        ax.set_xticklabels(sorted_df['Model'], rotation=30, ha='center')\n",
    "        for i, v in enumerate(sorted_df[metric_name]):\n",
    "            ax.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "    # Plot each metric\n",
    "    plot_sorted_bar_chart(axes[0, 0], 'Accuracy')\n",
    "    plot_sorted_bar_chart(axes[0, 1], 'F1-Score')\n",
    "    plot_sorted_bar_chart(axes[1, 0], 'Precision')\n",
    "    plot_sorted_bar_chart(axes[1, 1], 'Recall')\n",
    "    \n",
    "    # ROC Curve\n",
    "    ax_roc = axes[2, 0]\n",
    "    for model_name, model in models.items():\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(x_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax_roc.plot(fpr, tpr, lw=2, label=f'{short_names[model_name]} (AUC = {roc_auc:.3f})')\n",
    "    ax_roc.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_title('Receiver Operating Characteristic')\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Bar chart for AUC\n",
    "    plot_sorted_bar_chart(axes[2, 1], 'AUC')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfitting_index_plot(all_models, x_train, y_train, x_test, y_test):\n",
    "    metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "    overfitting_indices = {metric: [] for metric in metrics}\n",
    "\n",
    "    for _, model in all_models.items():\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "        overfitting_indices['Accuracy'].append(abs(accuracy_score(y_train, y_train_pred) - accuracy_score(y_test, y_test_pred)) / accuracy_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['F1-Score'].append(abs(f1_score(y_train, y_train_pred) - f1_score(y_test, y_test_pred)) / f1_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Precision'].append(abs(precision_score(y_train, y_train_pred) - precision_score(y_test, y_test_pred)) / precision_score(y_train, y_train_pred) * 100)\n",
    "        overfitting_indices['Recall'].append(abs(recall_score(y_train, y_train_pred) - recall_score(y_test, y_test_pred)) / recall_score(y_train, y_train_pred) * 100)\n",
    "\n",
    "    overfitting_df = pd.DataFrame(overfitting_indices, index=all_models.keys())\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Overfitting Index for All Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "    def get_bar_colors(models, highlight_model='SEL-NNML', default_color='tab:blue', highlight_color='tab:orange'):\n",
    "        return [highlight_color if model == highlight_model else default_color for model in models]\n",
    "\n",
    "    # Accuracy\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Accuracy', ascending=False)\n",
    "    axes[0, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Accuracy'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 0].set_title('Accuracy Overfitting Index')\n",
    "    axes[0, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 0].set_ylim([0, 100])\n",
    "    axes[0, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Accuracy']):\n",
    "        axes[0, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # F1-Score\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='F1-Score', ascending=False)\n",
    "    axes[0, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['F1-Score'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[0, 1].set_title('F1-Score Overfitting Index')\n",
    "    axes[0, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[0, 1].set_ylim([0, 100])\n",
    "    axes[0, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['F1-Score']):\n",
    "        axes[0, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Precision\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Precision', ascending=False)\n",
    "    axes[1, 0].bar(overfitting_df_sorted.index, overfitting_df_sorted['Precision'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 0].set_title('Precision Overfitting Index')\n",
    "    axes[1, 0].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 0].set_ylim([0, 100])\n",
    "    axes[1, 0].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Precision']):\n",
    "        axes[1, 0].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    # Recall\n",
    "    overfitting_df_sorted = overfitting_df.sort_values(by='Recall', ascending=False)\n",
    "    axes[1, 1].bar(overfitting_df_sorted.index, overfitting_df_sorted['Recall'], \n",
    "                    color=get_bar_colors(overfitting_df_sorted.index))\n",
    "    axes[1, 1].set_title('Recall Overfitting Index')\n",
    "    axes[1, 1].set_ylabel('Overfitting Index (%)')\n",
    "    axes[1, 1].set_ylim([0, 100])\n",
    "    axes[1, 1].tick_params(axis='x', rotation=30)\n",
    "    for i, v in enumerate(overfitting_df_sorted['Recall']):\n",
    "        axes[1, 1].text(i, v + 1, f'{v:.2f}', ha='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 SEL-NNML Model Evaluation**\n",
    "\n",
    "This section evaluates the SEL-NNML model from the selected sampler. Change `SELECTED_SAMPLER` in the cell below to evaluate a different sampler's SEL-NNML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected sampler: TPE\n",
      "Models available: ['Logistic Regression', 'Decision Tree', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine', 'AdaBoost', 'Gradient Boosting', 'SEL-NNML']\n"
     ]
    }
   ],
   "source": [
    "# Select which sampler's models to evaluate\n",
    "# Options: 'TPE', 'GP', 'CMA-ES', 'QMC'\n",
    "SELECTED_SAMPLER = 'TPE'\n",
    "\n",
    "# Extract models and training times for the selected sampler\n",
    "selected_models = all_models[SELECTED_SAMPLER]\n",
    "sel_nnml = selected_models['SEL-NNML']\n",
    "\n",
    "# Extract training times for the selected sampler\n",
    "if SELECTED_SAMPLER == 'TPE':\n",
    "    base_models_training_time = tpe_base_models_training_time\n",
    "    meta_model_training_time = tpe_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'GP':\n",
    "    base_models_training_time = gp_base_models_training_time\n",
    "    meta_model_training_time = gp_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'CMA-ES':\n",
    "    base_models_training_time = cmaes_base_models_training_time\n",
    "    meta_model_training_time = cmaes_meta_model_training_time\n",
    "elif SELECTED_SAMPLER == 'QMC':\n",
    "    base_models_training_time = qmc_base_models_training_time\n",
    "    meta_model_training_time = qmc_meta_model_training_time\n",
    "\n",
    "print(f'Selected sampler: {SELECTED_SAMPLER}')\n",
    "print(f'Models available: {list(selected_models.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show SEL-NNML Evaluation Metrics\n",
    "y_pred_stack = sel_nnml.predict(X_test)\n",
    "evaluation_metrics_plot(y_test, y_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: [0.84166667 0.85714286 0.88235294 0.82352941 0.8907563 ]\n",
      "Mean: 0.8591\n",
      "Standard Deviation: 0.0250\n"
     ]
    }
   ],
   "source": [
    "# Show SEL-NNM: all fold scores with mean and std \n",
    "sel_nnml_cv_scores = cross_val_score(sel_nnml, X_train, y_train, cv=CV_FOLDS, scoring='accuracy', n_jobs=N_JOBS)\n",
    "print(f'SEL-NNML CV Accuracy Scores [Fold 1, Fold 2, ..., Fold n]: {sel_nnml_cv_scores}')\n",
    "print(f'Mean: {sel_nnml_cv_scores.mean():.4f}')\n",
    "print(f'Standard Deviation: {sel_nnml_cv_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Models Tuning & Training Time: 53.73 seconds\n",
      "Meta Model Tuning & Training Time: 193.78 seconds\n",
      "Total SEL-NNML Tuning & Training Time: 247.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# Show SELL-NNML Training Time\n",
    "Total_training_time = base_models_training_time + meta_model_training_time\n",
    "print(f'Base Models Tuning & Training Time: {base_models_training_time:.2f} seconds')\n",
    "print(f'Meta Model Tuning & Training Time: {meta_model_training_time:.2f} seconds')\n",
    "print(f'Total SEL-NNML Tuning & Training Time: {Total_training_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Multiple Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation below compares all models (base models + SEL-NNML) for the selected sampler. To compare models across different samplers, change the `SELECTED_SAMPLER` variable in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the selected sampler's models for comparison\n",
    "model_comparison_plot(selected_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABikAAASdCAYAAAA1wb/FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdB5RT1ff28T3SQYr0Ks1GUUFABBQQKQoWECsWbIiCSlGxoFIUEAuKoNixotixoIDAD1FQaTZQsQCigiBtUJCadz3nv27em0xmmIHM3Ezy/awVmCQ3mZubm8w5Z599dlooFAoZAAAAAAAAAABAHjsor38hAAAAAAAAAACAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAwH4JhUL29NNPW4sWLaxUqVKWlpYWvrzzzjtuG/9ttWrVyvUjvXLlyojf2bZt21z/nclEx8t//HQ884N//vnH7rjjDqtfv74VK1Ys4jVs3rzZko0+S/7X6Pe///0v4r7LLrsssP1MZHxXAAAAJI6CQe8AAABAMlq4cKG98MIL9sknn9jq1att69atVqZMGTe4ePLJJ9tVV11lhx9+uOVngwcPtlGjRu334zV4/PDDD4ev69hkNqCqgVddPF27drVGjRpZstExWLVqVfj67NmzCbRkI1h26qmn2meffWb5zfr1661q1aq2e/fuiNtnzJhh7du3DyxQNWfOnIjbmjVrZl9++WXM7d9//30744wzMtwez3M3VT7/AAAAqYogBQAAQJxndPfq1cteffXVmAOSuixYsMAefPBBu/766+3++++3ggXzX5Ps33//tTFjxkTcVqRIEReIkaJFi7r/K1WqFL6/QoUKGYIUw4YNC19v06ZNlkEK/7YazI81SFmgQIGI31m2bNn9eHXIT2bOnJkhQFGyZEkrXry4+/mggxI3eXzy5MkZAhTy8ssvBxakiEXfWUuWLLHGjRtnuO+JJ57I9d+f3c9/TvBdAQAAkDjyX48YAAAgQW3fvt3NHF60aFHE7Rok1XJIW7ZscbO+Zc+ePS6L4Ndff3VLI0Uv2ZLoli1bZjt27AhfP+6449xAsRec8KxduzZP96tGjRp5/jsRLA2e+/Xp08ceffRRyw8mTZoU8/a33nrLJkyYkOHzFKQnn3zS7ZOfssQ+/PBDy4/4rgAAAEgciTutCAAAIJ/p379/RIBCgYfhw4fbhg0bbNOmTbZx40Z33R+QePfdd102RX6zbdu2iOtHH310Qg2oInVEn4tamig/WLFihc2fPz/mfenp6W4ZpUSi7A5lUPk99dRTLuAKAAAAHAiCFAAAAHEqwvrss89G3DZkyBC78847w0sg6X9dv+uuuyK2Gz16tFsmSq6++uqIorezZs2KOYCpgIC3zVFHHZVhm6+++so9l+47+OCD3dI3RxxxhPXt29dlb8SipZb8v1tLrCxevNi6devmlmpSRshzzz0XsyD1888/H7OQb2aFs3W9du3aEc+hdfCjt/d+n3+pF7n88ssjth06dGi2CmdrO//9ev41a9bYtdde62ZWa8kq/d5bbrklw+C3R8vzPPDAA65Is96HKlWquGOnWeXe/kbvV24WTJ42bZp16NDBnV96n5s3b25vv/12loPjl1xyiVWsWNFtf+yxx9pjjz0WzvLZF73+l156yU4//XT32gsXLmyHHHKInXjiifbII49EZNjI33//7bbz9lmFrZcvXx6xza233hrxugYOHLjP/fCOdfQx9p8b0e+/BtmVwaS6MDqnCxUq5JYEO+GEE1wAUfua3eP++uuvu9dcunTp/SoyHp1F0bFjxyzvD4reL1FdnVdeeSXiPHjmmWfC173ltfZFdXp0/tWpU8c9Rt9PCnLqM/fXX39FbBuPz/+uXbtc7ZwGDRq41+J9D2W3cLaCy/fee69bjk7njM53/a/ssZtvvtl9nvy++eYbu/LKK+3II4+0EiVKuO21BN0xxxzjvieUkRId7AEAAEh5IQAAAByw0aNHa4Q3fClZsmRo27ZtMbfV7brfv/3rr7/u7ps7d27E7VdffXWGx7/wwgsR24wYMSLi/jvvvDOUlpYWsY3/UqRIkdCrr76a4Xl79uwZsd2gQYNChQoVirht4sSJmT6v/+Lx31azZs2Yt2d20fbZ/X1Dhgxxz7tixYqI29u0aRPxGrWd//6+ffuGypYtG/M5O3bsGNq7d2/E43ft2hXq0qVLzO31PDfddFPM/couvWb/42fPnp3l/XqvMzsmL730UobnX7JkSahMmTIxtz/33HNDJ510UsRtOp5+f/75Z6h58+ZZvhdHH310aPXq1RGPe//99yO2ad26dfjYLlq0KFSwYMHwffXr1w9t3759n8cqO+eG//3/+uuvQ7Vq1cpy+3LlyoVmzpy5z/dl8ODBGR4bfaz2pUGDBhGPX7p0qfv9/s/ppk2bYj42en/8dM7479PnOid0zKIf7/3ctGnT8HZvvfVW+PY6deq49zSrc1efnSuuuCLL469z0/+4A/38t2jRItSuXbsM3yvZ+a6QadOmhcqXL5/l79Y++rcvXLjwPvf322+/zdF7AgAAkOzIpAAAAIiDTz/9NOK6ZuV6M5Cj6XbNyo31eM3Mrlu3bsTa9NGFdV977bXwz5oBfPHFF4evqyD33XffHTErXjN5/Usxaaa7HpPZUjOe++67z81CVmFvzRYXZQtoVrBmzvvp+XW7d9kXbVO+fPmI2zSr3f8cmq2sY6WfNSPZTzU+/NtqNvb+UO0CzZTWa9Tv95s+fbp99NFHGbJePvjggwwFeHWM9TzKsMhLeq8l1rk2aNCgiKV4du7caeeff74rWO7nzYBXZkB0AWo/PV7ZE1988UWGItX+7Jlvv/3WzjzzTLe9p0uXLi6zxz+bXjPKdW5fccUV4XNc74GyNLKzdFh2zg2vcLoK1p922mkZsh2iZ/9rabauXbtmyPSINmLECPe/9jP692eHMp2WLl0avt6wYUOXmXPGGWdEfE7ffPNNC5rOGS8bbOHCheEaIP6C2b169dpnXZ0BAwZkyDbTe+j/3OncPOuss+yXX34J338gn399x3nZaHpM9Gd8X8XCtS/R2TX+78Not99+e8R5r211DiZy8XYAAIBEQGsJAAAgDn7//feI64cffniW20ff73+8P+igATL/kk8qvq3Bc38w5NBDDw0PsPqXvtEA6uTJk11Bby0vMnHixPBAogaFb7rppn2+Lm2jehoaPPzzzz/dMi0qTK3gSfRApm73LvuibTQI6NeyZcuI59D93vNG7+vYsWMjts3Oa8mMlpnRcdXr1OC6n78osI5jdBBCg7M6NloKJ4jaIgoWffzxx+791eBxuXLlwvfp/fr666/D1xWE8A++a2BXARctNaZldtq1a2d79+7N9Hdp6R0t/+U5/vjj7ccff3TLj+nc07JgHu2LlgDzGzNmTEQATkEU1XHx76PO38aNG2frtWfn3PDOU703Oh6eww47zP1eHTcFLrRElkfvpZZly4qWBXvxxRfdtjp+WuInOuiWleilnLp37+7+P/vss7PcLggKFOhz71FwQksced9DGvjX8ktZ+f77792SYh6dpzNnznTHX5d77rknfJ/OJ29JvHh8/rW8k4IV+ozrM6zvxOzQkmP//fdf+HrNmjXd94H2V595fWcrSKjghz9A5/8e1+/UZ0PPo8DL008/7QIfCmoCAADg/yNIAQAAEAcarPTb1/rs0TODNZjlufTSSzPNnHjnnXciZur6t/UGnD39+vWz8847z83i1UXroat2gWfevHn222+/ZbqPGoTW4K43S1l1Bfx1JZJBo0aN3Hrzer/0nkQPdvrrdyjbxZ+FULlyZRs/frw7Php01GNbt26dp/uvuiennHKKCz7ptWgANLP9j84AUX2Szp07u8eqPoXqCygrJDOvvvpqxHUFIVTnxAuWKCvFz1+/QHR8X3jhhfDv0GC0/zEKUilglBsUoPFTXQrVCPAGnzV47Pfee+9lqK3hp8+WBqE1U15UUyG72TzKcoo+ll5wQp9P//OoLow/uBKU3r17RwROFHDysrWUebKv7Ckdf38ATEEJBcV07inIMXjw4PC5JAouZXX8c0LBEdUcEZ17/oBUZpQx5s+O0/enslpOPfXUcIChWrVqdscdd0QElvzvnX6X95r1GlWDQ7Uq9B3uf60AAAAgSAEAABAXWvLGL7Oiy57owqn+5UM0mNWqVavwdRVB1rJL0QELDayfc8454euazR29NJG/MKwu/iwMb/mWzPhnTyer6MwJDdZn9j4tW7Ys4j4t2RU9I7p9+/aWqPuv2ex+GiT2UwAqupi5X/T5Va9evYhzq2rVqvs8txSIUAZFNA3u+gMY8aTAXfQyTwrs+Gm5Jf9Au2bc//zzz7ny2dBSVxoE92d1eAETZT9pWSqPBrmjAxpBUNFp7ztJAVkF52IFMLJ77qhQffR3kz/LR5kH/uWw9peyW/zHM7v82T3e62/SpMk+H+dfrktBPH2vK3tIy6RpKShlj2SVrQQAAJCqyKQAAACIg+rVq0dc/+mnn7LcPvp+zcr182dIqNaBlvTRLH7979EMXv/MXX82RnZFr7ful2xZE9l536KDDv7aHtHZMtEBgcxuS9T9j7U8UVZLFuX0/NLv82f9ZFW/QBko/qWg4il6vxVQjFXzQjVQsnpcvD4b0Us4RS/x5F82K9b2QYkVjFCAJTrYFUu8v5uyS1ky+yN6f2vUqJGtxylDRwEJjwISymZSFtOoUaNcEFMBqeigGQAAQKr7v/xkAAAAHBDNMtYSMf5lWjQbO1ZBY90+Z86ciNtUMNtPyzTdcMMN4SVPlEGhtdczW+pJoou5qtit1s7PSlaFZPe3GHV+Ev36syr+6197XrTWfDQVaE7U/Y/O9ok1CJzVwLDOL+81e0tE7Ytqn/gDJwqaaLDbHzyRqVOnuiV+ogfs4yH6c6HgiWbqRwcqot+7zIojH8hnQxlRb7zxRoYC9bpkZtGiRa72x5FHHmlBOvfcc10NEQVNPSqGvq+C2bGOpWpSeEtlZSYexab3933yCoV7/Jkv+3qc/g4oCD1jxgz77rvvXEaO6ut4S8UpQ0THUcs+AQAA4P+QSQEAABAHCir4l6rRQGhmA49ahsk/q13r+Wut8+jBLv/SIRrQeumllyIyL6KXrPGWjPFcd911EcVloy9a635fBW9zU/Qg5J49e+KybW6pX79+xHWtWR+9HxqYTFRansnPX5BdNLtbBZEz4z+/FGTQ69/X+RVdm0XLBPmPkf99VfBCBbzjTQPV0ZkPWnbHT4PJ/t+t4KKyBOJNhZf9g/zZlQjZFArq+AOjCj6pzk12RH836TtwX+eOf+m0vP78H3vssRHXFVjwF43fl8MPP9z69Onj6mFoiT29Hi3j55k9e3Zc9xcAACC/I0gBAAAQB1rLP3rAf/jw4a5ArLd0iP6/++673e1+KhYcPctd/AOCmoXrH1S+6KKLMgzcdenSJaIgt4peP/nkkxF1CTZt2uSWjBowYIC1aNHCghQ9u/qHH36wdevWZWtbDZDn9druypZRQMmjouMqlq36I8pweeCBB1y9gUTlX4ZGVLRaGQwKOOi4X3XVVVkO/ioQFz2z/vPPPw9nReh/BTm0Fr8KeGt5Gz9lA/gLYyszwB94UxaHCgvnBn/tFtH579VJWLVqlXvt0cdqX1lI+yM62KBgpGphRF+il55KhCCFXHPNNS44qovO/ej9zOr4+7+vbr75ZpdR4s8M0zmoLARlZ0Rn1OT151/LqPmz2/S79BoUcPDqAymopc+8MoA8F154oQvALFmyJKLwt77b9N3r8Z4DAAAA/4cgBQAAQJyMHTvWGjVqFDGwdeedd1rZsmXDl7vuuitiqRsFFjRgF4sKvmY2CBi91JO3hMrQoUPD1zVIptnpmkmu361AiP7v0KGDWzs9N2at54QGHg899NCIQWoVX9YyQpUrV7YRI0ZkOhP7ueeec69L2+mSVZHjeNHs+htvvDHiNh1HLQOlY6v3MTtL3wRFg6xHHHFEREFpnX86jhoYj84uiHbFFVdY48aNw9e/+uorF+jSjHrVstBMe80W1+z6d999N2IgVss+6ZzVUmeiAetnnnnGDerq4tHa/U899VScX7m5Yt1VqlQJX9dyPJot72VZfPHFF+H7dJuCifGm4+1fEk6+/PLLmJkEa9asiagP4i0ZFDQFlhTk1MX/+cxOFpKKZXs0YK8gl84ZfW8puKpzUIXg9f57SyMF+fkfM2ZMxJJgCsB16tTJZQcpWKnfq898enp6RHH6W2+91Y477ji3nb5v9f2g6/4gRfPmzeO+vwAAAPkZQQoAAIA40aCUZtJHz9pWsEIDVP6Zvxqk1XJMb7/9dqZrr2vNdv8ArkcDXg0aNIj5GM1uVmAk+jn1+zVI6hcreyOv9e3bN+K6ZvKrNoACKP4lsVRYuWHDhhHbasBb2+miQfC8oEyAzp07Z9hnzQhXQMmfKRCvdfXjRcGEV199NcN6+8oEEQWvssqu0eMVRIjeRsdetSqii2T76wFoQFsD8p7rr7/eZabIuHHj3AC1Z+DAga7YcDzpvdFSS9GFlP1ZRqIB8ylTpuRK/Qd91r1jLQpoalmgWLR0XNeuXSNue/nlly0/U0AvOmNFAVstf+U/LrG+m4L4/Ddr1swts6dzwk+/KzqIEov3vR9dsF4Bjoceeiju+wsAAJCfJU6vCQAAIAlocO311193A7IagD/66KPdoJQCDpoZ3bRpUxdIWLZsmRuczapwdWYZE7Fu89NyUl9//bX7/RrY0z5p0FOD0wpwKLtCg28qyBs0zUR+5JFH3IBtrCLjHu2/ahloOSAtxbKvoru5Rb9Xg9haSuuoo45ySwJphr6yDJRZ4F9uS/zLQyUCZUJobX0tF6aBe+2/Zrnfe++9buknf5HrWPRa586d64Id3bp1c++FnkOPUxaMlgFSNo/OP53nsnDhQrfsmUfZFiNHjgxf1yDwhAkTwtcVTNM5Hu/lfJQ5odoTGiBu06ZNuHizMnqOP/54t99alqddu3aWG6KXbFImQVai7588eXIgtVjiRcdaWRLz5s1znxdl9ejzotv1Xii7oF+/fm5JJX3GEuHzr8yJ5cuXu6XLTjrppPA5o//1WVJmlc4lz7PPPuvObdUYUgBK37nady+bQkFMnYP+jDsAAACYpYX86w0AAAAAOKBBTQ2yejSw6i8ADAAAAACIRCYFAAAAkAM9e/Z0s6H9NMP9wQcfjAhQqLaGv/guAAAAACAjMikAAACAHPCKY2vZIi3povX0f/zxR1u3bl3Edlr65fLLL+fYAgAAAEAWCFIAAAAA+xGkyIzqM6jGw4ABAziuAAAAALAPwVQcBAAAAPKpJ554wj7++GNbsmSJrV+/3v79919XGFdZFW3btrWrr77aZVkAAAAAAPaNTAoAAAAAAAAAABAICmcDAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAEnjkUcesbS0NGvYsGHQu5IvrV692q677jqrW7euFS1a1A455BBr27atvfzyyxYKhQLdtyVLllibNm2sdOnS7j1++OGH7X//+5/7Wf97pk6dakOHDo35HCNHjrR33nknw+2xnieveL/7jTfeiOvz6jkzOw4AAADYt+eee861qWJdbrrppvB277//vl166aV29NFHW6FChdz9+9MO79Onjx1xxBFWrFgxK1u2rHu+Xr16ufvyo++//94uu+wyO/TQQ61w4cJWvnx569y5s3344YdB75rNnDnTmjZtaiVKlHDvl/oI3vu9cuXK8HaTJk1y/Y5o27Ztc23tWP2HWM+TV7zfvXDhwrg9p16HnlPPDQC5qWCuPjsA5KFnn33W/b906VL74osvrHnz5hz/bPrss8/s9NNPt4MPPthuvvlmO+aYY2zLli322muv2cUXX2zvvfeea6QfdFAwse0rrrjC/v33X3v11Vdd8KRWrVpWvHhxmz9/vtWvXz8iSPHoo4/GHKBXkOKcc86xrl27Rtx+3HHHZXgeAAAAQCZOnGhHHXVUxMGoWrVq+Oe3337bPv/8c2vcuLEVKVLEFi1alKMD9/vvv7v2aJkyZezGG2+0I4880rXDly1b5triv/76q9WoUSNfvRlvvfWW9ejRw+rUqWN33nmne01//fWXO5YKVKi/cd999wWyb5p8dd5557mA0LvvvusCFdq/3bt3uz5BlSpVwtuq//Pdd99Z//79MwQphg0b5n7WpC6/Ll26ZHgeAMC+EaQAkBQ0W+Trr792jcIPPvjAnnnmmYQNUqhRqwH2RLF582Y7++yzXZaCgjuVKlUK33fWWWe5gMWtt95qjRo1cv/nlT179rjOgjp76hxoJtlpp50Wsc0JJ5xwwL+nVKlScXkeAAAAJB9laWvWfWaeeuqp8EQeZSXnNEihx//999/25ZdfWu3atcO3a2LN7bffbnv37rW8sn37dpdRvT/ZIJ5ffvnFLrnkEpcJokwDBQE85557rl177bV2//33u8DMBRdcYHll165d7nUpWLJx40br1q2bnXLKKRHbVKhQ4YB/j54jHs8DAKmG5Z4AJAUFJeTee++1li1buhn3CgZE++OPP+zqq692s5GUdqxZUJpdr8aqf9Bes5g080cD5BUrVnQzfn744YcslweKlQqrFGdlJ3z77bfWsWNHK1myZLgxPGPGDBcEqF69uusMHHbYYda7d2/XSYmm333hhRe6AIL2SWnTSivfsWOH+70FCxa0UaNGZXjcJ5984vbp9ddfz/TYPf3007Zu3Tp37PwBCs+gQYPc7DF1JtS4X79+vTt2mhUVaz/1+7T0lmft2rXudel16nHqfGnmkQIQ0cdOM6ruuecet41ep2Zb6XZtO2HChHCKfaz3QcdaWRTiT8f3nluZGM8//3z4dm/WU6z303vffv75Z/fe62edMzovdMyjZ7/pHNJ7qxlwF110kS1YsGC/06KVBaLHKiNI77mCR3pflE2iWXV+6enpLnhTrlw5t4+nnnqqLV++PObz/vTTT25Gm85nHdt69eqFj5f8999/bgagzkP/79H7V7lyZXe8FDgCAADA/3egmcYbNmxwz6E2WnaeX5OKzjjjDNf+Ux9CS7VGz/T/9NNPXZ9D7VNNjlL/SBO5Yi0NNH36dNfO1MC6tvXaupMnT7YWLVq4IIPamZ06dXJLsO7LQw895Pph48aNiwhQeB588EHXZh4xYoS7rolm2g+vP+enpaF0nzIestum9bfvX3zxRdd+r1atmttWGeLqk8gtt9zitlGGdqxlmtT21TFbtWpVhr6FF4RQn8a7Xf2HWM/jPZeCXeojnHTSSe44q6+p/ld0EEp9APUbtY1+T9++fd1+7O/ytDnp1/z5558uy0Tnjfog559/vusLZDZJ8Mwzz3RLk+k8VD9CmT8e9Wn1e3TuqQ/pUYaQzgsFsgDAjyAFgHxPM35eeeUVa9asmWv8qZG9devWDAPzClBoG6VkDxw40DV6tcaoGmCbNm1y2+hxJ554oj3xxBN2+eWXu2WOHn/8cZcOvGbNmv3av507d7oGXLt27WzKlCnh1GDNMlLDX4Pv6hzcddddrtOh3+9vyKnhrv1WGvnw4cPdfisgoUalnlsNaz2/9jN6EHn8+PEuEKOZQplRsKRAgQKusxOLGsR6fs040swwNZa1NJQG/KMb1QoqKBChgXpRo/b444+3adOmudenfb/yyivd/mtwPZqCG7NmzbIHHnjAbdukSROXLi0KBOhn73o0BU20jXjbeanW+l/r+6ph7t3+2GOPWVb0Huh1q4On903nlTpdo0ePDm+jwMfJJ59ss2fPdrerYa6Aghr0B6p79+7uvHvzzTddBovSzQcMGBCRqq4Zdl7nS+e1MkKis028zoDOIWWkqGOotZOVdXTDDTeEz0d1LrT/CljptYreX72X+l36jOk8AQAASCVedq//Ek/qD6jNpcxmtZk1CSUzul+D3L/99puNGTPGtZfvuOOOiAlXc+bMcf0OTTrRwL/acBp0VltfgYdoaveplobalKqTpp+1TKomy2g5VLUPdZ/6SfrdaldmRX0LtYczy1TW4LsG4dUuVV/h2GOPdQPc6kdE04C/N2Esu21av9tuu80dK/WT1K/ThCgtRSXXX3+96xOoDR2L+gqtWrVyk3Wi+xYfffSR20b9Gu/2WBO4/PRa1a5WoERBF7XZtX8vvfRSeBv1N1WH78cff3R9xBdeeMEdd2XoHIjs9GvUp27fvr3rl6qvpr60Xnusfo36Pjo2mtynY6vnVNa9tvUmaakGiSYOKjCjgJAoeKVsGk240+MAIEIIAPK5F154QVWdQ48//ri7vnXr1tDBBx8cOumkkyK2u+KKK0KFChUKLVu2LNPnGj58uHuuGTNmZLrN7Nmz3Tb632/FihXu9okTJ4Zv69mzp7vt2WefzfI17N27N7Rr167QqlWr3PZTpkwJ39euXbtQmTJlQuvWrdvnPr399tvh2/74449QwYIFQ8OGDcvydx911FGhypUrZ7nNhAkT3PNPnjzZXX/33Xfd9enTp4e32b17d6hq1aqh7t27h2/r3bu3ey/0uvweeOAB9/ilS5dGHLu6deuGdu7cmeH3676+ffvu833QNpn9aStRooR7P6LFeh7vfXvttdcitu3cuXPoyCOPDF9/9NFH3XYffvhhxHZ63dHnQize73799dfDtw0ZMsTddt9990Vs26dPn1DRokXduSL6ndpu7NixEduNGDHC3a7n8XTq1ClUvXr10JYtWyK2ve6669xzbty4MXyb3mM9/uGHHw7dddddoYMOOijifQYAAEgFasepTRTronZ7LFm1RTOjtp3ajmpz6bFpaWmhevXqhQYMGODayH5qK+uyffv2TJ/vhBNOCFWsWNH1ifzt9IYNG7r2oNeW9F7fpZdeGvH43377zfUhrr/++ojb9XzqM5x33nlZvh61LbUPWbnlllvc7/7iiy/c9UceecRd//HHH8PbqH1apEiR0I033pjjNq3Xxm7dunWG3+31O+6///6I273j4T/mXbp0CdWsWTPDc6xfvz5Dezur52nTpk3E6/XUr1/fvSbPzTff7N5/r4/kf92x+p+Z/e4FCxbkuF/j9ff8/VDp1atXhn6N+o+NGzfO8Dk4/fTTQ1WqVAnt2bMnfNvo0aPD/VTtS7FixULffPNNlq8DQGoikwJAvqcZQpol761pqhRWzdCYO3euSwf2aKaRZr0rJTgz2kaz1zWLJJ40Kz6aZqxfc801Lg1WyzVp1lLNmjXdfd9//314tolmQyntNqu1TZVCrFlI/lRnzU5RFoSWtzpQ/xcn+L+sCtHMH82s8c940swupQh7s/BFs5t0zJXN4Z995s3212vz0wwfHYdEoNcanV2i+hxK+fZo/zUzTcss+Wnm2YHSsYj+3VqSSeeNN4NJvKwVj9Lf/fSYmTNnumwazVzzvw+alab7laXj0bmmtYJV0FBLb2kt5A4dOhzw6wEAAMiPNJtds8H9F7Xdcyo6G8Pfvla7XQWyNXtf2dya+a6Z7g0aNAi3l7WkpzKxNXtfGbCxKMtXmdnKLlafyKNsWC2vo2VKNUs/q36K2vTaPy0t699f/U7N8t+fJYf21bdQe1bLMfmXSlUGiDLHdTz2p00b67UFSX0nZZjvq2+hlQGUwRLPvkV2+jXqW6hfE90Hie5baNkoLfHr9UGi3wdlg/jPMfUplO2i16BMfC0DpnolABCNIAWAfE2NJNVdUMNHjV2lnOriLfvz7LPPhrdVLQVvDdLMZGebnFIjWsWZ/ZTSrTRnpRur5oMa3CqW5zWslW4rWoZKKebZ2SelOet51ChUx0ZF+HQc1CDOitJt9brVqcmMt6aqAiqijpk6OkqP1vEWdSqU/qz1aj1KPVdqtQIP/os6XBJdf0OPTxR636I7gOo8qQPkX0M4Vh2PWLfllNYZjv7d/nNDv1vvQ/R20e+3tlOnQR2C6PfBS52Pfh8UaNI5pOfXeQUAAJCqNMFJhbP9l/0R3Q7TgK2fJitpoogmYGmilZZmUrtTg7yi9rpk1S9Q30F9olhtak0a8tqGftHbektHaVml6H3WPsWqnxfdt1ixYkWW20T3LVTXQIPjCgh5y9eqb6FBfa/fsD9t2kTqW0S32b32vde2z82+xYH0a6L7Ft75cdNNN2V4H/r06ZPhffDqdeh36bmoRQEgMzkP/wNAAlEQQg1xrZ+qSzQ1/jUbXLOHlImg2UNZyc42XgMvutBYZg12b4aQn9ZRVa0JNb579uwZEXTxU4Nd+76vffJmuWi9T2VTaA1YrXuqQmv7olnyWntUwQQvG8VPx1frpmpfVCPCo1lNKqattUa1/qi2UdE+f90CrUWqWTpeYbzMOktZHatEps6GgkvRMiswF+/frY6aOhT+Tk/07z7kkEPCs+cyOx9UqNyjYJW2VUaROiFXXXWVW2cWAAAA+08ZGJm1v2JRdqtqA6jfIF5WdVb9ArX7VGg7Vi09ZTx77fOs2t/e/epbeVneOaG+hfojmnwVqy6FMsVVt0IZA/4BcPUtVAdB9ynQoeOlugz726aN9doSndr0/voied23yE6/xjs/VE9DdVRiOfLII8M/61zU+6WaFSoKruCG6hACQDQyKQDkW5ployBE3bp1XXpq9EXFhNUo0hJOoiWGdHt0irOftlEqtYo3Z0aFquWbb76JuF2D9NnlNZi92fEeFez20zJWSqtWg31fs5YUPNHSTjomKqSnhqAKmu2LBqFVkE4NTW8pIT8VmFNKrzI+/EsxaVZZ8+bN3ZJPKursT8f2qMC2OlZ6j6JnoOkSHaQ4UNHZBtH3xbr9QOi9UTE77xzzKHCT27SMlrz88ssRt+u9iJ45pW2XLFniAkax3gd/kENLkKnAoLJ8NJNP57WWGwAAAMD+y6z9FSugIP/884+tXr063F7WBBK1qTVJK3qylKdEiRKufa52nL/dqyxuFWhWFoaeJyvKilY2rZaWitVu3FcmyYABA1wfRoWpY2Vqa5BaGR8q+O2nLPNq1aq5voUu6tv4lznKaZs2HjLrP2TV5zjQvoX6TtHFyfOqb6F+TXSfNrpvoQDE4Ycf7ibcZXZ+aNkor7+u91B9X/WXFHRTJoxXvBwA/MikAJBvqaGjGUGjR492NRmiaXbO+PHj3UCrBsuHDx/uHtO6dWu3zr7WwtRSRR999JENHDjQjjrqKJcJoDTms846y2699VaXYqzGp9YH1XOo8aYZP6pZoUaWZvRohpGWWcpJY0u/S50M/Q5lKihLQZkMmjkUTQGHE0880XU4tP1hhx3mZtioAamghtcIFKXYKqiwaNEie/rpp7O1L2XKlHH7rtenTAmllKu+RXp6ujsWGgRXpoSXah69LFDv3r3d+9CyZcuIWTOiY67XpPu0bJDuV6qvUrynTp3q1t+N5/Ja3vqmOicUcNJsK3ViChcu7O7TGro6zkr91nGL3t+cUhaMBvAvvvhil7Gj90bnmNbyFc1kyy3qyOlcVvBIHUB1CD777DN78cUXM2w7duxYdw6ddNJJbhkBBdrUCVHmjo6HF5TTOaMOrDqGSq3X5brrrnMZOgp4Ra+jCwAAkOq0rr+XJaGBffEyvNXm2tegvjKO1YZTe1uTjDTAr+WS1I9Rxqwylz3KUFBtAWUoKBigjANNLlHb05u4oj6KshnUb1FAQO1g1brQ4LfqPOwru0D7rDb84MGDXZ0M1V5Tn0f9D820VyBk2LBhmT5efRy1R1WzQEtGqZ+lNrcerwCL2sraL71eP7XbVQdDfR8tlatZ+qVLl96vNm28qP+gfpIyOtRPUtveG4RXH1DZxqeccorryynDwJvMtr/UF9UxUj9G74GWX1KQQBPGcrtvoWOvfo3+1zmpQIT6a16/xk99UO2jAlpayknBpY0bN7q6iosXL3YT7GTIkCGuTqSy9tWH1iRC9atVV6Vx48b7zCYCkGKCrtwNAPura9euocKFC4fWrVuX6TYXXHBBqGDBgqG1a9e666tXrw5dccUVocqVK4cKFSoUqlq1aui8884L/fXXX+HHbNq0KdSvX7/QoYce6rapWLFiqEuXLqEffvghvM2aNWtC55xzTqhs2bKh0qVLhy6++OLQwoULVQEuNHHixPB2PXv2DJUoUSLmvi1btizUoUOHUMmSJUOHHHJI6Nxzzw399ttv7jmGDBmSYVvdX65cOfeatW+XXXZZ6L///svwvG3btnX7tW3bthwdT/3uvn37hurUqeN+h15X69atQy+99FJo7969MR+zZcuWULFixdw+P/XUUzG3Wb9+feiGG24I1a5d2x1P7VuTJk1CgwcPDv3zzz9umxUrVrjnuP/++2M+h+7TvvnNnj3b3a7/PTt27AhdddVVoQoVKoTS0tLc/Xpu+eqrr0KtWrUKFS9e3N3epk2bTJ8ns/dN70v0n04dt7PPPjt08MEHu/eye/fuoalTp7rtpkyZkunx9v/u119/PcPv0HHz03nlfz2yefNmdz6XKVPGvS6dTzpPY51Depy2rVatmnsfdIxatmwZuueee9z933zzjXsv9dr9dI7p/apVq5b7bAAAAKQCr+21YMGCbG0X6xLdrorl888/d+3cY4891rWTCxQo4Nppp556qmtTRps/f37otNNOc231IkWKhOrWrRsaMGBAxDZz584NtWvXzrVn1b474YQTQu+9916OXt8777wTOvnkk0OlSpVyv6dmzZqu//Pxxx+HsmPp0qXu9VevXj3cB9Br+uCDDzJ9zPLly8PHbsaMGTG32VebNrM2tv/xsfodsdraGzdudK9ZbW2vb+HRcWjcuLE7Nv73OtbzqN/RoEGDDPuix+i4+n333Xeh9u3bh4oWLeqO2ZVXXhl6/vnn3XN+/fXXmR67zN7TnPRrfv/9d9eX8fdr5s2bl6GPK9oX9aPVV9b7oP61zrnHH3/c3T99+vTQQQcdlKFPsmHDBteXbdasmeu7AYAnTf8EHSgBAMSHlmvSrB6lVyujAsEYOXKkS2HXzLZ4F2IHAAAAkDq0pK+yYJRZo8wYAEhGLPcEAElABfSUjq10cKUB9+vXL+hdShlKxfeW8Nq1a5dLM1cxOC0BRYACAAAAQHZpmSfVIalTp46rS/L++++7JVk1AYoABYBkRpACAJKAGq5q0GodVK1Hq3VBkTdUxE/rt6rOhooYam1g1XCILgYIAAAAAFkpVKiQm3imSWi7d+92tSFUp4NJaACSHcs9AQAAAAAAAACAQBxkAfrkk0/sjDPOcKlsaWlp9s4770Tcr3IZQ4cOdfcXK1bM2rZta0uXLo3YRrNWtfZ6+fLlrUSJEnbmmWe6iDMAAACA1EMfAwAAAMhfAg1S/Pvvv3bssceG1/OOpqKvSmvT/QsWLLDKlStbhw4dbOvWreFt+vfvb2+//ba9+uqr9umnn7o1+04//XTbs2dPHr4SAAAAAImAPgYAAACQvyTMck/KpFCwoWvXru66dksZFApCaG1vL2uiUqVKNnr0aOvdu7dt2bLFKlSoYC+++KKdf/75bps///zTatSoYVOnTrVOnToF+poAAAAABIc+BgAAAJD4ErZw9ooVK2zt2rXWsWPH8G1FihSxNm3a2Lx581yQYtGiRbZr166IbRTYaNiwodsmsyCFgh26ePbu3WsbN260cuXKuY4MAAAAkAw08UdZyGojH3RQoEnUSd3HoH8BAACAVBDKpf5FwgYp1HkQZU746fqqVavC2xQuXNgOOeSQDNt4j49l1KhRNmzYsFzZbwAAACDRrF692qpXr26pLrf6GPQvAAAAkEpWx7l/kbBBCk90ZoOiNfvKdtjXNrfddpsNHDgwfF3LRh166KHu4JYqVSoOew0AAAAELz093S2FWrJkyaB3Jan7GPQvAAAAkArSc6l/kbBBChXJFs1WqlKlSvj2devWhWc+aZudO3fapk2bImY6aZuWLVtm+txK6dYlmgIUBCkAAACQbFjSNHf7GPQvAAAAkErS4lwyIWEXpq1du7brIMyYMSN8mzoLc+bMCXcOmjRpYoUKFYrYZs2aNfbdd99lGaQAAAAAkHroYwAAAACJJ9BMin/++cd+/vnniEJ2X331lZUtW9Ytv9S/f38bOXKkHX744e6in4sXL249evRw25cuXdquvPJKu/HGG13Raz3upptusqOPPtrat28f4CsDAAAAEAT6GAAAAED+EmiQYuHChXbyySeHr3t1Inr27GnPPfecDRo0yLZv3259+vRx6dbNmze36dOnR6x59dBDD1nBggXtvPPOc9uecsop7rEFChQI5DUBAAAACA59DAAAACB/SQupAlyKU8EPZWWogDY1KQAAAJAsaOdy3AEAAIBE718kbE0KAAAAAAAAAACQ3AhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQiIQOUuzevdvuuOMOq127thUrVszq1Kljw4cPt71794a3CYVCNnToUKtatarbpm3btrZ06dJA9xsAAABAYqKPAQAAACSWhA5SjB492h5//HEbP368ff/993bffffZ/fffb+PGjQtvo9vGjBnjtlmwYIFVrlzZOnToYFu3bg103wEAAAAkHvoYAAAAQGJJ6CDF/Pnz7ayzzrIuXbpYrVq17JxzzrGOHTvawoULw1kUDz/8sA0ePNjOPvtsa9iwoT3//PO2bds2mzRpUtC7DwAAACDB0McAAAAAEktCBylOPPFEmzlzpi1fvtxd//rrr+3TTz+1zp07u+srVqywtWvXusCFp0iRItamTRubN29eps+7Y8cOS09Pj7gAAAAASH650cegfwEAAADsv4KWwG655RbbsmWLHXXUUVagQAHbs2ePjRgxwi688EJ3vzoPUqlSpYjH6fqqVasyfd5Ro0bZsGHDcnnvAQAAAKRCH4P+BQAAAJCkmRSTJ0+2l156yS3dtHjxYreU0wMPPOD+90tLS4u4rmWgom/zu+2221zHxLusXr06114DAAAAgOTuY9C/AAAAAJI0k+Lmm2+2W2+91S644AJ3/eijj3azlzRTqWfPnq5ItjfbqUqVKuHHrVu3LsPMJz+la+sCAAAAILXkRh+D/gUAAACQpJkUKoB90EGRu6iU7L1797qfa9eu7ToRM2bMCN+/c+dOmzNnjrVs2TLP9xcAAABAYqOPAQAAACSWhM6kOOOMM9z6sIceeqg1aNDAlixZYmPGjLErrrjC3a906/79+9vIkSPt8MMPdxf9XLx4cevRo0fQuw8AAAAgwdDHAAAAABJLQgcpxo0bZ3feeaf16dPHpVdXrVrVevfubXfddVd4m0GDBtn27dvdNps2bbLmzZvb9OnTrWTJkoHuOwAAAIDEQx8DAAAASCxpIVWAS3Hp6elWunRpV0S7VKlSQe8OAAAAEBe0c4PBcQcAAEAySs+lcfSErkkBAAAAAAAAAACSF0EKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAFMzpA3bs2GFffvmlrVy50rZt22YVKlSwxo0bW+3atXNnDwEAAAAkNfoYAAAAQOrKdpBi3rx5Nm7cOHvnnXds586dVqZMGStWrJht3LjRdSrq1KljV199tV1zzTVWsmTJ3N1rAAAAAPkefQwAAAAA2Vru6ayzzrJzzjnHqlWrZtOmTbOtW7fahg0b7Pfff3fZFD/99JPdcccdNnPmTDviiCNsxowZHFkAAAAA9DEAAAAAHHgmRceOHe3111+3woULx7xfWRS69OzZ05YuXWp//vlndp4WAAAAQIqijwEAAABA0kKhUCjVD0V6erqVLl3atmzZYqVKlQp6dwAAAIC4oJ0bDI47AAAAklF6Lo2j57hwtt93331nc+bMsT179ljLli2tadOmcdsxAAAAAKmHPgYAAACQWrJVkyKWRx991E455RQXpJg9e7b7ecSIEfHdOwAAAAApgz4GAAAAkHqyvdyTimRXr149fL1evXo2d+5cK1++vLs+f/58O/PMM239+vWW35CODQAAgGSU6O3cZO1jJPpxBwAAABKpnZvtTAplSowdO9a8mEa5cuVs2rRptmPHDtu6dat9/PHHVqFChbjtGAAAAIDkRh8DAAAAQLaDFAsWLLAffvjBmjdvbkuWLLEnn3zSxowZY8WKFbMyZcrY5MmT7fnnn+eIAgAAAKCPAQAAACC+hbOVvjFhwgT77LPP7LLLLrP27du7VGwVzdZFgQoAAAAAoI8BAAAAINcKZ7dq1coWLlzo1p5q3LixffLJJwQoAAAAAOw3+hgAAABA6sp24ezdu3fbU089ZcuWLbNjjz3WLr/8cvvll1+sd+/errDduHHjrHLlypYfUdgOAAAAySjR27nJ2sdI9OMOAAAA5MvC2b169XKdhBIlStjEiRNtwIABdsQRR9js2bOtU6dO1qJFC7ccFAAAAADQxwAAAAAQ10yKQw45xObNm2f16tWz7du3W8OGDd0sJ8+6deusf//+NmnSJMtvmOkEAACAZJTo7dxk7WMk+nEHAAAA8mUmRcWKFW369Om2c+dOmzlzppUrVy7D/fmt8wAAAAAgOPQxAAAAABTM7iEYP368XXzxxTZw4ECrUqWKvfbaaxw9AAAAAPuNPgYAAACAbAcpOnToYGvXrrW///7bKlSowJEDAAAAcEDoYwAAAADI9nJPkpaWRoACAAAAQNzQxwAAAABSW7aCFKeeeqoraLcvW7dutdGjR9ujjz4aj30DAAAAkKToYwAAAADI9nJP5557rp133nlWsmRJO/PMM61p06ZWtWpVK1q0qG3atMmWLVtmn376qU2dOtVOP/10u//++zm6AAAAAOhjAAAAAMhSWigUClk27Ny509544w2bPHmyzZ071zZv3vx/T5CWZvXr17dOnTpZr1697Mgjj7T8Jj093UqXLm1btmyxUqVKBb07AAAAQEq0c5O1j5Hoxx0AAABIpHZutoMU0bQj27dvt3LlylmhQoUsP6MTAQAAgGSU39q5ydLHyG/HHQAAAAiynZut5Z5i0c7oAgAAAADxQB8DAAAASD3ZKpwNAAAAAAAAAAAQbwQpAAAAAAAAAABAIBI+SPHHH3/YxRdf7NalLV68uDVq1MgWLVoUvl8lNYYOHWpVq1a1YsWKWdu2bW3p0qWB7jMAAACAxEUfAwAAAEgcCR2k2LRpk7Vq1coVzfvwww9t2bJl9uCDD1qZMmXC29x33302ZswYGz9+vC1YsMAqV65sHTp0sK1btwa67wAAAAASD30MAAAAIJ8HKT7++ONM73viiScsnkaPHm01atSwiRMn2vHHH2+1atWyU045xerWrRvOonj44Ydt8ODBdvbZZ1vDhg3t+eeft23bttmkSZPiui8AAAAAcgd9DAAAACB15ThI0aVLF7vxxhtt586d4dvWr19vZ5xxht12221x3bl3333XmjZtaueee65VrFjRGjdubE899VT4/hUrVtjatWutY8eO4duKFClibdq0sXnz5mX6vDt27LD09PSICwAAAIBg5Pc+Bv0LAAAAIA+DFJ988om999571qxZM1f74YMPPnAZDP/88499/fXXFk+//vqrTZgwwQ4//HCbNm2aXXPNNXbDDTfYCy+84O5X50EqVaoU8Thd9+6LZdSoUVa6dOnwRdkaAAAAAIKR3/sY9C8AAACAPAxSNG/e3JYsWWLHHHOMNWnSxLp16+ZmPc2aNSvug/179+614447zkaOHOlmOPXu3dt69erlOhV+aWlpEde1DFT0bX6ajbVly5bwZfXq1XHdbwAAAACp08egfwEAAADkceHsH3/80RWprl69uhUsWNB++OEHVwci3qpUqWL169ePuK1evXr222+/uZ9VJFuiZzStW7cuw8wnP6VrlypVKuICAAAAIDj5uY9B/wIAAADIwyDFvffeay1atLAOHTrYd9995zoS3qyn+fPnWzy1atXKdVb8li9fbjVr1nQ/165d23UiZsyYEb5f69jOmTPHWrZsGdd9AQAAAJA76GMAAAAAqatgTh8wduxYe+edd+y0005z1xs0aGBffvml3X777da2bVtXNC5eBgwY4IINSsU+77zz3O958skn3UWUbt2/f393v9aU1UU/Fy9e3Hr06BG3/QAAAACQe+hjAAAAAKkrLaTFVXPg77//tvLly8e8TxkMbdq0sXh6//333RqvP/30k8ucGDhwoFsz1qPdHzZsmD3xxBO2adMmt57to48+6grtZVd6eroroK36FCz9BAAAgGSRX9q5ydbHyC/HHQAAAMiJ3Grn5jhIIZs3b7Y33njDfvnlF7v55putbNmytnjxYrdGa7Vq1Sy/oRMBAACAZJSf2rnJ1MfIT8cdAAAACLqdm+Plnr755htr376925mVK1e6GUfqQLz99tu2atUqe+GFF+K2cwAAAACSH30MAAAAIHXluHC2UqEvu+wylxpdtGjR8O2qUfHJJ5/Ee/8AAAAAJDn6GAAAAEDqynGQYsGCBda7d+8MtysFe+3atfHaLwAAAAApgj4GAAAAkLpyHKRQ9oTWnor2448/WoUKFeK1XwAAAABSBH0MAAAAIHXlOEhx1lln2fDhw23Xrl3uelpamv3222926623Wvfu3XNjHwEAAAAkMfoYAAAAQOrKcZDigQcesPXr11vFihVt+/bt1qZNGzvssMOsZMmSNmLEiNzZSwAAAABJiz4GAAAAkLoK5vQBpUqVsk8//dRmzZplixcvtr1799pxxx1n7du3z509BAAAAJDU6GMAAAAAqSstFAqFLMWpxkbp0qVty5YtroMEAAAAJAPauRx3AAAAINH7F9nKpHjkkUey/YQ33HDDgewPAAAAgBRAHwMAAABAtjMpateuHXFdNSm2bdtmZcqUcdc3b95sxYsXd3Uqfv3113x3ZJlhBgAAgGSUyO3cZO5jJPJxBwAAABKtnZutwtkrVqwIX1Qcu1GjRvb999/bxo0b3UU/qy7F3XffHbcdAwAAAJC86GMAAAAA2K+aFHXr1rU33njDGjduHHH7okWL7JxzznGdjfyGmU4AAABIRvmlnZtsfYz8ctwBAACAfJNJ4bdmzRrbtWtXhtv37Nljf/31V7z2CwAAAECKoI8BAAAApK4cBylOOeUU69Wrly1cuNC8JAz93Lt3b2vfvn1u7CMAAACAJEYfAwAAAEhdOQ5SPPvss1atWjU7/vjjrWjRolakSBFr3ry5ValSxZ5++unc2UsAAAAASYs+BgAAAJC6Cub0ARUqVLCpU6fa8uXL7YcffnDZFPXq1bMjjjgid/YQAAAAQFKjjwEAAACkrhwHKTwKShCYAAAAABAv9DEAAACA1JPjIIUKZD/33HM2c+ZMW7dune3duzfi/lmzZsVz/wAAAAAkOfoYAAAAQOrKcZCiX79+LkjRpUsXa9iwoaWlpeXOngEAAABICfQxAAAAgNSV4yDFq6++aq+99pp17tw5d/YIAAAAQEqhjwEAAACkroNy+oDChQvbYYcdljt7AwAAACDl0McAAAAAUleOgxQ33nijjR071kKhUO7sEQAAAICUQh8DAAAASF05Xu7p008/tdmzZ9uHH35oDRo0sEKFCkXc/9Zbb8Vz/wAAAAAkOfoYAAAAQOrKcZCiTJky1q1bt9zZGwAAAAAphz4GAAAAkLpyHKSYOHFi7uwJAAAAgJREHwMAAABIXTmuSQEAAAAAAAAAAJCnmRSNGze2tLS0fW63ePHiA90nAAAAACmAPgYAAACAbAcpunbtytECAAAAEDf0MQAAAACkhUKhUKofhvT0dCtdurRt2bLFSpUqFfTuAAAAAHFBOzcYHHcAAAAko/RcGkenJgUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAFMzpAx555JGYt6elpVnRokXtsMMOs9atW1uBAgXisX8AAAAAkhx9DAAAACB15ThI8dBDD9n69ett27Ztdsghh1goFLLNmzdb8eLF7eCDD7Z169ZZnTp1bPbs2VajRo3c2WsAAAAASYM+BgAAAJC6crzc08iRI61Zs2b2008/2YYNG2zjxo22fPlya968uY0dO9Z+++03q1y5sg0YMCB39hgAAABAUqGPAQAAAKSutJBSIXKgbt269uabb1qjRo0ibl+yZIl1797dfv31V5s3b577ec2aNZYfpKenW+nSpW3Lli1WqlSpoHcHAAAASKl2brL1MfLLcQcAAAASoZ2b40wKdQp2796d4XbdtnbtWvdz1apVbevWrfHZQwAAAABJjT4GAAAAkLpyHKQ4+eSTrXfv3m5Wk0c/X3vttdauXTt3/dtvv7XatWvHd08BAAAAJCX6GAAAAEDqynGQ4plnnrGyZctakyZNrEiRIu7StGlTd5vuExXQfvDBB3NjfwEAAAAkGfoYAAAAQOrKcU0Kzw8//OAKZuvhRx11lB155JGWX7FmLAAAAJJRfmvnJksfI78ddwAAACDIdm7B/X2gOg26AAAAAEA80McAAAAAUk+OgxR79uyx5557zmbOnGnr1q2zvXv3Rtw/a9aseO4fAAAAgCRHHwMAAABIXTkOUvTr188FKbp06WINGza0tLS03NkzAAAAACmBPgYAAACQunIcpHj11Vfttddes86dO+fOHgEAAABIKfQxAAAAgNR1UE4fULhwYTvssMNyZ28AAAAApBz6GAAAAEDqynGQ4sYbb7SxY8daKBTKnT0CAAAAkFLoYwAAAACpK8fLPX366ac2e/Zs+/DDD61BgwZWqFChiPvfeuuteO4fAAAAgCRHHwMAAABIXTkOUpQpU8a6deuWO3sDAAAAIOXQxwAAAABSV46DFBMnTsydPQEAAACQkuhjAAAAAKkrxzUpAAAAAAAAAAAA8iyT4rjjjrOZM2faIYccYo0bN7a0tLRMt128eHFcdgwAAABA8qKPAQAAACDbQYqzzjrLihQpEv45qyAFAAAAANDHAAAAAJAdaaFQKGQpLj093UqXLm1btmyxUqVKBb07AAAAQFzQzg0Gxx0AAADJKD2XxtFzXJOiTp06tmHDhgy3b9682d0HAAAAAPQxAAAAAORKkGLlypW2Z8+eDLfv2LHDfv/995w+HQAAAIAURx8DAAAASF3Zqkkh7777bvjnadOmubQOj4IWKqxdu3bt+O8hAAAAgKREHwMAAABAtoMUXbt2Df/cs2fPiPsKFSpktWrVsgcffJAjCgAAAIA+BgAAAID4Bin27t3r/le2xIIFC6x8+fLZfSgAAAAA0McAAAAAcOA1KYYNG2YlS5bMcPvOnTvthRdeyOnTAQAAAEhx9DEAAACA1JUWCoVCOXlAgQIFbM2aNVaxYsWI2zds2OBui1VUO9Glp6e7GhtbtmyxUqVKBb07AAAAQEq1c5Otj5FfjjsAAACQCO3cHGdSKKaRlpaW4fbff/89opg2AAAAANDHAAAAABCXmhSNGzd2wQldTjnlFCtY8P8/VDObVqxYYaeeemp2nw4AAABAiqOPAQAAACDbQYquXbu6/7/66ivr1KmTHXzwweH7ChcubLVq1bLu3btzRAEAAADQxwAAAAAQ3yDFkCFD3P8KRpx//vlWtGjR7D4UAAAAAOhjAAAAANj/IIWnZ8+eOX0IAAAAANDHAAAAALB/QYqyZcva8uXLrXz58nbIIYfELJzt2bhxY3aeEgAAAEAKo48BAAAAINtBioceeshKlizpfn744Yc5cgAAAAAOCH0MAAAAANkOUnz99dd2zjnnWJEiRax27drWsmVLK1gwxytFAQAAAAB9DAAAAABhB1k2jBs3zv755x/388knnxzYkk6jRo1yS031798/fFsoFLKhQ4da1apVrVixYta2bVtbunRpIPsHAAAAIHvoYwAAAACQbKVD1KpVyx555BHr2LGjCwrMnz/f1aaIpXXr1rlyZBcsWGBPPvmkHXPMMRG333fffTZmzBh77rnn7IgjjrB77rnHOnToYD/++GN4iSoAAAAAiYU+BgAAAABJCynqsA/vvPOOXXPNNbZu3TqXyZDZQ3Tfnj174n5klcVx3HHH2WOPPeaCEI0aNXK1MbQfyqBQZsUtt9zitt2xY4dVqlTJRo8ebb17987W86enp1vp0qVty5YtVqpUqbjvPwAAABCERG7nJnMfI5GPOwAAALC/cqudm63lnrp27Wpr1651O6FG+/Lly23Tpk0ZLrm1DFTfvn2tS5cu1r59+4jbV6xY4fZLGR4e1c1o06aNzZs3L1f2BQAAAMCBo48BAAAAQHJU/bpo0aL27LPPuv8VMckLr776qi1evNgt9xRNAQrRrCY/XV+1alWmz6mZULp4FHwBAAAAkPeSoY9B/wIAAADI5UwKT8GCBa1Pnz65km4dy+rVq61fv3720ksvuU5LZpQC7qdsj+jbogtwqwPkXWrUqBHX/QYAAACQOn0M+hcAAABAHgUppHnz5vbVV19ZXli0aJFbo7ZJkyau86LLnDlzXBFv/ezNbvJmO3n0mOiZT3633XabWzfLu6ijAgAAACAY+b2PQf8CAAAAyKPlnkSznAYOHOgG9tWwL1GiRMT9xxxzjMXLKaecYt9++23EbZdffrkdddRRrohdnTp1rHLlyjZjxgxr3Lixu3/nzp2uk6GidplR3QpdAAAAAAQvv/cx6F8AAAAAeRikOP/8893/N9xwQ/g2pT176c/xTNMuWbKkNWzYMOI2dVjKlSsXvr1///42cuRIO/zww91FPxcvXtx69OgRt/0AAAAAkHvoYwAAAACpK8dBihUrVlgiGTRokG3fvt3Nvtq0aZNLFZ8+fboLcAAAAABIfPQxAAAAgNSVFlIKRIpLT093BbRVn6JUqVJB7w4AAAAQF7Rzg8FxBwAAQDJKz6Vx9BwXzpYXX3zRWrVqZVWrVrVVq1a52x5++GGbMmVK3HYMAAAAQOqgjwEAAACkphwHKSZMmOCK2nXu3Nk2b94crkFRpkwZF6gAAAAAAPoYAAAAAHIlSDFu3Dh76qmnbPDgwVagQIHw7U2bNrVvv/02p08HAAAAIMXRxwAAAABS10H7U9SucePGGW4vUqSI/fvvv/HaLwAAAAApgj4GAAAAkLpyHKSoXbu2ffXVVxlu//DDD61+/frx2i8AAAAAKYI+BgAAAJC6Cub0ATfffLP17dvX/vvvPwuFQvbll1/aK6+8YqNGjbKnn346d/YSAAAAQNKijwEAAACkrhwHKS6//HLbvXu3DRo0yLZt22Y9evSwatWq2dixY+2CCy7Inb0EAAAAkLToYwAAAACpKy2kdIj99Pfff9vevXutYsWKlp+lp6db6dKlbcuWLVaqVKmgdwcAAABI2XZuMvQx8uNxBwAAAIJq5+a4JsWwYcPsl19+cT+XL18+X3ceAAAAAASPPgYAAACQunIcpHjzzTftiCOOsBNOOMHGjx9v69evz509AwAAAJAS6GMAAAAAqSvHQYpvvvnGXdq1a2djxoxx9Sg6d+5skyZNcjUqAAAAAIA+BgAAAIBcr0khn332mQtQvP766/bff/+5danyG9aMBQAAQDLKr+3c/N7HyK/HHQAAAMgXNSmilShRwooVK2aFCxe2Xbt2xWevAAAAAKQs+hgAAABA6tivIMWKFStsxIgRVr9+fWvatKktXrzYhg4damvXro3/HgIAAABIevQxAAAAgNRUMKcPaNGihX355Zd29NFH2+WXX249evRwdSkAAAAAYH/QxwAAAABSV46DFCeffLI9/fTT1qBBg9zZIwAAAAAphT4GAAAAkLr2u3D233//bWlpaVauXDnL7yhsBwAAgGSU39q5ydLHyG/HHQAAAMg3hbM3b95sffv2tfLly1ulSpWsYsWK7ufrrrvO3QcAAAAA9DEAAAAAxH25p40bN7q1Yv/44w+76KKLrF69eqYkjO+//96ee+45mzlzps2bN88OOeSQbP9yAAAAAKmLPgYAAACAbAcphg8fboULF7ZffvnFZVFE39exY0f3/0MPPcRRBQAAAEAfAwAAAED8lnt655137IEHHsgQoJDKlSvbfffdZ2+//XZ2nw4AAABAiqOPAQAAACDbQYo1a9ZYgwYNMr2/YcOGtnbtWo4oAAAAAPoYAAAAAOIbpFCB7JUrV2Z6/4oVK6xcuXLZfToAAAAAKY4+BgAAAIBsBylOPfVUGzx4sO3cuTPDfTt27LA777zTbQMAAAAA9DEAAAAAZEdaKBQKZWfD33//3Zo2bWpFihSxvn372lFHHeVuX7ZsmT322GMuULFw4UKrUaOG5Tfp6elWunRp27Jli5UqVSro3QEAAABSop2brH2MRD/uAAAAQCK1cwtmd8Pq1avb/PnzrU+fPnbbbbeZF9tIS0uzDh062Pjx4/Nd5wEAAABAcOhjAAAAAMh2kEJq165tH374oW3atMl++uknd9thhx1mZcuW5UgCAAAAyDH6GAAAAEBqy1GQwnPIIYfY8ccfH/+9AQAAAJCS6GMAAAAAqSnbhbMBAAAAAAAAAADiiSAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUAAAAAAAAAAAgEAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABCIhA5SjBo1ypo1a2YlS5a0ihUrWteuXe3HH3+M2CYUCtnQoUOtatWqVqxYMWvbtq0tXbo0sH0GAAAAkLjoYwAAAACJJaGDFHPmzLG+ffva559/bjNmzLDdu3dbx44d7d9//w1vc99999mYMWNs/PjxtmDBAqtcubJ16NDBtm7dGui+AwAAAEg89DEAAACAxJIWUipCPrF+/XqXUaGORevWrV0WhTIo+vfvb7fccovbZseOHVapUiUbPXq09e7dO1vPm56ebqVLl7YtW7ZYqVKlcvlVAAAAAHmDdm4wfQyOOwAAAJJRei6Noyd0JkU0vXgpW7as+3/FihW2du1al13hKVKkiLVp08bmzZsX2H4CAAAAyB/oYwAAAADBKmj5hGY0DRw40E488URr2LChu00BCtGsJj9dX7VqVabPpZlQuvgjQAAAAABSS7z6GPQvAAAAgBTIpLjuuuvsm2++sVdeeSXDfWlpaRk6G9G3RRfLU1qKd6lRo0au7DMAAACA5O9j0L8AAAAAkjxIcf3119u7775rs2fPturVq4dvV5Fs/2wnz7p16zLMfPK77bbbXFq3d1m9enUu7j0AAACAZO5j0L8AAAAAkjRIodlKmt301ltv2axZs6x27doR9+u6OhEzZswI37Zz505X9K5ly5aZPq/qVqiwh/8CAAAAIPnlRh+D/gUAAACQpDUp+vbta5MmTbIpU6ZYyZIlw7OZtERTsWLFXLp1//79beTIkXb44Ye7i34uXry49ejRI+jdBwAAAJBg6GMAAAAAiSWhgxQTJkxw/7dt2zbi9okTJ9pll13mfh40aJBt377d+vTpY5s2bbLmzZvb9OnTXVADAAAAAOhjAAAAAIkrLaR85xSXnp7usjNUn4KlnwAAAJAsaOdy3AEAAIBE718kdE0KAAAAAAAAAACQvAhSAAAAAAAAAACAQBCkAAAAAAAAAAAAgSBIAQAAAAAAAAAAAkGQAgAAAAAAAAAABIIgBQAAAAAAAAAACARBCgAAAAAAAAAAEAiCFAAAAAAAAAAAIBAEKQAAAAAAAAAAQCAIUgAAAAAAAAAAgEAQpAAAAAAAAAAAAIEgSAEAAAAAAAAAAAJBkAIAAAAAAAAAAASCIAUAAAAAAAAAAAgEQQoAAAAAAAAAABAIghQAAAAAAAAAACAQBCkAAAAAAAAAAEAgCFIAAAAAAAAAAIBAEKQAAAAAAAAAAACBIEgBAAAAAAAAAAACQZACAAAAAAAAAAAEgiAFAAAAAAAAAAAIBEEKAAAAAAAAAAAQCIIUSWjr1q3Wv39/q1mzphUrVsxatmxpCxYsyHT7Tz/91Fq1amXlypVz2x911FH20EMPRWzz1ltvWdOmTa1MmTJWokQJa9Sokb344ot58GoAAAAAAAAAAMmKIEUSuuqqq2zGjBkuiPDtt99ax44drX379vbHH3/E3F5Bh+uuu84++eQT+/777+2OO+5wlyeffDK8TdmyZW3w4ME2f/58++abb+zyyy93l2nTpuXhKwMAAACQ6JOgNMGpQ4cOVqFCBStVqpS1aNEiQ79h6dKl1r17d6tVq5alpaXZww8/nAevBAAAAImIIEWS2b59u7355pt23333WevWre2www6zoUOHWu3atW3ChAkxH9O4cWO78MILrUGDBq6TcPHFF1unTp1s7ty54W3atm1r3bp1s3r16lndunWtX79+dswxx7gsDAAAAADJK6eToDT5SUGKqVOn2qJFi+zkk0+2M844w5YsWRLeZtu2bVanTh279957rXLlypbsdu/e7SaCqV+mQI9e+/Dhw23v3r1ZPu7ll1+2Y4891ooXL25VqlRxE8U2bNgQvn/Xrl3uedRHK1q0qNv2o48+yoNXBAAAED8EKZKw8btnzx7XQPVTQzi7AQV1HubNm2dt2rSJeX8oFLKZM2fajz/+6AIhAAAAAJLT/kyCUlbEoEGDrFmzZnb44YfbyJEj3f/vvfdeeBvdd//999sFF1xgRYoUsWQ3evRoe/zxx238+PEue13HU69/3LhxmT5G/bdLL73UrrzySpd58vrrr7sMFgWNPAp8PPHEE+55li1bZtdcc42bXOYPCAEAACS6gkHvAOKrZMmSLp367rvvdlkPlSpVsldeecW++OIL1zHISvXq1W39+vUu0KGOh7/xK1u2bLFq1arZjh07rECBAvbYY4+5GVIAAAAAklM8JkEpW0BLRmkJ2VSlZXPPOuss69Kli7uuDHb10xYuXJjpYz7//HO33Q033OCuKzDUu3dvF+DwKLtFy/J27tzZXb/22mvd0loPPvigvfTSS7n+ugAAAOKBTIokpIaqsh0UUNCspEceecR69OjhAgtZ0fJOaiRrho9mP6nRHB0A+eqrr9zsnREjRtjAgQPtf//7Xy6/GgAAAACJMAnqzz//dAELDX5rEtSaNWuy9RwaMP/333/tvPPOs1R14oknumz05cuXu+tff/21C/J4wYVYVPvj999/d8tmqX/3119/2RtvvBEOdIgmkB1IAAkAACARkEmRhLQe6Zw5c1xHID093a1dev7557uZN1nx7j/66KNdA1jZFKpV4TnooINcerc0atTIpSmPGjXK1asAAAAAkLyToK644go3CUoTn4477jg3CWrx4sX7fKwmPqlfMWXKFKtYsaKlqltuucVlph911FHuGCrYo4lf/v5WrCCFalKoL/fff/+5rJYzzzwzYoko1RIcM2aMW4pL/UAFQnSs9fwAAAD5BZkUSaxEiRIuQLFp0yaX8qv04uzSTB3NyjnQbQAAAAAkxySof/75x1avXm1ffvmlK9i8r0lQkydPdvUUXnvtNVdoO5XpWCgDZdKkSS648/zzz9sDDzzg/s+Makxoqae77rrLFSBXQewVK1a4uhOesWPHumV9FfwoXLiwXXfdda649r6y6AEAABIJmRRJSAEJBRCOPPJI+/nnn+3mm292P6uxKrfddpv98ccf9sILL7jrjz76qB166KGuYStKDVaD+frrrw8/pzImmjZt6jooO3fudCnHenxmxfIAAAAAJN8kKF28SVD+2gixMiiUfaH//csTpSr1yW699VZXKNzLXl+1apXrZ/Xs2TPmY3Rfq1at3GPlmGOOccf/pJNOsnvuucdNSKtQoYK98847LtNiw4YNVrVqVfd79hVAAgAASCRkUiQhpRH37dvXBR0uvfRSt/7p9OnTrVChQu5+rR3722+/RRSyU+BCSzgpEKH04XvvvdeGDx8e3kZLR/Xp08caNGjg0o61FqpmAkUX104GKk6XlpaW4aJjGouOp9LdFQjSklj9+/fPsM1zzz0X8znVmQAAAAASmQIS3iz+GTNm2Mknn5xhEpT6HR4FJnRdtShOOOEEW7t2rbuon+LRxCfVu9NFP2sSlX7WJKtktG3bNtdX8FO2g/piOX2MaFKan+pSaDkuLQn15ptv5iiLHgAAIGgEKZKQCtL98ssvbikmDaCPHz/eSpcuHTFg7i94rYyJ7777zgUi1HFQ+vG1114b0SDWTJ2ffvrJtm/fbhs3brR58+a5tVGTkQqD67h5F3XE5Nxzz425vY6zZjANHjzYjj322Eyft1SpUhHPq0t0kTsAAAAgv0+CeuKJJ9xguR6j2f7epV+/fuFtVIS7cePG7qLHK5NbPyfjJCg544wzXA2KDz74wFauXGlvv/22qyXRrVu38DbRwR495q233nLZ67/++qt99tlnbvmn448/3mVMiAqYaxvdP3fuXDv11FNd4GPQoEGWjBTMuvjii61cuXJWvHhxN9FOS2FlRSsH1KtXzxUUV3DNW1HAoxqLsSaUkQEEAEDeYbknIIoCDn7KKtEyV23atMk080Jrwcqzzz6b6fFUQ7dy5cocbwAAAOS7SVC6ZEaToPz8E6IyozZ0dDZAMlO2+p133umy09etW+eCDL1793b1JjzRwZ7LLrvMtm7d6iad3XjjjVamTBlr166djR49OryNMrPvuOMOF6Q4+OCDrXPnzq7QubZNNlpmTMtfKZPnww8/dIXYNTkvq9eqAI+CP0899ZQ1a9bM1VPp1auXHXLIIS4IJAryKJvHo2WzNPkss0lqyRDoUSF3HUNNQjziiCPsmWeesSZNmsTcXudhrNop9evXt6VLl4avb9682U3c0/HUe6Ulx5RNpXMSAIB9IUgBZEGNVS1rNXDgQBdkOBAqNFizZk3bs2ePm/Fz9913u9liAAAAAJJbyZIl7eGHH3aX7AZ7vKx3f63AaJpIpQLbqUDBmRo1atjEiRMjgl1ZUcBGwSBvFYA6derY559/7p7LC1KULVs24jGvvvqqy9JIxiDF/gR6NCFPE/c8ypKKDuKo39yhQwf3fFoaunr16rZ69Wp33gMAkB0EKYAsqAidZoRo9siBUGq8Oh0qkJeenu4aemocfv3113b44YfzHgAAAABAFt59913r1KmTGxyfM2eOq8GhzBRlRmRGS/NGL7GrZZ+UUbFr167wkmV+yipQgXMVKU82+xPo0dLR/uWj1UdWsMOrSeOtKOAtC+0dU03QAwAgu9JCqZRjmwkNGuuPrtZaVd2AINS69QNLdSvv7WKJRo3gwoUL23vvvZet7bWeqbIkspohJVon9rjjjrPWrVvbI488Eqe9BQAASLx2biriuAPx5wUblOWuQIUCDf3793c1UPy1PPxuv/12NyD//vvvu/6X6leo1oSW3FJdFNVK8dNzNm/e3NX6UO2PZKMlmtTH/f3337Md6ImmDBQFf1SXxqMlnZSRogyUKVOmuCWUe/To4ZaV8oq9J5OhQ4fasGHDIm6rVKmSrV27NsvaKFq6TTVpDj30ULc0lv+8VdBs1KhRbmktLcml+ikKKqnODACkQjuXTAogE6tWrbKPP/7YrakZbypKrjVRVYwcAAAAiDcmQSXmJCjsP030atq0qY0cOdJd19K5qomguhOZBSlUB0QDxyeccIKrgaKBZGXJ33fffTEHz5VF0bBhw6QMUIhql+h4KdCjAI6CMirGXqRIkUyPoZ/qpmiZqEmTJmV43lmzZtlFF11kU6dOdf3cvn37uqWh/HVXkkmDBg3ceIEnq2BMdmqjqLaMlprWNlqJYdq0adatWzeXncIy0QBSAUEKIBOacaM1NTXTJt7UQP7qq6/c8k/JaH9mlng+++wzt7auOgc6Rh4Fi9Qh+fnnn90sEy2TpQKCl1xyiSWrnB7HTz/91M1W+uGHH2zbtm0uxVpr8A4YMCBiO2X6qKGswozly5e3c845x83aiU6FBwAASGUEehIr2KOsB2UC+NWrV8/efPPNTB+jpZ20FJGyLf766y/3HE8++aSrlaB2sJ/az6pHMXz4cEtW+xPo8dMSxqpf0bVr1wzPq76zjq0G61WEW5kq999/f9IGKQoWLGiVK1fO1rbZqY2ibZRd4RUav/baa12gQsXHFbwAgGRHkAKIQY0sBSl69uzpGh9+mgGh9MsXXnghfJs3mK7i2OvXr3fXtUyU14jWQLNm72hgXWlRWuJJ2yjlM1nlZGaJR6liahyfcsoprhPhp/RhNdo0q0THVinbWgdVjWGlLCernBxHrZt73XXX2THHHON+VtBCjWH9fPXVV7ttXn75Zbv11ltdZ61ly5a2fPnycM2Vhx56KA9eEQAAAJBzqun3448/Rtymtmx2ah+oToKKOYsCEaeffrrLbvd77bXX3DJGF198cdK+PfsT6PFPtFMfQpPE1B+Lfl4dY39fRc+ryVUqqh29fTJQtkjVqlVdFoqWCFPgR8GH/a2Nktk26tMBQCogSAHEoEFhzTK/4oorYqa46j4/f/ql1jlV+qsay1pvUlR8W4PEaqRp3TZt/8knnyRtGnFOZ5Z4NKCutUvVuFVBtuh6H379+vVz63Wq0ZbMQYqcHEedV/5zUUXwlIEyd+7ccJBi/vz5roOn4+xtc+GFF7oGMgAAAJColB2sSTYaDD7vvPNc+1Uz93XJbEKZghhenQkVex4zZox99913rh8Ra6knZQiUK1fOktWBBHpUw0JZ7VdeeWXM51UfWJP9vOCPnlfBi2QMUOh80jl2xBFHuMl199xzjzs3lZUS6/xRf/Xpp59255dXG0UBHwUo/v77b3ectI3OT9WtrFu3rs2cOdPV99izZ08grxEA8lrk1AEATseOHd1METU6YqW4/u9//4u4TdtGX7wAhTdDXTUuNDtCRdqUttmiRYukPtrezJLatWvbBRdc4NYpzYoyV3755RcbMmTIPp9bx1eNNjWw1YhLZjk9jn5Llixxa5hq+SzPiSee6BrFXlBCz6d1Y3NjWTMAAAAgXrSW/9tvv22vvPKKWxr27rvvdsuYqg5CZhPKNMCr5XKOPfZY69Chg/3333+ufayJOn4aUNfkp1gD8MkW6NEyQ94yugosKMij+hH+QE+spZ8UxNHgvI59NC1NtGHDBjeRTMfygw8+cL/D/7zJ5LTTTrPu3bu75Zvbt2/vXq/ECn55tVH0GK2uoKyJs846K5zN7mWfjB071q284K0coAx5rRyQjIXHASAWMikABD6zRAPxWoJIM/6jl9eKXg6qWrVqLtijxtpjjz3mOhvJKqfH0aNUdi07pkJ1qmtx1VVXhe9ToEP3KVihYI+2UadCxx8AAABIZFqmSZfMaEKZn5Yc0sSdfVF7W23jVAn0KBCh2huaCLWvQI/XD9OSUBpIj6VGjRo2ffp0FwTR0rPqsylgoXp5qUDL6ypgoX7t/tZGqVChgltNQIE0BXw0UU19NL1HAJAKyKQAEOjMEs1u0tJDqtsRK3PFT4041fJYsGCBjRgxwgYOHJghqyWVZ+h4FOxZuHChPf74467TodlmHh0vHTsFeBYvXuyWg1J9D81ESwUqEJ6Wlmb9+/fP1vYq5K7AWaNGjTLcp46a1vTVOrT6Xx0+AAAAIJEpyPPtt9+6wfDvv//eevXqtc+VA7RksQqLR2/rp5UClKWh51WG/O23354yWQCaRKdjqeBDdmqj6LhkVhtFdSkU5NFkMvU3lHUBAKmATAoAgc4s2bp1qxtQ1wwnpbSK1jLVTCYNDmtGTrt27dztasAddthh7mcNGqshqEHn6HoVqTpDx+PNttG2mqmjbArVnfBSjVXszsuu0Db//vuvq1mhwuTRjeRkouCWZixpdld2ZFXIXbU9zj//fBfc6datmwtQaG1kLROgDBgAAAAAyemmm26yM844ww499FC3nLMy3tPT061nz577XRvliy++cI9RP1f/qw+nfvGgQYMCe50AkJcIUiBp1Lr1/2aZp7KV93ZJ6JklJ510Uob7SpUq5Wby+GmW/6xZs+yNN97IMr1VgQw9d6rI6jhm9xhpBlR0IEIzebxaKsnqn3/+cWnsTz31lOtEHGghd2WoaKkxdUBE/6uYYHTmCgAAAIDk8vvvv7tJYCp6rWWaVGtCWSReAfLMaqOopqKyKU4++eQMtVGUgXLHHXe4moEHH3ywde7c2V588UUrU6ZMIK8RAPIaQQoAgc4s0YB5dPG1ihUrujRX/+3KmGjatKnVrVvXdu7c6Yo96/ETJkxI2ncwpzN0Hn30Ubetiq2JZvU/8MADdv3114efU8+nmTuNGzd2M3lUME/ZFWeeeWZSp2OraJ+Kg2vZrOwEKbxC7i+99FLM7ZVJoTV3/Tp16uSCFAAAAPj/mEyWuJPJsH+0VFNW9qc2Sps2bWzZsmW8JQBSFkEKAIHPLMkOLUnUp08f99wqPKaBeA0ga8mdZJXT46h0YAUuVqxY4ZbKUkDn3nvvdRkBHs3OUU0G/a8Ah55XgQvVqUjmToTqb2i5p+zITiH3tWvXWqVKlSJu03XdnowUDNRl5cqV7nqDBg3srrvucnVTslPXQ50uBR1VU8ajAvB6jkWLFtmqVavsoYceynatEAAAgFRCoIdADwAkO4IUAAKfWRJN62/q4qfZ7NldpidVj6MyJvxZE7Fo0H3IkCHukgpWr15t/fr1c7VNlJ2zLzkp5K5gj5+Wy4q+LVmowJ8CXl5NGK2fqyJ+mhGmgMX+1PXQ0mN16tSxc889N0NWCgAAAAAASB3JWyEVAJDyNEtfS2U1adLEBWh0Ue2IRx55xP2soESsQu4q4u5tP3z4cPv666/dz6qVIpUrV86QNaHfE51dkSyUbaN1cRW40UWZN1orV5k92anr0aJFiwz3NWvWzO6//3674IILrEiRIrm49wAAAAASiZZzVn+gZMmSbrnnrl27upod+/Lyyy/bsccea8WLF7cqVarY5Zdfbhs2bIiYyKeJY9EX1fwAkNjIpAAAJC3N4I8uzK6GrJYLu+WWWzLU4chuIXcNus+YMSMiA0DZGi1btrRkp8DO66+/7pZgixV8yG5dDwAAACAvsWxW4iybpYljqhuoQMXu3btt8ODB1rFjR1eXo0SJEjEfo5qLytLWMrGaRKXli6+55hq76qqr7O23347o00UHPLKTVQ8gWAQpAABJSzNzoguzq9Fbrly58O37U8hdS0i1bt3aRo8e7ZY9mjJlin388ceu4ZysFLxRUEKzkJRFoY5A/fr197uuBwAAAIDU9NFHH2WY4KR+lzLh1c+KRVnctWrVshtuuMFd1wQyZW7fd999Edspc0KZ7wDyF0YOAIQxsyRxZpYg7+xPIXdlTKhmiAqQ33nnna5I+eTJk6158+aWrI488khX+Hrz5s325ptvWs+ePd0MqOhARU7qegAAAACAatlJ2bJls+yDKeNi6tSpdtppp7nldpXt3qVLZB/+n3/+sZo1a7p+SaNGjezuu++2xo0bJ+WSWW+99Zb98MMPVqxYMXd8NIlO/basqA83cOBAW7p0qVWtWtUGDRrkMlL8Hn74YZswYYLrJ5cvX97OOecc9/vISEFuIkgBAHFGsCexgz3/+9//DriQu6ihpkuqKFy4cLhwdtOmTW3BggU2duxYe+KJJ2LW9VBRbdX2kL1797rC4sqq0LJY7dq1C+Q1AAAAAEgs6ido0PzEE0/MkNXup0F41aQ4//zzXXa3lok688wzbdy4ceFttKyv+ndHH320paenu/5Kq1atXI3Bww8/3JLJ/iyZtWLFCldrsFevXm5Z3s8++8z69OljFSpUsO7du7ttdIyVFf/ss8+6Y758+XK77LLL3H1aagvILQQpAADAfnUmduzYkeH27Nb1AAAAAABNbPrmm2/2uXSuBt+11NNdd91lnTp1chnxN998s8sCeOaZZ9w2J5xwgrt4FKA47rjjXCDjkUcesVRfMuvxxx+3Qw891GVKSL169dwEswceeCAcpJg/f747bsqOFy2xdeGFF9qXX36Z668JqY0gBQAAyNLtt9/uUqpr1KjhMiW01JUyUryG8f7U9di5c6fraHg/6/FaTkr1LryMDQAAAADJ6/rrr7d3333XPvnkE6tevXqW22q5IQ2eKzAhxxxzjMsYOOmkk+yee+6xKlWqZHiM+ibKNFDNvGSXnSWzFIBQtoWfAj4K8uzatcsKFSrkMlqUZaGgxPHHH2+//vqrW2JLy/0CuYkgBQAAyNJff/1ll1xyiZutVLp0adchUICiQ4cO+13X488//4xYG1azd3Rp06ZNhiW5AAAAACRXVrYCFG+//bZr+2cn23rbtm1u+Vi/AgUKhJ8vs9+jiVBa/imZZXfJrLVr11qlSpUibtN1LRf1999/u0DPBRdcYOvXr3fPpefVfddee61bAgrITQQpAAAJh7oeiVXXw0ufzsz+1PVQ2nBmnQkAAAAAyUu1FCZNmmRTpkyxkiVLusFz0YQoFYGOztaWM844w9VSUEFnb7mn/v37u9n+KgAtw4YNc8s9qf6EalJoiScFKR599FFLZtldMkvS0tIirnt9Mu92BY1GjBjhluxt3ry5/fzzz9avXz8XwLjzzjstWen13n///e68atCggVsSS1k6sahGx/PPP5/h9vr167uC5J7Nmze7WiEqcL5p0yYXjHvwwQddXRBkRJACAAAAAAAAQJ5QoEHatm2boa6CV6Q5Oltbt2vp2fHjx9uNN95oZcqUsXbt2tno0aMjBoWvvvpqF/RQwEOZ21pKSoGMZJWTJbMqV64cDgh51q1b5zJUypUr564rEKEs+quuuspdVxbKv//+646rBty1hFaymTx5sgt4KVChJcWeeOIJt9yxlidWDY9oKsh+7733hq8r2+TYY4+1c889N3ybljTWygNa+li1GfXerF692gXlEFvynVkAAAAJSg1fzaBRjY4mTZrY3Llzs/W4zz77zHUeGjVqlOE+zfI58sgj3awz1Q0ZMGCA/ffff7mw9wAAAMCB0+z9WBcvQOFla0cvA6sBec1U19JPWj5WtROqVasWvv+hhx6yVatW2Y4dO9zg+7Rp06xFixZJ+ZbpeCmDQrP0Z82ala0ls3QsZsyYEXHb9OnTrWnTpq4ehejYRgcitKyW9x4lozFjxtiVV17pAjMqJq7+lfpVXjAtmgJgCvh4FxUfV6bE5ZdfHt7m2WeftY0bN9o777zjAh81a9Z0S2gpmIHYCFIAAADk4QwdzUBasmSJSx/WDJ191fNQEbxLL73UTjnllAz3vfzyy2592CFDhtj333/vlubS71F6fLLKSaBHM/B69OjhgjjqbOn4R1NHt3v37m4JMqW5q1MCAAAAJPqSWQrSaNksb8ksXbZv3x7eRn0C9SM811xzjQviqH6F+g4aSFf/4aabbgpvo2W1NDj/6quv2ooVK1xQQ9kVZ555ZrgGSDJRxsOiRYsyFBTX9Xnz5mXrOXQM27dv7wIRHmW3KCik90l1P1QrZOTIkbZnz564v4ZkwXJPAAAko6Glg96DxDB0iyXiDB3RYLhmd6kTMGrUqEwf17t3bzfQrk6BZuL4zZ8/383M0f2igfYLL7zQvvzyS0tGOU3F1iy6ChUquMCQZtbFotliderUcenZykIBAAAAknHJLE30mTp1qmvzqk6Hanmobocm7HjuuOMON3FH/6smiNrSClyoTkUyUsFwBQ5iFRSPXhorFh3jDz/80AWL/H799VeX4XLRRRe5Y/7TTz+5gIWWhrrrrrvi/jqSAUEKAACAPJqho6yHnMzQUSfjl19+cbOk7rnnngz3K2VY9ykoobV21RhWI7hnz56WjHIa6FHQRmvGimaKxdKsWTN3kej3BwAAAEhE2Vl6SUtmRWvTpo0tXrw408doiVllaeuSSmIVFI++LbNjrPooXbt2jbh97969rh7Fk08+6SabKQNcS5SpODdBitgIUgAAACTgDB3NttGguZYzUmchlgsuuMDWr1/vghVqSGtmzrXXXpuUg+37G+gBAABAnJCtnVCZ2jhw5cuXd0GEWAXFo/tu0dT/0kQoFRovXLhwxH1VqlRxdT78S2Sp3oV+j/o10duDmhQAAAAJN0NHAQ0t4TRs2DA74ogjMn0+FRNU6rWWP9KMKBXOe//99+3uu++2ZHOgqdgAAAAA4KdggbIcoguK63rLli2zPFhz5syxn3/+2WV6R9PStLpPGRWe5cuXu+AFAYrYyKQAAABIsBk6W7dutYULF7oC29ddd527TQ1cBTWUVTF9+nRr166dK2KnmTve8kdHH320/fvvv3b11Ve7OgwqFp1s9jcVGwAAAACiqZC4+lRNmzZ1xa61RJNqeajQuFeAXPU5XnjhhQwFs5s3b+6KYkdTdvu4ceOsX79+dv3117sseRXOvuGGG3gDMkGQAgAAIA9n6HTr1i18u66fddZZGbYvVaqUffvttxG3KVtCxdfeeOMNV/TOK/ocHYhQMEQD99lZpzZVUrEBAACARFDr1g8s1a28t4slkvPPP982bNhgw4cPd4WwFXRQnb+aNWvGLEAuW7ZssTfffDNc/y5ajRo13MQyFSk/5phjrFq1ai5gccstt+TJa8qPCFIAAAAk2AwdBR6iZ+So8FrRokUjbj/jjDNcMenGjRu7WTxKKVZ2xZlnnhmx/mkqBnoAAAAAIDv69OnjLtktQF66dGk3YSwr6vN9/vnnvAHZRJACAAAgQWfo7Msdd9zhljrS/wpwVKhQwQUuVKciGe1PKvZXX33l/v/nn39ckXFdV8Cjfv367nYVrlu2bFn4Zz1e2xx88MF22GGHBfI6AQAAACCVEKQAAABI0Bk6fkOHDnUXP9WnGDJkiLukgv0J9CjLxLNo0SKbNGmS237lypXutj///DNimwceeMBd2rRp4wqTAwAAAAByV9JUU9Q6zVqfWcsgaCmAuXPnBr1LAAAAiDMFeRRg2LFjhws6tG7dOiLQEx1Y8Opz+C9egEJq1aoVcxsCFBD6GAAAAEDuS4pMismTJ1v//v1dJ6JVq1b2xBNP2GmnneZS9w899NCgdw8AAABAPkMfAwAAIDFRgNwSrgD5gUqKTAoVjLzyyivtqquusnr16tnDDz/sqqhPmDAh6F0DAAAAkA/RxwAAAADyRr7PpFCBQ6X633rrrRG3d+zY0ebNmxfYfgEAgPyPGTrJN0MHyA76GAAAAEDeyfdBir///tv27NljlSpVirhd19euXRvzMVrDWBfPli1b3P/p6ekWlL07tlmqO9DjzzHkGCbCeci5GJ/jyOc5DufijtCBPT5ZcC4Gfi42HDLNUt13wzoF/v6pzgZyr49B/yIx0R7hOCYKzsXgj6HQx6CPERf0L+JwCPk8x0N6QOPYudW/yPdBCk9aWlrEdR2o6Ns8o0aNsmHDhmW4XUtEITilH+bocwyDx3nIcUwUnItxcm/peD1TyuJcTI5juHXrVitdms9DbvUx6F8kpkT47CUDjiPHMBFwHnIcEwb9iwPG5zk5juPWOPcv8n2Qonz58lagQIEMM5rWrVuXYeaT57bbbrOBAweGr+/du9c2btxo5cqVyzSwkcwUAVOAZvXq1VaqVKmgdyff4jhyDBMB5yHHMVFwLnIME0Wqn4saVFcHomrVqkHvSlL3MehfZJTqn7144BhyDBMF5yLHMBFwHnIcE0Wqn4uhXOpf5PsgReHCha1JkyY2Y8YM69atW/h2XT/rrLNiPqZIkSLu4lemTBlLdfpgpeKHK944jhzDRMB5yHFMFJyLHMNEkcrnIhkUud/HoH+RuVT+7MULx5BjmCg4FzmGiYDzkOOYKFL5XCydCxna+T5IIcqKuOSSS6xp06bWokULe/LJJ+23336za665JuhdAwAAAJAP0ccAAAAA8kZSBCnOP/9827Bhgw0fPtzWrFljDRs2tKlTp1rNmjWD3jUAAAAA+RB9DAAAACBvJEWQQvr06eMuyDmlpw8ZMiTDEljgOOY1zkWOYaLgXOQYJgLOQ44jgkcfY//xHXbgOIYcw0TBucgxTASchxzHRMG5mDvSQqp2AQAAAAAAAAAAkMcOyutfCAAAAAAAAAAAIAQpAAAAAAAAAABAIAhSAAAAAAAAAACAQBCkAAAAwH7bvXs3Rw8AAAAAEsjufNZPI0iBpED999yX377cDhTnVOJIhvdi7969ET8nw2sCPvvsM3cQChYs6P7fuXMnBwVAUuHvde5Ktf5FvKT6eZnqr9+PPgaAZOqnEaRAvrZnzx73f1pamvv/3XffteXLlwe8V8l5jPXlpi+26dOn27p16yyZX68avt45hWDfC0mG9+Kggw6yX375xT7//HP3s17T5s2bg94tYL9NmTLFzjnnHPd397vvvrNTTz3V5s2bxxFNUPq75h/IAJA1+hi5K9X6F/GSTG3j/UE/LSP6GMD+Sea28ZR83E8jSIF8/aVSoEAB9/M333xjkyZNsnPPPdc+/PBDZuXEkXeMH3roIatatao9/vjjtnjxYkvm16uG/7Rp02zIkCH2xBNP2Nq1a4PerZTiNRa8c++NN96wCRMm2NKlSy2/2rFjhw0dOtTOOOMM1xm/+OKL3WXDhg1B71q+o8/mxx9/zCy6gD+frVu3trZt29rVV19tTZo0sYYNG1qLFi2C2i3sY1BHf9c0kKHgKDOXgazRx8h9qda/OFDJ2DbeH/TTMqKPET/0MVJHsraN9yZBPy0tRK4c8rGVK1faBRdcYH///bedcMIJ9vbbb1uDBg3cwHLjxo2D3r18/aXtNYL1FXHddde5GU533323tW/f3ooUKWIlS5ZMyoyDLVu22OWXX26zZs1yQS+9bn2xn3feee5cQ97Ztm2bde7c2X766ScrXry4u02BIw3u+8/RRG8oqPEjv/76q2sg6HqzZs1s/Pjx7vsKOXPiiSe64M6MGTOsevXqHL48Ev2Z099fzcpZsWKFXX/99fbAAw/wXiQw/b3u37+/C/BVq1bNatasaY8++qgVLlw46F0DEhJ9jPhL5f5FvCRD2/hA0E/7/+hjxB99jNSSTG3jPUnUTyOTAvnauHHj3P9fffWVm4mj6LfSmd58803bunVr0LuXb1OI9QX322+/2ZNPPml//vmn/fjjj3bjjTe6QfpixYq5RvG///4bjtQmU6xTKXEbN250M5Oeeuopmzlzpi1ZssSda9u3bw9691KCMg3UcdUMMUX8dS7qfVEWgv7I/vfff+4cTeTzTvumz5MXoBCdS9p33ffRRx+5AEWyppjGk47Za6+9Zn/99Ze7rp/V4NL3/K5du4LevZSg89Rr+L7//vs2ceJEK1GihJvJefPNN7u/vd5Si97fESQOTeRo166dLVy40O69914bMGCAC/L16tXLfb8CyIg+RvzQvzhwydA2jgf6afQx4ok+RupKprbx3iTrpxGkQMKL9UHSBzE9Pd3mzp1rJ598sh188MFWrlw5F/0eOHCgvfTSS/bFF18Esr/5mfflpiwCZQ/8/PPPtmrVKnestaSWvsB1fBWVbd68uVu+Jj+vZxp9mwY8NaNLr0/R9Mcee8ylyimq/uCDD7oADeL/XkRbs2aN+0OqP6paAkDnZb169ezaa6+1ChUqWN++fd12iTrA780A1H7r83PTTTfZBx98YD169LA//vjDatWqZX369Al6N/MFZUzoPVeA9NNPP3WddJ0T6pDff//9LoCK3Kdg2w8//GAtW7Z0jXctyaG/C8oM6tSpk5UtW9buu+8+t20qDJIkKh33WMdegXb9fdNymBrQOuqoo1zHXN9P+aGzAuQW+hh5I1X6F/GSjG3jnKCfljn6GPFDHyM1pELb+KAk66cRpEBC8X9gvC8Ur2Gr6vRvvfWWWzNOH8RSpUq5LxZ9mXjrMYpShpUK+vLLL7ssAGSfMlI0O0czlJU6rC8zfdmp4avBQEVjy5cvb6eccopdeumlNmrUKPeY/JSS7UWatc/a96lTp7p0ON1WqFAh+/77710nQMuHjR492kaMGGGzZ89211XQj2LH8S1U5X2+9Vn1Pv8KCvXr18+l/Kugove+1alTx2677TY3O2DZsmXusYnYGfM+D4MGDXLZEkrJ94JgVapUsdtvv929BjWO9F2WLGtg5gYFn/UdpM/mmDFjwtkUClDou1/ZTsrqkkRvcOVnmzZtsmuuucZ9BvX9qL8NdevWdffp/VHjXkEkfVd6nwEFlJD3a+vqEt25+uSTT9xnSe2mbt26ueUwL7nkErdEZu3atXmbkBLoYwQnFfoX8ZDMbePsop+WNfoY8UMfI/mlStt4U7L101STAkgEv/76a+j33393P+/Zsyd8e3p6eujMM88MHXLIIaEqVaqE2rZtG/rggw/cfQ888ECoZMmSbhvZvXt3aNu2baH69euH6tSpE3rllVcCejWJbe/eve5YxVKmTJlQWlpaaNq0aRG3b9myxf2/fft29////ve/UOPGjUPfffddKL/5+++/3TlVqVKlUKNGjUK1a9cO3XXXXe6+CRMmuNc/cODA0NatW8OPWblyZWjo0KGhTz75JMA9z79Wr17tPpvRvvrqq1CrVq1CRx99dOikk04KPf/88+72f//9N3T11VeHqlev7s5Xz19//RU69dRTQ8cdd1woUfj3z/PCCy+EjjrqqNDnn3+eYRt9ljp06OC+y/y8z1Yq27FjR4bP6mWXXRZ68MEHQwcffHBoxIgR4eM0ceLEUNGiRUOzZ8+OeMyuXbtC8+bNC61duzZP9z0ZZPZ3YdasWe77Un+n5ZdffnGfRe/7X9e7desWatq0aei3335z35+33XZb+G8zcofaStHv2Z133hnq2bOn+8x4n6fnnnsuVKFCBfd5OffccyP+buvzo/cPSGb0MfJGqvcvciqZ28YHgn7a/0cfI37oY6SGZG4b706RfhpBCiSE5cuXh9q0aRN6+umnI/4oq1E2bNiw0HXXXRdat26dG3g644wzQu3bt3cfvD///DPUoEGDUNeuXUObN292j9OgoBpwTZo0CZ1zzjkxG3+pzB8A2rRpU2jJkiWuMeh57bXXXCdC/0c3jNSB0HH+8ssvQ61bt3ZfdmowJ5Lofd65c2eGba6//no3SPzHH3+461OmTHGv+a233nLn4hFHHBG66KKLQitWrHCPVyeiR48eoRNPPDElOk3x9vrrr4dOOOGE0OLFizP8QVVHq1+/fu58u/baa91A9COPPOL+CC9atMgFkG699daI9/bdd991nd2gGw+xOuP6fOmc0Wvp3r27u23NmjWhr7/+OjRz5szQ999/72777LPP3Dmn4Nizzz4bat68eWjSpEmhVOS9r/reVmc8egCjS5cu7jipMVm6dOmIz6CCjPqb4H2H6Zzp1KmTO7b6e4Gcvw8yd+5c97n1PrP67i9QoEDo0ksvDXXs2NF999eqVcs1iEeOHOkeqwZ9s2bN3Gf6yCOPdIMsiD/9vRo9enSG2/V36rzzzgs1bNjQfZb0GdB3q/7O63Ohjok+S37r16937+VTTz3FW4WkRR8jbyR7/yLekrVtvC/007J/nOhjxO98o4+R3FKhbbw3hfppBCmQMA1bBR38NMCkAahy5cq5GbP+L6EWLVqE7rjjjvB25cuXd7OWNThVqFAhl0HxzjvvhAoXLpz0jdz9NXjwYDfgd8wxx7iskyeffDJ8n467vrD1Je3Rl9uoUaNCZ599tmsE64teM5YThfbP30GaPHlyhpntb7/9dmjjxo2hatWqhQeLdW4ddthh7jV/++234QFkdQD0xa7joNeroIb+0CHnNEtu1apVGW5XZoo+y/5AkgKSCgbpj693zunz7X/8f//9l2E2TJANBQVQFWCdP39+eEagBtX12VKwVBkTCqwWKVLEzQ7Ud5iow6lZbzVr1gw99NBDoVSmwQk1HHXRMfMfDwWrTzvtNPe+H3744aErr7wyPPNDQemCBQuGHnvsMRd81M+dO3d2s0SQcwqoqXFbuXJl99nU31/NtJGPP/7YzTS66aabXGBNjVs19PXd6X03eo1+5J4BAwa4v2Wiv3n6XFx44YVuhpj+LnufjVdffTVUt27d8N92fZcqG/Xmm28Ovffee+5+tZv0/eT9PQSSEX2MvJVs/Yvckoxt46zQT8vZsfLQxzhw9DGSX6q0jdekSD+NIAUCpS8R/8DysmXLXEPMo+WctMyTP5KpSOGgQYPcQJa3lMqCBQvcl41mm6gB5z1WM+L1xz1WqmQqU6qbIqj6MtbA/DXXXOOWyLr77rvDgR8NFirY439/NCtq/Pjx4VSyrNLO8pJ/H7744ovQscce6/ZfmTYbNmxw2TgKTLz00ktuSbHjjz/eBSf0B6hq1aruNXkdIi/d/IcffnCzksaNG5dhORlkj/e5884hfV792QL6I6sBZ/E6Vnp/FDS69957w98JSnc/5ZRTsnzfg6LZCQo+aB8V1FIQQvus16zXqsaBGk1aJmzp0qXunOvdu3f48epg+j9jqWThwoWhDz/8MPzeawaMBij0PXTooYe6z62+v9944w23jIG8+eabbqaIZhp6x00Zc/q8K6tODTRkT6zz7oYbbnBBHjViRUsr6tg+8cQTMT/b+n7UOZ0KA0qJ9n6pA+ZNwlC7Se+T933qUWdFAXb9PdN7pL97CvRp5pg6aeqcAcmKPkbeS7b+RW5IhbZxNPpp+4c+xv6jj5EakrltvCeF+2kEKZDn9KHRB0tRPw0ii/5XA0az3TXQ533QlLKq2gG6aLDZowadZtaef/75MX+HGsFqvCmYkar0ZeQ1Cv1BGn3haWkZzTr2qPaCZu5oRrc3K0df4BpwzSxtWM8d9OCq//drRtLll1/uBjAVDddrUuBKUXQtB6YOkNewV3q1BpYV1PK+5EXBCK82BQ5MrD+GahBoWTcvgq/1ITV7IfoxGnTWEj6imWQa5Pfq0CQSBUTVmJk6dao739S5VoBM55vOs2gKgOmzp1kaCIUuueQSNwPEPxNQa4Pqu0jZE1piTdlxCjwqWO39DWjXrp07lxTA8D77L7/8Moc0m6KD9mPGjHGZZ5plpFmvCqaJBowULNISXN5tooEnnd/6G6737+GHH3bPyWSA3BN9bDUxQ0uieDPB/vnnn1C9evVcm8hfi0WddA0YaoDQ67Tpe0gDXurIJfKgFrA/6GPkvlToX+SWVGgb+9FP23/0MQ4MfYzkl6xt47300whSIBgaXFLUT9kOffv2dT9rRq2+QDRwrEimluURfdGo0auBFD81epW+5A0G6stFz6EBwuLFi7tUp1SiLzQdk+jAjL5s9SXt0bJaagxHR4kV+NFx13siOv7eexTdWUi0wSillmuZL+2vf5kYzUDRzGytv+enYkFaZkdLgvnT5xTk0LqF3rmHnPOfG+pYaQDz008/ddc1y13vxZAhQ9x233zzjRuUvueeeyLOV80M03mcCOdZZmvC+r+DFOjytlGgSwFSLeWk7bQes163BtGV2aUBX9U6SWVeh1vBBQ1y6zh6tYN0nIoVKxaaPn26+07X8gaaVej9jRANmOu6UlmTdSAjL+jvrWa9KstMszgVBNJMogkTJrhArgaVdIw9eo/UmNfnVeeyshlV4BTx51+jPFZdJf2N0mdDa8/+/PPP7jYteaZlCpVt5Ke2kLKMNLM5GsEJJCP6GPGVyv2LeEm2tnFO0U+LjT5G/NHHSF6p1jZem8L9NDIpkGe8hqj3paJUJdWMUBqw1nL3aFaIGrO33HKLu64BQA0ee2lZ/g9u9GCyiuMpCyMV1yPXF5OKqJUsWTIcLVanQjNh9YWtJWa86LAauhqM90eVNSCoWeH+pbU0KJjINT00y6RixYruC1vr7umPkmZn6TzwzjUFrXSO+WcCa/aWZmkrgKHoutIBtbar6gak+gByvDz66KNuAFrrJXodU9EMOw3Ue3801VFTZ1Wfd51vt99+u1tnMRGW2PJ3nvU5UPFrfc68DqIaOApIeNt6t6tYlbK/RI/ReaWZHImSPhoEzfjT50zBQD+9/6VKlYoo3qXl2JQtoc+vBj103BSo0PeVd4z1Pa8ZL8g5HUOl/2owSRmJXqN/5cqVLnNF2Wj6PGoGrEefV70Peqxmw2r5MuSOGTNmuFm0jz/+ePi2n376yX2nqmi8V/dGmaf6e+cPzLdq1SrUvXv3iBnK+sxp9q1XcwlIRvQxck8q9i9ySzK0jXOCflrm6GPED32M5JdKbeO99NMIUiBvPmj+iKSKF6nBqgigGrxqmPn/UGtWjmZcaFBPA3zy/vvvu2igfy13j39wMNWpwE/Lli1dKrWWvFK2gL6sNTunRo0aLjCkYz9nzhx37J955pnwYzXwpNQ3r+iQX6LOVtayOc8991z4umatK6NCGRTe7C7VldASPNEDxLpf0fUbb7zRBSreeuutPN//ZOAvhOd9DhXtVwRf5554xapEASRlRvXp08d9F4jeGw2YqlCVMhNUuDyvX0NWRowY4YJYmnGh7yEtgyMKrqpQs9dp9AKw+rzp9XvHRUuNebVOUpFev4KJ6nArYOOtqexRkPHiiy8ONzAVsNC2+mxHvzd81+dMZrOB9N2n9a31efNT6rPOc60X7lHQX8vmaeBJ37HIXfpbfNVVV7lBLH0mxo4d6/6u6ftRs6a0nKFHf+sVaPLqc02bNs1to/c3v60/C+wP+hh5I9X6FwcqGdrG8UA/jT5GbqOPkRqStW1MPy02MimQZ5SipMI1GozSjE1Rg1XZFIqO+ulLRYNZWk/QozU6NeCM/y96HXB90Wkt97Jly4YaNmzoCkV7FCnWuu5KG5Orr77abaOZs0ob08CUZvFo5nKiizVQ6RWX0+wupUn7UwKViaPZXV5qdbJ2ivKa/w+9Zl17f2iV0eJlEqiztXr1aveZ9zKfNHtM2VL+81O81EzJizXuY6VZ++8TNYKUJqogloISWp5OAQuvk6k1gnW/Bm91XumY6LtL31epTDMkvc+blt5QZ7t06dIuKK0Zlco28dZS1ixBBSXUiPTeD333K0sl+pxAbLE+L/7rynz48ssvQ+vXrw8HaXv16hWqWrWqW1rCo8+pirLp77L+Nui7U+/b6aefHq4hhdzh/7ukto4yijRg1a9fP7d+rga0VExeg1wvvvii227mzJlusFATO/xZqvp+9dd6SaT0dSA30MeIr1TtX8RDfm8bxwP9NPoYuYk+RupIlrYx/bScIUiBPKEUX82s0ReEAhP+1Cqtw6mGrFcE1fsga3BQjV5muEd+Ub/++uvhn2NR8d7LLrvMDTJ5DVuvwawBVmWoiL7U9V6cddZZrvOgVOL8zN8g1sCbOklew1/F6JS5o+V5UjG9PLcpHV2zvd54441wR0ufXTUgunTp4gJEqhOjz7rOSb0HWr5Nn/tYhRPzosHg/x2awaYGjuoheNlbOp8U+FIjxz87Qx1OvV4FKrSNOt2axaGCw0ol1cC6MgO8Qu2pSEtDDBgwwJ0DXkaTipnpM3jNNdeE/vjjj9AFF1zgak8oS0WddQWvlY7rLQelxylwcccddyTcrJdEE52p6P8uVAq0ZmBWr17dzXZVJtBHH33k7ps1a5abGdu/f/8Mz6kgnD4TmrWk4BHyNliq7xktr6LlPfQ32qPPjiZ7HHPMMeHH6Hu2bdu24VnKWgZN7zuQKuhjHDj6F/GXH9vGuSmV+mn0MXIPfYzUkExtY/ppOUeQArk+c0IzN5XC6l+L1E9RUA1G+WeOaGaJZkVpAEtfPFk9fyqZOnWqO1ZKp/aosLgCDF4j2JuZfPDBB7s1TcVbaubHH390qXFesXHRAKC3lmwiNoL9KdP74g1mKpCjZXg0uOavH6AoO2upx3etWW/gUynd3rFVwFGDywpKak1IzWzQzAUNSnvLbmkpH3Xg/EUX85qCED179gwVLVrUdQpr1arllgbT7DavIdy6devQXXfdFX6Mzic1cpQ2qnX9veVwVLjq2muvDY0ePTqw15NIVAhSAR6v0KaOpepIlChRIlx/YsyYMe5vgxqV+lm1EHSueB3UyZMnh+vLICP/96I6+srgUQ0eb9ksHXPV9lAASPdrZtEVV1zhBkm0dIeosa/UaRUqFwJCwdF3pCYS6LzX94zaRpr1pffQT0EmTTbwvpf0GdHSXXov9Z3m/c1L9fYSkg99jNyTiv2L3JLf28Y5RT8tNvoYuYc+RurIz21j+mn7jyAF4iazwQ19mWiWsQaONXtfjV01fLUuuZdypaU9NOingWTNStagCUvyxKZlNzQzR8vLqOCPjtvJJ5/sBuW11JHoOGtZFQ1G+Yufaqa4vrAVBIr+kk7E2h7+c0ADbjmhYn6nnnpquLiugmVeQToc+Nq6ogHPWHViMqMBf3/BqyBpvWRld2mfvOVuNIirIIXX+VaKqDqTCmQoEOHRgK+KcnlBCk+ifX7yimYAKuPNXxRb3zv33HOPm8HvDVpoO80e1Ox9j76rVO9An1cNkGgpKIrX54zSmZU5p/VX/bMvtdyW/gYoi8VPjXgtOyHK+NF7ctFFF4WXzEv18zkIqgWigSotBaJBLX3H6PhrIEvtJw0MehSEUidMRWu9bEmtEQ8kM/oYuS+V+hfxkIxt45yinxYbfYz4oY+RupKlbUw/LecIUiCuNANWEcvhw4e7iKesXbvWDYCocGq1atVcw1czZ1VETTNtvcdpto5mgmpgyy8ZG7Y55Z99pOVoNONYS3EolU2D95rJpJnc6kh4s6CUOqsvanU4NJiq4r5aikbpcdGDUYnc6NX7r6VjtCSVOklerYnMgljesdJsdw16Tpw4kYBXnM49b11H0TnkzdIWFdrVTPmBAwe6GS7e9goAaLBUKZc6/3766afw+5rV+5jbFAjVOsn+AXF9Dyn4oJn+3v7p/Klfv37o0UcfDW+nTAvVoZgyZUoo1en7SLMn9VnTzBZ973iZEPpZ77vqdoiO6TvvvOPWtPbWDRVt76X6K3sO2aNsCGWH6Xveq//hp+9AZQl5gQtvxutrr73m3jOvOOfIkSPd83jZFMhbmsihyRn6bER/J/7www9uGTm1jfxUH0ftqPHjx0fczuQOJDP6GPGXav2LeEnWtnF20U/LGn2M+KCPkbqSoW1MP23/EaTAAfMaVBqwK1OmjPvDrIinGrSaTaIghbZRQ00zOlWPQo1eLcVTpEiR8LITavD5Z0qx7ETGL1WvUaw18jUoqNlMfprxpIs6cmoEq66H1jvVDNsePXq49eDzE2XaKLtGM68V/FJgSw16bw3TfQUqlLGjGWGIz2wGdUB1DnnrO6pzqpnyykjQOro69xRM0nV1uJTiriypKlWquLXt/Wn/QfHOjc8++8x1sr3gg4oCe+sD63zTZ+b/sXcncDbW7//Hr7EvmbFvESpbKWQLFWUrEkn4tpD6SiFbJdKCiqhElorKmjZJm4oQWSpbQlkSiojKGlGc/+P9+f7v8ztzZoaZMWfOzDmv5+MxZc4259znPvf5XPf1+VyXV/ZJz137ngZEKlunJfzqn+Ct0ol2N998s9smmkWphmbqN+HNsNRsMtUe/vDDD93vWm2hfUh9O4IDfI75KS/PoQSaTn4E0uBdP9p/tZ/qGBpcikITBvQZ8EpQRHMPlXDV1vWoAaA+P/oceLcJ/G5TQk8nsQJn2up2gSuXgEhFjBEa0R5fpJVIGRunFnFafMQYaY8YI3JF+tiYOC31SFIgxRJb2aADiAaqqqPpUVJCJ/tURy4xatbZrl27eDNQInlZcEpoGwQeiDds2OBWnXzzzTf+0kU6yeRtW++2SgBlyZLFNT0VJYBU812zkwO3c0avC6sk1oABA9yJTJ3w9BINmumrk6De605qP4n2/edsBH/+tHRf+55KxGhmgpqy64S9NyjQic6vvvrK1X5UHxndV/WK9fnX+6gSW15Zt3Dte8F/03t9ei2ava8AOzY21g2ENVNQr00rJTRDQ5+b/fv3u3J16luhBoda2YP/267z5s1z5Zr0mdXSW31uNbCcMmWKW6nSuXNnt8rCo9mDRYoUSbRhM87M23/1+dKxXTONvM+YJgZoabSSafos6z3R51dNsj0qZ6bjqLeyAul3/FGdcZ3kCzzG6nOgz0vw++vR91+XLl3cSS8vQR8oo8+4BVKCGCO0oj2+SK1IHBufDeK0/0OMERrEGJEtksfGxGlnjyQFUiSpma4arKk2XGBzbA1a1QhMJ/W+/vprd9kHH3zge/HFF11JFc1i1skt/K8kVmIDVNXS08BXS4U1s0klsbwSHZqpo1lMXr1374CozLNm5wT2YvDoNhntBH5S+9QLL7zgGhkrSRE4KH722WddAKVlgJlxYJ+RBe4bml0t+kxrlphH210n9BWcBS7r9+6rpn8KXIMbHgcHxukh+G9qQBP4GrV6QjWX9XnRsSmQSuLoMxf4OnRMS2lvlGihpuGqq6yl2drOOnERFxfna9++ve/xxx93gbwXvCvpo8+3+lggdbz9WOXvNEFAKyqU+NFqIJ0YCTwBpbITKvukGZsa0OtEiRq8Z8Tvg8zsTNtSDVOVUNJqQH2ve7Saq0qVKr6PP/443neaxgVa9eI1BNR3Pu8ZIhkxRtqL5vgirUTa2DiliNMSR4yRfogxMq9oHRsTp50dkhRI1Zfy9OnT3QFi165d7jLNBtEJEjVO827jDdpU69prWKwZnDqh4jVgg8+ddFdd1+DSMRoAK0hQqQ41CNJM5bx58/prmurgp7p7OgkYOMBVkKEEkHcSP/B9yygS+yJ599133XPWiWNRqRI11FUjXa/GvXfSTfuQSooh7d8PnYjXzHc1jFbyUTOzH330Ubf/6HKd4NQMu8D9VTPjlXxs2rSpW84e3FA6vQT2lwh8TQrGtdRepW+0GkL7kDfYefrpp93sN68ev3c/vYbixYu72yLpwNU7rqi8kGbn9+jRwyUhRANLfYZ13FL5P/WiUGMzpC0lfwJnviZG+7kSFDqpopqtCB0ljgL3802bNrlVpdWqVfPNmDHD9esqXbq0O+Gn45A+OzfeeKP7jlcSVJ8rHYf69evnAvPA7z8g0hFjpJ1ojC/SUqSMjVODOC0hYoz0RYwRWaJ5bEyclnIkKRDPmbKQWuarmSLKbKrOuP7vzdpUvXaVTglccqUTzmrC9tFHH7nfdXAKnIkczTXIvW2t2nk///xzvOu0XdRsVgNfjw7YOpBfe+21LovsZZBz5MjhX5GSkRuuqWeJl/kOpIZISnApGaEvJ50w9ppj6ySnXrMasQdSkkwDfv0fZ8/bb5RM1GwvBWFq6qc6uRog6AS/N0vbKwkg+uzr86z6upr9oBPU3ky89DZ//ny35FMrILzPgD5HSogWLVrUBeO6Tq+natWq8RoNax/r2LGjP0Gmxtk6lt11111RfYxK6rVrfwk8xniNmXUiXCvnAptiy/jx491KCiUX1asio812yajOtO9521GBs+pb63PqzeD03p+M+F0QqbRvKymn72TvZJTeI32PqezWoUOH/Al4zRrTSiNvNZFODuo4pGNVixYt3OQOfSd6Ezw8fHaQmRFjpO92jpb4IlQiYWycEsRpSSPGSHvEGNEhksfGxGmhQ5ICfoEDz8APnTfjWDNHVFJCs250vUo4tWnTxpXk0UBYqynUCFt9KXSSTwcMlXvSyT7v5F/g3yLY/h9vOyxcuDDeiVMlgbyDuXfiSTVOtSxbJwG990h181UDPrjxWkYqg6TBumrSa8AeSF9IF198sdtPlBHXfqOZ7vpCUr1blXdSxlz7nZrNebSvaXlgYFCAlAkONFVvWPuWZmSrZq5H+5ouV8meQD/99JMLcr0VCN4gw9v30vvzrbIEmvWnz4P3tzWjTfuPEmGeoUOHutejoNFrjP3mm2+6QY9mvKkkjq7XLI1oTVDodavZY/B7HkzHKw0Y9T2gba4ktLb/rbfeGq/WsniNtJFy+q71VqckZebMmS75pmNptJ1ICofEjm86uadSKCp9qf42OqZ6STyNnzQTVzV2FYCpOa2Wtut70VuRqs/PhAkTfP3793eJPSCSEGOkv2iIL9JapI2Nk4s47fSIMdIOMUbkitaxMXFa2iNJgXiDTSUTunbt6gZYjz32WLyto7qlOshopURgQxhlN3XCWHQQUZObYsWKub4T+fPnd0u4kPgg2NuO+sLWtlXtcG+psA7kOlB7vNvqhL2Wb2uZnDeLNiP39vD2L+81B+5vWpmj2e/6kvJen/YvBVDewF+BlWYpderUKSzPP9IEnnjX5129GLwgSkvVFXRpBl0gfZa1XF3l3DQr77PPPnMDCF3mzaL3pPfJUe1P3t/USgkdf0aMGOE/Mb5mzRr3b31GLrzwQnf9fffd5ytQoIBLTniuueYa99o1M86rwxxttB94sygHDhzoK1SokAu4E6NZhZoVoxUqgXWpFcRfcsklvieffDLdnnekfi+oBJ5KZCmBpgREYK8JT+BxU++Fbue9Zxn1ZEgk8r7XNFtMSXaVI9RnKJBOCmql0aJFi9zvmkWmz5CSo2oamJhoTZQichBjpK9oii/SUqSNjVOCOO3024YYI20QY0SfSBsbE6elH5IU8OvVq5crzaSyTZpNnDt3bl/fvn3912vplU5aeTXglKAQzdzUSWWPMp/vvfeeb9KkSRl6UBbuYM2rrefR9lKW2TtxqpN9OqkamOTRyScd5LNkyeJ77rnnfBld8Pv/zjvv+G655RZ/nX/VH1TZJo+3TylBVq5cOf92Gjx4sGtwrPqESJv3RTMZVJ9eJdu8ZZNajq4GuxpABJZlUzNklT7SoKFu3bruBL9WTGUkSnS98sorLhBXLeXffvst3udGDQu1H3kDHvWbUKCu1yYKyhcsWOCLVn369HEnMrzZf/os6vij74LE6DMcGIQHHstUSuLVV19Nh2cdOQKPld73hEo46XtB5SV04kOlJrxERWIJCJUj0EkmbzUFQkcn7rTayuvvofdPM5L13aXl6+r/oZN93rFVK2G0qvT+++/3B1e6rcZZKqEZWOs6qfcXyMyIMUIr2uKLUIjEsfGZEKclDzHG2SHGiA6RPDYmTktfJCngW7VqlTshrB/vhJ0OFGq4ppNWWobl1YVTY1RvlrJ3oPDqjXulU4JF40xAb9skdTB95plnfFdffbWvQ4cOro574Gxu1dzTjBzNjNWBXoNe9V7QjHAFeXpfNAjWEuyMSgfywIDJa5Sk3iR6PWogpOsVDChQ0vYI3Fc0g1gnkb2SMdoe3rI/nB0FpWqQ2K5dOzcLTIGXBo979+5116v/h5KRXl+QwPd08+bNbmXL77//nq7L/k+X7NTf79mzp3sd6iuhIFsz3gIDRa3w0slblRATNX1U/5Ps2bO7mRqRXLrgTFSyQO+3Vj94TTM9+hwqca0yEMl9LyS4NASSFrjvaRWLkmwqn6XPoVY0eqU4VApPiQqtlvCSucHfLzp+rl+/ns2dDmMmrRbVcUarXBSMee+JAi2t+tN3V/369d13uHedmv+p5rvGWSq/0rJlS3dMCp6dC0QSYoy0Fe3xRahkxrHx2SBOi78tkkKMcXaIMaJHpI6NidPCgyQF3LIqzRhR7fZAGpxp0Or1k1DpFNVx10lAzez03HnnnW4wnJhonw3oJXi8A5wyxloGrBlNEydOdE19VdNdmWVZtmyZW5UyevRoN2jSjB0d1HUblf1QKQ/1ZtBsKJXSCl5OHC5eEiL4PdeXjPYN1Rr0TrZpdrC+oJSg0BeUTrqdd955bpaKRyXHNBsbaUuBqXqAaEVBYM8GlWxTwzyPau9qBr231D2xz3G4+k4EU2CoRJdOsOv5aAWFlpUqyPZmciiRqoSrVnjpRLDKPenzp3Jj3iAp2mh2Sr169dxMFa1ASYpqUuuER2KJB1bKpZ0ff/zRNRbXj06SaJCvbR9Iszg1W1P7McJH+72+0xRUqXycerB44yf1SVJwpu9uTejQDDGVAhGd3FKTVU0IyZMnj79MJhDJiDFCI1rii/SQ2cfGyUGcdmbEGGmHGCP6RPrYmDgtfZGkgKNmNDph5a2k0Ek+nSRR2RQtuVIG9I8//nAlUVRPTjNMdPJZ9dsLFy7s++STT9z9MuLALFwHah2YtaQtcLtoGZzqwHqzbbT6pFKlSq75uLcSRUkfHby9sh56LAUfXqMh7zaabZsRDB8+3O0TXi177/VqWZ/2kzvuuMMtLfeSEPq/khKPPvqoC7K0xFw9JxQMaL+7/vrrXfMkNYJF6iS1ekmlfLRCRQ2eAik4U+kjr5a9Srvp8x8YnIWTAkIlUrWkXgF04KwGzX7TMShw/9Pr0z4V+BlRYkwDJJ2UV6I1MCkWTbxtp+2o93jKlCkJtrXqg+7evds/gz9btmz+waRHS3U120WzMpF8wd+RmqWphu/6rlXyzKPZrLpszpw5/sv0nuj7Q+UlWFkWHl5iTquLVBJE5Qv1va4Aa+jQoe7zpO8xHV/0HqlEl373vt8VuOuzEzjjFoh0xBhpJ5rii7QWaWPj5CJOOz1ijLRDjBGdImlsTJyWMZCkiHBnShp4BxUt9W3WrJk7KaKTeDrAqCSKZpM8//zz7iTVyJEj/fd74YUXXL+KBx98MF59zmiU2GxibXed1NNg1msEJE899ZSvdevW7t86IXXOOee4mUyBM5Z08Fb/BTVqU/Dg0YFdB3DdX7N5VIolI+xbSmwFlxjRl5RmZS1evDjR+2pGsIInr7yMBjXav+655x63BNBbXo2zox4geg+8sll6r1Rv2Ovt4fWX0QlrlfV57bXX/ANMzdjOKH0FtD+olJOCZ/WW0Alcb2a/yjVpaX5gkO19vjQb0Jt1riTGihUr3FLSaKUya9qG3udOsy5vvPFGl4AWlYZQj5gmTZq4mYWebt26uQSPjkc6VumYpVJZmi1DaafkHy8TO0GiHilK6KrsRmAdcO3P3iA+cLXPuHHjXKkyfbYR+vfsdKuF1BxeJTD1vayTWyrVpe+9nDlzujGVVwteJ7qeeOKJTDPjFkguYozQitb4ItQiZWx8JsRpyUOMkTaIMaJDpI6NidMyFpIUUSI5fSG0BFgz3FXSKVipUqXcya2kamxGY9+JYJpRHLh9dOJPZTt0Mt6jZkCXXXaZm/mtmd2BAYYO5N7sbq0y0IlYbzm3N6jWLCkFEd4s54xUF1dfPN5KHAU4SnbpRKey47Nnz3bLz3WCzdtf9IWlpIQXJAjlY1K27ZPy9ttvu7qQ2te0lF/b2ps5pwDrpptuivc4qvuok85aEaOZ8xK474WbEqF6DRrwKAGm8kNKqmr/2rdvn0tG6PgVmDDVwEfJ1YoVK0b9iXTNEtRsSq1GUXLZS9zo+KNjuz6HKpml3kKJnfxWAKf9Sct3dTJdK1FUexQp/7yqbKJOfKjxuFd+QcdOzW5V0iiQ9mkl5XSCJPAY6a1cRPq8ZyohF/jd7n1PaXatJnToO1kntTQDTMGYVhB++eWX7jYqc6gTgl6TQCASEWOEVrTFF6kVbWPjMyFOSx5ijLNDjBE9InVsTJyW8ZCkiHAHDhxw9eFefvll97tOjHgDreCDinpPaFmrSnh4fSi8yzWQ03KtxET7iWXNTFJAoHJFOjEaOLNYJ1TViE3lU0QzmHVCVX0ZAulkq+qcerdL7MCpE1qB70tGCkgVMOnkpRoYa7Cn+oI6kawmc+oNoBJOyphrlrZW34hOvKl8D/XVUyZwQBD4PnifQyV9dMLTa0au90Mz45WA1GqCt956y80M0/91wtSbQa/BguoSq8mZ93ja98I909d7vaqrrDI33klzHacUOKphoY5NCjg1u00DHw2I1HRYZeq0zF3bINyvI1y0ckSfvWHDhrkZ+cErH5Sg0IxMrZYI3LeCt5dWOukzHlz2CQl98MEH/ibtwdtQ9VZ1Ykm1wdUszjshpBloSqgFlrlTAKAl00pUUFYrPFSjXO9L4Am/QPoe04wxbxWMTmB59cqjfWyEyEeMEVrRGF+kVrSNjc+EOC15iDHODjFGdMrsY2PitIyPJEWE08k8NSDWrGMlIHQySkusgnmDLZ2A0iBOJ7S8bKhOBmoGbnBJH/yPlgfXqlXL9VFQ/w6dOA080aQTpTo57w2E1EhIM5J1YlUlPfQFr34gOph7s5O99yMjHMgDBQ/KJ0+e7FZKiAKoiy66yNUgFA36lRzTDC5vhcXDDz/sZnR71LgYyRO4L2iZvmbE60S8GkwFriDQSXntj17ySAGr9k3dXkGLTuKr3JaCWZ381H6nAFgnG6655hp3nMhotN/pdankk0fNsHU80woAJbp0nfatmjVrupPpakBM3X6fa0yvQDywtEMgnSRX+QfNwtQ+EEjl/lRHlJVyKWu8qBMd+g4NPKGk0hLaP1XTWp9LNZFTg1N9PyupphNEKu2kxEXg9p4+fbqbaJAR6rRGE8320kkpzQZbsGBBgtmz3nehgi4dh/UZ8xJTiS2Fz2jf5UBaIMYIrWiKL1IrmsfGiSFOS902I8ZIHWKM6BIJY2PitMyBJEUE8g4Q3qC1T58+/pN5XvOvpO6jmbaaUauGbGqMrZnuqlkeWJ8cCamMkVYLdO3a1TdkyBA3u0kzlHWS9Mcff3QzZ71Z4JrNoxNYKofkDYI1Uyejz8oJTk7oeavsS2Addf2uGriBJZw8CgB0Qk6BQ1Jlw3BmCqJUxkj7m07MK0DVdvXq1qtEjJqVqyakgi3Vtf/uu+8SPM5HH33kZkLo8VQXX5Sg1GqYjMT7XEyYMMGdwNXsciUgVNtSnyMNghRAKuDU4OnZZ59ltn8A9Y1QY2aPSgWpz5C+F3QiQwNJzeJXzwmvjJAGnUoo6ntDPWL02c1Mx6dw8Y5r+gzp2L5kyZJ4gZwu00kT73a6Xgk1lX/ySm7oBJNqiyN9JBY06TOhY6d+9DkIfG+D7+uVBNH7pu9/INIRY6SvaIsvUivaxsZnQpyWPMQYZ4cYIzJF6tiYOC3zIEkRQXRQCD5Y6ICiEx4ajKneqDejPbGDincw0pJhJTRUs3PZsmX+66PxxPKZBvbe9Vo1oLIcqimuZdMa5GomjlagjBgxwp1g1Qm/wCSRZs6q/FZg/dfMsI312jQDWA2LdcJNPQEC672qqau3QkL7n5bUaYaKToKqwXFiZVBwZtrHrrzySlcuxpsRp+BLgZf2La1Y8UrKKIjVe/Thhx/G27e0zD1wFl4gXVeuXLkkm52Hm8rdaIa6XqtmcKikmCiI1GxzBadqjI34PvvsM7fNdPzXTH4tz9XMlksvvdS93/q/6Hh19913u/1JjTNVPiuam4ynVOCxW6seVOZOiQl9bkWzNZXE9XirJRTgabWiNytZvZ/03esti0boBK5YCf7ufeWVV9zx5vHHH0/WY2klkr7rgEhFjJH22zM510dTfJEa0T42TgxxWsoRY6QOMUbkidSxMXFa5kKSIkIEZjvVHE0zabQMS0taxWs2G5jNPN0AWUuhAh87UpYFp1ZwHfdA3nbUAFczl1T2SHQCX6sGVHv8qquu8mXJksV/MiqxA2dG28ZJBTRaWaOfwNsE7kstWrRwJ940w0sn6wYNGuQCCK9pNlJHs+bUeErNjQNpH9MJei/AUi1dBa9aCaVVBx41M9dKhMAmvL/88ou/Fr7q8gYGbhmNkls6eauVEonxmhAjIQ0Q+/Xr574XNHt/y5Yt7nLVEtVMy/nz57ugVgG9ai+PHTuWzZhKWlmm7afPmnqBzJ49213+/vvvu+8CBXSi1SkyYMAAN9PI+33Tpk0kKNKZvrNVykNJpeXLl/sv1+xZJUS3bt2a5Jgpo31vA6FAjBE60RhfpKVoHhsTp6UdYozUI8aITJE6NiZOyxxIUkQY9ZRQiSbNji1VqlS8QauymZp94500Sc4BJFJn3qQkm6xVAF6zZ5W90myaxBrM6rY9evRwg93AMh+a3a1ZUDoBqJ/AmU0ZUfB+oZnqgc31Gjdu7N8eiX05aYa7ZmIrOaFtom2Wkb+sMhOVM9JKFe8kspb4a5/SZ37lypX+smw6DuizXrx4cbfUX+/ZOeecE680l2g/VjJTfQcyA63G0ew4ifZjU1rQSgklJebMmeN+V8NIpJyOgVr5oHrh+t5VvxQd8/WZa926tVshoZmt7dq1c4m2wGOmJg/ouxmhEfjd4/3b2/7qp6Sxknop6T3QCSmVTtHMZNFYSd9lmjmWnO+waCipguhGjJF2ojG+CJVoGxsTp4UGMUbaIsbIuKJtbEyclvlkMUSEefPmWadOnWzbtm02Z84c+/bbb+2ZZ56xVatW2ZNPPulu0759eytevLhNnz7djh49almyZLH58+fbkSNHknzcrFmzWjTT69+5c6ctW7bM7rrrLitUqJC9//778W4TExNjp06dsmzZslmHDh0sR44cNnXqVP/1NWvWtNdff90WLlxof/31l3sPMjLtF/LGG29Y9erVrW3bttayZUv79ddfLTY21r3WrVu32t69e93tlOwUbafDhw+7+1xzzTV28OBBd9sCBQr4HxNnp1q1anbnnXdav379LC4uzm3zN9980x555BEbMmSI1a9f333mb7nlFvvoo4+sS5culjNnTqtSpYrt2LHD+vbtG+890/599dVXW8eOHTPFW1OvXj1799133b+j/dh0tvQd8PHHH1uNGjXcfiXt2rUL99PKFE6ePBnvc6TvgD179rjv3YkTJ9q9997rjvmTJk2yBQsWuM9iiRIl7IEHHrBDhw5ZxYoV3ffJ5Zdfbtu3b3fHV4SGvnt2797tvr+87yG9X6KxUt68eW3RokU2ePBg9//rr7/evU9///23tWrVymrVquWOsevXrz/j3/IeF4g0xBhpLxrji1CJtrExcVpoEGOkHWKMjC3Sx8bEaREg3FkSnH1NWP2u/gCaMaKa/wcOHPAvIdZSLTWY9S579dVX3XJXNcbWMuGqVavSFDtIcHkrZYq9MiheqY7TUVO2+vXr+5uhBmeZ1ZQ23LysdvBz0+X6UcM47R+qxapmuqphr9ekGrfqWaKZR8EzjLS0WrPCgusZImXvy5lmJXz77beuv4BmgwXS8n8tv1SJGS1918ztYDpWZIQZDamlGpiqK5yZX0M4qWa1+neojIH6Dmlf8eo148xO99nU8b5YsWLxevSIjp01a9b09+JRGQmV3VKjdx0zEVrqw1WkSBHfG2+84Va7qKmqV7qjW7duCY6j+oyoH0vv3r3d7/rO03dh//79fX/99RdvFyIaMUZoRUN8EQrRODYmTkt/xBhnhxgj84jUsTFxWuQgSZGJBH7w9u/f79u5c6ersek1fGrfvr1rCBZI9eI0MFMNTq90j5bF3nPPPfHqb8KX4OS6lk1rwD9x4kRf27Zt3QH7vffeO2Pj8c2bN7sl2VqandFK0gTuQ8HPzRsQa59SDwnVafWoJmFcXJy/VJhOsCnZdd1117kTnmropy+rd955J95jIfkC3w8tTfe2YfC21D6pwDZfvny+r776yt8kUJSM1HukE9AK2JJ67zOrSHgN4a4bq+NYvXr1fGPGjAn308k0vOStR98JGtA/9NBD/gbuWh6tk01z5871nxiRefPm+bJnz+4SE95kAclo3w2RJvBY0aZNGxdcqWlq3bp1/T1Z+vTp4/on6b0LvN99993nu+mmm/yBl4IynRzk+INIRowRWpEeX4RKtI2NidMyxrZHyhFjZHyROjYmTos8JCkyMO9gEUyNNkuUKOEOKKoZt2zZMne5mp/qRPLLL7/sv60OHKrBqZMn3qAtGLPe49Og9u6773bN0ryGa3v27HHNolVz3GtGfrqD8rp163wZSfBgXitvNKNIPUuaN2/usude42GtlChXrpz7t1ZS5M+f39eoUSNX19WjrLsG/M2aNXM11Tt37kzj4lQI/uzpferVq5drADh58uQk77djxw733ulkc1LvMZCY77//nmN+Kqm3hGpelylTxtURV01WHQO971YN+PWdHOjpp5/25cmTx50cUf1whJa+l4NP3mklixqoduzYMd7ls2bNcjV3gydsaPWLEvEejq2IRMQY6S8S44tQiMaxMXEaIgExRsYULWNj4rTIQZIig9EHXjM+dFJY2cnAA4oGbVqCpZJOH330kVtJceedd7qTImp8qus1iFPjzsAlv7/99pubefPAAw/E+1sZIfOZ0SjhoxNP2v46cf/NN9/4t5MO1prt9Oyzzyb74JzRtrESC2oup9U1Q4YM8XXp0sW91ty5c7vMuezatctXuHBhX6FChdyXlJYCerRiRytxjh8/7n7X/umt5kHyKJlYrVq1BJdr6aQaU11++eVuRp1mYJ+OjgFFixb1N7IK3teiZZYdEGo61iv5rzKJaoS9atUqd/nSpUtdklerGEWXK6mrAf/HH3/sVlkocaHPswb9CK3AY6BmgD311FOu7OXGjRvdjC81LVcjx0B673TM1coiBTdaCaPvvcQapma073MgpYgxwifS44uzxdj4f4jTAKSlaBgbE6dFHpIUGYhOAGuGumjwGkyzbZSg0Elirz6cTnaWL1/et2DBAneZ6ovrRKeXkPAGuioPhdPXN9Vl2m6dOnVKdFNppcFdd93la9y4sW/9+vXuMm13JYEyOr3/+sLRihqtovBKkXi0EkL11LX0XLTKQsmM4ATEoEGDXDIjI9UfzGx0YvPtt992/w7cB9U/Rssrk/tZ/f3333233nqrm30HIG0kldxTPycti9Z3cCAN4PU9PG3aNPe76orXrl3bzZTVEmp9Z2TE2UaRyptxq22vk4FaSSoaW1WsWNEtVw/8zlZJTPUGUUkuvbdK2D/88MNhfAVAaBBjpI9oiy/SSrSPjYnTAIRKJI2NidOiA0mKDDTDRk2sld306ESyZtcoGSGamamlrlourIGu6m7ee++9Lnnh0WoKlejRyWgdYIIxuzr+NvCSQh6V7tBsWWWNx48f7wbHGuhqebEO8Hqf1LRO75WWyamMh2rEZnTfffed+5LxZvwGL/3Tsn/1ldCqHCUgNIu/bNmy7vaaBaxyJppBrBNvXsM+nFlgoBV8olKBlHrEiD7TKpsVuIwyOZ/X4Ca9ANLmxJJWNumknkezjrp37+5KPXl9KLxG2Erq6uSS93nU94rqXus6pC8ljfT9rMkcej+9VX+i/kkqZej1VgpuIqgEk777PSSXECmIMdJHNMYXqcHYOCHiNAChEgljY+K06JLFkCFUqFDBqlataosXL7YtW7a4y9577z179NFH3f/l8ssvt507d1qePHns4MGDtmDBAhs/frwVK1bMvv/+e5s1a5bFxMRYq1atbNSoUVaqVCkloeL9naxZs1q00zbQdunTp481atTI2rRpY4888oi77uGHH7atW7da2bJl7aOPPrL169e72/fv399mz55tdevWtbFjx1rTpk2tbdu29tdff1n58uUto7vkkkusY8eOtmPHDpsyZUqC/eHCCy+0a6+91nbv3u32q8aNG9vUqVPdvvjYY4/Z7bff7m63YsUKa9++fdheR2aTJcv/DrGbNm1yn02P9htt41tvvdX9/u+//7qfuLg4O3r0qLtM++iZPq+FCxd2/z958mQIXwUQWYK/F0WfT31edcyvV6+eO77r/wMHDnTHwZw5c7rvinLlytlrr73mv5++Z/Wdu2/fPhs+fLi7LF++fO77XNchNO9fYsc8HTtfeukla9KkiV1xxRXudjly5HDHVunatauVKVPGXnnlFVuyZIkbM+k9lUsvvdR9rxcpUsQ9tu4beMwGMjNijPQRjfFFajA2Tog4DcDZiKSxMXEaWEkRZoHZzE8//dQtwfJ6A8gtt9zial57NbDVk6JgwYLxspiahd2jRw93P29mNuJv48DtpdmxKseh+q9aFaASR9qm/fv3d9dr5YpWoShr7JVFKlmypO+FF17wP0bg42WWxuPqNXHzzTf7WrRo4du9e3eC1RRqOKcGStOnT4+3b2k7qIYhUkcrUFq1auWW86tkTLt27dzlmkmn/W758uXu9379+rlZ2sEN7t966y03i0GY2QukXlJ1U73PlZY/q8G1vmf1HaDftcJM5fA8Wv6sOq2qKR44Y1afX69UBUL3ngX221L/Lh1XvcvUp0srBseNG5fk42kW2VVXXeWOtUWKFPENGzbMXc6xFZGIGCP025f4InUYGydEnAYgud89kTg2Jk6Dh5UUGWA2ibKZmuH+xx9/uFURX375pfuRLl26uNntWk1x6tQp69atm1tJoRk6TzzxhE2fPt1q1aplX3zxhZt5kzdv3tNmIaONtoG2sbK+mzdvdpctXbrUChQo4LLFWhVw5ZVXum37zTff2N69e91M2fPPP9/Nas+dO7dNnjzZihcv7razR4/3/8ulWbZs2SwzKFmypLVu3drtZ5MmTXKXadt4s/WPHDliuXLlsuzZs/vvo9+VPdfML6SM9inp27ev27c0S+qhhx6y+vXru8ubN2/uZs7petEsbO1vTz75pM2cOdN27dplH3zwgQ0ZMsStbmFmL5A63nehN3tT35vPP/+8+1ydOHHCPytIn1mtbho3bpz7DtDqCH1PfPrpp/bmm2+627Rr186KFi3qHkMzXb2VE8OGDbObb76ZtyiNee+ZvrfF+37q16+fVatWza6//nq77rrr3PHy3HPPde/n2rVrbf/+/e523qwyXfbPP/+4WWRvvPGG+17/7bff3CxmYdUEIhExRugQX6QOY+OkEacBiMaxMXEaEvCnKxAWylA++uijvixZsrg+E5qhqX4SaqDmZRPV6EZ1Sr3Z1OvWrXM1sBs2bOirVauWm9mJpKnHQseOHV29Pa0gUHMgr5mpZvLExsa6WbB//vmn/z4rV650KyuuuOIKX4ECBdwM+EiglRFdu3Z1dXFVM120kkKXq6mfXq/+jdQLXlkzYcIE13iqVKlS/lUTnvfff9+tppg0aZK/UaKOA16jKu2bw4cP5+0A0oD665QuXdp38cUX+y677DL32bv//vvjfXa1KkKNS1UT/KKLLnIr6K6//np3bFRfClHfp/Lly8dbTYHQ+c9//uNWmWrVqd4f9UqqUaOG76OPPnLfY+rnozGSeoBoJWDhwoX9TQFF75saqSb2PZ5ZVkICqUGMEVrEF8nH2Dh5iNMAROvYmDgNHpIUYbZp0ybf+eef75s5c6b/Mp1EVgPjKVOmuN9//PFHX7169VwJisDGNRrIeOWIhKbYCanZ+NChQ11SZ+PGje6gO3jwYHeCKW/evL42bdq4E1IeJYK0TXVA18mrQYMGxTtQR0JJCJ0IV5JCJcI8jz32mO+SSy7xN8WOhNeZnrS9grfZjBkzfGvWrHENstWIXE3HtS8GNlPUdffcc49rUh74OVYDvblz57oA+ExLIAGc3v79+93gXRMAXnzxRffdqWP8vffe6y7bsmVLvM+ZEoVKZP/666/uMn335syZ0/f000+739UgW4lshJZ3zBsyZIj/GKnvcSVw9X+vfGPlypV9VapU8b8nKmuoyzSRQ99tKuGlpJSXmAeiBTFG6BBfnBlj49QhTgMQTWNj4jQEI0mRToO04ASCd0JTfShKlCjhTmZ6VAtbfQNatmzpT0qMHDnSV6lSJd9LL72U4DGCa6JGo8RO4Oqgq1mzyhwH1uGbPXu2SwzpJFQgrbK49tpr/SfqvV4hkTjbUqt3VHtQK0gqVKjgvqgWLlwY7qeVqWimghKJwZ9trY5QQqJatWq+J5980p+U0EoVJR8VfARatmyZew/69u2b6N+JtH0PSG9K+mnwrkRFoIcfftiXO3fueJ9JJSYCexDpe0BJC32e9RiBK+6QPt544w03sUC9kfRvvQ9ez658+fK5hHvgBA4dc7XK5fbbb3fjKI2fgEhFjBFaxBcpw9g4bRCnAYiWsTFxGoLRkyLEVPNN9dxU91/9DlTfWv/3HD9+3P79919/bTnV6lQtbNWGU58Jrw723XffbTVq1HB17T1enTiv50I0b+PA7eepWrWq3XPPPXbs2LF4l7dq1cquvvpqW758uesDoHp+6gFwzTXXuNtpO4t6hWS2vhPJ1aFDB1dP/cUXX7S77rrLtmzZYg0bNgz308pU3nnnHVcDUp9tr5bihx9+6HpM9OjRw+1f+r/q1cugQYPc53327NnxjgHqdaJeIfq86/pgkbbvAelN35sdO3Z0vZ/0+ZOxY8faCy+84Ho8lSpVyn9bfV/oO0CfZfWSeeyxx1wfn1GjRtnixYtdPyOExsSJE10fEI/GRqJeXXv27LG///7bypcvbz/++KP7fj569KgtWrTIxowZ43onrVy50r1H6u2jerxTp05173efPn3i1eAFIgUxRui3L/FFyjA2ThvEaQCiZWxMnIYEEqQtEBKaJa3615pJrVnrY8aM8V+nWvU9e/b0nThxwn/Z5MmTfXFxcW6Z1qpVq3hXzkDZYW1jzVZ/5ZVXfAcPHvTPilUtcWWVvdIdsn37dldXvFixYq5+n1ZcqBRPNFF/hMDVIkgeb+VE4Eomr4+H+sOo/qO3AmLPnj1uCaP+Ly+//LL7/I8aNcq3Y8cO33XXXefKjXm17gGExq5du9xS57p16/pXj6m04n//+19Xt1UlnbzP4bvvvuv6Q5177rmuL8U333zD2xJiWvmYP39+933srWb0ZjDr+FqoUCHftGnTfAcOHHC9pNRXJNDhw4d9nTt39j3xxBMJVp9RKg+RjhgjdIgvkoexcdojTgOiWzSNjYnTEIgkRRrTicvAD71KQ9xwww2+K6+80pWUUI15HShU/19Ls0RNbNQoVw12dSJdJ0pUK/vuu+/2Pf/88/4T7hnxgJIRTJw40R2k1WdBJZxUPqt3797+pIQSQjq4a/sG07bdvHlzvGbR9PZAUgI/f/qsr1ixwiUltLxdlHwoU6aMK6PVtm1b99lXuTElJ7UcU9TEXaVjNOhQAk1JDA+lnYDQ0QBfCQp9Hwc3atN3skrgvfbaa+4yfVevXbuWtyMd6TtbQVaBAgV8U6dO9ffkUf8QvWePP/64+109vIoXL+7r0KGDm5Tw1ltvucBMzc51TAYiFTFG+iK+SB7GxgAQGtE0NiZOg4ckRYgCB81+UONcXaYZTj/88IO7fN26de6EpWrF1alTx5+AuO+++1xduYoVK7rZ/ZrtqaY3iL+NE2sK2KhRI3+TcenTp49bnTJs2DB/0kG199Qk+/vvv/dfFkyXRXtvDySv+d9vv/3m/q+EoppWqfm1ZttpxYQas9euXdvVk1WTXs3C1kodfcZFsx00M8LbFwGkD31etXpCTeOCG8Xps6vrcuTIQVPsEAieYBH8Xetdr/q5/fv39xUpUsStMPVup/dMKyK99/GLL75wwZlWvCgI84I0IBIRY4R++wYjvkjedmNsDACpw9g4PuI0eEhSpMLpVjPoRLdm3igJoYY0uq3XaPOhhx7yFS1a1JUkevXVV33lypXzDRkyxF2nmfwbN270jR071jd9+vR4j8mJ86RnmB89etT38ccf+wMKlc9RplknLjTD3cscq1GQynbo5AeQEoEJLX15qkyYVkhs2LDBXTZp0iTXKNtbhpmYFi1auBVUwXR8YOUOkH60olGr7rykYeD3i75PaIwdWokd7xIbUw0fPtwld3Ws1WwxjY20CiZ4PKT3y5tVltTjA5kJMUb6Ir5IHcbGAJA2GBv/H+I0SIz+k7BTBRKjTRXYoHr37t2uIY3X2FZNrl999VU777zz7MYbb3TNaTxffvmla1Dz5JNP2rXXXmu///67a+yspp1qXnPxxRcn+HtqZKOmvNG8jQOdOHHCbb9zzjnHzj33XLv11lv9123cuNFuv/12q1y5smsUtHbtWtcg+84777TnnnvO3UZNtNUcu127dun2ehA5evXq5T6Taqarz/6DDz5oPXv2dNdpv1KD7GeeecYqVKjg9uPt27e75uTDhg2zr776yjUTvOyyy8L9MoCop2bYCxcudJ/hG264wU6dOuVvjorQ0LFQY6KGDRva448/bp999pn73tZxNZD3XuhYu2bNGmvbtq1deOGFFhcX5x7jpZdesrJlyyYYM3gNbpMaPwAZHTFG+m7fQMQXqcfYGABSh7Fx4ojTQFSeisHtu+++a02aNHEDs4EDB9rOnTvd5TVr1rT58+fb+++/706WiwJn0UnzX3/91erXr+9+/+677+yCCy6w2NhY+/TTTxP8LYm2BIUEBxA6YSEffPCBS0zMmzfPtmzZYn379nU/W7duddd/9NFHLsgYNWqUO5mRN29ey5Ejh82aNcslj2T8+PEkKJBiBw8etOuuu86++OILl2Ds0KGD27dmzJhhy5Ytc7cZPHiwrVq1yp1402d+6dKlNnz4cHf7AwcO2KJFi0hQABmEPsP//POP+17xTm4jdDSm0XeyEg7PPvus1atXz1q2bOnGP8G890JjAY2ppk2b5pIU7733ns2dO9dy5syZ6JhB4yUSFMisiDFCj/gibTE2BoDUY2ycNOI0/G8JAJI1uP3pp5+sc+fOtmnTJnvggQfcjGmtpChVqpQ70CiQ7tevn40dO9atlFASwks0FCxY0IoVK2YPP/ywXXnllS5Qb9OmjXXs2NFKliyZ4G9Fqw0bNtjkyZOtU6dOVqVKFXfCQomKl19+2a1E0faTokWL2ujRo61SpUpuO+/du9dt3/3797tt/fHHH7sZsppxefnll7v76LFON5MK0e3/l79LsJ/os7x+/XqX5PJWR9WtW9e6dOniTnJqdYQ+002bNrW33nrLrrjiCrfPaXZE165drXr16lG7MgrIiC666CK3wq527dp8JtOBt9Jh8+bN7ri4b98+O3r0qH8VamK8ZIWOrTqmSqFChaxEiRLp8ZSBdEWMEXrEF6nD2BgA0h5j46QRp4GeFMl0+PBhX6tWrXwdOnRI0NBaday//vprfy3ZuLg413dCl3t+//13V2NZTbPLlCnj70WRnBq0kSqx16z+Eurb8fzzz/uvX7p0qa9q1aquXt9PP/3kalRrG6vGv5oVy6xZs3yXXHKJr3Llyu622sbBjVGB5NSCPH78eIJ9snjx4q7niXg10e+9917X7N7riaK66bly5XKf7cDH0+2pkw4gWr/fp0yZ4qtRo4bv/vvv9w0bNswXExPjb05+prGPd+ykNxciGTFG2iK+SBuMjQEg7TA2BpKHJEUyqZm1mmEvXrw4XrD89NNP+woXLuxr3Lixb926de4yNXjMmzevO7kebPfu3a5JdjQnJxITuE3vuusuX8OGDX1ffvml+33NmjW+bNmy+Xr06OGSE+3atfNt3brVf/sdO3a4/3/zzTe+QYMGuZMggdjGSK7HHnvM16RJE1+XLl18M2fO9CctcufO7Xv55ZfjNVlcu3at2y+1v/7666/usnnz5iXZhBEAoomOkfoeb968uW/ChAnuhNfff//ta9Giha9WrVqpGieQrEAkIsYIHeKLs8fYGADSBmNj4MxIUiRTz549fRdddFG8yzSTWjP2+/bt62YJBp4cv/jii33t27d3KygkOLBWsB7twfabb77pO++883xTp0717dy503/5xo0b3bZ+6KGHfAcOHPCdOHHC16hRI5f48RJBnjfeeMNtd90uGCeLkVy7du1yJ82qVKnie/bZZ30NGjTwFSpUyPfMM8+467UyqkSJEr69e/f676OkRaVKlXz16tVz+3IgEmMAoklix7ySJUv6smbN6rvzzjvjXb58+XJfzpw5fdOmTUvHZwhkXMQYaYv4Im0wNgaA1GNsDKQO3SKTaceOHZYrVy7X/Nrz1FNP2Q8//OBqW6vuvJrjLliwwF33wgsv2Ntvv20rVqxwvwf3QaDJo9mcOXPsl19+saefftrV+l+3bp0dO3bMKlas6Pp1qAnxkiVLLHv27Na+fXtXw1qNsnfv3u2anr7xxhv25JNPuvvovQmkBNzp6l0jeniN6JP6XbSfaZ9SA/b777/fPvnkExswYIA9/vjjbp/T/3Pnzu0av+rzriaur7/+ujsGHDp0yO27gY9NI14A0UC9JpI65mkMpJ5S+fLli3d5jRo1rFu3bvbggw/anj177MCBA/b888/b999/n27PG8hIiDHSFvHFmTE2BoDQYGwMnKVUJjeijko4aebfwoUL42VHvXqdq1atcnXr+/fv769p/+6774bt+WbUDHLg6hH1l1CprO7du/tat27tVk/85z//cdtUqycuv/xyX6dOnXx79uxxt+/Xr5+vWLFivooVK/rq1q3ri42Nde8LcCYqMbJgwYIkr3/00Uddf4ng+6i/ifZB2bBhg5sRrL4nWlWh+4hKvV133XW8CQCi1owZM9yx8uGHH3bHSm8cpFJPOo5u37493u21Kq1ChQquT5d6+ajMnrfyFIg2xBgpR3xx9hgbA0DoMDYGUockRTKp5rxKO7Vt29Ytfw2mJIVOnKsmfbBoL+skSTWxfuSRR3znn3++b9u2bb7PPvvMlX+qXbu277333nPNNmvWrOlqWXvUoFy9Al555RWXyPBQXgdJUdkvlWbTybAffvgh0f1Fjdovu+wyVycy8PqhQ4e6y70G7bJv3z4X2MnmzZtdcu2dd97hDQAQdVRq8YYbbnATDu677z7fBRdc4KtWrZpvyJAh7nolJ7JkyeJ74YUX/N/Z3pjo559/9r366qvxJn8A0YgYI/WIL1KHsTEAhAZjY+DsUO4pmUqUKOFKvrz77rs2ePBgV55A5Yf2799vr776qitHdOmll1rNmjUT3De41FM0+fvvv61atWpuGwUuL/b+/9BDD9nx48ddCZ2mTZvaF198YTfccIPdcccd9vnnn9u+fftcCa01a9a429euXdtuuukmu+uuu1wZqH///dddTnkdJEVlv1q0aGGFChWy1157Ld7+4u2HVatWdeWcZs2aFe/69evX23nnnefKlahsiai02OrVq91xoGHDhnbBBRe4/wNAJEuqVJ5K4n355ZeuzOWqVatc+cYJEya4cpdlypSx7t272zPPPGM//vijf0ykxypdurTdeeed/uOntzweiDbEGClHfHF2GBsDwNljbAykPZIUKdC5c2fr16+fq0dfrFgxu/LKK92JdZ1oV23ll156yfLnz2/RKrGD9ObNm+23336zHj16+C/TiQgvcXPOOee4uv4vv/yyO/Fbrlw5GzhwoE2bNs1y5sxpP//8s7311lvuusT+Hn0nkBxKUtSqVcuWLl1q8+fPd5cp6eDth1dffbXVq1fPZs6caYMGDXIn03S7b7/91n8CzUtcaP9VDwrVPNaJtw8++MAKFy7MGwEgInnJg8AJF17SVt/xOllYtmxZ93tcXJzdeuutdskll7jjoyh5oUkdI0eOtL/++ivBY3ljB/XqAqIVMUbSiC9Cg7ExAKQOY2MgdGK0nCKEjx9xtLl27drlGuzq4JQjRw7r0qVLvMA9mmf1a1XE8uXL/Sd2lXxQwkErJAITCkeOHLEnnnjC+vfvbwUKFLArrrjCndzQTHYlJzxjxoxxM9z/+9//huX1IHIo4aD9rWjRom5FhfZH70SbPrNKpmn/U9JRs3/VyPK+++5zSbRgOtGWN2/eMLwKAEgfweOZzz77zCVo69ata/Xr13eXDRkyxD799FObOnWqXXjhhf7bPvzww7Z27Vr3/V+wYEEbP368u50mHeg7HUBCxBhJI74IDcbGAJB8jI2B0CNJkYoAIrHyTSo7FO2z+rUNevbs6Warv/7661alShWXfKhTp44r5+TR7MqhQ4dajRo1bMqUKXbuuef6Extvvvmm3XjjjYlu52hPAOHsaSbv22+/bd26dbOOHTvG28/27t3rEg/ajzds2GCVKlVyJ9eEfQ9AtPrnn3/c8VKrx5TA1USNJk2a2BtvvOFWnem7fNSoUe423jjo3nvvtZUrV9rXX3/N9zaQTMQYiSO+CC3GxgCQMoyNgdDhjG8KJZagoOxQ/PqmWhkxY8YM27lzp5t12bZtW/+2Ut3qTz75xCZOnOh6TihBIZqZ2bp1a3diQ7PUg7eztjEJCpytDh06uB4TSlRo5YT2s4MHD7oATeWgtF9qRY9KPylBodVS7HsAopV676gfl3r6KCGh73CtJP3www/tscces/Lly7u+EpqIoD4U6telJK9m57Zr1y7B9zZ9J4CkEWMkjvgitBgbA0DyMTYGQouVFEhzKpejExQlS5a03bt3uzIQKrHjOXHihCuTFUwnjTXzUokOIFSUQBs3bpy1bNnSLr/8clfSSb1PtLpHDV4BINooeaCEQuBJ0t9//9369u1r06dPt06dOrkyeV7SdsSIEa4co3r3KPE7YMAAmzx5sl1wwQW2ceNGa968ubu9+k4BQFogvggdxsYAEB9jYyA8SFIgzanJtepRz5071/1eoUIFu+yyy+y6665zs9VVRgcIZ13jXr162aRJk9xSTZV+Gjt2rP96SjsBiNYSM0rYFi9e3D+RQCsn7rjjDmvcuLHrMaUm2bly5XLXFS5c2K2mUJlHTT7YsmWLbdq0ySUqqlatmuCxAeBsEF+EDmNjAPg/jI2B8CFJgZBQfWqV1Ln44otd7WrNqFy1apU7wVG6dGlXw7pRo0bu5AeQ3hYsWOCSaEpQaBaw0FcGQDQJTMhq1aPKNqnZtY6JKr+oWcuaRaZVZvrZvn27S2B4JZtUFk8NtFUuL7HHFso0AkhLxBehw9gYQLRjbAyEHz0pEBI333yzlSpVyvbs2eOSFJ9++qkrAfHxxx+7xMQff/zhn2kJpLdrrrnGnn76aXcyzus7Ee2N7wFEFy+BoB4SL730kuvDo74S+s4eMmSI60Wh2bVqiK0VkUpiqARU1qxZ3X1+/fVXa9asWYLH9UpCkaAAkNaIL0KHsTGAaMfYGAg/VlIgpPVNVUZHtf9Vr1oo/YCMhNJOAKL5mDdw4EAbNmyY68/zxhtvWJkyZdzlSuLOnDnTHnnkEbeqQv0m7r33XtdAu23bti6Zcf3119N3AkC6I74ILcbGAKIJY2MgY2ElBULmpptusksvvdQFE2qkLapNrUSFeCUjgHBhpi+AaDvmfffdd650k9x6661uVaNWTKiUk/f93Lt3b3fbzz//3P3eoEEDa9eunVtxpibaKguiko40xgaQ3ogvQouxMYBowtgYyFhIUiBkcubM6QIJ/ZQrV85/uddEUyUjAABAaCQ2GUAlmh544AH7559/rHLlyq4E47p162zHjh3u+1n9edQc+9prr3XJCNF3uJIUx44dszVr1riVF2qWzWQDAOmN+AIAkFqMjYGMjXJPAAAAmVhySil6t/nggw+sffv29tFHH1mjRo1s3759LnGhHj2zZs3yz6K96667bP/+/a4MlE4K6t/qVfHuu+/ajz/+aDly5EinVwcAAAAkH2NjIHNiJQXSrdYfAABI++9XL0GxdOlS++KLL+zIkSPudzW4vvLKK2337t3+29xwww3ussGDB9vBgwetSJEirkm2khZqSqsSjc8++6y99dZbLnmhBIUUKFDAXf/333/b66+/ztsIIOyILwAAiX03MDYGMieSFEifHS2gUScAAEi779e1a9faVVdd5Uo3aaXDli1b3HXqM7Fy5UobN25cvPuMHj3aJTR0W2ncuLG773vvvef6VWi1xbRp06xr167ueq9XRY0aNWzFihXWuXNn3j4AYUd8AQBI7LuBsTGQOXHmGAAAIJPxEgdjx461Jk2a2KWXXmoffvih9ezZ06pXr+6uK1SokI0ZM8ZGjhxp69ev988uUy8KNcDWign1osibN69LSOTOndslNhYvXmw33nij+xuBs9G0qqJMmTJhfNUAAABAQoyNgcyPJAUAAEAmo8TB4cOHbebMmfbII4+4ZEWlSpWsfPny8W6n3hK6XP0k1BTbm3lcrFgx27hxo7344osuEXHZZZdZt27d3GMdP37cf39mKgMAACCjY2wMZH4kKQAAADKhr776yq2QaNCggf+yn376yX744QdXlum3335zAduIESNcMmP27Nmup4ScPHnSbrvtNnf/f/75x7JmzeqSFEePHnWrMeRMzbgBAACAjIKxMZC5xfi8NVEAAADINI4dO+YaX7dt29aaN2/uekns2rXL9u7d61ZJ1K5d215++WVXCuqee+5xzbDr16/vbhMXF2dz5syxPHny+B9PQ0I1zs6XL59rsA0AAABkFoyNgcyNJAUAAEAm9fbbb9v48eNt9erVbkVF06ZNrWLFiu66wYMHu34Tc+fOdQmIqVOn2pdffmlly5Z1ZZ08KgOVLVu2ML4KAAAA4OwxNgYyL5IUAAAAmdihQ4dcuSYlJAITDt27d7eVK1e6htpFixZ1l6n/hNdnQiWfdD8AAAAgUjA2BjInps0BAABkYrGxsf5/ewmKI0eOuP4UjRs39icoRAkKr9InCQoAAABEGsbGQOZE42wAAIAIcPjwYdu3b5/Nnz/fmjVr5hpnt2vXLsHt1BCbptgAAACIZIyNgcyFlRQAAACZ3IEDB6x9+/bu3999953796hRo8L9tAAAAIB0x9gYyHzoSQEAABAB1CBbJZ5uuOEGK1mypLuMvhMAAACIRoyNgcyFJAUAAECEUXJC/Sco6wQAAIBox9gYyPhIUgAAAEQQNcYmOQEAAAAwNgYyC5IUAAAAAAAAAAAgLLKE588CAAAAAAAAAIBoR5ICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAGR6kydPtpiYGP9PtmzZrFSpUta5c2fbtWtXuj+fO+64w8qWLZui+2zfvt09d72WcPn000+tRYsWVqRIEcuZM6eVLl3aOnXqZN9//72F25gxY+zCCy+0HDlyuO104MCBRLfz0KFDbfbs2Qnur9cwaNAgt53T4v1KK/rb55xzTkg+D4m9VgAAAKRPPFKiRAnr0KGDbdmyJUNsco13NfZMbfzxyy+/WI8ePeyCCy6wXLlyWYECBaxhw4b2+uuvm8/ns3Bas2aNNWjQwOLi4txrGjVqlH3xxRfu3/q/Z86cOS4mSExScURij5NevL89c+bMNH1cPWZS2wEAwoUkBYCIMWnSJFu+fLnNmzfPunTpYm+88YZdeeWV9tdff6Xr83j00UftvffeS9F9FMTouStJEA79+vWz6667zk6dOmXjx4932/Dxxx+3FStW2GWXXWazZs2ycPn222+tZ8+edvXVV9uCBQvcdsqXL1+i2/l0SYrBgwcneuI+Ne8XAAAAkFQ88vnnn7sT+h988IFdccUVtn///ky9sZYuXWqXXnqpvf/++9arVy83uUnJjXPPPdduu+02+89//uPiiHC58847bffu3fbmm2+67a/kkGIY/Vv/D0xSKCZITFJxRGKPAwBIe9lC8JgAEBZVqlSxmjVrun/rhPbJkyftiSeecIPNW2+9NdH7HD161PLkyZOmz0Ozi1JKKxcuv/xyCwclc5555hm79957XYLCc9VVV7mAQ7OSbr/9dqtWrZqdf/756fa8vPdmw4YN7nclnmrXrn1W2zkxafU4AAAAiG6B8YhWGSge0cQfxSNa5Z0ZaQVzmzZt3CqFr7/+2ooVK+a/rlWrVi550b9/fxcr6P/pRdv233//dXHU+vXrXaygSVeB0iK+io2NDVucBgDRhJUUACKWN5jcsWNHvNI669ats6ZNm7rZ+I0aNXLXnThxwp588kmrVKmSG+iq5JECiX379iV43BkzZljdunXdY+lHA/JXX331tOWD3nnnHatTp44b3OvEu072a8bPmZZbL1myxD1HPVfdr169evbxxx8nurx84cKFLtFQuHBhK1SokAsmfv311zNup6eeesot13722WcTXJc3b15XakkJg+eff95dpuXT+ns//vhjgts/9NBDriTT77//7r9MM8n0GjTA12uoX7++zZ8/P979tNxYj7l69Wpr27atez5KHii40+ws0fbTbbxl6sHbWddp1cyUKVP8S+11f22fm2++2Z+88q7ztnVi75eu1+y3adOmWeXKld3zrlq1qn300UcJXrNmlCk4036j93X06NH+15Maei7XX3+9m6GmGVu5c+d2++Vrr72W4LZfffWV255acl+yZEkbMGCA/fPPP4k+7ltvveX2W72n2m+bNWvmlsYH7mvZs2e3Bx54INH9K3AfBwAAwJl5CYvffvst3uUrV660G264wQoWLOjGcdWrV7e33347wf1Vuvbuu+92ZVg1xtZ4T2Nl7/H+/vtvu//++108ojhDj6fxnsanaeWVV16xvXv32tNPPx0vQRG4IltjVU160jhU8ZOeq1YrB9u4caMbV77wwgv+y/bs2WNdu3Z15Xp1v3LlyrnVDkpABMdKI0aMcDGbbqOxt1au6HLd9sUXX/SP8xMr06Qx/7hx49y/A0tzeY+dWByR2ON4j6XxtOKh5s2bu3/rPdJ7cfz48XiveefOne49UzyXP39+N3lOq9VTW+rXizM0kUsTyvS+631RbHnw4MF4tz106JBL3ig21HO89tprbfPmzYk+rsqS3XLLLVa0aFG3bRUDedvL29e0n6oEb+Df0ftXvHhxf1IOAFKLJAWAiOWdRFfCwaNkhAKCa665xg3eNQDW0mTNAtLAWwMzJQH0b5U80mDr2LFj/vs/9thjbmCpAEGDSpUJUt8GLxGSGC0Pbt++vTuBrSXIenw9TuDAOzGLFi1yz1ODQJ0g1ooHDW5btmzpTjgH++9//+tOMiuJogG8BtLeCf6kaFm0BrhK2iS1okSBjgar2h6ix1QAETyo1qB0+vTp7vkpUSL6XY+tBIUG/Qq+FDzpBHlwokKUWNHAV0mdl156ya3seOSRR+Itn08s4BFdpxP6ChT0b/3o/iqhpeXbooG2d92ZSmvpfRo7dqwNGTLE3n33Xfe8b7zxRvvpp5/8t1EiQc9ZA3+9J9ruep/0Ws/G2rVrXZDTp08ffxLkrrvussWLF8crYaXkj2a36b3Q9lLSQYFbML1+BTEXXXSRew+UfDl8+LArh+b1HFEpAt33ueeec6UJRPtG9+7d3Xuuvw8AAIDk27Ztm/t/hQoV/JdpYpEmmWgMp/GbxnpKMiheCBxfK0FRq1YtF2/07dvXPvnkEzdZSCelvfJROiH+559/ukkmWq2hcajGdBqfTp06NU3eKsUAWbNmdWP8xOiEueIrPY9Vq1a52EsTbjQeDi4BpfG84ghvlbtOcGul9GeffebiI71GjTmHDRvmTq4HU3JD5V81uUq3rVGjhhvXixIB3jg/MYohdBvxbqcfr+xuYnHE6Sgho9et8bjeQyUJNKlr+PDh/tso8aFJUnrPdbnG4Uoo6L0+WzfddJPbrxSnaAWLYkDFDh71CWndurUb9yuu0H6kSXzBq01E8YD2Na1IUSygiVmKlVRy1yuPpWSanr8SVt5kO72/ei/1t7TvaT8BgFTzAUAmN2nSJHVq83311Ve+f/75x3f48GHfRx995CtSpIgvX758vj179rjbderUyd3utddei3f/N954w13+7rvvxrt8xYoV7vLx48e733/66Sdf1qxZfbfeeutpn4/+TpkyZfy/P/vss+5xDhw4kOR9tm3b5m6j1+K5/PLLfUWLFnWvx/Pvv//6qlSp4itVqpTv1KlT8V5/t27d4j3miBEj3OW7d+9O8u9qm+k2/fv3P+1rqlOnji937tz+39u0aeOew8mTJ/2XzZkzxz3Whx9+6H7/66+/fAULFvS1bNky3mPpPlWrVvXVrl3bf9njjz/u7vvYY48l+Nve69P7cbrtLHnz5nWXB3vnnXfcYyxcuDDBdYk9jm5brFgx36FDh/yXaT/KkiWLb9iwYf7LatWq5StdurTv+PHj/sv0fhUqVMg9xpnob+s5B9JzyZUrl2/Hjh3+y44dO+a2ZdeuXf2XtW/f3r0n3v7t7R+VKlVyf1v7lPz888++bNmy+e677754f0fPs3jx4r527dr5L9M+1bx5c1/+/Pl969ev91100UXu8Y4cOXLG1wIAABCtEotHPv30UzfWuuqqq9xlHo2tqlevHu8yuf76630lSpTwj6/vvPNOX/bs2X3ff/99sp+HxoJ63Lvuusv9jeAxZuA4ObH4IzF6vnodp/Piiy+6x3rrrbfc7x988IH7fe7cufGeW8mSJX033XST/zKNbc8555x4497A+GnDhg3xnusFF1zgO3HiRIK/r+u6d+8e7zKN+4PH/7pNUmP0pOKIxB7HiyvffvvteLfVOLpixYr+38eNG+du98knn8S7nV53cra997cVywTHTYr1AikWVAzhxYj6m7rd6NGj493uqaeecpfrcTzNmjVzsd3Bgwfj3bZHjx7uMf/880//ZXqPdf9Ro0a52E3xUeD7DACpxUoKABFDM0O0kkCrDTR7R8tONcMmeFmyZp0E0kwRLb3V7CCtbvB+NKNJj+Et7dUsIq0W0MzylNCsFGnXrp2bfaJZUWeiWTeq+arZPlqa69HsFPWH0LLhTZs2xbuPZvIE0ux7Od0qj+TS2D+wfJFKYek5qJRT4MwobS9vds6yZcvcjCqtNAncrppxo6XGWuYc3NQ8+L0JJ8160r7k0X6kFSXe9tRz11J9zVDSjDCP3q+kZpoll/a98847z/+7Zi5pplTge6kZWZq5Fbh/a/8InpmlmWna7h07doz3Pugx1W8kcOm63mPNutPrVnkCzf7TPqsSUQAAAEh+PKLxrkqYapZ9tmzZ/Cu9VfLIW0kQODbTLH6tcvbG+IpjNB5V2Z3T0QpkrczQGFR/R39fq7B/+OGHdHu7/pcn+N9YUhQPKC5QfBA4JlUp2sCSt4rD9Bq1Sj1wW3jxhFaWB8c7en0ZgV5r8Jhf8VfgeF3P39sXAmmF89lKLPZTSSatdPBiBQnuzajKAYF0H61w14pxrawP3id1vUrMehTTqsTwgw8+6FZhP/zww9akSZOzfj0AQJICQMTQyVWd+FbJGw2Av/vuOzdgD6SBl0oPBVJNVy231olmDXoDf7QE2euv4PWnUL3UlFADai2/9k4U6/5qqqclsUnREm4N9rX8OJgG8fLHH3/Eu1wlhwKplqgElqsK5p0I95aiJ0WDbdVZ9Shw0HPzAg89X5UI0uvzlvl6tXKVaAnerlrurNenJEagxF5vuARvT2+betvTe48Sq82b2GVp+be991/BX7Dgy7z3Qcmy4PdBJaoC+4d4f1tBjwISBVSXXHLJWb0WAACAaItHVJJIfRaUKAg8Ie2Ny1SeKXhc1q1bN3ddYOxxprhj1qxZ7qTxueee68qsqkyR/r4SARrLpQXFC3ouwZOLAqmvg3jxgpIlmlilEkOKs0SlrDTWV9nXwO3x4YcfJtgWF198sbs+eJyakWIFxZWa9BM8Xg/c7hqvhyJWSE7sp7+t9yH4dsGxgm6nOFV9CIPfByUpEnsftH+p3JUeXyWhACAt/C+dDwARQLOMvOZ0SUmsmbHXaFr9BRLjzab3eltoBUHgCfvkUM8L/ahurGaiqM6qZrGoSbJ6PgTTrKssWbK42VTBvGbYXt+Hs6GBvoKAuXPnuubYifWlULCjAMJrPh24okN1YRV4qAaqXptWWHi856cBr9fE/EwD9NQ2mw4HvUd6vsGNEEXJrVDTPpvY3wm+zHsfZs6caWXKlDnj42rFkBoPqj6wAkvVuc1IK1wAAAAyQzyiFQJaha3G0xqHaeKONy4bMGCA6xuRmIoVK/pjD8Udp6PEhJpIa+JJ4Dg6uHnz2dAsecUKSiZ06NAhwfWatKPJSurfph4RHsUFaqatnnxa6avb9O7dO17fAm0PrQB46qmnEv3b3uSszBgreOP1b775JmyxgpIPSkIEJiqC/7ZiGi+2S6pigPYxj5JVuq1WeSsOUl/EtGzUDiB6sZICQNRTaSgN3hREKKgI/vECBTWA1gBOJ3BTSzNcVGLHa6imVR+JUXmdOnXquNlRgbPnVSpJwYhmVQU24DsbAwcOdKsCNKMrmAahmh2j5EVgIzYv8NBMIa0I0cwoJVsqVarkv16rWFRGS43YEtuu+gksk5QWglcbBF5+plUlKaX3SK9Bq2TUkN1z5MgRt3Q91BT4aml2YJJE+3BwU3XNVtMsp61btyb5PniUFFOTbO2jKtelFRVqXnimlTYAAABIaMSIEe4ksJpCaxyvuKJ8+fK2du3aJMdl3gQprVxWyZ7gEq/BJ+01ng48ea+T0Gl50lgnoVXyVIkVr5RQ8GtUCat+/frFK8WkhI3iGa28TmxCkxeHqVnzBRdckOi2CE5SnK3TxQRJxRFnQ2Pqw4cPu9JdgZS4SY9YQV5//fV4l+u9CKQ4T7dVXKqEUWLvQ2CS45577rGff/7ZxakqK6bkkxqGA8DZYiUFgKinGUEavGk5a69evdwMcg2wNXNJgYFWQKhGp1Y9qObmE0884QawWrodFxfnTsJrCezgwYMT3ZYKSvRY6h+g5IJWHowePdr9DQ1ck6LVFpq5pEGjEggKQMaPH+8G8koMpNVMIr2O1atX27PPPuuWamv5rlY4KCDSgFMntzWYPf/88+PdTwkJJSb0PH/55RebMGFCvOtVF1erKNSTQmWdNHtMAY6Wiysw0//PJuGTGJUmUo8FzfTSKhEFeQoGVV5L9Bx1mZZma0ZQYmWVUmLIkCHWokULlwjQvqMkgWaM6bUHl7JKa4888ogLCq655hq3jynAGDduXIKl+Npv9TyVjPrpp5/89ZGV3NDMLiVbtO/quWtf0H6l91sJOSWf1B9Ds9+WLFmS5kklAACASKYxl07u6wS+xleaDPLyyy+7BITGj3fccYcr1aRxo0pDaUyuHhOi8ZtObqt0rGIQjXMVR2j1d9++fd1YXCf5dbJYpaI01taYXLGKxsFbtmxJk9egSUf6G/pbWimhXgRVq1a1Q4cOuckxiqM0VtTlwRRXqOyVVoLXq1fPP/nLo9eoVby6ThOjdL0mQSkmmTNnjr300kspLrV7Ol4ZU00Y03ug8a5OzGuMm1QccTYUByme0vuu/g0XXnihe0/Vn0O0cj5UNMFO+472PcUHSjYsXbrUpk2bluC2ik2vuOIKu/LKK12/CcUPSq6oh4q2h8qXiVYFacKcEk9aja+fHj162EMPPeQmqCmOBoBUS3XLbQDIICZNmqRObb4VK1ac9nadOnXy5c2bN9Hr/vnnH9+zzz7rq1q1qi9Xrly+c845x1epUiVf165dfVu2bIl326lTp/pq1arlv1316tXdcwj8O2XKlPH//tFHH/muu+4637nnnuvLkSOHr2jRor7mzZv7vvzyS/9ttm3b5l5D4OOIbnPNNde45507d27f5Zdf7vvwww+T9foXLlzoLtf/k2POnDnueRUqVMiXPXt293xvv/1234YNG5K8z4QJE9zf0HM7ePBgordZtGiRr0WLFr6CBQv6H1e/v/POO/7bPP744+5x9u3bl+D+Sb2+4O0s3377ra9+/fq+PHnyuPs0aNDAf92oUaN85cqV82XNmjXetk7scXR99+7dEzwX3U63D/Tee+/5LrnkEvfennfeeb6nn37a17NnT1+BAgWS3G6n2yf1N7R9gum1BL4eWbp0qdsncubM6StevLjvwQcf9L8n2qcCzZ4923f11Vf7YmNj3e31d9q2bev7/PPP3fUDBw70ZcmSxTd//vx491u2bJkvW7Zsvl69ep3x9QAAAESj08Ujx44dc2PE8uXL+/7991932dq1a33t2rVzcYHGxxrHacz/0ksvxbvvL7/84rvzzjvd9bpdyZIl3f1+++03/2009ixbtqwb31WuXNk3ceJE/9j6dOPYpOKPpPz8889ufHz++ee7cW9cXJzvqquu8k2fPt136tSpRO+j+EBxgv6OnldiNP7X2FnjdL1GxQw1atRwY9MjR47Ee67PPPNMoo+R2Ng9sVjo+PHjvv/+97++IkWK+GJiYuKNmZOKIxJ7nKTiysS2u7ZbmzZtXNyYL18+30033eTiLt3u/fffT3J7B/7t5MRN3j4YGAMcOHDA7T/58+d3r6tJkya+jRs3utvpcQLpfrqtYjW9D9pG9erV8z355JPu+u+++869l8Gx0N9//+3eL+2D+/fvP+3rAYDTidF/Up/iAAAAgdRETqsPNCtO9XsBAAAAwDN06FC3Klplk9JypQgAZGaUewIA4CyoZ4PKcmlZuGoAa1m6lutr2TQAAACA6DV27Fj3f5Xn0mQmlU564YUXXAkoEhQA8H9IUgAAcBZUr1U9Q9RjQ31GLrvsMldDt3HjxmxXAAAAIIqpb5z6UqjPhpqHn3feea6Hg1ZSAAD+T+i69CTD4sWLrWXLllayZEnXqHP27NnxrlclqkGDBrnrc+fObQ0bNrQNGzbEu40O8vfdd58VLlzYNf+84YYbXINaAADSw9tvv+2+d/R9dOTIEffdpubUAIDwIMYAAGQUah6+bt06N7HpxIkTrhm1GoarWTcAIIMkKf766y+rWrWqf/lbsBEjRtjIkSPd9StWrLDixYu7kho6uHt69+5t7733nr355pu2ZMkSd4Lo+uuvt5MnT6bjKwEAAACQERBjAAAAAJlLhmmcrZUUSja0bt3a/a6npRUUSkJoKZxolmqxYsVs+PDh1rVrVzt48KAVKVLEpk2bZu3bt3e3+fXXX6106dKu1EazZs3C+poAAAAAhA8xBgAAAJDxhXUlxels27bNNSBt2rSp/7KcOXNagwYNbNmyZe73VatWucZDgbdRYqNKlSr+2wAAAAAAMQYAAACQMWXYxtlKUIhWTgTS7zt27PDfRnX8ChQokOA23v0ToxUZ+vGcOnXK/vzzTytUqJCbbQUAAABEAq1OVqlUTeTJkiXDzk/K9DEG8QUAAACigS9E8UWGTVJ4gpMG2hBnSiSc6TbDhg2zwYMHp9lzBAAAADKyX375xUqVKhXupxGxMQbxBQAAAKLJL2kcX2TYJIWaZItmK5UoUcJ/+d69e/0zn3SbEydO2P79++PNdNJt6tWrl+RjDxgwwPr27ev/Xb0tzjvvPLdxY2NjQ/SKAAAAgPR16NAh168tX758bPoQxhjEFwAAAIgGh0IUX2TYJEW5cuVcgDBv3jyrXr26u0zBwqJFi1zjbKlRo4Zlz57d3aZdu3bust27d9v69ettxIgRST62elvoJ5gSFCQpAAAAEGkoaRraGIP4AgAAANEkJo1bJoQ1SXHkyBH78ccf4zXL/vbbb61gwYJuZUPv3r1t6NChVr58efejf+fJk8duueUWd/u4uDi766677P7773f9JHS/Bx54wC655BJr3LhxGF8ZAAAAgHAgxgAAAAAyl7AmKVauXGlXX321/3evBFOnTp1s8uTJ1q9fPzt27Jh169bNLbeuU6eOzZ07N95ykueff96yZcvmZjnpto0aNXL3zZo1a1heEwAAAIDwIcYAAAAAMpcYnzrARTnV0tKqDPWmoNwTAAAAIgXjXLY7AAAAkNHjiyxp9kgAAAAAAAAAAAApQJICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWGTpJ8e+//9ojjzxi5cqVs9y5c9v5559vQ4YMsVOnTvlv4/P5bNCgQVayZEl3m4YNG9qGDRvC+rwBAAAAZEzEGAAAAEDGkqGTFMOHD7eXXnrJxo4daz/88IONGDHCnnnmGRszZoz/Nrps5MiR7jYrVqyw4sWLW5MmTezw4cNhfe4AAAAAMh5iDAAAACBjydBJiuXLl1urVq2sRYsWVrZsWWvbtq01bdrUVq5c6V9FMWrUKBs4cKC1adPGqlSpYlOmTLGjR4/ajBkzwv30AQAAAGQwxBgAAABAxpKhkxRXXHGFzZ8/3zZv3ux+X7t2rS1ZssSaN2/uft+2bZvt2bPHJS48OXPmtAYNGtiyZcvC9rwBAAAAZEzEGAAAAEDGks0ysIceesgOHjxolSpVsqxZs9rJkyftqaeesv/85z/ueiUopFixYvHup9937NiR5OMeP37c/XgOHToUstcAAAAAILJjDOILAAAAIEJXUrz11ls2ffp0V7pp9erVrpTTs88+6/4fKCYmJt7vKgMVfFmgYcOGWVxcnP+ndOnSIXsNAAAAACI7xiC+AAAAACI0SfHggw9a//79rUOHDnbJJZfY7bffbn369HFBgKhJduBsJ8/evXsTzHwKNGDAADd7yvv55ZdfQvxKAAAAAERqjEF8AQAAAERokkINsLNkif8UtST71KlT7t/lypVzQcS8efP81584ccIWLVpk9erVS/Jx1bciNjY23g8AAACAyBeKGIP4AgAAAIjQnhQtW7Z09WHPO+88u/jii23NmjU2cuRIu/POO931Wm7du3dvGzp0qJUvX9796N958uSxW265JdxPHwAAAEAGQ4wBAAAAZCwZOkkxZswYe/TRR61bt25ueXXJkiWta9eu9thjj/lv069fPzt27Ji7zf79+61OnTo2d+5cy5cvX1ifOwAAAICMhxgDAAAAyFhifOoAF+UOHTrkGmirPwWlnwAAABApGOey3QEAAICMHl9k6J4UAAAAAAAAAAAgcpGkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYZEvpHY4fP27ffPONbd++3Y4ePWpFihSx6tWrW7ly5ULzDAEAAABENGIMAAAAIHolO0mxbNkyGzNmjM2ePdtOnDhh+fPnt9y5c9uff/7pgorzzz/f7r77brvnnnssX758oX3WAAAAADI9YgwAAAAAySr31KpVK2vbtq2de+659tlnn9nhw4ftjz/+sJ07d7rVFFu2bLFHHnnE5s+fbxUqVLB58+axZQEAAAAQYwAAAAA4+5UUTZs2tXfeecdy5MiR6PVarbtInwAAntNJREFURaGfTp062YYNG+zXX39NzsMCAAAAiFLEGAAAAAAkxufz+aJ9Uxw6dMji4uLs4MGDFhsbG+6nAwAAAKQJxrnhwXYHAABAJDoUovPoKW6cHWj9+vW2aNEiO3nypNWrV89q1qyZZk8MAAAAQPQhxgAAAACiS7J6UiRm3Lhx1qhRI5ekWLhwofv3U089lbbPDgAAAEDUIMYAAAAAok+yyz2pSXapUqX8v1euXNm+/PJLK1y4sPt9+fLldsMNN9i+ffsss2E5NgAAACJRRh/nRmqMkdG3OwAAAJCRxrnJXkmhlRKjR482L6dRqFAh++yzz+z48eN2+PBh+/zzz61IkSJp9sQAAAAARDZiDAAAAADJTlKsWLHCNm7caHXq1LE1a9bYhAkTbOTIkZY7d27Lnz+/vfXWWzZlyhS2KAAAAABiDAAAAABp2zhbyzdefPFFW7p0qd1xxx3WuHFjtxRbTbP1o0QFAAAAABBjAAAAAAhZ4+z69evbypUrXe2p6tWr2+LFi0lQAAAAAEg1YgwAAAAgeiW7cfa///5rEydOtO+//96qVq1qnTt3tq1bt1rXrl1dY7sxY8ZY8eLFLTOisR0AAAAiUUYf50ZqjJHRtzsAAACQKRtnd+nSxQUJefPmtUmTJlmfPn2sQoUKtnDhQmvWrJnVrVvXlYMCAAAAAGIMAAAAAGm6kqJAgQK2bNkyq1y5sh07dsyqVKniZjl59u7da71797YZM2ZYZsNMJwAAAESijD7OjdQYI6NvdwAAACBTrqQoWrSozZ07106cOGHz58+3QoUKJbg+swUPAAAAAMKHGAMAAABAtuRugrFjx9ptt91mffv2tRIlStjbb7/N1gMAAACQasQYAAAAAJKdpGjSpInt2bPHfv/9dytSpAhbDgAAAMBZIcYAAAAAkOxyTxITE0OCAgAAAECaIcYAAAAAoluykhTXXnuta2h3JocPH7bhw4fbuHHj0uK5AQAAAIhQxBgAAAAAkl3u6eabb7Z27dpZvnz57IYbbrCaNWtayZIlLVeuXLZ//377/vvvbcmSJTZnzhy7/vrr7ZlnnmHrAgAAACDGAAAAAHBaMT6fz2fJcOLECZs5c6a99dZb9uWXX9qBAwf+9wAxMXbRRRdZs2bNrEuXLlaxYkXLbA4dOmRxcXF28OBBi42NDffTAQAAAKJinBupMUZG3+4AAABARhrnJjtJEUxP5NixY1aoUCHLnj27ZWYEEQAAAIhEmW2cGykxRmbb7gAAAEA4x7nJKveUGD0Z/QAAAABAWiDGAAAAAKJPshpnAwAAAAAAAAAApDWSFAAAAAAAAAAAICwyfJJi165ddtttt7m6tHny5LFq1arZqlWr/NerpcagQYOsZMmSljt3bmvYsKFt2LAhrM8ZAAAAQMZFjAEAAABkHBk6SbF//36rX7++a5r3ySef2Pfff2/PPfec5c+f33+bESNG2MiRI23s2LG2YsUKK168uDVp0sQOHz4c1ucOAAAAIOMhxgAAAAAyeZLi888/T/K6l19+2dLS8OHDrXTp0jZp0iSrXbu2lS1b1ho1amQXXHCBfxXFqFGjbODAgdamTRurUqWKTZkyxY4ePWozZsxI0+cCAAAAIDSIMQAAAIDoleIkRYsWLez++++3EydO+C/bt2+ftWzZ0gYMGJCmT+6DDz6wmjVr2s0332xFixa16tWr28SJE/3Xb9u2zfbs2WNNmzb1X5YzZ05r0KCBLVu2LE2fCwAAAIDQIMYAAAAAoleKkxSLFy+2Dz/80GrVquV6P3z88cduBcORI0ds7dq1afrkfvrpJ3vxxRetfPny9tlnn9k999xjPXv2tKlTp7rrlaCQYsWKxbuffveuS8zx48ft0KFD8X4AAAAAhEdmjzGILwAAAIDUy5bSO9SpU8fWrFnjBvM1atSwU6dO2ZNPPmkPPvigxcTEWFrSY2slxdChQ93vWkmhoEVBRceOHf23C/67KgN1uucybNgwGzx4cJo+VwAAAACpk9ljDOILAAAAIJ0bZ2/atMk1qS5VqpRly5bNNm7c6PpApLUSJUrYRRddFO+yypUr288//+z+rSbZEjyjae/evQlmPgVSWaqDBw/6f3755Zc0f+4AAAAAoiPGIL4AAAAA0jFJ8fTTT1vdunWtSZMmtn79ehdIaNbTpZdeasuXL7e0VL9+fResBNq8ebOVKVPG/btcuXIuiJg3b57/evXKWLRokdWrVy/Jx1XfitjY2Hg/AAAAAMIjs8cYxBcAAABAOpZ7Gj16tM2ePduuu+469/vFF19s33zzjT388MPWsGFDV481rfTp08cFAlqK3a5dO/d3JkyY4H5Ey6179+7trldNWf3o33ny5LFbbrklzZ4HAAAAgNAhxgAAAACiV4xPxVVT4Pfff7fChQsnep1mFzVo0MDS0kcffeSWT2/ZssXNaurbt6916dLFf72evvpLvPzyy7Z//35Xz3bcuHGu0V5yqXF2XFycK/3EqgoAAABEiswyzo20GCOzbHcAAAAgJUI1zk1xkkIOHDhgM2fOtK1bt7pmdgULFrTVq1e7Gq3nnnuuZTYEEQAAAIhEmWmcG0kxRmba7gAAAEC4x7kpLvf03XffWePGjd2T2b59u5txpADivffesx07dtjUqVPT7MkBAAAAiHzEGAAAAED0SnHjbC2FvuOOO9zS6Fy5cvkvV4+KxYsXp/XzAwAAABDhiDEAAACA6JXiJMWKFSusa9euCS7XEuw9e/ak1fMCAAAAECWIMQAAAIDoleIkhVZPqPZUsE2bNlmRIkXS6nkBAAAAiBLEGAAAAED0SnGSolWrVjZkyBD7559/3O8xMTH2888/W//+/e2mm24KxXMEAAAAEMGIMQAAAIDoleIkxbPPPmv79u2zokWL2rFjx6xBgwZ24YUXWr58+eypp54KzbMEAAAAELGIMQAAAIDolS2ld4iNjbUlS5bYggULbPXq1Xbq1Cm77LLLrHHjxqF5hgAAAAAiGjEGAAAAEL1ifD6fz6KcemzExcXZwYMHXYAEAAAARALGuWx3AAAAIKPHF8laSfHCCy8k+wF79ux5Ns8HAAAAQBQgxgAAAACQ7JUU5cqVi/e7elIcPXrU8ufP734/cOCA5cmTx/Wp+OmnnzLdlmWGGQAAACJRRh7nRnKMkZG3OwAAAJDRxrnJapy9bds2/4+aY1erVs1++OEH+/PPP92P/q2+FE888USaPTEAAAAAkYsYAwAAAECqelJccMEFNnPmTKtevXq8y1etWmVt27Z1wUZmw0wnAAAARKLMMs6NtBgjs2x3AAAAINOspAi0e/du++effxJcfvLkSfvtt9/S6nkBAAAAiBLEGAAAAED0SnGSolGjRtalSxdbuXKleYsw9O+uXbta48aNQ/EcAQAAAEQwYgwAAAAgeqU4SfHaa6/Zueeea7Vr17ZcuXJZzpw5rU6dOlaiRAl75ZVXQvMsAQAAAEQsYgwAAAAgemVL6R2KFClic+bMsc2bN9vGjRvdaorKlStbhQoVQvMMAQAAAEQ0YgwAAAAgeqU4SeFRUoLEBAAAAIC0QowBAAAARJ8UJynUIHvy5Mk2f/5827t3r506dSre9QsWLEjL5wcAAAAgwhFjAAAAANErxUmKXr16uSRFixYtrEqVKhYTExOaZwYAAAAgKhBjAAAAANErxUmKN998095++21r3rx5aJ4RAAAAgKhCjAEAAABErywpvUOOHDnswgsvDM2zAQAAABB1iDEAAACA6JXiJMX9999vo0ePNp/PF5pnBAAAACCqEGMAAAAA0SvF5Z6WLFliCxcutE8++cQuvvhiy549e7zrZ82alZbPDwAAAECEI8YAAAAAoleKkxT58+e3G2+8MTTPBgAAAEDUIcYAAAAAoleKkxSTJk0KzTMBAAAAEJWIMQAAAIDoleKeFAAAAAAAAAAAAOm6kqJ69eoWExNzxtutXr36bJ8TAAAAgChAjAEAAAAg2UmK1q1bs7UAAAAApBliDAAAAAAxPp/PF+2b4dChQxYXF2cHDx602NjYcD8dAAAAIE0wzg0PtjsAAAAi0aEQnUenJwUAAAAAAAAAAAgLkhQAAAAAAAAAACAsSFIAAAAAAAAAAICwIEkBAAAAAAAAAADCgiQFAAAAAAAAAAAIi2wpvcMLL7yQ6OUxMTGWK1cuu/DCC+2qq66yrFmzpsXzAwAAABDhiDEAAACA6JXiJMXzzz9v+/bts6NHj1qBAgXM5/PZgQMHLE+ePHbOOefY3r177fzzz7eFCxda6dKlQ/OsAQAAAEQMYgwAAAAgeqW43NPQoUOtVq1atmXLFvvjjz/szz//tM2bN1udOnVs9OjR9vPPP1vx4sWtT58+oXnGAAAAACIKMQYAAAAQvWJ8WgqRAhdccIG9++67Vq1atXiXr1mzxm666Sb76aefbNmyZe7fu3fvtszg0KFDFhcXZwcPHrTY2NhwPx0AAAAgqsa5kRZjZJbtDgAAAGSEcW6KV1IoKPj3338TXK7L9uzZ4/5dsmRJO3z4cNo8QwAAAAARjRgDAAAAiF4pTlJcffXV1rVrVzeryaN/33vvvXbNNde439etW2flypVL22cKAAAAICIRYwAAAADRK8VJildffdUKFixoNWrUsJw5c7qfmjVrust0naiB9nPPPReK5wsAAAAgwhBjAAAAANErxT0pPBs3bnQNs3X3SpUqWcWKFS2zomYsAAAAIlFmG+dGSoyR2bY7AAAAEM5xbrbU3lFBg34AAAAAIC0QYwAAAADRJ8VJipMnT9rkyZNt/vz5tnfvXjt16lS86xcsWJCWzw8AAABAhCPGAAAAAKJXipMUvXr1ckmKFi1aWJUqVSwmJiY0zwwAAABAVCDGAAAAAKJXipMUb775pr399tvWvHnz0DwjAAAAAFGFGAMAAACIXllSeoccOXLYhRdeGJpnAwAAACDqEGMAAAAA0SvFSYr777/fRo8ebT6fLzTPCAAAAEBUIcYAAAAAoleKyz0tWbLEFi5caJ988oldfPHFlj179njXz5o1Ky2fHwAAAIAIR4wBAAAARK8UJyny589vN954Y2ieDQAAAICoQ4wBAAAARK8UJykmTZoUmmcCAAAAICoRYwAAAADRK8U9KQAAAAAAAAAAANJtJcVll11m8+fPtwIFClj16tUtJiYmyduuXr06TZ4YAAAAgMhFjAEAAAAg2UmKVq1aWc6cOf3/Pl2SAgAAAACIMQAAAAAkR4zP5/NZlDt06JDFxcXZwYMHLTY2NtxPBwAAAEgTjHPDg+0OAACASHQoROfRU9yT4vzzz7c//vgjweUHDhxw1wEAAAAAMQYAAACAkCQptm/fbidPnkxw+fHjx23nzp0pfTgAAAAAUY4YAwAAAIheyepJIR988IH/35999plb1uFR0kKNtcuVK5f2zxAAAABARCLGAAAAAJDsJEXr1q39/+7UqVO867Jnz25ly5a15557ji0KAAAAgBgDAAAAQNomKU6dOuX+r9USK1assMKFCyf3rgAAAABAjAEAAADg7HtSDB482PLly5fg8hMnTtjUqVNT+nAAAAAAohwxBgAAABC9Ynw+ny8ld8iaNavt3r3bihYtGu/yP/74w12WWFPtjO7QoUOux8bBgwctNjY23E8HAAAAiKpxbqTFGJlluwMAAAAZYZyb4pUUymnExMQkuHznzp3xmmkDAAAAADEGAAAAgDTpSVG9enWXnNBPo0aNLFu2/7urZjZt27bNrr322uQ+HAAAAIAoR4wBAAAAINlJitatW7v/f/vtt9asWTM755xz/NflyJHDypYtazfddBNbFAAAAAAxBgAAAIC0TVI8/vjj7v9KRrRv395y5cqV3LsCAAAAADEGAAAAgNQnKTydOnVK6V0AAAAAgBgDAAAAQOqSFAULFrTNmzdb4cKFrUCBAok2zvb8+eefyXlIAAAAAFGMGAMAAABAspMUzz//vOXLl8/9e9SoUWw5AAAAAGeFGAMAAABAspMUa9eutbZt21rOnDmtXLlyVq9ePcuWLcWVogAAAACAGAMAAACAXxZLhjFjxtiRI0fcv6+++mpKOgEAAAA4K8QYAAAAAJKdpChbtqy98MILtmjRIvP5fLZ8+XJbvHhxoj+hNGzYMNcPo3fv3v7L9HwGDRpkJUuWtNy5c1vDhg1tw4YNIX0eAAAAAM4OMQYAAAAASVbNpmeeecbuuecef5LgxhtvTPR2uu7kyZMh2bIrVqywCRMm2KWXXhrv8hEjRtjIkSNt8uTJVqFCBXvyySetSZMmtmnTJn8fDQAAAAAZCzEGAAAAgGSvpGjdurXt2bPHDh065FYubN682fbv35/g588//wzJVlWpqVtvvdUmTpxoBQoU8F+u56JG3gMHDrQ2bdpYlSpVbMqUKXb06FGbMWMG7zAAAACQQRFjAAAAAEh2ksKTK1cue+2119z/4+LiEv0Jhe7du1uLFi2scePG8S7ftm2bS540bdrUf5maezdo0MCWLVuW5OMdP37cJVwCfwAAAACkv0iIMYgvAAAAgHRKUmTLls26desWspJOiXnzzTdt9erVrtRUMAUPUqxYsXiX63fvusTosQKDntKlS4fgmQMAAACIhhiD+AIAAABIpySF1KlTx7799ltLD7/88ov16tXLpk+f7mZWJUW9MAKpDFTwZYEGDBhgBw8e9P/o7wAAAAAIj8weYxBfAAAAACFunB1Is5z69u3rBvc1atSwvHnzxrs+uLH12Vi1apXt3bvX/R2PZlgtXrzYxo4d65pji2Y0lShRwn8b3Sd45lMgLdfWDwAAAIDwy+wxBvEFAAAAkI5Jivbt27v/9+zZ03+ZZhR5M4vScpl2o0aNbN26dfEu69y5s1WqVMkeeughO//886148eI2b948q169urv+xIkTtmjRIhs+fHiaPQ8AAAAAoUOMAQAAAESvFCcp1EguveTLl8+qVKkS7zLNqipUqJD/8t69e9vQoUOtfPny7kf/zpMnj91yyy3p9jwBAAAApB4xBgAAABC9UpykKFOmjGUk/fr1s2PHjrkl4vv373f1bOfOnesSHAAAAAAyPmIMAAAAIHrF+FSnKYWmTZtmL730kpvxtHz5chdUjBo1ysqVK2etWrWyzObQoUMWFxfnmmjHxsaG++kAAAAAUTfOjaQYIzNtdwAAACDc49wsKb3Diy++6JraNW/e3A4cOODvQZE/f34XRAAAAAAAMQYAAACAkCQpxowZYxMnTrSBAwda1qxZ/ZfXrFkzQZNrAAAAACDGAAAAAJBmSQotv65evXqCy3PmzGl//fVXSh8OAAAAQJQjxgAAAACiV4qTFKoJ++233ya4/JNPPrGLLroorZ4XAAAAgChBjAEAAABEr2wpvcODDz5o3bt3t7///tvUc/ubb76xN954w4YNG2avvPJKaJ4lAAAAgIhFjAEAAABErxQnKTp37mz//vuv9evXz44ePWq33HKLnXvuuTZ69Gjr0KFDaJ4lAAAAgIhFjAEAAABErxiflkOk0u+//26nTp2yokWLWmZ26NAhi4uLs4MHD1psbGy4nw4AAAAQtePcSIgxMuN2BwAAAMI1zk1xT4rBgwfb1q1b3b8LFy6cqYMHAAAAAOFHjAEAAABErxQnKd59912rUKGCXX755TZ27Fjbt29faJ4ZAAAAgKhAjAEAAABErxQnKb777jv3c80119jIkSNdP4rmzZvbjBkzXI8KAAAAACDGAAAAABDynhSydOlSl6B455137O+//3Z1qTIbasYCAAAgEmXWcW5mjzEy63YHAAAAMkVPimB58+a13LlzW44cOeyff/5Jm2cFAAAAIGoRYwAAAADRI1VJim3bttlTTz1lF110kdWsWdNWr15tgwYNsj179qT9MwQAAAAQ8YgxAAAAgOiULaV3qFu3rn3zzTd2ySWXWOfOne2WW25xfSkAAAAAIDWIMQAAAIDoleIkxdVXX22vvPKKXXzxxaF5RgAAAACiCjEGAAAAEL1S3Tj7999/t5iYGCtUqJBldjS2AwAAQCTKbOPcSIkxMtt2BwAAADJN4+wDBw5Y9+7drXDhwlasWDErWrSo+3ePHj3cdQAAAABAjAEAAAAgzcs9/fnnn65W7K5du+zWW2+1ypUrmxZh/PDDDzZ58mSbP3++LVu2zAoUKJDsPw4AAAAgehFjAAAAAEh2kmLIkCGWI0cO27p1q1tFEXxd06ZN3f+ff/55tioAAAAAYgwAAAAAaVfuafbs2fbss88mSFBI8eLFbcSIEfbee+8l9+EAAAAARDliDAAAAADJTlLs3r3bLr744iSvr1Kliu3Zs4ctCgAAAIAYAwAAAEDaJinUIHv79u1JXr9t2zYrVKhQch8OAAAAQJQjxgAAAACQ7CTFtddeawMHDrQTJ04kuO748eP26KOPutsAAAAAADEGAAAAgOSI8fl8vuTccOfOnVazZk3LmTOnde/e3SpVquQu//777238+PEuUbFy5UorXbq0ZTaHDh2yuLg4O3jwoMXGxob76QAAAABRMc6N1Bgjo293AAAAICONc7Ml94alSpWy5cuXW7du3WzAgAHm5TZiYmKsSZMmNnbs2EwXPAAAAAAIH2IMAAAAAMlOUki5cuXsk08+sf3799uWLVvcZRdeeKEVLFiQLQkAAAAgxYgxAAAAgOiWoiSFp0CBAla7du20fzYAAAAAohIxBgAAABCdkt04GwAAAAAAAAAAIC2RpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAAAAAAAAhAVJCgAAAAAAAAAAEBYkKQAAAAAAAAAAQFiQpAAAAAAAAAAAAGFBkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFhk6STFs2DCrVauW5cuXz4oWLWqtW7e2TZs2xbuNz+ezQYMGWcmSJS137tzWsGFD27BhQ9ieMwAAAICMixgDAAAAyFgydJJi0aJF1r17d/vqq69s3rx59u+//1rTpk3tr7/+8t9mxIgRNnLkSBs7dqytWLHCihcvbk2aNLHDhw+H9bkDAAAAyHiIMQAAAICMJcanpQiZxL59+9yKCgUWV111lVtFoRUUvXv3toceesjd5vjx41asWDEbPny4de3aNVmPe+jQIYuLi7ODBw9abGxsiF8FAAAAkD4Y54YnxmC7AwAAIBIdCtF59Ay9kiKYXrwULFjQ/X/btm22Z88et7rCkzNnTmvQoIEtW7YsycdRkKENGvgDAAAAIPqkRYxBfAEAAABEQZJCM5r69u1rV1xxhVWpUsVdpuBBNKspkH73rkuqDq0yPt5P6dKlQ/zsAQAAAERqjEF8AQAAAERBkqJHjx723Xff2RtvvJHgupiYmATBRvBlgQYMGOBmTHk/v/zyS0ieMwAAAIDIjzGILwAAAIDUy2aZwH333WcffPCBLV682EqVKuW/XE2yRTOaSpQo4b987969CWY+BdJybf0AAAAAiE5pGWMQXwAAAAARupJCs5U0u2nWrFm2YMECK1euXLzr9buCiHnz5vkvO3HihGt6V69evTA8YwAAAAAZGTEGAAAAkLFk6JUU3bt3txkzZtj7779v+fLl89eAVR+J3Llzu+XWvXv3tqFDh1r58uXdj/6dJ08eu+WWW8L99AEAAABkMMQYAAAAQMaSoZMUL774ovt/w4YN410+adIku+OOO9y/+/XrZ8eOHbNu3brZ/v37rU6dOjZ37lyX1AAAAAAAYgwAAAAg44rxab1zlDt06JBbnaEm2rGxseF+OgAAAECaYJwbHmx3AAAARKJDITqPnqF7UgAAAAAAAAAAgMhFkgIAAAAAAAAAAIQFSQoAAAAAAAAAABAWJCkAAAAAAAAAAEBYkKQAAAAAAAAAAABhQZICAAAAAAAAAACEBUkKAAAAAAAAAAAQFiQpAAAAAAAAAABAWJCkAAAAAAAAAAAAYUGSAgAAAADgLF682Fq2bGklS5a0mJgYmz17tn/L/PPPP/bQQw/ZJZdcYnnz5nW36dixo/36669n3HoHDhyw7t27W4kSJSxXrlxWuXJlmzNnTrzb7Nq1y2677TYrVKiQ5cmTx6pVq2arVq3inQEAAIhw2cL9BAAAAAAAGcNff/1lVatWtc6dO9tNN90U77qjR4/a6tWr7dFHH3W32b9/v/Xu3dtuuOEGW7lyZZKPeeLECWvSpIkVLVrUZs6caaVKlbJffvnF8uXL57+NHqt+/fp29dVX2yeffOJuu3XrVsufP39IXy8AAADCjyQFAAAAAMC57rrr3E9i4uLibN68efEuGzNmjNWuXdt+/vlnO++88xK932uvvWZ//vmnLVu2zLJnz+4uK1OmTLzbDB8+3EqXLm2TJk3yX1a2bFneFQAAgChAuScAAAAAQKocPHjQlYU63YqHDz74wOrWrevKPRUrVsyqVKliQ4cOtZMnT8a7Tc2aNe3mm292qyiqV69uEydO5F0BAACIAiQpAAAAAAAp9vfff1v//v3tlltusdjY2CRv99NPP7kyT0pKqA/FI488Ys8995w99dRT8W7z4osvWvny5e2zzz6ze+65x3r27GlTp07lnQEAAIhwJCkiuLGdzJo1y5o1a2aFCxd213/77bdnfEzdR7OYNBtKDfHUsG7atGkJbkdjOwAAACA6qYl2hw4d7NSpUzZ+/PjT3la30eqICRMmWI0aNdz9Bg4c6JISgbe57LLL3AoLraLo2rWrdenSJd5tAAAAEJlIUkRIY7uxY8cmeb0a0D399NPJfsyCBQu6oGH58uX23XffuaZ5+tGMpuDGdqopq8Z233//vZsNRWM7AAAAIPITFO3atbNt27a5HhWnW0UhJUqUsAoVKljWrFn9l1WuXNn27Nnjmmp7t7nooovi3U+3Ua8LAAAARDYaZ0dwYzu5/fbb3f+3b9+e7Mds2LBhvN979eplU6ZMsSVLlrhVGUJjOwAAACD6eAmKLVu22MKFC61QoUJnvI8mN82YMcOtlsiS5X/z5DZv3uwSEzly5PDfZtOmTfHup9sEN9gGAABA5GElBU7L5/PZ/PnzXcBw1VVX+S+nsR0AAAAQeY4cOeJKxHplYrVaQv/WioZ///3X2rZtaytXrrTXX3/d9ZjQaojAFRHSsWNHGzBggP/3e++91/744w83+UmJh48//tiVdVIjbU+fPn3sq6++cpf/+OOPLqmh8lCBtwEAAEBkYiUFEnXw4EE799xz7fjx425ZturMNmnSJEFju759+9rDDz9s33zzjWtslzNnTheUAAAAAMh8lIC4+uqr/b9rvC+dOnWyQYMGuclKor51gbSqwluRrYSGt2JCSpcubXPnznWJiEsvvdTFGUpYPPTQQ/7b1KpVy9577z2X3BgyZIiVK1fORo0aZbfeemvIXzMAAADCiyQFEpUvXz43Y0ozqbSSQsHJ+eef7w88tFRbzbU100nU3G7Dhg0ucZHZkhRqPv7MM8/YqlWrbPfu3S44at26dbzVJIMHD3YzudSLo06dOjZu3Di7+OKLT9t83JsFpiXx5cuXt/vvv99ffks0E02BnmahafaZlrvfcccd9sgjj8QL6gAAAID0ovG+xr9JOd11ni+++CLBZXXr1nUrJU7n+uuvdz8AAACILpwJReI7RpYsduGFF7oZUjq5rmXdw4YN818fSY3tztR8fMSIETZy5Eh3/YoVK6x48eJuVcnhw4fPqvm4+nq89NJL7nF/+OEH93eULBkzZoxlRkr2tGzZ0kqWLGkxMTE2e/bsBAGtkjK6Pnfu3C4AVmLrTN599123r2mVjv6vJFKwXbt22W233eZqIufJk8ftt0o6RQLtZ71793b1mLXd6tWr5/bD01ESTZ9H3b5ixYo2derUJG/75ptvuvcrMDEHAAAAAAAApBeSFEgWnWBW6SdPJDW2U+PxJ5980tq0aZPo69YycyUcdH2VKlVcE/GjR4+6OrlJ0Qn4G2+80Z0ovuCCC9xydi1tV/NxjxIYrVq1shYtWljZsmVdIqhp06ZuiX1mFIpkj7ZR+/bt3QqUtWvXuv+rUePXX3/tv41Wt2h/zJ49u33yySf2/fff23PPPWf58+e3SPDf//7X5s2bZ9OmTbN169a5faRx48YuMZMYrWZSmQQlhJQE0iog1XL+8MMPE9x2x44d9sADD9iVV16ZDq8EAAAAAAAASIgkRQQ3tpM///zT/a4Tt6LEgn5XeaGkGttpxYROiqrvxMaNG92JZc3E1kz1aGtsp+2pbaUTwx7N6G/QoIEtW7bsrJqPX3HFFe5yJXdEJ+GVxGjevLllRqFI9ug+SmRo/6xUqZL7f6NGjdzlgStSVOd40qRJVrt2bZfw0W2UHMrsjh075laSKMGjfUerm5R8UI1mJSMSo2RG165dXXJHJdo6dOhgd911l9tOgdToUjWelcTQ7QAAAAAAAIBwoCdFBDe2mzx5smtspzJDHp2wlMcff9yd7EyssZ1mxHfr1s127tzpysXo5PD06dPdSc9oa2znJXOKFSsW73L9rlnoZ9N8XI0CdRttX12vk8ZPPfWU/ec//7FIc6Zkj06qJ7WSQgmxQM2aNYuXpNA+rstuvvlmW7Rokdvm2n+7dOlimZ36lmi/yJUrV7zL9bkMXJUTSPtbYrdXc3v1R9GKE9HntkiRIi6B8eWXX4bwVQAAgHAo2//jqN/w259uEfXbAAAAIDMgSRHhje3UiFk/KWlsp9nw+jmTaGpsp5r9gbTNgy9LafPxt956yyV/tJJATbh1W/UeUM8GJZkiSWqTPbpfYvcJXAmkFT9aVaDt+/DDD7uT8T179nRJkMzWxD2xfUhNJp944glXOkyv/Y033nDlrtSMPTFK2Lzyyiuux8Rll13menO89tprLkHx+++/u34yS5cutVdffdW/AgsAAAAAAAAIF5IUwGmob4LopLhO7nr27t2b4OR5Us3HRY2c1RxbpbS8JMWDDz5o/fv3969uueSSS9wJe90m0pIUZ5PsOdN9Tp06ZTVr1nSlx6R69equF4MSF5k9SeGVb7rzzjvdChGtuFHi4ZZbbrHVq1cnevtHH33U7a+XX36521baT5WoVMko3V89QFS6beLEiVa4cOF0fz0AAAAAAABAIHpSAKehMlZKVKhHh+fEiROurFC9evXOqvm4+jEEltkSnUTWSfdITvYEOlOyR/c7032UPLrooovi3UarDry+LJmdemtof9OKnF9++cVftkn7ZmJU2kkrJ7R/bd++3W0H9enQqgwlJbZu3eoub9mypWXLls39qOeMymbp37oeAAAAAAAASC+spEDU08lfNf/2eM3HCxYsaOedd54rwaRZ+iqvox/9O0+ePG42u0cz9jXTXasgRP/X7H6dYFZSY86cOe5EcGCzY50kVg8K/Q2Ve1qzZo1rUq5Z85Gc7NFKh8BkT3BD50AqdaT7BPalmDt3brwEUf369V1T8kBqRl6mTBmLJHnz5nU/+/fvt88++8ytjDgd9Z4oVaqU+/ebb77pSrMpKaYeKOvWrYt320ceecStsBg9erRrQg4AAAAAAACkF5IUiHpnaj7er18/O3bsmGvGrBPEderUcSfKNTPdk5rm42PGjHGleXQ7rQ5QLwo1kH7ssccy5XsSimRPr1697KqrrnKJjFatWtn7779vn3/+ebym0UpgKGmhx2vXrp1baTBhwgT3EwmUkNAqnIoVK7rtqzJh+nfnzp3d9Wpev2vXLpcE8xI02gbaT7W/KvG1fv16mzJlirteTbWrVKkS72/kz5/f/T/4cgAAAAAAACDUYnyn67ocJQ4dOmRxcXF28OBBi42NDctzKNv/Y4t2259uEe6ngLOgBuyByR6Pl+zRoWbw4MH28ssv+5M948aNi3diXP06VJpIt/fMnDnTzfRXg2ytTNHqkzZt2sT7Gx999JE7Wb9lyxa3akOJpi5dukTE+/n222+716aElxI+N910k9sGOmaJ+k2ofJO2v6j3iRI/Wl2i1RR6T5TkUWIjKXqMAwcO2OzZs9PtdQEAomecG40ywnYnviC+AAAAyCzjXJIUBBEZBkkKAACAyDtZHo0ywnYnSUF8AQAAkFnGuTTOBgAAAAAghLRaOCYmJsFP9+7dz3jfpUuXWrZs2axatWrxLp81a5brg6fSnepdpuunTZsWwlcBAAAQGvSkAAAAAAAghFasWGEnT570/66eYU2aNLGbb775tPfTLEX1bWvUqJH99ttv8a5TKdCBAwe6/nc5cuRwJVDVt6xo0aLWrFmzkL0WAACAtEaSAhGDJe0saQcAAAAyoiJFisT7/emnn3b91ho0aHDa+3Xt2tX1G8uaNWuC/mHq5xaoV69eNmXKFFuyZAlJCgAAkKmQpADgR6InbRI9bEcSZgAAAEk5ceKETZ8+3fr27etKPiVl0qRJtnXrVnfbJ5988rQb1Ofz2YIFC2zTpk02fPhwNj4AAMhUSFIAAAAAAJBOtCLiwIEDdscddyR5my1btlj//v3tyy+/dP0oTlcO6txzz7Xjx4+71Rbjx493ZaQAAAAyE5IUAAAAAACkk1dffdWuu+46K1myZKLXq3eFSjwNHjzYKlSocNrHypcvn3377bd25MgRmz9/vludcf755ycoBQUAAJCRkaQAAAAAACAd7Nixwz7//HObNWtWkrc5fPiwrVy50tasWWM9evRwl506dcqVdNKqirlz59o111zjLs+SJYtdeOGF7t/VqlWzH374wYYNG0aSAgAAZCokKQAAAAAASAfqM1G0aFFr0SLpPmixsbG2bt26eJepjJN6TsycOdPKlSuX5H2VyFDpJwAAgMwkS7ifAAAAoTJo0CDXkDLwp3jx4sm679KlS91sRc1KDDZq1CirWLGi5c6d20qXLm19+vSxv//+OwSvAAAARAqthlCSolOnTgn6TAwYMMA6duzoXx1RpUqVeD9KbOTKlcv9O2/evO52WjExb948++mnn2zjxo02cuRImzp1qt12221heX0AAACpxUoKAEBEu/jii11ZBY+aSp6JmlDqREGjRo3st99+i3fd66+/7hpZvvbaa1avXj3bvHmzv/Hl888/H4JXAAAAIoHGIz///LPdeeedCa7bvXu3uy4l/vrrL+vWrZvt3LnTTZyoVKmSTZ8+3dq3b5+GzxoAACD0WEkBAIhomqmo1RPeT5EiRc54n65du7qGlXXr1k1w3fLly61+/fru+rJly1rTpk3tP//5j6sdHQ00a1MrUnr37p3kbZS0CV7Boh8ljDxq6JnYbU5X/gIAgMxMYwaVY0qsGfbkyZPtiy++OO3qUDXIDvTkk0/ali1b7NixY/bnn3/asmXLSFAAAIBMiSQFACCiKXgvWbKkq9/coUMHVxLhdFSGYevWrfb4448nev0VV1xhq1atsm+++cb9rsebM2dOVJxcX7FihU2YMMEuvfTS095u9OjRbkao9/PLL79YwYIF7eabb/bfRg1DA2+zfv16t8ol8DYAAAAAACDyUe4JABCx6tSp42oza8aiyjZpxqFKNG3YsMEKFSqUaEJDpZy+/PLLBLWiPUp07Nu3zyUrNBvy33//tXvvvdfdL5IdOXLEbr31Vps4caLbjqcTFxfnfjyzZ8+2/fv3W+fOnf2XKWkR6M0337Q8efKQpAAAAAAAIMqwkgIAELGuu+46u+mmm+ySSy6xxo0b28cff+wunzJlSoLbnjx50pVwGjx4cKJlGDwqxfDUU0/Z+PHjbfXq1W5FwEcffWRPPPGERbLu3bu71SLajin16quvuvuVKVPmtLdRAshrBgoAAAAAAKIDKykAAFFDJ8CVsNCKiWCHDx92fSXWrFljPXr0cJedOnXKrZbQqoq5c+faNddcY48++qjdfvvt9t///tfdRo+nxpV33323DRw40LJkibz8v1Y5KCGjck8ppVJOn3zyic2YMSPJ26h0lso9KVERLdTb4+GHH7ZevXrZqFGjkrzdokWLrG/fvm71j8qW9evXz+655x7/9VrZotVC2n5So0YNGzp0qNWuXTtdXgcARLKy/f83uSHabX+6RUR/l8q7777rxngq+XnBBRe4CSk33nhjOrwKAAAgkXcmBQCAJBw/ftx++OEHK1GiRILrYmNjbd26da4ppfejALZixYru3yodJUePHk2QiFAvBSUz9BNp1E9Cwf/06dMtV65cKb6/GoHmz5/fWrduneRtlJyoUqVK1JxYT25vj23btlnz5s3tyiuvdMkznYjp2bOnO5ESuLJHjdsXLlzomrqfd955rjHrrl270uGVAACQ+b9L9f3Zvn17Nwll7dq17v/t2rWzr7/+Oh1eCQAAEFZSAAAi1gMPPGAtW7Z0J2737t3reikcOnTIOnXq5K4fMGCAO5mrmehKPOhEeaCiRYu6E/OBl+vxRo4cadWrV3eJix9//NHNvLvhhhtcsiLSqEm4tp1m6AeWxlq8eLGNHTvWJX6Set1K2rz22msu2M+RI0eit1HSRys1hgwZYtEgJb09XnrpJbfverNDK1eu7Fb7PPvss66Mmbz++uvx7qPHnTlzps2fP986duwYwlcCAEBkfJfquiZNmrhxoej/Wn2hy9944410eEUAAICVFACAiLVz5043y1yrIdq0aeNOlH/11Vf+3ggqRfTzzz+n6DEfeeQRu//++93/L7roIrvrrrusWbNm9vLLL1skatSoUYIVJjVr1nQnB/Tv0yVmFOAriaNtlJS3337bJTpuu+02iwYp6e2hmZ1aFRFI+5pOrvzzzz9JJn10XXBjcgAAIkVaf5cmdZtly5al8TMHAABJYSUFACBiaYb+mUoRnc6gQYPcTyD1p3j88cfdTzTIly9fghUm6u1RqFAh/+WBK1KCyzhptUnw/YNvo1JQerxIl9LeHnv27LFixYrFu0y///vvv/b7778nWrasf//+du6556aqwTkAANH4XZrUbXQ5AABIHyQpAADAWUlsRcrBgwddvefRo0cneb/NmzfbkiVLXFPySOf19tBrTUlvj5iYmHi/e31Pgi+XESNGuLIU6lORmv4hAABE63dpYrdJ7LsWAACEBuWeAABAiugkuFfb2VuRossCxcXFudJDXbp0SfJxKlSo4E4CqA50pAvs7aHVOPpROawXXnjB/Vt9PoIVL148wSxOPYZuH7zyRLW1hw4d6k7cnKmJKAAAmVGovkuTuk3w6opIMGzYMKtVq5ZbKavea1rNumnTptPeRxNK6tev77ZX7ty5rVKlSvb888/Hu82sWbNcOdD8+fO7FbfVqlWzadOmhfjVAAAiCUkKAACADNjbo27dujZv3rx4lykJoftlz57df9kzzzxjTzzxhH366afuOgAAIlGovkuTuk29evUs0iipo54e6tGm16yyV+rH8ddffyV5HyUdevToYYsXL7YffvjB9WXTz4QJE/y3US+sgQMHuv4e3333nXXu3Nn9fPbZZxaJUpPsUSJHE3OKFClisbGxbr8L3j4NGzZ0K3iCf9SDBQAiHeWeAAAZTtn+H1u02/40wUi09/a45557bOzYsda3b1+3IkWBv3p4qKRTYImnRx991GbMmGFly5b1zwQ955xz3E+k0QkSJWU0m1Zlxt577z13YuB0xo0b57bj9u3b7bzzznMnUTp27BhvJZBOpAQ7duwYZbMAIAq+S1VC6qqrrrLhw4dbq1at7P3337fPP//crSCINJrQEGjSpEnuJLu+V7UNElO9enX349F4Qyfcv/zyS7v77rv9J9cDaZtOmTLFbUM1IY/UZI8SFUr0aGyhZM/333/v9smkxjBKUmjlq1acaNu3bNnSvv76a//21XY9ceKE/z5//PGHVa1a1W6++eZ0e20AEC4kKQAAADJgb49y5crZnDlzrE+fPu5Ee8mSJV1Ji5tuusl/m/Hjx7tgtm3btvEeS43dg5u+RwLN9FSwrqRC4HZIyosvvuhOWE2cONGdSPjmm2/cSaoCBQq4EwMezWgMngFJXw8AiI7vUq2YUENurQ5Q4v+CCy6wt956y+rUqWORTj3EvJUQybVmzRpbtmyZPfnkk4ler1KeCxYscN+rSvxEotQkewJLpYqSFUqI/b/2zgTcprL9/w+JZKpUxkJzoaJSKA1ElNKElCYlEUVvMpSpMkQ0Eg006U2STJWiUZokhUL1oiRDL6W5WP/rc7+/Z//X2c7BOWfP+/u5rtOxp9Neaz3reZ57+t7Tp0+PBCmirwPjcs8991SQQgiRFShIIYQQQgiRBKL7eJDRH82pp57qPvnkkzz/BtUB2UTz5s3tZ1dBD/u6665zbdq0sccHHXSQSVzgNAkHKZBSQJNcCCFE9q2lQLA/OuCf6RBMoMLk5JNP3q5CJTeqVq3qNmzYYJUDJEJcc8012wU8qlSp4v7880+T3iKRIhv6jhU02LNt2za3ZcuWHX6Gqp+2bdvmWZ0hhBCZhIIUQgghRCYyoFyyv0FqMOB/RqPITnCURFdE0PSTioq///47okf+yy+/uGrVqlnTVZp90uMjLG0hhBBCZBr0maB/xK7KWiHvxHpJsL9Xr17ukEMOcZdcckkOOS56g/CeOXPmWACE5IBoKahsD/Z47rnnHqsQbd26da6vs1dZvHixBSqEECIbUONsIYQQQgiRkaCD/eijj5r8Ak6Ejz/+2D3++OMWoNi4caO954gjjrDM22nTpplGOUGNhg0buhUrViT76wshhBBxoWvXrrbuvfHGG1YhsSsgnVW7dm2TTUQ+K1pWsmjRoha4INh/8803W2UKDaazJdgT7nOyM3gv5w9ZMWSicoPgBEGPevXquUyGihvGFvuv4447zoJhOwLZtiOPPNKSTg4//PBI/xmPmo8Lkb6okkIIIYQQQmQkaIvTTPykk06yIEWFChXclVdeaQ3HkaIAXuPHQ4Cibt267oEHHjDdciGEECJTYC0kQPHiiy+aVBbO4YL+HaoVC/ueTAn20BR7V4M9BCY6dOjgnn/+edekSZNc3/Pbb79ZP4pBgwa5TIZzcdNNN1mggv3X2LFjTdaTBuQHHnhggXqNqfm4EOmLghRCCCGEEHlQvdfMrD83K4eenbbngCw7KicwetetW+cqVarkxo0bZ5IU++67b66fIRMUw1eVFEIIERu0lrqUWUu7dOniJk6caA2bWQsJ5EO5cuVszQScwGvWrIlkqJO5jsOYykNAHmrEiBHmoPdQMXH88cdb0/G//vrLmpXzeZzKmUhBgz1UUFx99dX2++yz8x4TkyZNsgDPZZdd5jKZkSNHWsDG9zehufirr75q4ya3Kpxd6TWWjc3HCfIMHz7crV271tWsWdPO4ymnnLLTz82bN8969lCxg1SbhyAQ9y9yY0CFC43es6GqJ5bnccmSJa5fv35W0b1q1So3atQoC8qJvJHckxBCCCGEyGjoPUGGI9UTGKvnnHOOBSPycjxgYBDQEEIIITIJnL80eUYSh3XO/5DR7sFBt3r16hwNnglcIONEIIJKw6FDh+bI8qe3QufOnc2x16BBAzd58mT39NNPb9dcO1Mg2MPxEfDxwR5+fv/998h7OGeXX3555DGBCR7Ti4IKTv8Z33Q7WuqpVatWrnz58i5TIZiF87Zp06Y5nufxe++9V6BeY9nYfNxXo/Tt29ctXLjQnOpUo4Tv4dxg3DEeGzduvN1rBN7oN4Mc3Pz58y1IyXUheJmpxOM8UhFFII35smLFinH89pmDKimEEEIIIURaQDPOr776KvL4P//5jwUUyJrDgIrO/ly+fLkZrieeeKLbtGmTZeyRFfbEE09E/sbAgQPNWXDooYe6n3/+2SSe+JtkjgohhBCZBIH4nUGfpjBUDISrJnLjzjvvtJ9swVeIRDcFHz9+vMlK5hbsoarzn3/+sQAHP54rrrgixzln70K1yuzZs10mQ2+wrVu3mhRnGB77Cp+8eo0RwEGakyBHuNdYdIJJNjQfz281ioeKlHbt2lkCz9SpU3O89swzz+R4TGUFgcc5c+bkCLxlEvE4j1Rm8wO9evWK8xFkBgpSCCGEEEKItIDG16effnrkcY8ePXIY+NEOAYxfMhaXLVtm1RR8luy86tWrR96zefNm17FjRzOIkbuoU6eOaUtnekm7EEIIIRIX7CE7fVc47LDDdunvZwpFihTJ8Zhjj34uP73Gsqn5uK9GiXaA76gaxQfTvv76a6sG2pXgIhUBBIKipbQyhUSdR7FzFKQQQgghhBBpARmLOzLcox0CRx55pJVs7wj0YfkRQgghhBCJgd5gBBaiqybWr1+/XXVFQXqNZUPz8YJUo9BzDWf8O++844oV2zWXMO+vUqVKno3e051EnUexc9STQgghhBBCCCGEEEIIkRCKFy9uDZlfe+21HM/zmL4mhe01li3Nx/NTjYIjHmkipE6p2NkVqFKhn8qUKVO26weSacTzPIpdQ+EeIYQQQgghhBBCCCFEwkC2s3379taQvX79+lYVgWxnp06d7PWC9BrLpubj+a1G2bJli0mnUmV8ww032HPbtm0zZzzVAPRBOeOMMyLvHzFihBs8eLB7/fXX3dFHH+0ylXifR7HrKEghhBBCCCGEEEIIkaJU7zXTZTsrh55d6L+h8xib8xgr2rRp43788UeTZKKvGP0jZs2a5apVq2avF6TXWDY1Hw9Xo5x//vmR53l83nnnbff+smXLus8//zzHc6NHj3Zz5861xtg1atSIPD98+HDrs0DzaIJImUw8z6PIHwpSCCGEEEKIuCGHQGo5BIQQQgghUoXOnTvbT6x6jWVb8/H8VKMgiUUgKMz+++9vMk7h55F4okn5xIkTLQDkKwxKly5tP5lIPM4jDbmXLl0a+Tef//TTT+0cHnLIIQk+wvRAQQohhBBCCCGEEEIIIYRII/JbjbIrUBWAU/2iiy7K8Xz//v3dgAEDXCYSj/P4/fffuzp16uSQz+Ln1FNPdW+++WbMjyETUJBCCCGEEEIIIYQQQgghMrgaJRqCDtGBh5UrV7psJNbnkSqUbKnoiRVFY/aXhBBCCCGEEEIIIYQQQgghsrGSgnIkGrtQglOzZk137733ulNOOSXZX0sIIYQQQgiRpsjGEEIIIUIMKKfTMeAnnQMh4kBGVFI899xz7qabbnJ9+/a1JjoEJ5o3b55vvTAhhBBCCCGEkI0hhBBCCCFE4siISoqRI0e6Dh06uGuuucYeU0Xx6quvujFjxrghQ4Yk++sJIYQQQggh0gzZGEIIIYSINdV7zcz6k7py6Nk6jylyHlOJtA9S0HF+wYIFrlevXjmeb9q0qXvvvfdy/cyff/5pP56ffvpfqdbPP//sksW2P39z2U5hz7/Ooc5hKoxDjcXYnEfdzzEYi3+qSdf/DUaNxUKi+7nwJHOP6f/fatwXXxtD9kVqovlL5zFV0FhM/jkE2RiyMWKC7IsYnELdz+lsY/wcJ/uiSJDmFsv333/vqlSp4ubNm+caNGgQeX7w4MHuiSeecMuWLdvuM3RcHzhwYIK/qRBCCCGEEMnh22+/dVWrVtXpj5ONIftCCCGEEEJkE9/G2L5I+0oKT5EiRXI8JvYS/Zynd+/erkePHpHH27Ztc//9739d+fLl8/xMJkME7IADDrDBVbZs2WR/nbRF51HnMBXQONR5TBU0FnUOU4VsH4vsibds2eIqV66c7K+S0TaG7IvtyfZ7LxboHOocpgoaizqHqYDGoc5jqpDtYzGIk32R9kGKfffd1+22227uhx9+yPH8+vXrXYUKFXL9TIkSJewnzF577eWyHW6sbLy5Yo3Oo85hKqBxqPOYKmgs6hymCtk8FsuVK5fsr5DxNobsi7zJ5nsvVugc6hymChqLOoepgMahzmOqkM1jsVwc7IuiLs0pXry4O+6449xrr72W43keh0uzhRBCCCGEEEI2hhBCCCGEEKlF2ldSANJN7du3d8cff7yrX7++GzdunFu9erXr1KlTsr+aEEIIIYQQIg2RjSGEEEIIIURiyIggRZs2bdyPP/7oBg0a5NauXetq1arlZs2a5apVq5bsr5YWUJ7ev3//7SSwhM6jxmL6oftZ5zFV0FjUOUwVNBZFQZGNoXsv2Wj+0jlMFTQWdQ5TAY1DncdUQWMxPhQJ6HYhhBBCCCGEEEIIIYQQQgiRYNK+J4UQQgghhBBCCCGEEEIIIdITBSmEEEIIIYQQQgghhBBCCJEUFKQQQgghhBBCCCGEEEIIIURSUJBCCCGEEEIIIYQQQgghhBBJQUEKIYSII0EQpP353bZtW45/Z8IxCSFEKvHPP/8k+ysIIYRIEzJhLy77QgixI7Q3zk4UpBApRSZsuDIVLRL5Y+vWrfa7SJEiLt0pWrSo+/rrr937779v/+aYNm/enOyvJXaC5lORSWM57MzIJObNm2e/ixUrZr//+uuvJH8jIUQYraXxRfZF/pB9IWKF5jaRqmhvnN12moIUImU2XAzuTHDoZupmGAcKzpPZs2e79evXJ/trpSx+gt5tt93s9+TJk92YMWPckiVLXLry559/ugEDBriWLVvaGLjsssvs58cff0z2VxO7YMBOmzbNLV++XOdKpO14ZiwTICU4mkkOrZdeeslddNFFdo8uXrzYnXXWWe69995L9tcSQmgtjTuyL/KH7AsRy3tPfheRqmhvnF7Ew05TkEKkBDh0Gdyvvvqq69+/vxs7dqz74Ycfkv21RMjZPmrUKFe5cmX38MMPu08++UTnJg+YoOG3335zp512mrvxxhvdyJEjXatWrdzTTz+dwzBLF4OoRIkSbuDAge7XX391++yzj1uzZo0bNmyYK1++fLK/oogCo8Pfs5999pmbOHGiu/jii93LL7+cMc5d1onXX39dGWBZAuOZcc1c2rBhQ9eiRQt37bXXpnXFgZ9bGzVqZOtEx44d3XHHHedq1arl6tevn+yvJ0TWkw1rabKRfZE/ZF+IWN578rvkjmyM5KG9cXqyWxzstP/VlguRZH766Sd31VVXublz55oRMGHCBFskWrdu7dq2bZvsr5d14ET3xgOTzg033GAVFA8++KBr0qSJOa39a6p+yQkTco8ePVyNGjXM2TRnzhzLYn/kkUdc165dLWt2jz32SOlz50v2/BgAjuOPP/5wJUuWdK+88oqNAd7jjSaRGjCmVq5cafPmxo0b3UknnWRVUM8884w5ROvUqePSnTvuuMOqeF577TVXtWrVZH8dEWcYx+wLmFuHDh1q4/n666+3DTBj4cADD0y7tdXPm+x9Fi5c6DZt2mTrw4gRI5L9FYUQWbKWJgPZFwVH9oWIFfK75I1sjMSjvXF6szEOdpq8SyIlQOrgv//9r0ni4MzFIYrh/sADD7jff/892V8va/AZ/jhRVq9e7caNG+e+//57t2zZMnfzzTebsYaTes8997Sseh/xzlZNy9wqItauXWtBiVtuucUqTziXRx55pE3W++23n+vSpYu9L1X11X3whO+9atUq969//cvNnDnTtWvXziooqlev7jp37pzsryl2APMmfPrpp1YBRcAXKZkXXnjBbdmyJe3OHcGxSZMmuXXr1tlj/v2f//zHjufvv/9O9tcTMZx7cltL2AtwnclgRnLuiCOOsDHB/JQuVWkQDvzOmDHDjR8/3pUqVcokAVkvuE+9LFs6HZcQmUqmraXJRPZFwc5XGNkXIlbI7/L/kY2RXLQ3Th+CBNppClKIhOsfRj/HoCZLHy3mKlWquNGjR1uWUrVq1dw999xjTnGRGLwDhYoWpCe++uorm2B+/vlnK3cnOkqVANfqxBNPtD4F2Uh0pQGBHD+2GbeUu5UpUybSCJX3HnTQQa53797mmFq6dKl9NhUDFb66o2fPnq5mzZpuxYoVkfu0UqVKrk+fPnYMLEhkA0v2IDnktugznrhX33nnHXf66ae70qVLmyTXySefbPctcmMffPCBSyeomCC4R4D03XfftSwNgn9knQ8fPtwCqCJz9Ez5iR7bb7/9to3jsmXLuvPPP98ymNu3b+9efPFFq1hLF5gvv/zyS9egQQPLLkI2kfsViadmzZqZlN7dd9+do3RaCBFfsmUtTTayL3YN2ReyL2KF/C47RzZG8tHeOD3Ymmg7LRAiAWzdujXy74ULFwYzZ84M/vOf/0SeO+6444KrrroqOPHEE4MDDzwwePzxx4Nt27bZa+vWrQs2bdqk65QAuDYnnXRS0Llz5+CBBx6IPD9hwoTgjDPOsOvUp0+fYMiQIcGwYcOC3XbbzT6T6Xz77bfBb7/9tt3zn376adCwYcOgdu3awSmnnBI88cQT9vyvv/4adOzYMahatWpkHPuxfNZZZwV169YNUoXw9/M8+eSTwRFHHBG8//77273np59+Cs4888zgtNNOy/GZ33//PQHfNjsJn3/+HX787rvvBi+88EKOOfLYY48NbrrpJvu3H7d8Zq+99gquvPLKYM2aNUE60bRp06B48eJBgwYNgtWrV0eeL1++fNCtW7fgl19+yXMsi9TeF/zzzz85nrv99tuDK664IrjnnnuCP//8M7L+7LfffsEee+wRXHzxxcHixYsj73/jjTeCr7/+OkgH/vvf/wannnpqcOmllwY///xzjjWF8zB8+PDg8MMPD+bOnRt53p8DIUThyfa1NJnIvsgd2ReyL+KB/C67jmyM5KK9ceqyNYl2moIUImFs3LgxOPfcc4MKFSrYxr9GjRpBv3797LUxY8YERYoUCXr06BFs2bIl8pmVK1cGAwYMCN5++21dqRiCkRU96XgwvrgWr776ao7ncU6HndFvvvlmUKdOnRwTUSby/PPPW+Dmk08+yfE8jiSCEDfeeGMwadKk4Prrrw9Kly4d3H///XZuFyxYYGO8V69e9n5vDE+bNs3OcbIda7mNARajv/76y47lwgsvtOfWrl0bLFq0KJgzZ07wxRdf2HPz5s2zMcL9S0CR4OLEiROTchyZzjfffBN899132xkdODmZT/fee++gUqVKFjQi+AsjRowIypQpY+8BrjMOlqOOOio46KCDgmeffTZIVaKdsqwbOIPYDHF/3XXXXZE5aPz48bYhYgMU5u+//w7ee++94Icffkjodxc756WXXrIAd26OmtatWwe1atWyAC/zC3MrDkPm0uOPPz44++yzc3xmw4YNwfnnnx888sgjKXXq81pbWTPY/3BPA2sAgWu/hvKY4+FYCcaxH+rdu3fkPhZCFJxsW0uTheyLXUf2heyLeCK/y/bIxkge2hunBy+liJ2mIIWICdEZrDg6o+natatlYPvMI24CBviUKVOC5cuXB4cddphlGFJhwee5Gdq1axecfPLJGe8ITyRh44yJhewmNjIeHO5cF35HX1ecg5s3bw4+/PDDoFGjRjbxUDWQyRCcWbVq1XbPEzyrX79+jrF+ww032Hh955137NxRcbLvvvvm+Pwff/yR9OzY8HVdv3598Oijjwbz58+PBKIIPhx99NFWOYPB3qRJk6BEiRIWlOK+BYIxVIRUq1YtGDVqVNKOJZNhXiTzmusTvnZU7AwcONDGG9cPh3zLli3tOuH0/P7774OaNWsGrVq1svsVqIphU8E1veiii3KtDEr2eOT7UZEUHSBl08OYJFOjXLlyOdYDAt4cu5/D2Cg1a9bM5jDOi0gtunfvHrz44ouRtYj58JJLLrGsHK6/dwb++9//Dg4++OBg3Lhx9pi5FAfiLbfcEkyfPt1ep9qL+ckHT1OB8NzKOoATyge4WT+pPrz88sstc4/1s3r16ha4GDx4sH2WgNsJJ5xgAXCqKqjWE0IUjmxZS5ON7Iv8IftC9kVBkd8l/+dKNkby0N44feieInaaghSi0JNOeFP63HPPbScbw0CnlKtKlSqRQUoG7CGHHGIOps8//zySnU3mOQY7TimyzQlqEKwQsadv377m8MMZTUaYn2SA68I1IAIavtZMQBdccIFdGyYqMpYzfUH14xvDNFwtgJOpQ4cO9m8fdCBLj3E9dOhQe7x06VKTgmrcuPEuZxQkEhxjBB/4jtx3BCH4zhwzx0qEnPuXSqYlS5bYQnPddddFPk/wJXz/i9jCucVREgYnCvcnUkfMox6CRwTNbrvttsj7CJCxQcBpv/vuu1vW59SpU006KdWCiziACCzwg/MnHPjCkdS8eXPbKB166KF23/lNEvdlsWLFgtGjR1sgnH+3aNEihyyUSD7R8wTX0o9BHIRcdz+feigZZg/w5Zdf2lrDeOf6k63Dxpj1KBWh+oz1oWLFinZPcq9SEQGvv/66Hde//vUvq0IjCME8yz3t9zo+K0kIERuyaS1NBWRf7BjZF7IvCor8LgVDNkby0d44tdmaYnaaghSiwISdrB988EFwzDHH2AAm8+jHH3+07CQCE08//bQ5b+vVq2eDF0dn5cqVgwcffDDi5PbyHQxy5HDohxAt4SFiB9IpZGkS6SRI1KlTJytfv+OOOyJGGdcSQyxa15Lr5uUqosdBppBb8IVJmEw87zxCk4+IcfRnyKwjEw+ossDJ76UDUgmyfFlAZs2aZRJrXFPuYTIGCVREwz2KrBORcRFfuOfC9x3Xgw2CBwkKpCnC5ZNcn549e5qD3/cS+eijjyz4iHwX19t/lqo1skaT3cPh448/Dl5++eVIkI/yUgKgzEP0JmIN4XtOnjzZerkAmuFkoyOd488R9xzzFRmvOIFFahE9zhiXVOL5wDg9RY488sigTZs2OSS6GB+sU4wHv1FmnLOfYPOcCmtQbkFa+qQQKPPa9sz/jM+xY8fmel7Y77AvyuSgvxDJIFvW0lRC9sWOkX0h+6KgyO+SP2RjJA/tjdOLbSlopylIIQo18VCqSsNrnEaU9+DsZEBTFoSz0zdVxjBA15+sbTb54cZ0BCN8bwoR242wnxTCkw/XD2czWccerhvyRUj3eGkioqNk1ufVO4G/nWlZ9OHzxPm79957rZki4PxEhqN///72vs8++8yaBN15552RzzAhUzWBgZsKRmtefSeA600WIfeifw/3IlUVSDnxPiR0OO5nnnnGjHGkeMIN70VsrxXXgoxrAr3Ab64NFWlUungnJ/ckGtr8EBD24FCh4oBNRG4QfOT6Mj5Tgfbt21sWa1gOjXuKsUn1BHJ/ZK4SBMeR5I/1jDPOsKAhziG/DjFGRWoQ7t+Tm/QjlZXI4iF79NVXX9lzVMJQSUkQKgwVBwSfCKhHk8zgRPT8PnLkSKskpcKHykQqz4CgPgE35k7/HJAcwL6I+517gLUmupGvEKJg92a2raWJRvZF/pF9IfuioMjvUjBkYyQe7Y3Tg0/SwE5TkEIUqpyXsmcyBMPSHEjIkA2LQzcMTSDRsKdEOlz6RZCDRizcEKJwCwPOvWijCcc5EVAPJe9UBESXYGGUUZ5FdhhwPbi2PI4ORmS6I+Whhx4yxxEl//58AIEdnE00DQccS5yjW2+91TLC+/TpYxIfqVAFFL5mRLdpfo12sr92LCoY2f69/nl00jHYgc+gzUz0PFWlVTIJnO7+nuvSpYv9m3FF1gLBXe5PP08SDCbYiHM0jA8++WoYMhr4GwSN99xzT7vuqZJJSHCB+4zv7HW9CTaULFkymD17tn13NklI5/hzATh7eYxcTqYFStOd1157zSrMHn744chzK1assDmVXiK+7w3OQoLg4b1Dw4YNgwsvvDBHYJw9ApVpXhYy1eDeJHOYqlEk8nB0Uuo8ZswYS8wg8M849TDOmY8JbhP4JVvbrydCiNiQLWtpopB9ETtkX8i+KCjyu+wasjGSj/bGqctraWKnKUgh8g2lzvvvv78Z4ugpE2VjENOYzkfk2MQjHxTOHGRAkxlLAIPsJEqu0XnFCars7MKD86NXr15BmTJlIqVYGFlkceLoo5eAL70i25/AULhkCwMM+Z9w2TsGWSbr7Ya1Pb2THkcTziMmZ/Da98AYx5jt3LlzpIkiznuCPugVY9DSWyXRx7Aj7rrrLrvPiHLjECOzF2iUjX6/D6j4SDqVIhy/Py9UQ3k5NhF7/Hn25x+ZGHSumT+5Rh4kY3CsEBADMkUJ8HotSA/3dHTAl3FL5mgy+zQge8acz2YmDIG+smXL5mgQjDQg1RKcE4Kq3GMEKjg2P945HspJRWpBVcw111xjAV42uvfdd58lMzA/4rCn4tJDtR7Zyl5ShYbpvIdsnVSXPmIcItPE3M8x+KyklStXWvUP1aXcq1QpeghGMJb5LOeJXj9CiNiQLWtpMpB9kX9kX8i+iBXyu+wc2RipgfbGqc+qNLHTFKQQ+QZN+gkTJkQeIwnD4KaCwmfs01cCffvo7GteZ2DffPPNFqiYMmWKrkAMoTF5gwYNbFKhHJ3KFZztOJ4POOAAM9pwOL/11lsWzHjsscdyTFroyrHQR5OJ2crhyRVHki9JI+jmKwkIRNDMFMeTN1bJzMPApddKGF8OB4mQ7chNyin8GrDwUJrHfYaRTkYhAQsfgEHLn9e5h7nGnBOChvTbEEFCrx9jjXuT7GvuTap2wvcdcydZVFS1UOECM2bMsMBTuJm5J1wdk2wIdBHYJpuV8eUby3sIeF922WWR7A0CFryXdSb6GFLlmEROwmOV9Z9AE8FcmkKjWUqwlx4jBECfeuope9+cOXNsjWJchx2LzK9hCbBkSzvl9f9mL3PIIYdYcDoM2qwEhenp5MGpiQwmyQHMt0KI2JBNa2kykX2x68i+kH0RS+R32TGyMZKD9sbpxdY0s9MUpBC7TG6bdN/wlIx9tMTDGmdkJpGx7zX9M9HRnWyineFMEGi577PPPkGtWrVyONIpw0LXHWkK6Nixo72HrE+kKXCqIGVE5nI2QTYd2bA05w03UmTSPvvss20MU9qPfBmBCCpLyLjjvOXWryMRzrTw/4PMPhYVZHK8wc2Y4N5kYQlHxAnGcLwEKngP15rIORrqlO8h/4TD2PeSEfEHeZgOHTqYk55gGBAoJAOUkswwZDLg5Edn1UNAic1GqsF94ud+pDcIWJcrV84cRlRsISvmG8pTsUVQggwNP7Y5RsZjdPBPpBa5BUuZZ6jqQ/ruvPPOizy/Zs0aG+tHH3105DPMszSN9sFxqmMoN04GuQWXw4+pfPjwww+DDRs2RJyd1157bVC5cmXrUeThPqZ5Nvcw6wR7Icb+OeecE9HIF0LElkxdS5OF7IvCI/tC9kVh78Fo5Hf5H7IxEof2xunNtjS10xSkEDFbQDHUcXz7jPMFCxZYJhO6rZksGZRICPQ8//zzkX/nxjfffBNceeWVZph5B5/P6iGTnuwxIGLKhMPkRHCCfgrZVj5LdQnZc2SpeOkNHKq33XabRYrR4SOaTLQYnXxfGUSGN8ZHuNdHomGjesUVVwR77LGHOcKqV69u1UtUfvjy/EaNGuVoSs/9ysJCqR5SJT7DF810dJqHDRuWtOPJRpBWI9OTsca9GNZzJCjGdfXNof31ozqGIFoqV6Ex9rp3727f098jH330ka0HnTp1sk1Q27Zt7Z5CjozMVxxLaF16OSg+R+CCezHVpX/E/yrxWF9oHs04JSuHTBtku8K88sortgb5eYkgK9UIbJaZ0/yeItEBqehM7PD/nzmTaomqVatG1gyOA+bOnWvVizfddNN2f5OKNQLIlFUTgBNCxIdMXUsTieyL2CH7QvZFvJDfRTZGItHeOHNYlWZ2moIUYqdamjvDO5BwnqNxjzEebs5L2ZC0l2PDrFmzzHGHXJOHpn8EGHwlgM9MLl26tOm9g+8psGzZMpPm8o0A/fXzvSqSLauRKF1YuPrqq3Mt7c8LHP7hJkPJBJkuDHK+k8/gpSSPIIW/5pTlYbATyAjrJxNEpIeMD1J4lKUeP3I7t2Rj098k3AMmDJsH7vVwNRTZoWSL4tjH0b+jv59sXn/9davk6dmzZyRwgZZ3qVKlIv0naFTKOSBjg3+j409Q0Ae12Uj5XkcidUHeiIATMnkEfJljGJMEeanS8g3PAUkvNr70SvJBdKQJk0V4n8P3JruanlpeeoxxywaeIBqvM8+yduDcRP4E2Lij7Uqzd1BQTYj4kI1raaKQfZF/ZF/IvogV8rvkD9kY8UV748zijjS00xSkEDucmDDQ8wMNms8666xIQ1OMB5pFitiBZATyROhat2zZ0rLiTz/9dAsQIbvlqySQVcGREm7ciSQQ0VAMtGhjLBN1d8MBF6+lB0SCveMJ0A7HgdqjRw/b+Pj3EwBAsoYyN6RnVqxYYa/585QsCTMcYshzhRvO49gl+IAD2H+/8ePHW9PIhx56KPI+Ki3oQ/HSSy8l5btnG3k5LHGcsDEguMv9SpCRgCP9GrzOI1IU3N8Ee5Hl4rqnomwemxiyUcNNsZl37rzzTss+90FR3oeEGpnnHo4drX7WDhxJSEGFx7VIbRjHjM2pU6fa4/D4pAktMnI4/sPQH4fA1IMPPpjj+WSObfRWqT6kQVxYxo/5n3WUSqAwZBnRvwiQx2NcX3rppREpBk+mralCJItsWEuTjeyLXUf2heyLWCG/y46RjZE8tDdOfz5OUztNQQqR68DDsEauAxkgHN++10Reg9Nv1pBFwNGEc1QGQHw2w/QdIOMYGQl04ggkUSmBZA+BCl9lgdwWUVACGmTNv/HGG+ZoR94p2pGSDRFkjhupGa+pxznBgUpFAj0mCPQw3nlMMILqHwzbSpUqmVxHuNok2eNg3rx5dm198AGdc987AwcwjjYv+8R3pyE6ixCZhkiVIKvjA4ki/hBAItt60KBBVh0AP/zwgzk1aShdpUoVCziyIeBaUYHgP0eVFJsHHP6p6PxkPqI6i3mfslHmHV8Jwb8J8NGg3X9nNkn0zPFNuYD3e3lAMltF6uuZemi6xpxCUNe/J7z2c51Zd8JVaLwvHNBKJlRDUO3JfOp7qIRhT4Okng9c+KrESZMm2bhHGgoGDx5sf8dXUwghYk8mr6XJQvZF4ZB9IfuioMjvsnNkYyQH7Y3Ti20ZaKcpSCG2g8wjso1wdmIMsNHH0eR7TewsUEEGE1n+ovBEn2t/jmmGjFOQaokwONr5wSBjMkJzF8c1Tut27dqZkz6Tia4GoWIEI5WsV6LB9OpgPPuJGGc/DRSRlKH0n88ik0VlBc4oqoB8Jl6ypLCi/5/++DgWnLpc17JlywYXX3yxBag4NiolMMYZA5s2bbIMQzSZ0WYm+Cjij79OVKzstddelrlJmSWBRORicKzwHsYaWdpoaDPmkMsrUaJEREqG6x/OIE1FKRnGHhsgqrTq1atn/SZ8BRfSZPQrmj59uj1m08M8RIP26CqnVDy2bCc8/9AnhLUlPMfSi4Frn5fDj70AzaUJCPs9RJhkJzMgcUK1GVV0Ycgu4odgL0Fd9kTRmuM4RFlDAL17KiqEELElm9bSRCL7Iv/nS/aF7It4IL/LjpGNkXi0N04f/slQO01BChGBTX3v3r3NeYSTyQcayAzE8USzlR1lHWV7NlIsYUIITwpLliwxZ/uHH34YkdHCQeKviX8vxlnRokWtYSdgnKHVS3ZyWO4o0/pORI8/3yCRygEqKMIlbzj0OZfhahL/WRpic76idfCjr0ciiP5/cj+Gj5HqCeQLqPSYNm1ajs+S5UsQK3wcXP/8yreJXSe3+Y9zToCQJuseHCkEgP29Gw2bidatW+e4X1NVjs3PI6+99prJNbF+oGvJGsKG6IknnjDppquuusqqLDxkrO+33365NhsWyWFnY4sG5pQLk7BAgNRDNVetWrWCmTNn5hgTOA5x5PsmbFSu8f9IlTHsvwf7HtZHjs0HpHF8ot3K+sF9x7hmzaBJtofeP+yLfGWFECK292Y2raWJRPZF/pF98f+RfRE75HfZMbIxEo/2xqnLtiyz04o6kZX8888/2z23xx57uEqVKrm///7bHpcvX95+n3LKKa5169Zu6tSpbsGCBa5IkSJu69at232e50XBWLduXY5zWrRoUfuZP3++u+qqq9y7777rFi5caNfgp59+cvvuu6/r1auXGz9+vPviiy/svQQda9Wq5Tp16uRuvfVWt2bNGnfEEUe4GTNmuD59+rjdd9/d3sPPbrvtljGXiuPx44+xe/XVV7srr7zSrVq1ys7f0Ucf7bZt22bPn3baaa59+/Zu2rRprnjx4va5efPmubFjx7pmzZq5rl27ussuu8wdeuihOf4f/nrEk5UrV+Y4pvAYaNSokTvvvPNc8+bN3dKlS22scK9ef/31rmzZsnbvhs8F46lChQqRexm4/iVLlozrMWTzfJrb/Pf999+7ZcuWuUMOOSTy3IUXXuhatmzpPvzwQ/uB6dOnu4cfftjVrVvXTZkyxV177bV2vcIwFlJtjvXzSJMmTVzt2rXtXqpcubKN2QsuuMB169bN5qkDDzzQ/frrr3afQc2aNd3tt99u41qkBn5ssc78/PPPkeeXL1/uGjZsaOtIv379bM6ZM2eO69Kli81DjRs3tvlyyJAh7vfff4+sMSNHjnQTJ050v/32m82tN9xwg/0/UmUM8z34nsydzKs1atSw3/vvv7+tHW+88Ya75ppr7L5jTTjqqKNcixYt7N7s2LGju+222+xeLlGiRGTeFUIUjmxdS+OJ7IuCI/tC9kWskN8l/8jGSDzaG6cuRbLMTlMlRRaRW2TshRdesOxysrIBaQOamNK81OuK+0x+spgosRaxZcSIEdY3IrpHAFmcSDUhMzFq1CjLVC5VqlSksTPXE93dNm3a5Mi4RyMbfW2uayrJasR7XCPNRCVEixYtrOE1PSTOP/986zNB1jY9G3wlCiDzRGUBvSeION9www0RffFEM2fOHCuzI0PJXyukCOgHg84yY4DXOJ5jjjkmh3b6scceaw1c/T1M42xkoDp06JD1cgaJhGv29NNPW1bCmjVr7Dkysxl7NKz37wHuTfTrGbM+K5v51Te+TxcYo/6YkMYhs5z7CIkxIGuD9YR5C2kOelH89NNPSf7WIjeQ5+Ja0TyabBo/t3INqSSgIa3fI5CpU65cOWuWDqxJzEPMVTSQZmyzh/Dj25Mq2Tm5gUxeuDoxN2jES0k01Xk0lRNCxJ5sXEvjheyLwiH7QvZFLMZPGPlddh3ZGMlHe+PUYUuW2WkKUmQ4aLj6Up4wNC9lw88APeCAA0yn3zfHZrAzkGlMFwajgabC/BaFx08EaLSvXr16u4WZZrPIpHgoz+K6nHXWWVai5cuzmKyQWwn/zUwNSHiijw+ZK+SNcDIhARBuBsTz/fv3z/H+b775xs6tb3LqJ3Z/nhM9SS9dutSCTfSR8P9vglY9e/a0e9VDc1aOB0ewb4z973//2+7jMWPGWJNsXr/++usVoIghOxsPyKshI0Y5Jf0X+E0QDGhYTtAorPNIQGm33XYLZsyYYY9x3IeluFJFKzuv78H5CN+DvqkwTlz6noSbYsPo0aOtLwzOIzZZqbQJykZyO/+sKUjHHXTQQab/y5zqry29fZBMQT6FTS89kSgnRsLLOxEZw/Sjoo8V1ztV2Nm95M8FsmTt27e3oLaXAvRjPNPXUyESRbaupYlG9kXBkX0h+6IwyO+y68jGSB7aG6c227LITssLBSkyGDbqDE4yxcPg3KxZs2YwZMgQq5Yg85qmujjA6WGARiLOUZpJrlixIvI5MpnQOwtno4vYTURvvPFGjgx5DDQfKfVOE5p04oTGCegXGBzbaMBTORAmE/tOhBdVjFN6MfgAAxmwnBsCN2Hq1KkTNG3a1DLwCAbRTJH7gue8c9WTaGcU18j/P6mUQMf/7rvvtsc4c30jVoJQNCXmdZql77333hac8Jxxxhl27DjYCHiI2BEeE+Hx5+8vNgbMlVQ78foHH3wQXHDBBUH16tUtAMm8SfNOtLSZa7nfmXtxtvjql/D/KxUc+BzHmWeeuV1wLxrmK7IxOF6+Nxsg5qNLL700R8N58I20RerhxzIZOuwDqJjs27dvjvewFhGAeuuttyLJDATICY7SqC03UslByH3pK3zyYvLkyVapxv0JCk4IETuycS1NNrIvdh3ZF7IvCov8Lrt+r8nGSA20N04P/skCOy0aBSkyfDB7oyDssCZTCWkZDAK/gSUzCae4d0rhfEIe54orrkjK9890/HXx559JgujoZZddFpF9IkpKFNTj34sRhzzUsmXLIhmgvpIiW84d0WMkN8iy86VqSDXtscceNmmHM+kWLVpk0kdM1PXr1zcHf7j5YirAvfjoo4/a9UfCa926dTmqPmjmPXDgwMgiU7FiRRsfHBswFsJNXUXhCc+ZOECuu+46q77p169fjveNHTvW7l3m0HDDMUoqCeoCmQsEmCpUqGBBs7322iuYOHFiyl0mAn6+Sov7qHz58jb+cgNpNe4ppMg2bNgQeZ5Kptq1awd33nlnwr63yB+sF1Rbecki5lQC4YxtSoaRNGKN8XMrzn0cgTfffHNkQ8t7aS5N1jNrUJhkOgej11akFZAZo9qMAITPyg4T3gcxnnmfH/dydApROLJxLU0msi8Kd+5kX8i+KAjyu+wc2RjJQ3vj9OK1DLbTdhUFKTKQ6Oy/559/PmjXrp31lYDnnnvOZJs8GAF+MNeoUcP+zQDHKVqtWjXTGhexN9Y4x+FJYvz48VbC5TPkcfaRPR82wHCcEEEtWrRocM8992TdZeFcoG/funVrM1AJSnTv3j1Yv369vY5EGY5VL10WvieWL19uwbeNGzcmtNpkR9m4/P+7detmx0FfCa4tFRHhIApGOYEpqpy8BjMSbbvvvrtFxzOxYiaVuPHGG01OAqkJ5LRY8Hv06BF5Hb1Hxpzv4ePnUzI8Cfx6KLd88cUX7T5PxQxt7iMcRF4CjeNg/uGYc4P1JFyJFJ7LkKp77LHHEvCtRX5ZsGCBOfiYZ3DcswH2Y5bNLYkJZCw3bNjQNsj+NXoiITVIYJSqv5YtW9qcFF25lkzC95WfF5Fw4p6jTxEVdPQs8oGK3Dbp9AdivvXVFEKI2JAta2mykH1ROGRfyL4oKPK77BzZGMlDe+P0IpPttPygIEWGTULhTapvUIpWK9njNL/hdbJEcD4NHz7cXvcRNzIOydD2Mh1I43gdM5E/vPMjr0gl5/70008P2rZtazruYdkeGtpw7skmY/Lh2tEHBOkfjDwa4eHERuIpm+B8IFNG8Czcs4EsOzRAPfSlwAD2MlC5XYNk9Z2IhqAJ9yINjfg+VFBQyse19dFzdANxHmOUk+WO3BNN1amI8guTiM8mgaAtP75ihbmS+4/rgfYjcO1oGO1luvy48n0YfO+QVC2xRDoOxxDVDxxLGNYEnErIzO1q0A2ipedE6sD1Q7OUjSwZyUhzMY8CUo5siKlEYzyTleMb1RL4pY8V98Oee+4ZyWxOBcL7HuZIKtKQiSFoTca2l0tEIoZABdUSfu6MXge4LxcvXpzgIxAic8mWtTRRyL6IPbIvZF8UBPlddo5sjOShvXF6kol2WkFQkCKN8UGIaEObqBnObwa4N87JJiTiRoAC4xwj/cADDzSZGQ8l2GTAitjhjS+/UFCORS8EKiZwNA8YMMA03Snbgvfee88yxu677z6bpJiEiJjyHiQrkKGgTwjVFpS5R/dUyATyMjjJ8CaIhn5iGAIXSB95eQ6y8Yg+hwMXyYRgCbJUSONw3cKbBjK39t1334jEDnB8SK3hZPNw77IoUbJHtUX4vhXxAS1HrpvfGISzgQgWeg1sei3QyJzrQra25+qrr7Z5ODdSocyS0s8GDRrYmEJqLC/oMUFANbfAg7JY0wt/vQg6IZdHhSUlxWxqBw8eHDzxxBMWJGV+IUGBqgMee+cgY4bS4nA1Wirx1VdfWXN2fqi2Yx1g/IZBxgzZP4K+Qoj4k+lrabKQfZF/ZF/IvigM8rvsOrIxUgftjdOHTLfT8oOCFGnKsGHDrGlK2LnJZh2dMqRjrrzySpML8s5MfhOUuP32221ji0MXRyhZ6Azuc845x7rB0zhSxGaSwSBDL85fG2Cioc+EnzyYVI444ghrDOgnGAwyIqNekoK/RXCDAJOH94Sd2JkIMmU0ffeVPWTgIXPl5ce8JACOf7K9H3/88UgAACdUqsjNIEWFlBPXjN4SVMF4hy9yTchWha8tUC1BEMo70rjPP/roIyvfE4mjV69e5sj32Z/MlTg+6RuCVAVllz/++KP1BGE+Zu7FmUIDc4JPL7/8cso5Uvw9wn3DsbDhiQ6q0XyLRqU++7xYsWKRTA0PmyBKSan6EqkHY25HQSR6hpC1zHUkMEr1AUFwGtNStQfIqRAEvuOOO1KiGs0T/f9ljm3Tpo3dl8ydHuZanps1a1bkOcY1azB9ilQpKkRiyMS1NFnIvig8si9kX+QX+V12DdkYyUN74/Qik+20WKAgRZrhBxsb/WhJAqJuDF4cu7lBBiEOcS/pweAdOXJk0KlTJ5MV8rr+In/kNsFwnXDqYYS99dZbkefvuuuuoFWrVvZvnCmlS5e2SolwRQSOE3qBdOnSxYITHgJNTFR8HkkjpFjSkZ1NmJMmTTItvrp161oFSbjZKcEH9IzDfwetPfozYNjiUA1nmKUCVMNwDFw77lGy0ps1a2bl5TQcJhhB5Uy42TeLDY7hww8/XNI5SRiD/p5mE8C1wpFCxQFZDfQEQWps1KhRdo2YQz3333+/aWzfcsstOa5nqoDkH8EyvwZQ1XX++eebcwiQnqNf0Zlnnmnj09O5c2er5GE+Yq5izuKeoxRV0k6pPb6RkAtXb/mxTaIC45n1hIAvgXM2wDgH33nnHXsPlZisQ74xWyocV26ZsL/88oslaCCNGO7VRPDXZxmFpfEeeugh6+uDo0oIUbh7MhvX0kQh+yJ/yL6QfRFr5HfZdWRjJAftjdOPTLXTYomCFGmuRcrG32cm4bRm849ziXKfqVOnmqQQBjlg3OMsJSjhs9NBkh2xgYzi8CSD4w/JCQJDHpqT43wnMwwJn3AAgyipr3yh4oUs0LCzHYcKGaBMVj7LOd0b+0WPQcYlVSS+XwrGKQ5TqoCoJqDpO1UT/EYawDtWmaCRw0L70v897pFkR5D98SLnReYuEAwkA52gCs28Kd8jGEPlB4sNixA66mQWkrnDOUj2cWQqu6JlTQCJ8YcMRTRVq1Y1p39ezctTRSsbqTSqtZDcwPHjK3SYfzgG1gR6o6D7nZvjljFL4BBtTBzByHGgMy5SG/r3EOgMrzNhqD4jS8c79llvfC+fVNsXhOdA5n4qgWje7uUX2AuxdhB4i75/qWDjWD0cm8/MFkIUnmxZS5OF7IudI/tC9kU8kN9l58jGSB7aG6c3mWSnxRoFKdKI6E06TnAcRt26dTNHJg1TyNKmCSqNd5FwogSIzFiykfxgRxtfesyxg8oHAg5IZ5EBH84sJnO+VKlSJp8CZDCTOU+PkDAElmj27N+X2wKEM8Zr96Yb4YmUbGwcpTjiaeoTzpLDKX/CCSdExjfnCRky3s/4x4lPRRDnEMcTEzfnffPmzdZ0nN4UqQbXj+NC8slDI0iqbHAMcy/yGk5kmrpyT6OpLimS+MF4oWfP2LFj7THOTl+FEz1muecYVwSWwvcf/yboS5ApN1Jl84BEGOvAkCFDLJs8uvKBAAVjkWqJsJEfHRgjy5WxGS37JFIPMmwI2JKBM3fu3O0qy/y1ZaPLPEwgmF5W/rXosZuMsTxt2rTId4oehzSEI/hP/6aTTz45ErQni4/Nfli2kgwlNF1ZLyRNJkRsyaa1NBnIvtg5si9kX8QL+V12jmyMxKK9cWaQCXZavFGQIg2IdhZNmDDBKiUAp/hRRx1lvQ6AbHOMBbLyfYVFnz59zAHqefLJJxP6/TMdeiTgWMeZjrYuGfJhJwkZ8QSKvAPw0ksvtYxkDDLkKFjg0erF4e6zk/01z7RJhwADZf0E0HDMc15o1u6lOMi0o58KOnwEIpDqCDdQ9MyYMcOiz/w9pD6ALFoCdqmEv47jxo0zZxoOMwIQ6AniNGbhIbhCMIYFa8SIEXICJwAqAxh3yE/gNMFJj65jXtcPxzzji2vmSzBxtFCZEC27l2r861//ss1NWDouDA5e5OWo8sLhFAYpDnpWZHsWa6qS20aVDS1zJz+s/ZBbdnJYLo/16LrrrgtShaVLl1rFHPdbOKiGlCV7mSlTplgQ+8MPPwwOOuggu5epQMPZibQTc214zD799NPmSM2ERnJCpBLZtJYmA9kXu47sC9kXsUJ+l11HNkbi0N44/chUOy0RKEiRRhCcIGscqY2w7jKP0QgPSzh5yDzHgCBjPa8yalF4kNTC8c4EMmjQIKueIEOZLKivvvrKsj693A/XCQMNaS5fCYBcUSZL+hA8owEiGbA+EENggqAERi1BNZ8ly7nD8TR9+vTI5xm7SEDl1did12rUqJFnP5ZkQwYvTjeOlag5VU9AgAUHGoEbGmOL+OHvLz8Pdu/ePVLNgqNkR59hrFJpcOqpp1ozT6rR6OUQ7tuQqtA3gqbCHmRu0ADn+AmUslkiA52eE14Ch4wONk6cH/oVsY5k8vyUjoSd8NFr+6OPPmrzTf/+/XfpbxGgIjsrFfDHQsCZ9fHdd9/NYQzzHNV3/n28ToUP8k+AXBmbefo/CSFiT7aupclC9sWOkX0h+yJeyO+yc2RjJAbtjdOPTLXTEoWCFGkCmeM4bseMGWMGOg13w42GaQLpKyRwOjGQkZjB8VSnTp1cZRPEztmZY86/ziYZSQn0sJFl4nohL0F22N13322Z9BhxYQOOrE9K48P9JTI1kESwhmY/aN6HIXiGg94HH9Aa55xhvFJ14KHfCtmxYV3xb7/9NiLvgc5xOKiRanD/0YuESonc8LrqIvZwj0bfV8yRODGp1KHPi686y+3+8xkQSLXhhOE6vvfee2lzz7766qs293CcZKFzv1BZQQNTAnv8Buarjh07WuCwSpUq1ieFKi+R2lBNSQYzDvz58+dHnidbmYAojc7zWstSrVIvfC9R9YBsJcfF+grI/pGUEW0AYCSTje0zu9G25z71uq1CiMKT7WtprJF9ERtkX8i+iAfyu+wasjHij/bG6U0m2WmJREGKFCOvTTqZRvyE3xMezGeffbYZ6mTtY9wPGDDAMtd902xROKJ13MP464CjnSxPJiMgmIQTHt3sRo0aBUWLFo04UqLhmmb6RIScEcG0Bx980B5TWYLzlEy6jz/+OJJJhxwADtOKFStahUmTJk2C0qVL56ge8ucMHT/kaNIBAoY4gLPRGE8W4XuKpvRUMDFmkIrxPWPo4xMuodyR44BS2/DfTpd7lqB1z5497fjJPF+xYoU9T6MuKrnmzJljBhn3Iw3o/T0qkkt4fPl/+/GJ5CMBJuQeybAh+ETFHgFxmDp1qgWbyNbZlXGaSpUyzPWMQQLT9FPhWOCll16y9RSjGKjwgd69e1v1hH+8bNkyBSiEiCFaS+OH7IvCI/tC9kVBkd+l8MjGSAzaG6ce2WqnJQIFKVKE6MGJDEy4YTKOWt/8OreBinwMA53gBNmFOHzTxYGWynAuqUjx557ziqRQbg1mee8NN9xgjpWwRAUyPlRZ4ADkJ1w5kU1QJUFZG5JPSF2hYfzcc8+ZPBZ9PKiyIFgBVArdfvvtljmLlrh3KqfzJE3fCYJVIvEQ+CIYxmahatWqOYKFbBwIinlH6K7Mm5kSZKJSgqDErFmz7DH3o0gtqLgjUzQaEhDq168fqaqk2oAsHeZW3+OnVatWtnfw2c2pDPM6WdmsBdyjo0ePtnWTADXHQYUE56J169aWgR1eBwg0ch8LIeKL1tLYIfsidsi+kH2RX+R3iT+yMQqP9sapT7bYaYlGQYoUY+LEiSZnQFUE1RF+0NNc94ILLohI4PjFFckbL2mAExRtWJ9NKGKzOHTt2jVo2LChSUgQZKARdrST0l8PghNcK2RTonnzzTetuiKbmgNF8+mnn5okAE7hMJwXSt7ImkUWigk/Gs55ugYogAANPTfS+RjSjdmzZ1uDdhqxIzHBuX/22WctG9tXPCG5xtijd8+vv/5qz/FejN5MhmP1De9yu99E8mHTut9++9mYZZ2n75GXtUPXPXoeRU4QmS4Cu35sM9Z79eoVGdupQm4VocuXLzfpPt8bxfeYYEPvpf5olo1UDFJQrMmcA2TL1NNHiPihtTT2yL7I37mSfZE3si8Kjvwu8UE2RsHQ3ji9yGQ7LdkoSJFAvDEevdHieX769u1rA5UmwBjpOI9wjjOAcZqRURgtbYOcEJn+0Q1aRMGJlnGhDMvLoHiZiR2BQ5Tr5ht5Rl9vmtJmGuGgDdUmfqxHO+Q5ds5nmTJlgvfff9+e89HkzZs3WzY7DiiCGWEyoSooE44hnbSyeUwPHyoo6MvD+PLSCgQoSpQoEXnuscces14oNPNkDj7mmGMyspEnmyMatdPLhfuMoKBvWi9Sc64gOYENbalSpSwjx0t1kZBAMgPlxOHPEVS/8MILI5tdNsKsSaky/+zoe7BmVqhQIUfPLWAvdPzxx0d6a5GcgXQZiRnsgYQQsUFraXyRfZF/ZF/s2rgS2yO/S2KRjVFwtDdOLzLZTksVFKRIAOFBF+1I8wsoWbv0kKBBsIcmK+XKlYvIkGCQ40hr3ry5OZlo0oxDjUzD8N8SBScc6EGWCaf6I488YlnWRENffPHFXK9j+DqTDYrkE9JPmSILkxvRQTHG34033miyTRMmTMjzc6tWrTK5nQYNGuT4rBCFnV83bdoUfPfdd5EqiNWrVwdt2rQJDjrooByfoUkVDnoatHt5PTSNO3XqlKM5eybqxjKPce898MADyf46IpexHL1m4JwvVqyYVQSFmTJliumcRo9XHPrsFVJtbvXJGB7WVTKObr31VpOrBDbyJASQtQ2+8vC1114Ldt99dwtM+MAiZPL6KkSi0VoaX2RfFOxcgewLkR/kd0kOsjHyj/bG6UUm22mphoIUcSR60JHVi5QNDtoWLVpYORD9JoBKCSQLgEqKvfbaK2jcuHFEox8oIyJggZY/GsxXXXVV5PMidpDZj1wTshM0w/Y6cjQuRy/b90fYUcTz888/z8hLQoNd5MiiodqHZkAnnXSSBXJwKu0ImvTSsNc3D4o+l3I+ibzwGQrR0Dy3UqVKlsVA74n33nsvMmYJ9o4dOzbyXsYb2to4RH1FTzSZWplG8+9MPbZ0JjwH4qy/6667rOrnyy+/tCwb+jCg7xuGABxzLgEnejbg3GdDHF1xGf33kwnfk6bY1apVs15P9NJiT+PvQzKSuH/DDB061HoZUf0jWSchYoPW0sQj+yJvZF+IwiK/S/KRjVEwtDdOfbLFTksVFKRIAAQWDjjgAMvcpUnwtddeawGIkiVLWikQ0Hti3333DcqXL2+DF20zD9nAZPn6XhM4cDNdLz1Z4NjEacL1IYiE/rWfNIiEkoU8YsSIXY58ZtqEM2/evGDSpEnbHRvyOZS0kcm+K2zcuDG49NJLLegjxM7gXiODmvuSkshwEAuHO7qPSDoR/KKSAq16HJ00hOZ1KnxoxhuWWqO/DxVP9GXI5HtWpA8+W5SSYcY6gTSfoHD44YdbibDvS+UrgpA7osqA8c+eok+fPkGqHhuBQiTVaBS3YMGCyJpC0gYbeeB5kjTISJo5c6ZVWRC4IPhNVpIQonD3odbS5CD7YsfIvhCxQn4XkS5ob5xeZLKdlmooSBFHcNhieJOtSxVFdNNkKiHQX0b2AKiyIJgRHYAYMGCABTPUUCW+Tdh4DoflFVdcketnqFrp0KFD0KRJk2Dx4sX23Ny5c3NMRplE+PxEB2QIMiCR4zPDqOwJl67tSjVEtO64ELlBkJbFHwgaRkOVEws/gVyviUq1D411uT+BvgtU+viAhB/PuxpUEyIRkGlDPxTGMvOvT0wAJB6ptvTyj9GN2+iXRJZOKpQP5zX30/sF3Vbu1+jj5p596qmn7DHHUq9ePatmxBBg3VU5tBCFQ2tpYpB9sXNkX4h4IL+LSGW0N05/MsVOSwcUpIgjn332mRnjPkMwWsuMUmv6SpDxSwACiZzq1avb+8kaRP6AjEMMdd+EWcR2kfDOTw+yE2R6MomMHj3aKgTI9qfHApMJmVA0xWaCQoMOCQp6UGQylLGFITiBQ+m8887L0U+FHhw+kJafiVfSTiIvuN+41yip9BDspaqJYASQbU0fFIJlBBhpyn799ddb8MJDNQUyegSMyWrQGBSp1JgWmDuptvSBNP+esDTXaaedZn0c2BzTvwoJwmj4XLI2vtHOOWQAcYx6KIvu0qWLST35PhS+ETZJGiQA+OA1a/Onn35qrwkhCofW0sQg+yJ/yL4QsUR+F5GKaG+cXmSynZZOFHUibtSuXdtdfvnlbtWqVe6JJ56IPL/bbrvZ70MOOcSdddZZbu3atW7u3LmuSZMm7sknn3QrVqxw/fr1c+3bt7f3ffTRR65Nmza6UjGC80+Arnv37q5x48buggsucLfddpu91qdPH/f111+76tWruxkzZrjFixfb+3v16uWmTp3q6tev7x588EHXtGlTd9FFF7lff/3VHXrooRl7bc4//3x36623up9//tk9/vjjNg5LlSrlOnbs6N555x33/vvvu9KlS9t5mT59uvv888/tc0WKFLHfkyZNcrNnz7Z/c85zw98PQkRz2GGHuWOOOca9/fbbNi/Ciy++6G6//Xb7DSeddJL77rvv3J577ul++uknm0tHjx7tKlSo4JYuXeqmTJli4/G8885z9957r6tatep2Y1FjUMSDbdu25Xj8999/21hkvDFWmVd5DjZt2uSKFy/uatSokWNMFitWLPL5O+64wz5z2WWXuU6dOrl69erZ8+HxzOf8/BtPcpvP+f8WLVrU1s0GDRrYGsnvvn372v1bokQJW285RtYTD/ck9+eGDRvcsGHD7LkyZcrYvc9rQojCobU0Mci+2HVkX4hYI7+LSDbaG6cXmWynpT3JjpJkOvSauPjii4Ozzz47WLt27XbVFKtWrbKO8E8//XTkM2QEk8lPUxZReDjf4YglmZ1ISdBfggoV5Lb22WefoFevXvY6GdpkW3MNvERX5cqVg/vvvz/yN8J/LxOb0Pps2LffftuaEVPNQ8+U++67z55fuXKljWmaFHuQ0yF6/Pzzz1tfgJdeeskizrfeeqsixiLf48+XUL7yyium++j790C7du1Mx97r2tOTgns4fF8yj1Ldw+e8NJkQyeDdd9/N8ZiG0VRNUoHG2Ga+BObLjh07Bv/973/tsd8nUFHg+6mwp6AxW7KycPLq2eK/D/qsNLjmnmQd5TEVo8hbetBnpZEcfZ88VE707Nkz0vNICBGb+1VrafyQfVGwcwayL0Q8kN9FJAPtjdObTLLTMgVVUsSZypUru1atWrkff/zRjR8/3p4j09BH33755Re3xx57uN133z3yGR7vt99+ls0vCgeRS843Ecvly5fbc/PmzXN77723e/fdd60y4JRTTrFI6ocffujWr19vEdKDDjrIlStXzpUsWdJNmDDBVaxY0Z1wwgmRv8vf+z+5tBwR1HTnn3/+sd+cM/jyyy/dxo0b7fxQKdGtWzd7vlq1alZNsWzZMjs/QPZ6+fLlXbt27VzLli2tEohKoqFDhypiLPIF449sBarQmDupiqByhx+49tprrQKNagrGZufOna2Sgsooshiefvppu1/ffPNNy+am+seTV0WPEPGA+bB///7ur7/+clu2bHFt27a1ah8q8h544AEbv6xDVAP17t3bKn9efvll+yz7hD///NMNHz7cPfXUU5E9xWmnnWZzqp+vE4G/b/zawD02atQoOxaOzWcFcTyXXnqpe+ihh2wdpTqCtfaVV15x//73v+09rVu3dvvvv7/9DaoRfeXEkCFD3MUXX5ywYxIi09FaGj9kX+QP2RciEcjvIhKJ9sbpT6bYaRlHsqMk2QAZvdddd531OiDS5iNvPI+u2cknn2z/FvEBDbnLL7/cmtlQzdK1a9dII056fpQtW9YyOH1UFD7++GOrrODa7L333tbwM1PhPERHeydOnBgsXLjQGmTTK4VKisGDB+fo4cFrnTp1skizh3GNJujs2bNzNHrPK8NAiLzG5O233x4ULVrU+kyQdU0/Ce5bP5ZuvPFG6w9DIyr4/PPPTdcePcgTTjjBsrWFSBZ+nA4aNCgyR6K/TZ8qr8NNVR/9VGrVqmVrDlB5yXOM4379+llVQt26dSN7h2RDv6wDDjjAson4XlQw3XzzzTkqC1knFi9ebH2bjjrqKKtCpMqO9ZS+FECPGJrbh6sphBCxRWtpfJF9sfPxJ/tCJBr5XUSi0d44/chUOy1TUJAiQcydO9eCFMiPeBjYtWvXjjTFVllQ7KGpLs51nJdMODhQBg4caM6RUqVKBRdccIE5Uzw4PJF4olknjpcBAwbkkHPKlGs0Y8aM4IknntiuMRASTQQkaIx95513RoISBNNo8M44jm7GeNhhhwU9evTI9f+TiVJYIv4sW7YsOOigg4LJkydHniPQyxhk3MJXX30VNGjQwGRlkGYLGydepg3UmF0kk2effdbWG+Qb+TebXy9ZRpN39gTh8cuci+O+ffv2QcuWLYORI0cGqcCmTZuCNm3aWLBwzJgxdp+xTtKknudWrFiRY+NPcJGg4vfff2/PcZ+WKFEiGDp0qD2mQbbf8Ash4oPW0vgh+yJ3ZF+IVEB+F5EItDdOfzLFTss0FKRIIGQGN2rUyLL2cewSeUOzTBSe3DL1iWiS8UkvhYceeijy/NSpU80BigMlDFUWZ511ViRo5HV8M9HZjgOJaolw4GXatGnBwQcfHNx9993mgNq8eXPk/Wj6H3744UG3bt2CdevW5TgvjGciyD5DVohdgXEXHUDwY5E+FPRCoZrHg749fVDYEPjNAhsDeqE8/PDD2/2NaK1oIeLJuHHjcmxi/ZqBocwm94svvjCnPP/efffdrYrvk08+ibz/o48+Ct56660ca014XUt2sI0KOTbuBCrC9OnTJyhZsmSOADaBiXAfJ9ZS1hyC3/yNcNWiEKJwaC2NL7Iv8ofsC5EqyO8i4o32xulDpttpmYZ6UiQQNM7QXx4zZozr0KGDW7FihWmWicKxdevWiE42unGeY445xnXq1Mn9/vvvOZ4/77zz3Omnn+7mz5/vhg0bZj0qJk+e7M444wx733HHHWfvQxM/0/pOcK6A/iiXXHKJHS9aekBPDnpv3HLLLXa8f/zxh9u8ebNbt26dafr36NHDzZo1yz377LNu9erVrkWLFtaTYtCgQW7BggWuRIkSST46kU7jEK1GtBzpA4NmPb89jEl0HMP3Nfr2J598svWZ8Nr29EXhfq1du3bks14b3/eiESLeLFq0yPXs2dM1b97cPffcc5HxB/Xr17e15OOPP3aHHHKI9U057LDDrJ9KnTp1Ir2p6Onz9ttv5/i7/A2/dvk+VsmCe4weQ/SJmTp1qj2HXuv9999v/WCqVq0aeS9rLvclfYxYV/r162e9Ze699147RnpCCSEKj9bS+CL7In/nCmRfiFRBfhcRb7Q3Tg+ywU7LOJIdJck25s+fnyNDX8QGSq+QHEKW6NFHHw1++umnSEYnOtiUbHnZCVi5cqVpYleoUCE47rjjrOICWahMJhztJfOOiDCa/pRmw7333htUq1bNKiMuuuii4Nxzz7UqFCR2KIEDenuQDbvXXnvZeaXMMVOrTUT84Z5F054xRmXZAw88EHmtatWqVrnz119/RZ6bMGFCUK5cOdOGXLBggS6RSBlYX8i6oYfRk08+GenJgyTSKaecEvTv398eI2FWsWLFoG3btrZWPffcc9bfgf4NzMmpzJo1a0yLtX79+pFqUGTYrrnmmuD00083SSdfUffCCy9YL5kqVapYX4oPP/ww2V9fiIxFa2n8kH2xc2RfiFRFfhcRb7Q3Tg+ywU7LJBSkEGnPI488EpQvX956fiDhhEzMTTfdFAlK4PgkEEGZVzQEM5YvX56jcXmmlWtFN67zck04k2gURPNrjLAffvjB+nXUq1fPSmTRHcexRACHZuOABBQyWkuXLk3a8Yj0g/EXNmKReyEIxqaAMks2CnfccYf16EEPEp555hkrt+S+5V5mvKJ/37Fjx2DUqFGRQCSoMbuIJ9HjK1pGzL9OGXGvXr2C/fbbzwJs/n00VyNQDozjN99808Y+Tnw2vn5jnA4gh0iAgu8f3TSQ+xdJy8cff9ye475etGhRkr6pEJmH1tLEIvtix8i+EEII7Y2Tjey0zENBCpE25KYvT1PAxo0bR5rpQvfu3S0Le8iQIZGgAzr2NMn2zvXcAhE8l2ka9uHjxDlG9QjO4SVLlthz48ePt0bZvg9HbtAHAAdybgtCpgV0RHwdKmQ00QuF58j8RP8RPv/8c6umQAfyxBNPjAQgCI7RzIp+KFQ9kcG9evVqXSaRFHKb73ILkA0bNsyCu8y1ZOg8+OCD5tiPXl8I1vlMnrz+fqrBOkL1BIEXAtZhCHTzWvHixdUUW4gYorU0vsi+yD+yL4QQ4n9ob5wayE7LHBSkEGlBXlJCv/32WzBz5sxIwKJ58+ZWxkWGKlJGvixr+vTpJjlBlms2QlZvly5dghNOOMECOPfdd1/kNWQ6cKZx/ryx9s0335jjmOxfmoxLWkfsjB1VM7BpICORIATNrnmvb5576623Bvvvv79JtT322GNBjRo1gkGDBtlrVDh9+eWX5uR9+umnc/zNTAsoitTll19+Maf8gAEDIo3dkcfL6x5gvLP2IJ9HEJ0AebNmzSKyedFjON0C5FQ/UbnoK+zCazRrshpjC1FwtJYmFtkXhUP2hRBCaG+cTGSnZR4KUoiUYkeOGnp5IENElmq0w5KMbLTi2rdvb5JEb731lvVNIFvbQ4YnunLZBOfirLPOsix1AjX33HOPBR3IVp83b5695+233zbd8Pvvv9+cZe+8846dK55r0aKFZQILsav3LNJMYaMf+aYmTZoEV199tY3BMIw9pNhefvlle7xhw4agcuXKpnW/ePHiXP9/6ZBtLjJvfBMoK126tFXzIEPmJY125GRkfDOXFilSxH7CfZHSHdZi+hK99NJL9liSa0IUDq2l8UX2RWyRfSGEEDnR3jjxyE7LTIolu3G3EGGKFCmS4/G2bdtc0aJF3bRp01yHDh3cIYcc4mrVquXuuecet2DBAtelSxd38MEHuxkzZri//vrL3Xvvva5cuXKuVKlSrnjx4m7KlCnuhBNOcG3btnWjR4+2v5WJ/F/A0Y6P3/48bty40S1evNiO/ZxzzrHn6tev76699lo7p3Xr1nWnnHKKa9q0qXvuuefcySef7E466ST366+/uuuuu87VqVPHPrN161a32267JfUYReoRHmsvvPCCe/jhh93ee+/tatSo4bp27eqqVq3qjj/+eNeuXTu3zz77uD59+uQYT4sWLXLff/+9a9iwoT3/2Wef2f3M+HvllVdczZo1t/t/aRyKRMKYY7wuX77cxuWGDRvcb7/95ooVy3v75NcZ5lbmVChfvryrVKmSyxRYU2fPnm3ryNlnn637UohCoLU0/si+KBiyL4QQYtfQ3jjxyE7LTDLTYyvSliVLlrhbbrnFHOve2UOgYuzYsa579+5u/vz57pFHHnHXXHONGzdunJszZ469b/369a5ChQpu06ZN9njmzJnu3HPPtffhdPd/i812poEDjQma4yNQEzbEli1b5v755x93+OGH22OOnyBFo0aNLIAzd+5ce37QoEEW9CHYw+ebNWtmAQrerwCFyAvGyjfffONOPfVUCxgybi677DLXqlUrC1Awfggs9uzZ0/3xxx8WNAMfaCBwwX1L8GLSpEmuV69erkWLFm769Onu5ptv3u7/JUQiYM3xPPnkk+7EE090u+++uxs8eLD7+uuvLbgW/b4dzc1jxoxxd911l8skjjrqKEsW4NgUOBSicGgtjT+yL/KP7AshhNh1tDdODLLTsoBkl3KI7CU3eQj6S6BPP2rUqMjryBIdc8wxJvNCrwT6J5QrV86aOf/888/2nilTpgS1a9cOjjzySHsvWuDRTT0znX79+gVnnnlmcO211waTJ0+OSGSVLFkyGDt2rD32MjyLFi0KihUrFnTo0CEiQfLaa6/lqc0rRG5s2bIlOO+884K2bdtu19AabfoPPvjA/s29zD1L3wme92zcuNHk25Aj4571vSg8kpARyYI5Euk7JO/GjRtn6w+N8c4++2zr7VOQcuR06jshhEgcWktji+yL2CL7QgghRCohOy2zUZBCpARh5w2Oc5qU4iCChQsXmkP9hhtuMEdn69atg6+//jry/lWrVtnvDz/80BqbDhkyJKscnWvWrDGnWa1atYIRI0ZYQ9Py5csHw4cPt9dxDFeqVClYv3595DMELY444oigQYMGwb///e+sOl8idtAbhmbYaO+H7+GhQ4cG++67r/WioAG71/QvVapUpBdKmLVr11qTbI/GoEgkuY03eqPstttu1kslzPz584MSJUoETz31VAK/oRAik9FaGj9kXxQc2RdCCCGSjey07ENBCpE0cI4feOCBwZNPPhl89913kee//PLL4KijjgpuvfVWa8z2119/BY0bNzYHp3d4hpvyEpTgfdFkQlVAdOZtbpm4NAM/9thjg5UrV9pjMtUJVuy5557BV199ZRl6NMtu1KiRPU/VCf9+4YUXLLDRt2/fPP+2EDuiW7dudq+Guf76660qgqb1NMUOBw1r1qwZtGnTxioochtzZKtrHIpEsaMm7O+++641u77xxhtzPM961L1796BixYoWXNu0aVMwcuTIYMmSJQn4xkKITERraWyRfbFzZF8IIYRIZWSnZS/qSSGSxqxZs9y3337rhg4dak2dP//8c/f7779b/4QLLrjAvfrqq+7dd981LfA2bdpYs1L0wNeuXev+/vtv9+yzz7o777zTPrPHHnvk+NsE4HbU2DSddIr//PNP98Ybb0QeR0P/Dhq6VqtWzR6XLFnS3XDDDe7QQw91d9xxhytdurRp/NMb4LHHHrPeAfQQ4BxXrFjRffLJJ3n+bSF2xKpVq+zeo/m1B+39L774wvTq6Wvy1ltvRXqf3H///dZ74qOPPsp1zKFtr3EoEoXvpcBacuWVV7q+ffu6pUuXWm8fmrk3b97cvfnmmzbOPaxHvXv3dmXLlrUeLDTDfvnll623ihBCFAStpbFF9sXOkX0hhBAilZGdlsUkO0oisqs8K5y5Q38JJGG6dOkStGrVyjKyL7nkEouakq160kknBVdccUXwww8/2Pt79uwZVKhQITj88MOD+vXrB2XLljUJmUyGahAy09Hs/+KLL3I9p/TvqFu3rmnzhV8fPHiwPe/7dsCGDRtMVx2WL19u5/z5559P4BGJTIL7D+mbN954I/Ic489nPixYsMAyznv16mX9UYAKHiFSASrw6HHEOtS1a9fg4IMPtqo03xuF6rSiRYsG999/v61J4TWMHiyPPfZYjrEvhBAFQWtp/pF9UThkXwghhEhlZKdlL6qkEHGlaNH/DbFFixbZ73CWdI0aNVynTp0sC3XUqFH2M2/ePNegQQM3c+ZMd/3117slS5a4adOm2fuHDRtm/yZTu0OHDm7jxo1WFQDbtm3LyCtJNcjZZ5/typcv7x5//PEc55RqETjmmGOsemLKlCk5XqfC4sADD3RlypSJnB+y3qmcGDhwoDvttNPcwQcfbL+FKAi+Guehhx6KVFMw/nzmg7/PGzdu7IoXLx75THj8CpEIchtvVOpRnffOO+9Ylc+CBQusqm/cuHFW7UN1GmvM8OHD3VdffRVZw/hbBxxwgLv66qsj8+fWrVt1IYUQBUJraf6RfVE4ZF8IIYRIFWSniTAKUoi48scff7hjjz3WZIbCE5D/feutt5qcEdIwTZs2NWmNc88916Q3Xn/9dbdhwwaTilm4cKG9v169eu7CCy+0IAWyG//8808Ox3wmQpDihBNOsADOnDlz7DmCDj7gc/rpp1tgZ/LkyW7AgAHmTON9n376acSB5s8PjjRktSiFx/FG0GffffdN4tGJdAapm/79+7sXXnjBAl+bN282WbZNmzbZPY9M29FHH+2OP/747T4rWSeRCHzwIDzefNB2+fLltkZVr17dHpcrV85deumlrnbt2jY/AsELxvTIkSNNVi/6b/m1LByYE0KI/KC1NP/Ivig8si+EEEIkE9lpIleSXcohMofcGt4iQYTcy7JlyyLviW6CM2HChGD33Xc3aRjPtGnTgmuuucYal/Lz6KOP7tL/L1NZuHBh0KxZs6B9+/aRhuCUuvtydySxRo8eHZQpU8aaYfO7T58+uf6tX375JaHfXWQ+NLnfb7/9guLFi5vE2PHHHx+UL18+GDt2bLK/mshSoqVAXnnllWD48OHWENszcOBAkw5csWJFjvf27t07aNGiRfDjjz/a44ceeiho2bJl8NtvvyXo2wshshGtpbkj+yJ+yL4QQgiRaGSniR1RhP/kHr4QIv9QFTF//vxIBv/YsWPdU089ZRUS4UbWv/zyizV17tWrl9t7773dySefbFmsSBaVKFEi8r4HHnjApIyuueaarL8cZPLSdLhz587u8ssvtwxen9G7fv16V6pUKassQSLriCOOcPvss08kaziTK01E8mEsrlmzxs2YMcMyIpB2uvbaayOvawyKZPH333/bfEn1GPJNjNMzzzzTmmVTdXbccce5e++9197j1yikBj/++GP3wQcfaO4UQiQMraV5I/sifsi+EEIIkQxkp4nc+P9eYyEKCQ7y7t27myzRM88842rVqmUBihNPPDFHgAIZjcGDB5tzCBkNghQ8R2ADR9L5558fccB37do18rlsd3S2bdvWvf/++xaoaNasmatQoYL76aefTFbnvvvus3N/0003mfQT4CzmfGXzOROJo2rVqtZjJnpO4N7XGBTJAAkyHFv09CEgQfBs6dKlrkmTJq5fv34WKKevBHKDSIe0a9fOghhI5bVu3Xq7ccucKlknIUQ80Vq6PbIv4ovsCyGEEIlGdprIC3kvRcybsBF0mDhxovvuu++s/8FFF10UeQ8NSmmU/cgjj1jPiSpVqtjz9evXd61atbIMVnS/o/XqCVpku6OzcuXKdo7Q+x8/frxVp1CBwgTfs2dPC1CEwZkm3X+RCHIbZ9yz4eCkEPGC4EF0UejGjRutKfbQoUNtTaH3TpkyZWytoY/KhAkTrCcFr9MPqW/fvha8IKhOU2zWomgUoBBCxBOtpbkj+yK+yL4QQggRL2SnifwiuScRc2iGTSYqm961a9e6J5980u2///6R1//66y/LaI1m3bp1JrFBoEPkDlnBN954owUpKI9D+unBBx+MvJ7t1SZCiOwiLHu3evVqV7Fixcj6QlD8yiuvtOAD0oNUS+yxxx72GkELqim6detma9KKFSvcsmXL3MEHH+yOOeaY7f62EEKI5CL7In7IvhBCCBFrZKeJgqAghYg5n3zyievTp4+bPXu2PT7ssMNc3bp1XfPmzd0JJ5xg/RJEwZk7d66dWwIUBx54YA5ZHSGEyAbCAVmC4cg2LVq0yOZEKs5wZpG5g7QgPytXrrQABs8BsngNGzY0Le7c/jYo4CuEEKmD7Iv4IvtCCCFELJCdJgqDghQiLtCIlN4JNWvWtCaljz/+uFuwYIFlsiKlQT+Kxo0bW5arKDi+74SyfYUQ2ciSJUtsraHnxCWXXGLNrukx8a9//csCFRs2bHDnnnuu6bxT1UcFxWeffWYVe48++qj19wmj6gkhhEhdZF8kBtkXQgghCovsNFEQlHot4sLFF1/s3nvvPffDDz9YkIImpD/++KNNVDR/pp+Cl9QQBY9QSyNdCJEtRMvZ0UdiyJAh7qSTTnLPPvusq1atmjvnnHNcqVKl3OTJk62Cj6qKHj16WI+JY4891nokjRs3zt5HJUU0CvgKIUTqIvsi/si+EEIIUZC1Q3aaiAWqpBBxg+bZ9Eto2bKl6927tz2nLFUhhBAFhSqIsmXLuurVq7ulS5e6Sy+91DbEBMXpRUGQgYq9Ro0auXr16tka9J///McNGDDAvfXWW+7FF1807W0CG0IIIdIP2RdCCCFE6iE7TcQCddgVcePCCy90Rx99tBkTNNIGHEgEKsBrgwshhBDR5LZGIM+ElNPff//tjjzySJMM/Pzzz92qVatsfaE/D82xzzrrLNPXhho1alg13++//+4WLlxoAQqaZWsNEkKI9EP2hRBCCJFcZKeJeKEghYgbJUqUMEOCH5xE0XIakioSQgjhA9fRhNcI/56xY8e6mTNnurffftvWknbt2rlatWq5nj17WplxsWL/U7Fcs2aNO+KII6xqwjfK5r1UVBCgoOpCa5AQQqQfsi+EEEKIxCA7TSQayT0JIYQQIun6pfPmzbMKieOPP96VLl3aehh16tTJGmNXqlQp8pmmTZuapNP06dNduXLl3EsvvWTB8PPOO89+f//99xaMoIH2ddddF/kcklD0qBg2bJi76qqrknK8QgghhBBCCJHqyE4TyUCVFCJhE5wQQgiRYxNStKhbtGiR9ZBAuumFF15wK1assNcqVqzoPv74Y/fQQw/l+Mx9991nAQ3eC02aNLHP0m9i5cqVbtq0ae6pp56KBCh8BtBxxx3nPvroIwUohBAiQ5B9IYQQQsQH2WkiGShIIRIz0P4vU1YIIYTwgQMaW5955pnWv4jKiG7durk6derYa+XLl3cPPPCAGzlypFu8eHHEIUUviiuuuMKNGDHCelGUKlXKAhIlS5a0wAZSUOeff779P3i/lxhEIqRatWo6+UIIkSHIvhBCCCFii+w0kUzkORZCCCFEQiFwsGXLFjd58mR32223WbCCHhKHHnpojvd16NDBnh80aJA1xfYOqQoVKrgvv/zSjRkzxgIRdevWdZ07d7a/5ftQgBxYQgghhBBCCCE7TaQ+ClIIIYQQIuG8//77ViFx6qmnRp775ptv3BdffGGyTOvWrbNgxt13323BjKlTp1ovCti6dau77LLL7PP0saAJNkGK3377zaoxwFdQCCGEEEIIIYSQnSZSGzXOFkIIIUTC+f33391+++3nLrroIteiRQvrJbFmzRq3fv16q5KoV6+eGzt2rElB0UD7ueeecw0bNrT30DB71qxZbs8998xRmjxx4kRXpkwZd+655+qKCiGEEEIIIYTsNJEmKEghhBBCiKQwadIkN3r0aPfJJ59YRUXTpk3d4Ycfbq8NHDjQ+k3Mnj3bAhBPPvmke+edd1z16tVN1smDDFSxYsV0BYUQQgghhBBCdppIUxSkEEIIIUTS+Pnnn02uiYBEOODQpUsX9/HHH1tD7f3339+eo/+E7zOB5BOfE0IIIYQQQgghO02kN0o9FEIIIUTSKFu2bOTfPkDxyy+/WH+KJk2aRAIUQICCqgpQgEIIIYQQQgghZKeJzECNs4UQQgiRdLZs2eI2bNjg5syZ45o1a2aNs1u3br3d+2iIrabYQgghhBBCCBF/ZKeJRKFKCiGEEEIklc2bN7s2bdrYvz/77DP797333qurIoQQQgghhBBJQnaaSCTqSSGEEEKIpEODbCSezj33XFe5cmV7Tn0nhBBCCCGEECJ5yE4TiUJBCiGEEEKkFAQn6D8hWSchhBBCCCGESA1kp4l4oiCFEEIIIVIGGmMrOCGEEEIIIYQQqYPsNBFvFKQQQgghhBBCCCGEEEIIIURSKJqc/60QQgghhBBCCCGEEEIIIbIdBSmEEEIIIYQQQgghhBBCCJEUFKQQQgghhBBCCCGEEEIIIURSUJBCCCGEEEIIIYQQQgghhBBJQUEKIYQQQgghhBBCCCGEEEIkBQUphBBCCCGEEEIIIYQQQgiRFBSkEEIIIYQQQgghhBBCCCFEUlCQQgghhBBCCCGEEEIIIYQQSUFBCiGEEEIIIYQQQgghhBBCJAUFKYQQQgghhBBCCCGEEEII4ZLB/wODtOsudS14ZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the selected sampler's models for overfitting index comparison\n",
    "overfitting_index_plot(selected_models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating feature importance for TPE...\n",
      "âœ“ Saved TPE feature importance to: ../artifacts/ds1/models/tpe/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for GP...\n",
      "âœ“ Saved GP feature importance to: ../artifacts/ds1/models/gp/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for CMA-ES...\n",
      "âœ“ Saved CMA-ES feature importance to: ../artifacts/ds1/models/cmaes/sel-nnml_feature_importance.csv\n",
      "Calculating feature importance for QMC...\n",
      "âœ“ Saved QMC feature importance to: ../artifacts/ds1/models/qmc/sel-nnml_feature_importance.csv\n",
      "\n",
      "All feature importance data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save feature importance results for all samplers\n",
    "import os\n",
    "\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    # Set the sampler\n",
    "    temp_sampler = sampler\n",
    "    temp_models = all_models[temp_sampler]\n",
    "    temp_sel_nnml = temp_models['SEL-NNML']\n",
    "    \n",
    "    # Calculate permutation importance for this sampler\n",
    "    print(f\"Calculating feature importance for {temp_sampler}...\")\n",
    "    temp_perm_importance = permutation_importance(\n",
    "        temp_sel_nnml, X_test, y_test,\n",
    "        n_repeats=30, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Create dataframe\n",
    "    temp_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns.tolist(),\n",
    "        'Importance Mean': temp_perm_importance.importances_mean,\n",
    "        'Importance Std': temp_perm_importance.importances_std\n",
    "    }).sort_values('Importance Mean', ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    sampler_folder = temp_sampler.lower().replace(\"-\", \"\")\n",
    "    os.makedirs(f'../artifacts/ds1/models/{sampler_folder}', exist_ok=True)\n",
    "    importance_save_path = f'../artifacts/ds1/models/{sampler_folder}/sel-nnml_feature_importance.csv'\n",
    "    temp_importance_df.to_csv(importance_save_path, index=False)\n",
    "    print(f\"âœ“ Saved {temp_sampler} feature importance to: {importance_save_path}\")\n",
    "\n",
    "print(\"\\nAll feature importance data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3 Save All Models Metrics (All Samplers)**\n",
    "\n",
    "This section calculates and saves performance metrics for all models across all samplers. This data will be used for cross-sampler comparisons in the visualization notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for all models across all samplers + baseline models...\n",
      "\n",
      "Processing BASELINE models...\n",
      "  âœ“ Logistic Regression (Default): Acc=0.8867, AUC=0.9577\n",
      "  âœ“ Decision Tree (Default): Acc=0.8600, AUC=0.8621\n",
      "  âœ“ Random Forest (Default): Acc=0.8800, AUC=0.9512\n",
      "  âœ“ K-Nearest Neighbors (Default): Acc=0.8733, AUC=0.9311\n",
      "  âœ“ Support Vector Machine (Default): Acc=0.9067, AUC=0.9490\n",
      "  âœ“ AdaBoost (Default): Acc=0.8800, AUC=0.9583\n",
      "  âœ“ Gradient Boosting (Default): Acc=0.8867, AUC=0.9597\n",
      "  âœ“ Stacking + Linear Regression: Acc=0.9000, AUC=0.9535\n",
      "  âœ“ Stacking + Default MLP: Acc=0.9000, AUC=0.9528\n",
      "\n",
      "Processing TPE models...\n",
      "  âœ“ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  âœ“ Decision Tree: Acc=0.8933, AUC=0.9354\n",
      "  âœ“ Random Forest: Acc=0.9000, AUC=0.9563\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.9133, AUC=0.9508\n",
      "  âœ“ Support Vector Machine: Acc=0.8600, AUC=0.9594\n",
      "  âœ“ AdaBoost: Acc=0.8933, AUC=0.9640\n",
      "  âœ“ Gradient Boosting: Acc=0.9067, AUC=0.9656\n",
      "  âœ“ SEL-NNML: Acc=0.9400, AUC=0.9631\n",
      "\n",
      "Processing GP models...\n",
      "  âœ“ Logistic Regression: Acc=0.8933, AUC=0.9513\n",
      "  âœ“ Decision Tree: Acc=0.8933, AUC=0.9354\n",
      "  âœ“ Random Forest: Acc=0.8867, AUC=0.9540\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.9133, AUC=0.9495\n",
      "  âœ“ Support Vector Machine: Acc=0.8600, AUC=0.9595\n",
      "  âœ“ AdaBoost: Acc=0.8800, AUC=0.9647\n",
      "  âœ“ Gradient Boosting: Acc=0.8800, AUC=0.9601\n",
      "  âœ“ SEL-NNML: Acc=0.9200, AUC=0.9613\n",
      "\n",
      "Processing CMA-ES models...\n",
      "  âœ“ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  âœ“ Decision Tree: Acc=0.8867, AUC=0.9312\n",
      "  âœ“ Random Forest: Acc=0.9133, AUC=0.9599\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.9133, AUC=0.9506\n",
      "  âœ“ Support Vector Machine: Acc=0.8400, AUC=0.9519\n",
      "  âœ“ AdaBoost: Acc=0.8933, AUC=0.9645\n",
      "  âœ“ Gradient Boosting: Acc=0.9067, AUC=0.9588\n",
      "  âœ“ SEL-NNML: Acc=0.9267, AUC=0.9613\n",
      "\n",
      "Processing QMC models...\n",
      "  âœ“ Logistic Regression: Acc=0.9000, AUC=0.9531\n",
      "  âœ“ Decision Tree: Acc=0.8933, AUC=0.9243\n",
      "  âœ“ Random Forest: Acc=0.8800, AUC=0.9494\n",
      "  âœ“ K-Nearest Neighbors: Acc=0.9133, AUC=0.9495\n",
      "  âœ“ Support Vector Machine: Acc=0.8600, AUC=0.9602\n",
      "  âœ“ AdaBoost: Acc=0.8933, AUC=0.9479\n",
      "  âœ“ Gradient Boosting: Acc=0.8933, AUC=0.9624\n",
      "  âœ“ SEL-NNML: Acc=0.9200, AUC=0.9617\n",
      "\n",
      "âœ… Saved metrics for 41 model configurations\n",
      "   - Metrics: ../artifacts/ds1/models/all_models_metrics.csv\n",
      "   - ROC Data: ../artifacts/ds1/models/all_models_roc_data.csv\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: Top 5 Models by Accuracy\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sampler",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUC",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f51a09cd-9122-4bae-8f05-774502dd41e4",
       "rows": [
        [
         "16",
         "TPE",
         "SEL-NNML",
         "0.94",
         "0.9426751592356688",
         "0.9630950258513103"
        ],
        [
         "32",
         "CMA-ES",
         "SEL-NNML",
         "0.9266666666666666",
         "0.9290322580645162",
         "0.9613121768586201"
        ],
        [
         "24",
         "GP",
         "SEL-NNML",
         "0.92",
         "0.9230769230769231",
         "0.96131217685862"
        ],
        [
         "40",
         "QMC",
         "SEL-NNML",
         "0.92",
         "0.927710843373494",
         "0.9616687466571582"
        ],
        [
         "12",
         "TPE",
         "K-Nearest Neighbors",
         "0.9133333333333333",
         "0.9171974522292994",
         "0.9507933678017472"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TPE</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.963095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>0.961312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GP</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.961312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>QMC</td>\n",
       "      <td>SEL-NNML</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.961669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TPE</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.950793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampler                Model  Accuracy  F1-Score       AUC\n",
       "16     TPE             SEL-NNML  0.940000  0.942675  0.963095\n",
       "32  CMA-ES             SEL-NNML  0.926667  0.929032  0.961312\n",
       "24      GP             SEL-NNML  0.920000  0.923077  0.961312\n",
       "40     QMC             SEL-NNML  0.920000  0.927711  0.961669\n",
       "12     TPE  K-Nearest Neighbors  0.913333  0.917197  0.950793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and save metrics for ALL models from ALL samplers + BASELINE models\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "\n",
    "print(\"Calculating metrics for all models across all samplers + baseline models...\")\n",
    "\n",
    "all_metrics_data = []\n",
    "all_roc_data = []\n",
    "\n",
    "# Process baseline models first\n",
    "print(\"\\nProcessing BASELINE models...\")\n",
    "baseline_models_dict = {\n",
    "    **{f\"{name} (Default)\": model for name, model in default_base_models.items()},\n",
    "    'Stacking + Linear Regression': stacking_lr,\n",
    "    'Stacking + Default MLP': stacking_mlp\n",
    "}\n",
    "\n",
    "for model_name, model in baseline_models_dict.items():\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get probability predictions for AUC and ROC\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_metrics_data.append({\n",
    "        'Sampler': 'Baseline',\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    # Store ROC curve data\n",
    "    for f, t in zip(fpr, tpr):\n",
    "        all_roc_data.append({\n",
    "            'Sampler': 'Baseline',\n",
    "            'Model': model_name,\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "    \n",
    "    print(f\"  âœ“ {model_name}: Acc={accuracy_score(y_test, y_pred):.4f}, AUC={roc_auc:.4f}\")\n",
    "\n",
    "# Process optimized models\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    print(f\"\\nProcessing {sampler} models...\")\n",
    "    models = all_models[sampler]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Get probability predictions for AUC and ROC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(X_test)\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Store metrics\n",
    "        all_metrics_data.append({\n",
    "            'Sampler': sampler,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-Score': f1_score(y_test, y_pred),\n",
    "            'AUC': roc_auc\n",
    "        })\n",
    "        \n",
    "        # Store ROC curve data\n",
    "        for f, t in zip(fpr, tpr):\n",
    "            all_roc_data.append({\n",
    "                'Sampler': sampler,\n",
    "                'Model': model_name,\n",
    "                'FPR': f,\n",
    "                'TPR': t\n",
    "            })\n",
    "        \n",
    "        print(f\"  âœ“ {model_name}: Acc={accuracy_score(y_test, y_pred):.4f}, AUC={roc_auc:.4f}\")\n",
    "\n",
    "# Create DataFrames\n",
    "all_metrics_df = pd.DataFrame(all_metrics_data)\n",
    "all_roc_df = pd.DataFrame(all_roc_data)\n",
    "\n",
    "# Save to CSV files\n",
    "os.makedirs('../artifacts/ds1/models', exist_ok=True)\n",
    "all_metrics_df.to_csv('../artifacts/ds1/models/all_models_metrics.csv', index=False)\n",
    "all_roc_df.to_csv('../artifacts/ds1/models/all_models_roc_data.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Saved metrics for {len(all_metrics_data)} model configurations\")\n",
    "print(f\"   - Metrics: ../artifacts/ds1/models/all_models_metrics.csv\")\n",
    "print(f\"   - ROC Data: ../artifacts/ds1/models/all_models_roc_data.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: Top 5 Models by Accuracy\")\n",
    "print(\"=\"*80)\n",
    "display(all_metrics_df.nlargest(5, 'Accuracy')[['Sampler', 'Model', 'Accuracy', 'F1-Score', 'AUC']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **SECTION 7: Statistical Significance Testing**\n",
    "\n",
    "Perform paired t-tests to compare SEL-NNML (TPE) against all other 12 models using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.1 Prepare All 13 Models for Statistical Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODELS PREPARED FOR PAIRED T-TEST\n",
      "================================================================================\n",
      "Total models: 13\n",
      "\n",
      "Baseline Models (9):\n",
      "  1. Logistic Regression (Default)\n",
      "  2. Decision Tree (Default)\n",
      "  3. Random Forest (Default)\n",
      "  4. K-Nearest Neighbors (Default)\n",
      "  5. Support Vector Machine (Default)\n",
      "  6. AdaBoost (Default)\n",
      "  7. Gradient Boosting (Default)\n",
      "  8. Stacking + Linear Regression\n",
      "  9. Stacking + Default MLP\n",
      "\n",
      "Optimized SEL-NNML Models (4):\n",
      "  10. SEL-NNML (TPE)\n",
      "  11. SEL-NNML (GP)\n",
      "  12. SEL-NNML (CMA-ES)\n",
      "  13. SEL-NNML (QMC)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Collect all 13 models for paired t-test\n",
    "models_for_ttest = {}\n",
    "\n",
    "# Add 9 baseline models (7 base learners + 2 stacking)\n",
    "models_for_ttest.update({\n",
    "    f\"{name} (Default)\": model \n",
    "    for name, model in default_base_models.items()\n",
    "})\n",
    "models_for_ttest['Stacking + Linear Regression'] = stacking_lr\n",
    "models_for_ttest['Stacking + Default MLP'] = stacking_mlp\n",
    "\n",
    "# Add 4 optimized SEL-NNML models\n",
    "for sampler in ['TPE', 'GP', 'CMA-ES', 'QMC']:\n",
    "    sel_model = all_models[sampler]['SEL-NNML']\n",
    "    models_for_ttest[f\"SEL-NNML ({sampler})\"] = sel_model\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODELS PREPARED FOR PAIRED T-TEST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total models: {len(models_for_ttest)}\")\n",
    "print(\"\\nBaseline Models (9):\")\n",
    "for i, name in enumerate(list(models_for_ttest.keys())[:9], 1):\n",
    "    print(f\"  {i}. {name}\")\n",
    "print(\"\\nOptimized SEL-NNML Models (4):\")\n",
    "for i, name in enumerate(list(models_for_ttest.keys())[9:], 10):\n",
    "    print(f\"  {i}. {name}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.2 Cross-Validation for All Models (10-Fold)**\n",
    "\n",
    "Run 10-fold stratified cross-validation on all 13 models to generate paired samples for statistical testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RUNNING 10-FOLD CROSS-VALIDATION FOR ALL 13 MODELS\n",
      "================================================================================\n",
      "Metric: accuracy\n",
      "This will generate 10 paired samples for each model...\n",
      "================================================================================\n",
      "\n",
      "[1/13] Evaluating Logistic Regression (Default)... Mean=0.8424, Std=0.0423 (Time: 0.04s)\n",
      "[2/13] Evaluating Decision Tree (Default)... Mean=0.7686, Std=0.0577 (Time: 0.03s)\n",
      "[3/13] Evaluating Random Forest (Default)... Mean=0.8558, Std=0.0483 (Time: 0.27s)\n",
      "[4/13] Evaluating K-Nearest Neighbors (Default)... Mean=0.8325, Std=0.0509 (Time: 0.03s)\n",
      "[5/13] Evaluating Support Vector Machine (Default)... Mean=0.8491, Std=0.0398 (Time: 0.06s)\n",
      "[6/13] Evaluating AdaBoost (Default)... Mean=0.8340, Std=0.0509 (Time: 0.12s)\n",
      "[7/13] Evaluating Gradient Boosting (Default)... Mean=0.8557, Std=0.0454 (Time: 0.19s)\n",
      "[8/13] Evaluating Stacking + Linear Regression... Mean=0.8507, Std=0.0435 (Time: 3.22s)\n",
      "[9/13] Evaluating Stacking + Default MLP... Mean=0.8507, Std=0.0461 (Time: 3.41s)\n",
      "[10/13] Evaluating SEL-NNML (TPE)... Mean=0.8625, Std=0.0429 (Time: 5.72s)\n",
      "[11/13] Evaluating SEL-NNML (GP)... Mean=0.8591, Std=0.0425 (Time: 1.35s)\n",
      "[12/13] Evaluating SEL-NNML (CMA-ES)... Mean=0.8591, Std=0.0285 (Time: 3.88s)\n",
      "[13/13] Evaluating SEL-NNML (QMC)... Mean=0.8358, Std=0.0490 (Time: 0.91s)\n",
      "\n",
      "================================================================================\n",
      "âœ“ Cross-validation completed in 19.23 seconds (0.32 minutes)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# Configuration for statistical testing\n",
    "N_FOLDS_TTEST = 10  # Use 10-fold CV for better statistical power\n",
    "METRIC = 'accuracy'  # Primary metric for comparison\n",
    "\n",
    "# Create StratifiedKFold to ensure all models are evaluated on the same folds\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS_TTEST, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"RUNNING {N_FOLDS_TTEST}-FOLD CROSS-VALIDATION FOR ALL 13 MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Metric: {METRIC}\")\n",
    "print(f\"This will generate {N_FOLDS_TTEST} paired samples for each model...\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "cv_scores = {}\n",
    "cv_start_time = time.time()\n",
    "\n",
    "for idx, (name, model) in enumerate(models_for_ttest.items(), 1):\n",
    "    model_start = time.time()\n",
    "    print(f\"[{idx}/13] Evaluating {name}...\", end=\" \", flush=True)\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        model, X_train, y_train, \n",
    "        cv=skf, \n",
    "        scoring=METRIC,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "    \n",
    "    cv_scores[name] = scores\n",
    "    model_time = time.time() - model_start\n",
    "    \n",
    "    print(f\"Mean={scores.mean():.4f}, Std={scores.std(ddof=1):.4f} (Time: {model_time:.2f}s)\")\n",
    "\n",
    "total_cv_time = time.time() - cv_start_time\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ“ Cross-validation completed in {total_cv_time:.2f} seconds ({total_cv_time/60:.2f} minutes)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.3 Perform Paired t-tests**\n",
    "\n",
    "Compare SEL-NNML (TPE) against all other 12 models using paired t-tests with Bonferroni correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PAIRED T-TEST: SEL-NNML (TPE) vs. ALL OTHER MODELS\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Control Mean Accuracy: 0.8625 Â± 0.0429\n",
      "Number of Comparisons: 12\n",
      "Significance Level (Î±): 0.05\n",
      "Multiple Testing Correction: Bonferroni (adjusted Î± = 0.0042)\n",
      "================================================================================\n",
      "\n",
      "Model                                    Mean Diff    t-stat     p-value      p (Bonf.)    Sig?    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Decision Tree (Default)                       0.0939      5.669      0.0003      0.0037        âœ“\n",
      "AdaBoost (Default)                            0.0284      3.281      0.0095      0.1141        âœ—\n",
      "SEL-NNML (QMC)                                0.0266      2.176      0.0575      0.6906        âœ—\n",
      "Logistic Regression (Default)                 0.0201      2.087      0.0665      0.7983        âœ—\n",
      "K-Nearest Neighbors (Default)                 0.0299      2.030      0.0729      0.8748        âœ—\n",
      "Random Forest (Default)                       0.0066      0.637      0.5401      1.0000        âœ—\n",
      "Support Vector Machine (Default)              0.0133      1.119      0.2922      1.0000        âœ—\n",
      "Gradient Boosting (Default)                   0.0068      0.741      0.4774      1.0000        âœ—\n",
      "Stacking + Linear Regression                  0.0118      1.137      0.2849      1.0000        âœ—\n",
      "Stacking + Default MLP                        0.0117      1.246      0.2441      1.0000        âœ—\n",
      "SEL-NNML (GP)                                 0.0034      0.428      0.6786      1.0000        âœ—\n",
      "SEL-NNML (CMA-ES)                             0.0034      0.429      0.6781      1.0000        âœ—\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Define the control/proposed method\n",
    "CONTROL_MODEL = 'SEL-NNML (TPE)'\n",
    "ALPHA = 0.05\n",
    "\n",
    "if CONTROL_MODEL not in cv_scores:\n",
    "    raise ValueError(f\"Control model '{CONTROL_MODEL}' not found in cv_scores\")\n",
    "\n",
    "control_scores = cv_scores[CONTROL_MODEL]\n",
    "n_comparisons = len(models_for_ttest) - 1  # Exclude comparison with itself\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"PAIRED T-TEST: {CONTROL_MODEL} vs. ALL OTHER MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Control Mean Accuracy: {control_scores.mean():.4f} Â± {control_scores.std(ddof=1):.4f}\")\n",
    "print(f\"Number of Comparisons: {n_comparisons}\")\n",
    "print(f\"Significance Level (Î±): {ALPHA}\")\n",
    "print(f\"Multiple Testing Correction: Bonferroni (adjusted Î± = {ALPHA/n_comparisons:.4f})\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Perform paired t-tests\n",
    "results = []\n",
    "\n",
    "for name, scores in cv_scores.items():\n",
    "    if name == CONTROL_MODEL:\n",
    "        continue  # Skip comparing with itself\n",
    "    \n",
    "    # Calculate differences (control - other)\n",
    "    diff = control_scores - scores\n",
    "    \n",
    "    # Paired t-test\n",
    "    t_stat, p_val = stats.ttest_rel(control_scores, scores)\n",
    "    \n",
    "    # Cohen's d for paired samples (effect size)\n",
    "    d = diff.mean() / (diff.std(ddof=1) + 1e-12)\n",
    "    \n",
    "    # Bonferroni correction\n",
    "    p_bonf = min(1.0, p_val * n_comparisons)\n",
    "    \n",
    "    # Significance\n",
    "    is_significant = p_bonf < ALPHA\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Control Mean': control_scores.mean(),\n",
    "        'Other Mean': scores.mean(),\n",
    "        'Mean Difference': diff.mean(),\n",
    "        't-statistic': t_stat,\n",
    "        'p-value': p_val,\n",
    "        'p-value (Bonferroni)': p_bonf,\n",
    "        \"Cohen's d\": d,\n",
    "        'Significant (Î±=0.05)': is_significant\n",
    "    })\n",
    "\n",
    "# Create DataFrame and sort by p-value\n",
    "results_df = pd.DataFrame(results).sort_values('p-value (Bonferroni)')\n",
    "\n",
    "print(f\"{'Model':<40} {'Mean Diff':<12} {'t-stat':<10} {'p-value':<12} {'p (Bonf.)':<12} {'Sig?':<8}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    sig_marker = \"âœ“\" if row['Significant (Î±=0.05)'] else \"âœ—\"\n",
    "    print(f\"{row['Model']:<40} {row['Mean Difference']:>11.4f} {row['t-statistic']:>10.3f} \"\n",
    "          f\"{row['p-value']:>11.4f} {row['p-value (Bonferroni)']:>11.4f} {sig_marker:>8}\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.4 Summary and Interpretation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTICAL SIGNIFICANCE TEST SUMMARY\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Control Mean Accuracy: 0.8625 Â± 0.0429\n",
      "\n",
      "Total Comparisons: 12\n",
      "Significance Threshold (Bonferroni-corrected): p < 0.05\n",
      "\n",
      "Results:\n",
      "  âœ“ Significantly Better Than:  1/12 models\n",
      "  âœ— Significantly Worse Than:   0/12 models\n",
      "  â‰ˆ No Significant Difference:  11/12 models\n",
      "\n",
      "Models Significantly Outperformed:\n",
      "  â€¢ Decision Tree (Default)                       (Î” = +0.0939, p = 0.0037)\n",
      "================================================================================\n",
      "\n",
      "DETAILED RESULTS TABLE:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Control Mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Other Mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Mean Difference",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t-statistic",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value (Bonferroni)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cohen's d",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Significant (Î±=0.05)",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "1ba2acae-a3f4-4d42-8c12-7388a3b60120",
       "rows": [
        [
         "1",
         "Decision Tree (Default)",
         "0.8624576271186439",
         "0.7685593220338982",
         "0.09389830508474575",
         "5.668669432886588",
         "0.00030624154060821516",
         "0.003674898487298582",
         "1.7925906710154393",
         "True"
        ],
        [
         "5",
         "AdaBoost (Default)",
         "0.8624576271186439",
         "0.8340395480225989",
         "0.028418079096045178",
         "3.2812412358914407",
         "0.009510400454085912",
         "0.11412480544903095",
         "1.0376195857503925",
         "False"
        ],
        [
         "11",
         "SEL-NNML (QMC)",
         "0.8624576271186439",
         "0.835819209039548",
         "0.026638418079096025",
         "2.1759858253329747",
         "0.05754962918008891",
         "0.6905955501610669",
         "0.6881071364115771",
         "False"
        ],
        [
         "0",
         "Logistic Regression (Default)",
         "0.8624576271186439",
         "0.8424011299435028",
         "0.02005649717514122",
         "2.086811677163499",
         "0.06652643009076048",
         "0.7983171610891258",
         "0.6599077947455515",
         "False"
        ],
        [
         "3",
         "K-Nearest Neighbors (Default)",
         "0.8624576271186439",
         "0.8325141242937854",
         "0.029943502824858737",
         "2.030301997859185",
         "0.07289885465893876",
         "0.8747862559072652",
         "0.6420378651087667",
         "False"
        ],
        [
         "2",
         "Random Forest (Default)",
         "0.8624576271186439",
         "0.8558474576271186",
         "0.006610169491525419",
         "0.6368505603256265",
         "0.5400806932416471",
         "1.0",
         "0.20138982997220867",
         "False"
        ],
        [
         "4",
         "Support Vector Machine (Default)",
         "0.8624576271186439",
         "0.8491242937853107",
         "0.013333333333333308",
         "1.118881399192373",
         "0.29216324914138336",
         "1.0",
         "0.35382136529500874",
         "False"
        ],
        [
         "6",
         "Gradient Boosting (Default)",
         "0.8624576271186439",
         "0.8557062146892654",
         "0.006751412429378512",
         "0.7413416214784982",
         "0.4773836829583413",
         "1.0",
         "0.23443280480730547",
         "False"
        ],
        [
         "7",
         "Stacking + Linear Regression",
         "0.8624576271186439",
         "0.8507062146892655",
         "0.011751412429378504",
         "1.137008193944354",
         "0.2849003958839864",
         "1.0",
         "0.3595535611028615",
         "False"
        ],
        [
         "8",
         "Stacking + Default MLP",
         "0.8624576271186439",
         "0.8507344632768362",
         "0.011723163841807882",
         "1.2462937011709438",
         "0.2441189839062035",
         "1.0",
         "0.3941126729088948",
         "False"
        ],
        [
         "9",
         "SEL-NNML (GP)",
         "0.8624576271186439",
         "0.8590960451977402",
         "0.0033615819209039553",
         "0.4281890061871379",
         "0.6785780372010488",
         "1.0",
         "0.13540525285407445",
         "False"
        ],
        [
         "10",
         "SEL-NNML (CMA-ES)",
         "0.8624576271186439",
         "0.8590960451977402",
         "0.003361581920903933",
         "0.42892391597547963",
         "0.6780624902424037",
         "1.0",
         "0.13563765173464692",
         "False"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Control Mean</th>\n",
       "      <th>Other Mean</th>\n",
       "      <th>Mean Difference</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value (Bonferroni)</th>\n",
       "      <th>Cohen's d</th>\n",
       "      <th>Significant (Î±=0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree (Default)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>5.668669</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>1.792591</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost (Default)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.834040</td>\n",
       "      <td>0.028418</td>\n",
       "      <td>3.281241</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.114125</td>\n",
       "      <td>1.037620</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SEL-NNML (QMC)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.835819</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>2.175986</td>\n",
       "      <td>0.057550</td>\n",
       "      <td>0.690596</td>\n",
       "      <td>0.688107</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Default)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.842401</td>\n",
       "      <td>0.020056</td>\n",
       "      <td>2.086812</td>\n",
       "      <td>0.066526</td>\n",
       "      <td>0.798317</td>\n",
       "      <td>0.659908</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors (Default)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.832514</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>2.030302</td>\n",
       "      <td>0.072899</td>\n",
       "      <td>0.874786</td>\n",
       "      <td>0.642038</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (Default)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.855847</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.636851</td>\n",
       "      <td>0.540081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.201390</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine (Default)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.849124</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>1.118881</td>\n",
       "      <td>0.292163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353821</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting (Default)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.855706</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>0.741342</td>\n",
       "      <td>0.477384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234433</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking + Linear Regression</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.850706</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>1.137008</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359554</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stacking + Default MLP</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.850734</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>1.246294</td>\n",
       "      <td>0.244119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.394113</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEL-NNML (GP)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.859096</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.428189</td>\n",
       "      <td>0.678578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.135405</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SEL-NNML (CMA-ES)</td>\n",
       "      <td>0.862458</td>\n",
       "      <td>0.859096</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.428924</td>\n",
       "      <td>0.678062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.135638</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Control Mean  Other Mean  \\\n",
       "1            Decision Tree (Default)      0.862458    0.768559   \n",
       "5                 AdaBoost (Default)      0.862458    0.834040   \n",
       "11                    SEL-NNML (QMC)      0.862458    0.835819   \n",
       "0      Logistic Regression (Default)      0.862458    0.842401   \n",
       "3      K-Nearest Neighbors (Default)      0.862458    0.832514   \n",
       "2            Random Forest (Default)      0.862458    0.855847   \n",
       "4   Support Vector Machine (Default)      0.862458    0.849124   \n",
       "6        Gradient Boosting (Default)      0.862458    0.855706   \n",
       "7       Stacking + Linear Regression      0.862458    0.850706   \n",
       "8             Stacking + Default MLP      0.862458    0.850734   \n",
       "9                      SEL-NNML (GP)      0.862458    0.859096   \n",
       "10                 SEL-NNML (CMA-ES)      0.862458    0.859096   \n",
       "\n",
       "    Mean Difference  t-statistic   p-value  p-value (Bonferroni)  Cohen's d  \\\n",
       "1          0.093898     5.668669  0.000306              0.003675   1.792591   \n",
       "5          0.028418     3.281241  0.009510              0.114125   1.037620   \n",
       "11         0.026638     2.175986  0.057550              0.690596   0.688107   \n",
       "0          0.020056     2.086812  0.066526              0.798317   0.659908   \n",
       "3          0.029944     2.030302  0.072899              0.874786   0.642038   \n",
       "2          0.006610     0.636851  0.540081              1.000000   0.201390   \n",
       "4          0.013333     1.118881  0.292163              1.000000   0.353821   \n",
       "6          0.006751     0.741342  0.477384              1.000000   0.234433   \n",
       "7          0.011751     1.137008  0.284900              1.000000   0.359554   \n",
       "8          0.011723     1.246294  0.244119              1.000000   0.394113   \n",
       "9          0.003362     0.428189  0.678578              1.000000   0.135405   \n",
       "10         0.003362     0.428924  0.678062              1.000000   0.135638   \n",
       "\n",
       "    Significant (Î±=0.05)  \n",
       "1                   True  \n",
       "5                  False  \n",
       "11                 False  \n",
       "0                  False  \n",
       "3                  False  \n",
       "2                  False  \n",
       "4                  False  \n",
       "6                  False  \n",
       "7                  False  \n",
       "8                  False  \n",
       "9                  False  \n",
       "10                 False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "sig_count = results_df['Significant (Î±=0.05)'].sum()\n",
    "better_count = (results_df['Mean Difference'] > 0).sum()\n",
    "worse_count = (results_df['Mean Difference'] < 0).sum()\n",
    "\n",
    "sig_better = results_df[(results_df['Significant (Î±=0.05)']) & (results_df['Mean Difference'] > 0)]\n",
    "sig_worse = results_df[(results_df['Significant (Î±=0.05)']) & (results_df['Mean Difference'] < 0)]\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL SIGNIFICANCE TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Control Mean Accuracy: {control_scores.mean():.4f} Â± {control_scores.std(ddof=1):.4f}\")\n",
    "print()\n",
    "print(f\"Total Comparisons: {n_comparisons}\")\n",
    "print(f\"Significance Threshold (Bonferroni-corrected): p < {ALPHA}\")\n",
    "print()\n",
    "print(\"Results:\")\n",
    "print(f\"  âœ“ Significantly Better Than:  {len(sig_better)}/{n_comparisons} models\")\n",
    "print(f\"  âœ— Significantly Worse Than:   {len(sig_worse)}/{n_comparisons} models\")\n",
    "print(f\"  â‰ˆ No Significant Difference:  {n_comparisons - sig_count}/{n_comparisons} models\")\n",
    "print()\n",
    "\n",
    "if len(sig_better) > 0:\n",
    "    print(\"Models Significantly Outperformed:\")\n",
    "    for _, row in sig_better.iterrows():\n",
    "        print(f\"  â€¢ {row['Model']:<45} (Î” = +{row['Mean Difference']:.4f}, p = {row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "if len(sig_worse) > 0:\n",
    "    print()\n",
    "    print(\"Models That Significantly Outperformed Control:\")\n",
    "    for _, row in sig_worse.iterrows():\n",
    "        print(f\"  â€¢ {row['Model']:<45} (Î” = {row['Mean Difference']:.4f}, p = {row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Display full results table\n",
    "print(\"DETAILED RESULTS TABLE:\")\n",
    "print(\"=\"*80)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7.5 Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Paired t-test results saved to: ../artifacts/ds1/models\\paired_ttest_results.csv\n",
      "âœ“ Cross-validation scores saved to: ../artifacts/ds1/models\\cv_scores_for_ttest.csv\n",
      "âœ“ Summary statistics saved to: ../artifacts/ds1/models\\ttest_summary.csv\n",
      "\n",
      "================================================================================\n",
      "âœ… STATISTICAL SIGNIFICANCE TESTING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save paired t-test results\n",
    "output_dir = '../artifacts/ds1/models'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save main results\n",
    "results_path = os.path.join(output_dir, 'paired_ttest_results.csv')\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"âœ“ Paired t-test results saved to: {results_path}\")\n",
    "\n",
    "# Save CV scores for reproducibility\n",
    "cv_scores_data = []\n",
    "for model_name, scores in cv_scores.items():\n",
    "    for fold_idx, score in enumerate(scores, 1):\n",
    "        cv_scores_data.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': fold_idx,\n",
    "            'Accuracy': score\n",
    "        })\n",
    "\n",
    "cv_scores_df = pd.DataFrame(cv_scores_data)\n",
    "cv_scores_path = os.path.join(output_dir, 'cv_scores_for_ttest.csv')\n",
    "cv_scores_df.to_csv(cv_scores_path, index=False)\n",
    "print(f\"âœ“ Cross-validation scores saved to: {cv_scores_path}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_data = {\n",
    "    'Control_Model': CONTROL_MODEL,\n",
    "    'Control_Mean_Accuracy': control_scores.mean(),\n",
    "    'Control_Std_Accuracy': control_scores.std(ddof=1),\n",
    "    'Total_Comparisons': n_comparisons,\n",
    "    'Significantly_Better': len(sig_better),\n",
    "    'Significantly_Worse': len(sig_worse),\n",
    "    'No_Significant_Difference': n_comparisons - sig_count,\n",
    "    'Significance_Level': ALPHA,\n",
    "    'CV_Folds': N_FOLDS_TTEST,\n",
    "    'Metric': METRIC\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary_data])\n",
    "summary_path = os.path.join(output_dir, 'ttest_summary.csv')\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"âœ“ Summary statistics saved to: {summary_path}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… STATISTICAL SIGNIFICANCE TESTING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **SECTION 8: McNemar's Test**\n",
    "\n",
    "Perform McNemar's test to compare prediction disagreements between SEL-NNML (TPE) and other models on the test set. This test examines whether models make systematically different errors on specific instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.1 Generate Predictions on Test Set**\n",
    "\n",
    "Generate predictions from all 13 models on the test set for McNemar's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERATING TEST SET PREDICTIONS FOR MCNEMAR'S TEST\n",
      "================================================================================\n",
      "Test set size: 150\n",
      "\n",
      "[1/13] Predicting with Logistic Regression (Default)... Accuracy: 0.8867\n",
      "[2/13] Predicting with Decision Tree (Default)... Accuracy: 0.8600\n",
      "[3/13] Predicting with Random Forest (Default)... Accuracy: 0.8800\n",
      "[4/13] Predicting with K-Nearest Neighbors (Default)... Accuracy: 0.8733\n",
      "[5/13] Predicting with Support Vector Machine (Default)... Accuracy: 0.9067\n",
      "[6/13] Predicting with AdaBoost (Default)... Accuracy: 0.8800\n",
      "[7/13] Predicting with Gradient Boosting (Default)... Accuracy: 0.8867\n",
      "[8/13] Predicting with Stacking + Linear Regression... Accuracy: 0.9000\n",
      "[9/13] Predicting with Stacking + Default MLP... Accuracy: 0.9000\n",
      "[10/13] Predicting with SEL-NNML (TPE)... Accuracy: 0.9400\n",
      "[11/13] Predicting with SEL-NNML (GP)... Accuracy: 0.9200\n",
      "[12/13] Predicting with SEL-NNML (CMA-ES)... Accuracy: 0.9267\n",
      "[13/13] Predicting with SEL-NNML (QMC)... Accuracy: 0.9200\n",
      "\n",
      "================================================================================\n",
      "âœ“ Generated predictions for all 13 models\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from all 13 models on test set\n",
    "test_predictions = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERATING TEST SET PREDICTIONS FOR MCNEMAR'S TEST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test set size: {len(y_test)}\")\n",
    "print()\n",
    "\n",
    "for idx, (name, model) in enumerate(models_for_ttest.items(), 1):\n",
    "    print(f\"[{idx}/13] Predicting with {name}...\", end=\" \", flush=True)\n",
    "    \n",
    "    # All models (baseline and optimized) were trained on the same X_train\n",
    "    # (which has both scaled numeric features and boolean features merged)\n",
    "    # So they all need X_test (not X_test_scaled which only has numeric features)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_predictions[name] = y_pred\n",
    "    accuracy = (y_pred == y_test).sum() / len(y_test)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ“ Generated predictions for all {len(test_predictions)} models\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.2 Perform McNemar's Tests**\n",
    "\n",
    "Compare SEL-NNML (TPE) against all other 12 models using McNemar's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MCNEMAR'S TEST: SEL-NNML (TPE) vs. ALL OTHER MODELS\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Test Set Size: 150\n",
      "Significance Level: Î± = 0.05\n",
      "================================================================================\n",
      "\n",
      "Model                                    b (Câœ“Oâœ—)     c (Câœ—Oâœ“)     Ï‡Â²         p-value      p (Bonf.)    Sig?    \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Random Forest (Default)                            9           0      7.111      0.0077      0.0919        âœ—\n",
      "Decision Tree (Default)                           15           3      6.722      0.0095      0.1143        âœ—\n",
      "Gradient Boosting (Default)                        8           0      6.125      0.0133      0.1599        âœ—\n",
      "AdaBoost (Default)                                10           1      5.818      0.0159      0.1903        âœ—\n",
      "K-Nearest Neighbors (Default)                     13           3      5.062      0.0244      0.2934        âœ—\n",
      "Logistic Regression (Default)                      9           1      4.900      0.0269      0.3223        âœ—\n",
      "Stacking + Linear Regression                       6           0      4.167      0.0412      0.4947        âœ—\n",
      "Stacking + Default MLP                             6           0      4.167      0.0412      0.4947        âœ—\n",
      "Support Vector Machine (Default)                   6           1      2.286      0.1306      1.0000        âœ—\n",
      "SEL-NNML (GP)                                      4           1      0.800      0.3711      1.0000        âœ—\n",
      "SEL-NNML (CMA-ES)                                  3           1      0.250      0.6171      1.0000        âœ—\n",
      "SEL-NNML (QMC)                                     6           3      0.444      0.5050      1.0000        âœ—\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def mcnemar_test(y_true, y_pred_a, y_pred_b):\n",
    "    \"\"\"\n",
    "    Perform McNemar's test for two classifiers.\n",
    "    \n",
    "    Returns:\n",
    "        - contingency table (2x2)\n",
    "        - chi-square statistic\n",
    "        - p-value\n",
    "    \"\"\"\n",
    "    # Create contingency table\n",
    "    # both_correct: both A and B correct\n",
    "    # a_correct_b_wrong: A correct, B wrong\n",
    "    # a_wrong_b_correct: A wrong, B correct\n",
    "    # both_wrong: both A and B wrong\n",
    "    \n",
    "    both_correct = ((y_pred_a == y_true) & (y_pred_b == y_true)).sum()\n",
    "    a_correct_b_wrong = ((y_pred_a == y_true) & (y_pred_b != y_true)).sum()\n",
    "    a_wrong_b_correct = ((y_pred_a != y_true) & (y_pred_b == y_true)).sum()\n",
    "    both_wrong = ((y_pred_a != y_true) & (y_pred_b != y_true)).sum()\n",
    "    \n",
    "    # Contingency table\n",
    "    table = np.array([[both_correct, a_correct_b_wrong],\n",
    "                      [a_wrong_b_correct, both_wrong]])\n",
    "    \n",
    "    # McNemar's test statistic with continuity correction\n",
    "    b = a_correct_b_wrong\n",
    "    c = a_wrong_b_correct\n",
    "    \n",
    "    # Chi-square test statistic (with continuity correction)\n",
    "    if b + c > 0:\n",
    "        chi2_stat = (abs(b - c) - 1)**2 / (b + c)\n",
    "    else:\n",
    "        chi2_stat = 0.0\n",
    "    \n",
    "    # p-value from chi-square distribution (df=1)\n",
    "    p_value = 1 - chi2.cdf(chi2_stat, df=1)\n",
    "    \n",
    "    return table, chi2_stat, p_value, b, c\n",
    "\n",
    "# Control model\n",
    "control_pred = test_predictions[CONTROL_MODEL]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"MCNEMAR'S TEST: {CONTROL_MODEL} vs. ALL OTHER MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Test Set Size: {len(y_test)}\")\n",
    "print(f\"Significance Level: Î± = {ALPHA}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "mcnemar_results = []\n",
    "\n",
    "for name, pred in test_predictions.items():\n",
    "    if name == CONTROL_MODEL:\n",
    "        continue\n",
    "    \n",
    "    table, chi2_stat, p_value, b, c = mcnemar_test(y_test.values, control_pred, pred)\n",
    "    \n",
    "    # Bonferroni correction\n",
    "    p_bonf = min(1.0, p_value * n_comparisons)\n",
    "    is_significant = p_bonf < ALPHA\n",
    "    \n",
    "    mcnemar_results.append({\n",
    "        'Model': name,\n",
    "        'Both Correct': table[0, 0],\n",
    "        'Control Right, Other Wrong': b,\n",
    "        'Control Wrong, Other Right': c,\n",
    "        'Both Wrong': table[1, 1],\n",
    "        'Chi-Square': chi2_stat,\n",
    "        'p-value': p_value,\n",
    "        'p-value (Bonferroni)': p_bonf,\n",
    "        'Significant (Î±=0.05)': is_significant\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "mcnemar_df = pd.DataFrame(mcnemar_results).sort_values('p-value (Bonferroni)')\n",
    "\n",
    "print(f\"{'Model':<40} {'b (Câœ“Oâœ—)':<12} {'c (Câœ—Oâœ“)':<12} {'Ï‡Â²':<10} {'p-value':<12} {'p (Bonf.)':<12} {'Sig?':<8}\")\n",
    "print(\"-\"*110)\n",
    "\n",
    "for _, row in mcnemar_df.iterrows():\n",
    "    sig_marker = \"âœ“\" if row['Significant (Î±=0.05)'] else \"âœ—\"\n",
    "    print(f\"{row['Model']:<40} {row['Control Right, Other Wrong']:>11} {row['Control Wrong, Other Right']:>11} \"\n",
    "          f\"{row['Chi-Square']:>10.3f} {row['p-value']:>11.4f} {row['p-value (Bonferroni)']:>11.4f} {sig_marker:>8}\")\n",
    "\n",
    "print(\"=\"*110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.3 Contingency Table Visualization**\n",
    "\n",
    "Visualize the contingency tables for significant comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš  No significant comparisons found (p < 0.05 after Bonferroni correction)\n",
      "   Contingency table visualization skipped.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get top 5 most significant comparisons (or all if fewer than 5)\n",
    "sig_comparisons = mcnemar_df[mcnemar_df['Significant (Î±=0.05)']].head(5)\n",
    "\n",
    "if len(sig_comparisons) > 0:\n",
    "    n_plots = len(sig_comparisons)\n",
    "    n_cols = min(3, n_plots)\n",
    "    n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_rows > 1 else axes\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sig_comparisons.iterrows()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Create contingency table\n",
    "        table_data = np.array([\n",
    "            [row['Both Correct'], row['Control Right, Other Wrong']],\n",
    "            [row['Control Wrong, Other Right'], row['Both Wrong']]\n",
    "        ])\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sns.heatmap(table_data, annot=True, fmt='d', cmap='Blues', \n",
    "                    cbar=True, ax=ax, annot_kws={'size': 14, 'weight': 'bold'},\n",
    "                    xticklabels=['Other Correct', 'Other Wrong'],\n",
    "                    yticklabels=['Control Correct', 'Control Wrong'])\n",
    "        \n",
    "        ax.set_title(f\"{CONTROL_MODEL} vs. {row['Model']}\\n\"\n",
    "                     f\"Ï‡Â²={row['Chi-Square']:.3f}, p={row['p-value (Bonferroni)']:.4f}\",\n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Other Model', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Control Model', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_plots, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nâœ“ Displayed contingency tables for {len(sig_comparisons)} significant comparison(s)\")\n",
    "else:\n",
    "    print(\"\\nâš  No significant comparisons found (p < 0.05 after Bonferroni correction)\")\n",
    "    print(\"   Contingency table visualization skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.4 Summary and Interpretation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MCNEMAR'S TEST SUMMARY\n",
      "================================================================================\n",
      "Control Model: SEL-NNML (TPE)\n",
      "Test Set Size: 150\n",
      "Total Comparisons: 12\n",
      "Significance Level: Î± = 0.05 (Bonferroni-corrected)\n",
      "\n",
      "Results:\n",
      "  âœ“ Significantly Different From:   0/12 models\n",
      "    - Control Better:                0\n",
      "    - Control Worse:                 0\n",
      "  â‰ˆ No Significant Difference:       12/12 models\n",
      "\n",
      "\n",
      "Interpretation:\n",
      "  - 'b' (Control Right, Other Wrong): Instances where control is correct but other model is wrong\n",
      "  - 'c' (Control Wrong, Other Right): Instances where control is wrong but other model is correct\n",
      "  - If b >> c: Control makes fewer errors â†’ control is better\n",
      "  - If c >> b: Other model makes fewer errors â†’ other model is better\n",
      "  - If b â‰ˆ c: Models make different but equal errors â†’ no significant difference\n",
      "================================================================================\n",
      "\n",
      "DETAILED RESULTS TABLE:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Both Correct",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Control Right, Other Wrong",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Control Wrong, Other Right",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Both Wrong",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Chi-Square",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value (Bonferroni)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Significant (Î±=0.05)",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "e81d7ae0-30fb-4358-bd66-08a8ae6b6958",
       "rows": [
        [
         "2",
         "Random Forest (Default)",
         "132",
         "9",
         "0",
         "9",
         "7.111111111111111",
         "0.007660761135179439",
         "0.09192913362215327",
         "False"
        ],
        [
         "1",
         "Decision Tree (Default)",
         "126",
         "15",
         "3",
         "6",
         "6.722222222222222",
         "0.009521891184098852",
         "0.11426269420918622",
         "False"
        ],
        [
         "6",
         "Gradient Boosting (Default)",
         "133",
         "8",
         "0",
         "9",
         "6.125",
         "0.013328328780817578",
         "0.15993994536981093",
         "False"
        ],
        [
         "5",
         "AdaBoost (Default)",
         "131",
         "10",
         "1",
         "8",
         "5.818181818181818",
         "0.01586133273977297",
         "0.19033599287727565",
         "False"
        ],
        [
         "3",
         "K-Nearest Neighbors (Default)",
         "128",
         "13",
         "3",
         "6",
         "5.0625",
         "0.024448945310089343",
         "0.2933873437210721",
         "False"
        ],
        [
         "0",
         "Logistic Regression (Default)",
         "132",
         "9",
         "1",
         "8",
         "4.9",
         "0.026856695507524453",
         "0.32228034609029343",
         "False"
        ],
        [
         "7",
         "Stacking + Linear Regression",
         "135",
         "6",
         "0",
         "9",
         "4.166666666666667",
         "0.041226833337163815",
         "0.4947220000459658",
         "False"
        ],
        [
         "8",
         "Stacking + Default MLP",
         "135",
         "6",
         "0",
         "9",
         "4.166666666666667",
         "0.041226833337163815",
         "0.4947220000459658",
         "False"
        ],
        [
         "4",
         "Support Vector Machine (Default)",
         "135",
         "6",
         "1",
         "8",
         "2.2857142857142856",
         "0.13057001811573699",
         "1.0",
         "False"
        ],
        [
         "9",
         "SEL-NNML (GP)",
         "137",
         "4",
         "1",
         "8",
         "0.8",
         "0.37109336952269756",
         "1.0",
         "False"
        ],
        [
         "10",
         "SEL-NNML (CMA-ES)",
         "138",
         "3",
         "1",
         "8",
         "0.25",
         "0.6170750774519739",
         "1.0",
         "False"
        ],
        [
         "11",
         "SEL-NNML (QMC)",
         "135",
         "6",
         "3",
         "6",
         "0.4444444444444444",
         "0.5049850750938457",
         "1.0",
         "False"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Both Correct</th>\n",
       "      <th>Control Right, Other Wrong</th>\n",
       "      <th>Control Wrong, Other Right</th>\n",
       "      <th>Both Wrong</th>\n",
       "      <th>Chi-Square</th>\n",
       "      <th>p-value</th>\n",
       "      <th>p-value (Bonferroni)</th>\n",
       "      <th>Significant (Î±=0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (Default)</td>\n",
       "      <td>132</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.111111</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.091929</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree (Default)</td>\n",
       "      <td>126</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6.722222</td>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.114263</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting (Default)</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.159940</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost (Default)</td>\n",
       "      <td>131</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>0.015861</td>\n",
       "      <td>0.190336</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors (Default)</td>\n",
       "      <td>128</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>0.024449</td>\n",
       "      <td>0.293387</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Default)</td>\n",
       "      <td>132</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.026857</td>\n",
       "      <td>0.322280</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking + Linear Regression</td>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.494722</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stacking + Default MLP</td>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.494722</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine (Default)</td>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>0.130570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEL-NNML (GP)</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.371093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SEL-NNML (CMA-ES)</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SEL-NNML (QMC)</td>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.504985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Both Correct  \\\n",
       "2            Random Forest (Default)           132   \n",
       "1            Decision Tree (Default)           126   \n",
       "6        Gradient Boosting (Default)           133   \n",
       "5                 AdaBoost (Default)           131   \n",
       "3      K-Nearest Neighbors (Default)           128   \n",
       "0      Logistic Regression (Default)           132   \n",
       "7       Stacking + Linear Regression           135   \n",
       "8             Stacking + Default MLP           135   \n",
       "4   Support Vector Machine (Default)           135   \n",
       "9                      SEL-NNML (GP)           137   \n",
       "10                 SEL-NNML (CMA-ES)           138   \n",
       "11                    SEL-NNML (QMC)           135   \n",
       "\n",
       "    Control Right, Other Wrong  Control Wrong, Other Right  Both Wrong  \\\n",
       "2                            9                           0           9   \n",
       "1                           15                           3           6   \n",
       "6                            8                           0           9   \n",
       "5                           10                           1           8   \n",
       "3                           13                           3           6   \n",
       "0                            9                           1           8   \n",
       "7                            6                           0           9   \n",
       "8                            6                           0           9   \n",
       "4                            6                           1           8   \n",
       "9                            4                           1           8   \n",
       "10                           3                           1           8   \n",
       "11                           6                           3           6   \n",
       "\n",
       "    Chi-Square   p-value  p-value (Bonferroni)  Significant (Î±=0.05)  \n",
       "2     7.111111  0.007661              0.091929                 False  \n",
       "1     6.722222  0.009522              0.114263                 False  \n",
       "6     6.125000  0.013328              0.159940                 False  \n",
       "5     5.818182  0.015861              0.190336                 False  \n",
       "3     5.062500  0.024449              0.293387                 False  \n",
       "0     4.900000  0.026857              0.322280                 False  \n",
       "7     4.166667  0.041227              0.494722                 False  \n",
       "8     4.166667  0.041227              0.494722                 False  \n",
       "4     2.285714  0.130570              1.000000                 False  \n",
       "9     0.800000  0.371093              1.000000                 False  \n",
       "10    0.250000  0.617075              1.000000                 False  \n",
       "11    0.444444  0.504985              1.000000                 False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "sig_count_mcnemar = mcnemar_df['Significant (Î±=0.05)'].sum()\n",
    "\n",
    "# Models where control is significantly better (b > c and significant)\n",
    "control_better = mcnemar_df[\n",
    "    (mcnemar_df['Significant (Î±=0.05)']) & \n",
    "    (mcnemar_df['Control Right, Other Wrong'] > mcnemar_df['Control Wrong, Other Right'])\n",
    "]\n",
    "\n",
    "# Models where other is significantly better (c > b and significant)\n",
    "control_worse = mcnemar_df[\n",
    "    (mcnemar_df['Significant (Î±=0.05)']) & \n",
    "    (mcnemar_df['Control Wrong, Other Right'] > mcnemar_df['Control Right, Other Wrong'])\n",
    "]\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"MCNEMAR'S TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Control Model: {CONTROL_MODEL}\")\n",
    "print(f\"Test Set Size: {len(y_test)}\")\n",
    "print(f\"Total Comparisons: {n_comparisons}\")\n",
    "print(f\"Significance Level: Î± = {ALPHA} (Bonferroni-corrected)\")\n",
    "print()\n",
    "print(\"Results:\")\n",
    "print(f\"  âœ“ Significantly Different From:   {sig_count_mcnemar}/{n_comparisons} models\")\n",
    "print(f\"    - Control Better:                {len(control_better)}\")\n",
    "print(f\"    - Control Worse:                 {len(control_worse)}\")\n",
    "print(f\"  â‰ˆ No Significant Difference:       {n_comparisons - sig_count_mcnemar}/{n_comparisons} models\")\n",
    "print()\n",
    "\n",
    "if len(control_better) > 0:\n",
    "    print(\"Models Significantly Outperformed by Control:\")\n",
    "    for _, row in control_better.iterrows():\n",
    "        b = row['Control Right, Other Wrong']\n",
    "        c = row['Control Wrong, Other Right']\n",
    "        print(f\"  â€¢ {row['Model']:<45} (b={b}, c={c}, Ï‡Â²={row['Chi-Square']:.3f}, p={row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "if len(control_worse) > 0:\n",
    "    print()\n",
    "    print(\"Models That Significantly Outperformed Control:\")\n",
    "    for _, row in control_worse.iterrows():\n",
    "        b = row['Control Right, Other Wrong']\n",
    "        c = row['Control Wrong, Other Right']\n",
    "        print(f\"  â€¢ {row['Model']:<45} (b={b}, c={c}, Ï‡Â²={row['Chi-Square']:.3f}, p={row['p-value (Bonferroni)']:.4f})\")\n",
    "\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"  - 'b' (Control Right, Other Wrong): Instances where control is correct but other model is wrong\")\n",
    "print(\"  - 'c' (Control Wrong, Other Right): Instances where control is wrong but other model is correct\")\n",
    "print(\"  - If b >> c: Control makes fewer errors â†’ control is better\")\n",
    "print(\"  - If c >> b: Other model makes fewer errors â†’ other model is better\")\n",
    "print(\"  - If b â‰ˆ c: Models make different but equal errors â†’ no significant difference\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Display full results table\n",
    "print(\"DETAILED RESULTS TABLE:\")\n",
    "print(\"=\"*80)\n",
    "display(mcnemar_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8.5 Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ McNemar's test results saved to: ../artifacts/ds1/models\\mcnemar_test_results.csv\n",
      "âœ“ Test predictions saved to: ../artifacts/ds1/models\\test_predictions_for_mcnemar.csv\n",
      "âœ“ McNemar summary statistics saved to: ../artifacts/ds1/models\\mcnemar_summary.csv\n",
      "\n",
      "================================================================================\n",
      "âœ… MCNEMAR'S TEST COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save McNemar's test results\n",
    "mcnemar_results_path = os.path.join(output_dir, 'mcnemar_test_results.csv')\n",
    "mcnemar_df.to_csv(mcnemar_results_path, index=False)\n",
    "print(f\"âœ“ McNemar's test results saved to: {mcnemar_results_path}\")\n",
    "\n",
    "# Save test predictions for reproducibility\n",
    "test_pred_data = []\n",
    "for model_name, predictions in test_predictions.items():\n",
    "    for idx, pred in enumerate(predictions):\n",
    "        test_pred_data.append({\n",
    "            'Model': model_name,\n",
    "            'Instance_Index': idx,\n",
    "            'Prediction': pred,\n",
    "            'True_Label': y_test.iloc[idx]\n",
    "        })\n",
    "\n",
    "test_pred_df = pd.DataFrame(test_pred_data)\n",
    "test_pred_path = os.path.join(output_dir, 'test_predictions_for_mcnemar.csv')\n",
    "test_pred_df.to_csv(test_pred_path, index=False)\n",
    "print(f\"âœ“ Test predictions saved to: {test_pred_path}\")\n",
    "\n",
    "# Save McNemar summary statistics\n",
    "mcnemar_summary = {\n",
    "    'Control_Model': CONTROL_MODEL,\n",
    "    'Test_Set_Size': len(y_test),\n",
    "    'Total_Comparisons': n_comparisons,\n",
    "    'Significant_Differences': sig_count_mcnemar,\n",
    "    'Control_Better': len(control_better),\n",
    "    'Control_Worse': len(control_worse),\n",
    "    'No_Significant_Difference': n_comparisons - sig_count_mcnemar,\n",
    "    'Significance_Level': ALPHA\n",
    "}\n",
    "\n",
    "mcnemar_summary_df = pd.DataFrame([mcnemar_summary])\n",
    "mcnemar_summary_path = os.path.join(output_dir, 'mcnemar_summary.csv')\n",
    "mcnemar_summary_df.to_csv(mcnemar_summary_path, index=False)\n",
    "print(f\"âœ“ McNemar summary statistics saved to: {mcnemar_summary_path}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… MCNEMAR'S TEST COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sel_nnml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
